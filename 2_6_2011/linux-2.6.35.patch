diff -puNrb linux-2.6.35/arch/mips/include/asm/checksum.h linux/arch/mips/include/asm/checksum.h
--- linux-2.6.35/arch/mips/include/asm/checksum.h	2011-04-26 16:27:15.102481641 +0300
+++ linux/arch/mips/include/asm/checksum.h	2011-05-02 10:08:24.592481111 +0300
@@ -14,6 +14,7 @@
 #include <linux/in6.h>
 
 #include <asm/uaccess.h>
+#include <asm/unaligned.h>
 
 /*
  * computes the checksum of a memory block at buff, length len,
@@ -105,23 +106,23 @@ static inline __sum16 ip_fast_csum(const
 	unsigned int csum;
 	int carry;
 
-	csum = word[0];
-	csum += word[1];
-	carry = (csum < word[1]);
+	csum = get_unaligned(word + 0);
+	csum += get_unaligned(word + 1);
+	carry = (csum < get_unaligned(word + 1));
 	csum += carry;
 
-	csum += word[2];
-	carry = (csum < word[2]);
+	csum += get_unaligned(word + 2);
+	carry = (csum < get_unaligned(word + 2));
 	csum += carry;
 
-	csum += word[3];
-	carry = (csum < word[3]);
+	csum += get_unaligned(word + 3);
+	carry = (csum < get_unaligned(word + 3));
 	csum += carry;
 
 	word += 4;
 	do {
-		csum += *word;
-		carry = (csum < *word);
+		csum += get_unaligned(word);
+		carry = (csum < get_unaligned(word));
 		csum += carry;
 		word++;
 	} while (word != stop);
@@ -208,42 +209,90 @@ static __inline__ __sum16 csum_ipv6_magi
 
 	"	addu	%0, %6		# csum\n"
 	"	sltu	$1, %0, %6	\n"
-	"	lw	%1, 0(%2)	# four words source address\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 3(%2)	# four words source address\n"
+	"	lwr	%1, 0(%2)	# four words source address\n"
+#else
+	"	lwl	%1, 0(%2)	# four words source address\n"
+	"	lwr	%1, 3(%2)	# four words source address\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 4(%2)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 7(%2)	\n"
+	"	lwr	%1, 4(%2)	\n"
+#else
+	"	lwl	%1, 4(%2)	\n"
+	"	lwr	%1, 7(%2)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 8(%2)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 11(%2)	\n"
+	"	lwr	%1, 8(%2)	\n"
+#else
+	"	lwl	%1, 8(%2)	\n"
+	"	lwr	%1, 11(%2)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 12(%2)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 15(%2)	\n"
+	"	lwr	%1, 12(%2)	\n"
+#else
+	"	lwl	%1, 12(%2)	\n"
+	"	lwr	%1, 15(%2)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 0(%3)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 3(%3)	\n"
+	"	lwr	%1, 0(%3)	\n"
+#else
+	"	lwl	%1, 0(%3)	\n"
+	"	lwr	%1, 3(%3)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 4(%3)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 7(%3)	\n"
+	"	lwr	%1, 4(%3)	\n"
+#else
+	"	lwl	%1, 4(%3)	\n"
+	"	lwr	%1, 7(%3)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 8(%3)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 11(%3)	\n"
+	"	lwr	%1, 8(%3)	\n"
+#else
+	"	lwl	%1, 8(%3)	\n"
+	"	lwr	%1, 11(%3)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
 
-	"	lw	%1, 12(%3)	\n"
+#ifdef __MIPSEL__
+	"	lwl	%1, 15(%3)	\n"
+	"	lwr	%1, 12(%3)	\n"
+#else
+	"	lwl	%1, 12(%3)	\n"
+	"	lwr	%1, 15(%3)	\n"
+#endif
 	"	addu	%0, $1		\n"
 	"	addu	%0, %1		\n"
 	"	sltu	$1, %0, %1	\n"
diff -puNrb linux-2.6.35/arch/mips/include/asm/fixmap.h linux/arch/mips/include/asm/fixmap.h
--- linux-2.6.35/arch/mips/include/asm/fixmap.h	2011-04-26 16:27:15.122481959 +0300
+++ linux/arch/mips/include/asm/fixmap.h	2011-05-02 10:08:24.602523432 +0300
@@ -73,7 +73,11 @@ enum fixed_addresses {
 #if defined(CONFIG_CPU_TX39XX) || defined(CONFIG_CPU_TX49XX)
 #define FIXADDR_TOP	((unsigned long)(long)(int)(0xff000000 - 0x20000))
 #else
+#ifndef CONFIG_MAPPED_KERNEL
 #define FIXADDR_TOP	((unsigned long)(long)(int)0xfffe0000)
+#else
+#define FIXADDR_TOP	((unsigned long)(long)(int)0xdffe0000)
+#endif
 #endif
 #endif
 #define FIXADDR_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
diff -puNrb linux-2.6.35/arch/mips/include/asm/io.h linux/arch/mips/include/asm/io.h
--- linux-2.6.35/arch/mips/include/asm/io.h	2011-04-26 16:27:15.112522056 +0300
+++ linux/arch/mips/include/asm/io.h	2011-05-02 10:08:24.612790840 +0300
@@ -199,6 +199,7 @@ static inline void __iomem * __ioremap_m
 		if (!size || last_addr < phys_addr)
 			return NULL;
 
+#ifndef CONFIG_MAPPED_KERNEL
 		/*
 		 * Map uncached objects in the low 512MB of address
 		 * space using KSEG1.
@@ -207,6 +208,7 @@ static inline void __iomem * __ioremap_m
 		    flags == _CACHE_UNCACHED)
 			return (void __iomem *)
 				(unsigned long)CKSEG1ADDR(phys_addr);
+#endif
 	}
 
 	return __ioremap(offset, size, flags);
@@ -618,4 +620,53 @@ extern void (*_dma_cache_inv)(unsigned l
  */
 #define xlate_dev_kmem_ptr(p)	p
 
+#ifdef CONFIG_MIPS_MIKROTIK
+
+unsigned rb500_readl(volatile void __iomem *addr);
+unsigned short rb500_readw(volatile void __iomem *addr);
+unsigned char rb500_readb(volatile void __iomem *addr);
+
+void rb500_writel(unsigned int b, volatile void __iomem *addr);
+void rb500_writew(unsigned short b, volatile void __iomem *addr);
+void rb500_writeb(unsigned char b, volatile void __iomem *addr);
+
+#endif
+
+#ifdef CONFIG_SOFT_PCI_IO
+
+unsigned _pci_inb(unsigned long port);
+unsigned _pci_inw(unsigned long port);
+unsigned _pci_inl(unsigned long port);
+void _pci_outb(unsigned char value, unsigned long port);
+void _pci_outw(unsigned short value, unsigned long port);
+void _pci_outl(unsigned value, unsigned long port);
+
+#define inb	_pci_inb
+#define inb_p	_pci_inb
+#define __mem_inb	_pci_inb
+#define __mem_inb_p	_pci_inb
+#define inw	_pci_inw
+#define inw_p	_pci_inw
+#define __mem_inw	_pci_inw
+#define __mem_inw_p	_pci_inw
+#define inl	_pci_inl
+#define inl_p	_pci_inl
+#define __mem_inl	_pci_inl
+#define __mem_inl_p	_pci_inl
+
+#define outb	_pci_outb
+#define outb_p	_pci_outb
+#define __mem_outb	_pci_outb
+#define __mem_outb_p	_pci_outb
+#define outw	_pci_outw
+#define outw_p	_pci_outw
+#define __mem_outw	_pci_outw
+#define __mem_outw_p	_pci_outw
+#define outl	_pci_outl
+#define outl_p	_pci_outl
+#define __mem_outl	_pci_outl
+#define __mem_outl_p	_pci_outl
+
+#endif
+
 #endif /* _ASM_IO_H */
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/irq.h linux/arch/mips/include/asm/mach-rb/irq.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/irq.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/irq.h	2011-05-02 10:08:24.632815648 +0300
@@ -0,0 +1,16 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2003 by Ralf Baechle
+ */
+#ifndef __ASM_MACH_RB_IRQ_H
+#define __ASM_MACH_RBC_IRQ_H
+
+#define I8259A_IRQ_BASE 0
+#define MIPS_CPU_IRQ_BASE 0
+
+#define NR_IRQS	168
+
+#endif /* __ASM_MACH_RB_IRQ_H */
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/kernel-entry-init.h linux/arch/mips/include/asm/mach-rb/kernel-entry-init.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/kernel-entry-init.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/kernel-entry-init.h	2011-05-02 10:08:24.642818614 +0300
@@ -0,0 +1,44 @@
+#ifndef __ASM_MACH_RB_KERNEL_ENTRY_H
+#define __ASM_MACH_RB_KERNEL_ENTRY_H
+
+.macro	kernel_entry_setup
+#ifdef CONFIG_MAPPED_KERNEL
+	.set	push
+	.set	mips32r2
+	/* check whether we are running under 0xc0000000 address space */
+	lui	t0, 0xf000
+	bal	1f
+1:	and	t1, ra, t0
+	li	t0, 0xc0000000
+	beq	t0, t1, 2f
+	/* set up 0xc0000000 address space */
+	mtc0	t0, CP0_ENTRYHI
+	li	t0, 0x1f
+	mtc0	t0, CP0_ENTRYLO0
+	li	t0, 0x0010001f
+	mtc0	t0, CP0_ENTRYLO1
+	li	t0, PM_64M
+	mtc0	t0, CP0_PAGEMASK
+	li	t0, 0
+	mtc0	t0, CP0_INDEX
+	li	t0, 2
+	mtc0	t0, CP0_WIRED
+	ehb
+	tlbwi
+
+	li	t0, 0xc8000000
+	mtc0	t0, CP0_ENTRYHI
+	li	t0, 0x0020001f
+	mtc0	t0, CP0_ENTRYLO0
+	li	t0, 0x0030001f
+	mtc0	t0, CP0_ENTRYLO1
+	li	t0, 1
+	mtc0	t0, CP0_INDEX
+	ehb
+	tlbwi
+2:
+	.set	pop
+#endif
+.endm
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/kmalloc.h linux/arch/mips/include/asm/mach-rb/kmalloc.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/kmalloc.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/kmalloc.h	2011-05-02 10:08:24.652790302 +0300
@@ -0,0 +1,4 @@
+#ifndef __ASM_MACH_RB_KMALLOC_H
+#define __ASM_MACH_RB_KMALLOC_H
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/mangle-port.h linux/arch/mips/include/asm/mach-rb/mangle-port.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/mangle-port.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/mangle-port.h	2011-05-02 10:08:24.662790956 +0300
@@ -0,0 +1,36 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2003, 2004 Ralf Baechle
+ */
+#ifndef __ASM_MACH_GENERIC_MANGLE_PORT_H
+#define __ASM_MACH_GENERIC_MANGLE_PORT_H
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+
+#define __swizzle_addr_b(port)	(port)
+#define __swizzle_addr_w(port)	(port)
+#define __swizzle_addr_l(port)	(port)
+#define __swizzle_addr_q(port)	(port)
+
+#else
+
+#define __swizzle_addr_b(port)  ((port) ^ 3)
+#define __swizzle_addr_w(port)  ((port) ^ 2)
+#define __swizzle_addr_l(port)  (port)
+#define __swizzle_addr_q(port)  (port)
+
+#endif
+
+#define ioswabb(a,x)		(x)
+#define __mem_ioswabb(a,x)	(x)
+#define ioswabw(a,x)		(x)
+#define __mem_ioswabw(a,x)	cpu_to_le16(x)
+#define ioswabl(a,x)		(x)
+#define __mem_ioswabl(a,x)	cpu_to_le32(x)
+#define ioswabq(a,x)		(x)
+#define __mem_ioswabq(a,x)	cpu_to_le32(x)
+
+#endif /* __ASM_MACH_GENERIC_MANGLE_PORT_H */
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/spaces.h linux/arch/mips/include/asm/mach-rb/spaces.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/spaces.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/spaces.h	2011-05-02 10:08:24.672790275 +0300
@@ -0,0 +1,24 @@
+#ifndef _ASM_MACH_RB_SPACES_H
+#define _ASM_MACH_RB_SPACES_H
+
+#include <linux/const.h>
+
+#define PHYS_OFFSET		_AC(0, UL)
+
+#ifdef CONFIG_MAPPED_KERNEL
+#define CAC_BASE		_AC(0xc0000000, UL)
+#else
+#define CAC_BASE		_AC(0x80000000, UL)
+#endif
+#define IO_BASE			_AC(0xa0000000, UL)
+#define UNCAC_BASE		_AC(0xa0000000, UL)
+
+#ifndef MAP_BASE
+#define MAP_BASE		_AC(0xd0000000, UL)
+#endif
+
+#define HIGHMEM_START		_AC(0x20000000, UL)
+
+#define PAGE_OFFSET		(CAC_BASE + PHYS_OFFSET)
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/mach-rb/war.h linux/arch/mips/include/asm/mach-rb/war.h
--- linux-2.6.35/arch/mips/include/asm/mach-rb/war.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/mach-rb/war.h	2011-05-02 10:08:24.692844674 +0300
@@ -0,0 +1,18 @@
+#ifndef __ASM_MIPS_MACH_RB_WAR_H
+#define __ASM_MIPS_MACH_RB_WAR_H
+
+#define R4600_V1_INDEX_ICACHEOP_WAR	0
+#define R4600_V1_HIT_CACHEOP_WAR	0
+#define R4600_V2_HIT_CACHEOP_WAR	0
+#define R5432_CP0_INTERRUPT_WAR		0
+#define BCM1250_M3_WAR			0
+#define SIBYTE_1956_WAR			0
+#define MIPS4K_ICACHE_REFILL_WAR	0
+#define MIPS_CACHE_SYNC_WAR		0
+#define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
+#define ICACHE_REFILLS_WORKAROUND_WAR   0
+#define R10000_LLSC_WAR			0
+#define MIPS34K_MISSED_ITLB_WAR		0
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/module.h linux/arch/mips/include/asm/module.h
--- linux-2.6.35/arch/mips/include/asm/module.h	2011-04-26 16:27:15.102481641 +0300
+++ linux/arch/mips/include/asm/module.h	2011-05-02 10:08:24.702843890 +0300
@@ -9,6 +9,9 @@ struct mod_arch_specific {
 	struct list_head dbe_list;
 	const struct exception_table_entry *dbe_start;
 	const struct exception_table_entry *dbe_end;
+
+	unsigned int core_plt_offset;
+	unsigned int init_plt_offset;
 };
 
 typedef uint8_t Elf64_Byte;		/* Type for a 8-bit quantity.  */
@@ -65,6 +68,8 @@ typedef struct {
 #ifdef CONFIG_MODULES
 /* Given an address, look for it in the exception tables. */
 const struct exception_table_entry*search_module_dbetables(unsigned long addr);
+int module_relayout(Elf32_Ehdr *hdr, Elf32_Shdr *sechdrs,
+		    char *secstrings, unsigned symindex, struct module *me);
 #else
 /* Given an address, look for it in the exception tables. */
 static inline const struct exception_table_entry *
diff -puNrb linux-2.6.35/arch/mips/include/asm/ptrace.h linux/arch/mips/include/asm/ptrace.h
--- linux-2.6.35/arch/mips/include/asm/ptrace.h	2011-04-26 16:27:15.132483071 +0300
+++ linux/arch/mips/include/asm/ptrace.h	2011-05-02 10:08:24.712790438 +0300
@@ -150,6 +150,9 @@ static inline void die_if_kernel(const c
 		die(str, regs);
 }
 
+unsigned long find_prev_frame(unsigned long pc, unsigned long ra,
+			      unsigned long *sp, int usermode);
+
 #endif
 
 #endif /* _ASM_PTRACE_H */
diff -puNrb linux-2.6.35/arch/mips/include/asm/rb/boards.h linux/arch/mips/include/asm/rb/boards.h
--- linux-2.6.35/arch/mips/include/asm/rb/boards.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/rb/boards.h	2011-05-02 10:08:24.722790312 +0300
@@ -0,0 +1,38 @@
+#ifndef _ASM_RB_BOARDS_H
+#define _ASM_RB_BOARDS_H
+
+#define MACH_GROUP_MT_RB500    1	/* Mikrotik RB500 */
+#define MACH_GROUP_MT_RB100    2	/* Mikrotik RB100 */
+#define MACH_GROUP_MT_CR       3	/* Mikrotik CR */
+#define MACH_GROUP_MT_RB400    4
+#define MACH_GROUP_MT_VM       6
+#define MACH_GROUP_MT_RB700    7
+
+
+#define  MACH_MT_RB500		0
+#define  MACH_MT_RB500R5	1
+#define  MACH_MT_RB100		2
+#define  MACH_MT_RB150		3
+#define  MACH_MT_RB133		4
+#define  MACH_MT_RB133C		5
+#define  MACH_MT_MR		6
+#define  MACH_MT_RB192		7
+#define  MACH_MT_CR1		8
+#define  MACH_MT_RB411		10
+#define  MACH_MT_RB433		11
+#define  MACH_MT_RB433U		12	/* RB433 + USB */
+#define  MACH_MT_RB450		13
+#define  MACH_MT_RB493		15
+#define  MACH_MT_RB450G		16
+#define  MACH_MT_RB411U		17
+#define  MACH_MT_RB493G		18
+#define  MACH_MT_RB750G		19
+#define  MACH_MT_RB750		23
+#define  MACH_MT_RB711		24
+#define  MACH_MT_RB_SXT5D	26
+#define  MACH_MT_RB_GROOVE	27
+#define  MACH_MT_RB711R3	29
+
+extern unsigned long mips_machgroup;
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/rb/cr.h linux/arch/mips/include/asm/rb/cr.h
--- linux-2.6.35/arch/mips/include/asm/rb/cr.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/rb/cr.h	2011-05-02 10:08:24.732791166 +0300
@@ -0,0 +1,52 @@
+#ifndef MT_CR_H
+#define MT_CR_H
+
+#define CR_MISC_IRQ		2
+#define CR_WMAC_IRQ		3
+#define CR_ETH_IRQ		4
+#define CR_LBUS_IRQ		5
+#define CR_WMAC_POLL_IRQ	6
+#define CR_CLOCK_IRQ		7
+
+#define CR_MISC_IRQ_BASE	8
+#define CR_UART_IRQ		8
+#define CR_SPI_IRQ		10
+#define CR_AHB_IRQ		11
+#define CR_APB_IRQ		12
+#define CR_TIMER_IRQ		13
+#define CR_GPIO_IRQ		14
+#define CR_WATCHDOG_IRQ		15
+
+#define CR_GPIO_NANDRDY	(1 << 0)
+#define CR_GPIO_NCE	(1 << 1)
+#define CR_GPIO_WLED	(1 << 2)
+#define CR_GPIO_BEEP	(1 << 3)
+#define CR_GPIO_CRST	(1 << 5)
+#define CR_GPIO_SRST	(1 << 6)
+#define CR_GPIO_ULED	(1 << 7)
+#define CR_GPIO_WDI	(1 << 8)
+#define CR_GPIO_SCON	(1 << 12)
+#define CR_GPIO_SIN	(1 << 13)
+
+#define CR_LB_ADDR_CLE	((1 << 0) * 4)
+#define CR_LB_ADDR_ALE	((1 << 1) * 4)
+
+#define CR_WLAN_BASE		0x10000000
+#define CR_PCI_BASE		0x10100000
+#define CR_LB_BASE		0x10400000
+#define   CR_LB_PIO		   0x20000
+#define CR_ETHER_BASE		0x10500000
+#define CR_CNTRL_BASE		0x11000000
+#define   CR_CNTRL_GPIO_IN	    0x0088
+#define   CR_CNTRL_GPIO_OUT	    0x0090
+#define   CR_CNTRL_GPIO_DIR	    0x0098
+#define CR_UART_BASE		0x11100000
+
+#define CR_CNTRL_REG(reg) \
+	(*((volatile unsigned *) KSEG1ADDR(CR_CNTRL_BASE + (reg))))
+
+#define CR_GPIN()	CR_CNTRL_REG(CR_CNTRL_GPIO_IN)
+#define CR_GPOUT()	CR_CNTRL_REG(CR_CNTRL_GPIO_OUT)
+#define CR_GPDIR()	CR_CNTRL_REG(CR_CNTRL_GPIO_DIR)
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/rb/rb100.h linux/arch/mips/include/asm/rb/rb100.h
--- linux-2.6.35/arch/mips/include/asm/rb/rb100.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/rb/rb100.h	2011-05-02 10:08:24.752900532 +0300
@@ -0,0 +1,35 @@
+#ifndef MT_RB100_H
+#define MT_RB100_H
+
+#define MR_PORT_USER_LED	0
+#define MR_PORT_NAND_CLE	2
+#define MR_PORT_NAND_ALE	3
+
+#define	MR_GPIO_NAND_RDY	(1 << 0)
+#define	MR_GPIO_NAND_NCE	(1 << 1)
+
+#define RB112_GPIO_ULED		(1 << 3)
+#define RB100_GPIO_ULED		(1 << 5)
+#define RB100_GPIO_BEEP		(1 << 6)
+
+#define RB100_SWITCH_BASE	0x12000000
+#define   RB100_SWITCH_GPIO_CONF0   0x00b8
+
+#define RB100_SWITCH_REG(reg) \
+	(*((volatile unsigned *) KSEG1ADDR(RB100_SWITCH_BASE + (reg))))
+
+#define RB100_GPIO()	RB100_SWITCH_REG(RB100_SWITCH_GPIO_CONF0)
+#define RB100_GPIN(x)	((x) << 8)
+#define RB100_GPDIR(x)	((x) << 16)
+#define RB100_GPOUT(x)	((x) << 24)
+
+static inline void rb100_set_port_led2(unsigned num, int on) {
+	unsigned reg = 0x100 + 4 * num;
+	unsigned val = RB100_SWITCH_REG(reg);
+	val &= ~0xf00;
+	val |= (on ? 0x200 : 0x300);
+	RB100_SWITCH_REG(reg) = val;
+	RB100_SWITCH_REG(reg);		// flush write (required for nand)
+}
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/rb/rb400.h linux/arch/mips/include/asm/rb/rb400.h
--- linux-2.6.35/arch/mips/include/asm/rb/rb400.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/rb/rb400.h	2011-05-02 10:08:24.762902444 +0300
@@ -0,0 +1,73 @@
+#ifndef MT_RB400_H
+#define MT_RB400_H
+
+#define IRQ_BASE 16
+#define PCI_IRQ_BASE 48
+
+static inline unsigned rb400_readl(unsigned addr) {
+    return *(volatile unsigned *) addr;
+}
+
+static inline void rb400_writel(unsigned val, unsigned addr) {
+    *(volatile unsigned *) addr = val;
+}
+
+/* SPI commands processed by CPLD */
+#define SPI_CMD_WRITE_NAND	0x08	/* send cmd, n x send data, read idle */
+#define SPI_CMD_READ_NAND	0x0a	/* send cmd, send idle, n x read data */
+#define SPI_CMD_WRITE_CFG	0x09	/* send cmd, n x send cfg */
+#define SPI_CMD_READ_FAST	0x0b	/* send cmd, 3 x addr, */
+					/*	     send idle, n x read data */
+#define   SPI_READ_NAND_OFS	    0x800000
+#define SPI_CMD_LED5_ON		0x0c	/* send cmd */
+#define SPI_CMD_LED5_OFF	0x0d	/* send cmd */
+#define SPI_CMD_SDPWR_ON	0x0e	/* send cmd */
+#define SPI_CMD_SDPWR_OFF	0x0f	/* send cmd */
+#define SPI_CMD_MON_VOLTAGE	0x11	/* send cmd */
+#define SPI_CMD_MON_TEMP	0x12	/* send cmd */
+#define SPI_CMD_READ_VOLTS	0x1a	/* send cmd, 3 x read data (LSB 1st) */
+
+struct spi_message;
+struct spi_device;
+
+extern struct spi_device *rb400_spi_get(void);
+extern int rb400_spi_sync(struct spi_message *message);
+
+extern int rb400_spiflash_read_verify(unsigned addr,
+				      uint8_t *rdata, const uint8_t *vdata,
+				      unsigned cnt);
+
+#define CFG_BIT_nCE	0x80
+#define CFG_BIT_CLE	0x40
+#define CFG_BIT_ALE	0x20
+#define CFG_BIT_FAN	0x10
+#define CFG_BIT_nLED4	0x08
+#define CFG_BIT_nLED3	0x04
+#define CFG_BIT_nLED2	0x02
+#define CFG_BIT_nLED1	0x01
+#define CFG_BIT_nLED5  0x100
+
+extern void rb400_change_cfg(unsigned off, unsigned on);
+
+
+#define GPO_RB700_LATCH_EN	(1 << 0)
+#define GPO_RB700_nPLED		(1 << 1)
+#define GPO_RB700_MON_SEL	(1 << 9)
+#define GPO_RB700_NOLATCH_nULED	(1 << 11)
+#define GPO_RB700_nULED		(1 << 12)
+#define GPO_RB700_USB_nPWROFF	(1 << 13)
+#define GPO_RB700_nLINK0	(1 << 13)
+#define GPO_RB700_nLINK1	(1 << 14)
+#define GPO_RB700_nLINK2	(1 << 15)
+#define GPO_RB700_nLINK3	(1 << 16)
+#define GPO_RB700_nLINK4	(1 << 17)
+
+extern int rb700_change_gpo(unsigned off, unsigned on);
+extern void rb700_beepled(int on);
+
+int is_ar7240(void);
+
+unsigned register_wifi_gpo(void *obj,
+			   void (*set_gpo)(void *, unsigned, unsigned));
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/rb/rb500.h linux/arch/mips/include/asm/rb/rb500.h
--- linux-2.6.35/arch/mips/include/asm/rb/rb500.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/rb/rb500.h	2011-05-02 10:08:24.771260820 +0300
@@ -0,0 +1,23 @@
+#ifndef MT_RB500_H
+#define MT_RB500_H
+
+#define RB500_GPIO_NUM_NANDRDY	8
+#define RB500_GPIO_NUM_CFRDY	13
+
+#define RB500_GPIO_NANDRDY	(1 << RB500_GPIO_NUM_NANDRDY)
+#define RB500_GPIO_CFRDY	(1 << RB500_GPIO_NUM_CFRDY)
+
+/* latch U5 bits, depends on revision */
+#define RB500_LO_WPX	(1 << 0)
+#define RB500_LO_NCE	(1 << 0)	// rev5 only
+#define RB500_LO_ALE	(1 << 1)
+#define RB500_LO_CLE	(1 << 2)
+#define RB500_LO_BEEP	(1 << 3)	// rev5 only
+#define RB500_LO_FOFF	(1 << 5)
+#define RB500_LO_SPICS	(1 << 6)
+#define RB500_LO_ULED	(1 << 7)
+
+extern void changeLatchU5(unsigned char orMask, unsigned char nandMask);
+extern void rb500_beep(unsigned freq);
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/include/asm/string.h linux/arch/mips/include/asm/string.h
--- linux-2.6.35/arch/mips/include/asm/string.h	2011-04-26 16:27:15.112522056 +0300
+++ linux/arch/mips/include/asm/string.h	2011-05-02 10:08:24.782847313 +0300
@@ -108,8 +108,9 @@ strncmp(__const__ char *__cs, __const__ 
 	__asm__ __volatile__(
 	".set\tnoreorder\n\t"
 	".set\tnoat\n"
-	"1:\tlbu\t%3,(%0)\n\t"
-	"beqz\t%2,2f\n\t"
+	"1:\tbeqz\t%2,2f\n\t"
+	"nop\n\t"
+	"lbu\t%3,(%0)\n\t"
 	"lbu\t$1,(%1)\n\t"
 	"subu\t%2,1\n\t"
 	"bne\t$1,%3,3f\n\t"
diff -puNrb linux-2.6.35/arch/mips/include/asm/vm.h linux/arch/mips/include/asm/vm.h
--- linux-2.6.35/arch/mips/include/asm/vm.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/include/asm/vm.h	2011-05-02 10:08:24.792790139 +0300
@@ -0,0 +1,43 @@
+#ifndef MT_VM_H
+#define MT_VM_H
+
+#define VIRQ_BASE	64
+
+#define hypercall(name, nr, ...)		\
+	asm(					\
+		".global " #name ";"		\
+		".align 2;"			\
+		".set	push;"			\
+		".set	noreorder;"		\
+		".type " #name ",@function;"	\
+		".ent " #name ",0;"		\
+		#name ": .frame $sp,0,$ra;"	\
+		"li $3, " #nr ";"		\
+		"li $2, -22;"			\
+		"mtc0 $0, $1;"			\
+		"jr $ra;"			\
+		"nop;"				\
+		".end " #name ";"		\
+		".size " #name ",.-" #name ";"	\
+		".set	pop"			\
+        );					\
+	asmlinkage extern int name(__VA_ARGS__);
+
+/* NOTE: do not allow vdma_descr to span multiple pages, so align it */
+struct vdma_descr {
+	unsigned addr;
+	unsigned size;
+	unsigned next;
+} __attribute__((aligned(16)));
+
+#define DONE		0x80000000
+
+static inline unsigned get_virq_nr(unsigned hwirq)
+{
+	return VIRQ_BASE + hwirq;
+}
+
+extern int vm_running(void);
+#define hc_yield() asm volatile ("wait")
+
+#endif
diff -puNrb linux-2.6.35/arch/mips/Kconfig linux/arch/mips/Kconfig
--- linux-2.6.35/arch/mips/Kconfig	2011-04-26 16:27:15.962477571 +0300
+++ linux/arch/mips/Kconfig	2011-05-02 10:08:24.812903534 +0300
@@ -616,6 +616,22 @@ config MIKROTIK_RB532
 	  Support the Mikrotik(tm) RouterBoard 532 series,
 	  based on the IDT RC32434 SoC.
 
+config MIPS_MIKROTIK
+	bool "Support for Mikrotik RB boards"
+	select CEVT_R4K
+	select CSRC_R4K
+	select DMA_NONCOHERENT
+	select HW_HAS_PCI
+	select IRQ_CPU
+	select SYS_HAS_CPU_MIPS32_R1
+	select SYS_HAS_CPU_MIPS32_R2
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_32BIT_KERNEL
+	select ZONE_DMA
+	help
+	  Say Y here to support all Mikrotik mips based routerboards
+
 config WR_PPMC
 	bool "Wind River PPMC board"
 	select CEVT_R4K
@@ -683,6 +699,14 @@ config CAVIUM_OCTEON_REFERENCE_BOARD
 
 endchoice
 
+config SOFT_PCI_IO
+	bool "PCI IO software emulation on RB4xx"
+	depends on MIPS_MIKROTIK
+
+config MAPPED_KERNEL
+	bool "Mapped kernel support"
+	depends on MIPS_MIKROTIK
+
 source "arch/mips/alchemy/Kconfig"
 source "arch/mips/bcm63xx/Kconfig"
 source "arch/mips/jazz/Kconfig"
@@ -1029,6 +1053,7 @@ config MIPS_L1_CACHE_SHIFT
 	default "4" if MACH_DECSTATION || MIKROTIK_RB532 || PMC_MSP4200_EVAL
 	default "6" if MIPS_CPU_SCACHE
 	default "7" if SGI_IP22 || SGI_IP27 || SGI_IP28 || SNI_RM || CPU_CAVIUM_OCTEON
+	default "4" if MIPS_MIKROTIK
 	default "5"
 
 config HAVE_STD_PC_SERIAL_PORT
@@ -1088,7 +1113,7 @@ config CPU_LOONGSON2F
 config CPU_MIPS32_R1
 	bool "MIPS32 Release 1"
 	depends on SYS_HAS_CPU_MIPS32_R1
-	select CPU_HAS_PREFETCH
+#	select CPU_HAS_PREFETCH
 	select CPU_SUPPORTS_32BIT_KERNEL
 	select CPU_SUPPORTS_HIGHMEM
 	help
@@ -1105,7 +1130,7 @@ config CPU_MIPS32_R1
 config CPU_MIPS32_R2
 	bool "MIPS32 Release 2"
 	depends on SYS_HAS_CPU_MIPS32_R2
-	select CPU_HAS_PREFETCH
+#	select CPU_HAS_PREFETCH
 	select CPU_SUPPORTS_32BIT_KERNEL
 	select CPU_SUPPORTS_HIGHMEM
 	help
diff -puNrb linux-2.6.35/arch/mips/kernel/backtrace.c linux/arch/mips/kernel/backtrace.c
--- linux-2.6.35/arch/mips/kernel/backtrace.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/kernel/backtrace.c	2011-05-02 10:08:24.822790335 +0300
@@ -0,0 +1,156 @@
+#include <linux/module.h>
+#include <linux/oprofile.h>
+#include <linux/mm.h>
+#include <asm/page.h>
+#include <asm/processor.h>
+#include <asm/uaccess.h>
+
+#define INSTR_JR_RA	0x03e00008
+#define INSTR_JRHB_RA	0x03e00408
+#define INSTR_ADDIU_SP	0x241d0000
+#define INSTR_SW_RA_SP	0xafbf0000
+#define INSTR_MOVE_RA_ZERO	0x0000f821
+#define REGS_MASK	0x03e00000
+#define IMM16_MASK	0x0000ffff
+
+#define REG_SP		29
+#define TO_REGS(x)	((x) << 21)
+
+static inline int fetch_u32(void *val, void *ptr, int usermode)
+{
+	if (((unsigned) ptr & 3) != 0)
+		return -EFAULT;
+
+	if (usermode)
+		return get_user(*(unsigned *) val, (unsigned *) ptr);
+
+	if (KSEGX(ptr) == KSEG3)
+		return __get_user(*(unsigned *) val, (unsigned *) ptr);
+
+	if (KSEGX(ptr) != KSEG0 && KSEGX(ptr) != KSEG2)
+		return -EFAULT;
+
+	if ((unsigned long) ptr < PAGE_OFFSET)
+		return -EFAULT;
+	if ((unsigned long) ptr  > (unsigned long) high_memory)
+		return -EFAULT;
+
+	return __get_user(*(unsigned *) val, (unsigned *) ptr);
+}
+
+static inline int is_bcond(unsigned i)
+{
+    unsigned c = (i >> 26) & 7;
+    switch (i >> 29) {
+    case 0:
+	if (c == 1)
+	    return (i & (1 << 19)) == 0;
+	/* fall trough */
+    case 2:
+	return c >= 4;
+    }
+    return 0;
+}
+
+static inline unsigned *find_prev_branch(unsigned *instr, unsigned *limit,
+					 int usermode)
+{
+    unsigned i = 0;
+    unsigned *target = instr;
+
+    for (--instr; instr > limit; --instr) {
+	if (fetch_u32(&i, instr, usermode))
+	    return 0;
+
+	if (is_bcond(i)) {
+	    if (instr + 1 + (short) i == target) {
+		return instr;
+	    }
+	} else if ((i & ~(IMM16_MASK | REGS_MASK)) == INSTR_ADDIU_SP) {
+	    if ((i & REGS_MASK) != TO_REGS(REG_SP)) {
+		/* not simple sp adjustment, probably switching stack here */
+		return 0;
+	    }
+	    /* check if frame start has been hit */
+	    if ((short) (i & IMM16_MASK) < 0) {
+		return 0;
+	    }
+	}
+    }
+    return 0;
+}
+
+unsigned long find_prev_frame(unsigned long pc, unsigned long ra,
+			      unsigned long *sp, int usermode)
+{
+    int storedRA = -1;
+    int frameSize = 0;
+    unsigned *instr;
+    unsigned *limit = (unsigned *) (pc - 4096);
+    unsigned i = 0;
+    int imm;
+
+    if (!fetch_u32(&i, (unsigned *) pc, usermode)) {
+	if ((i & ~(IMM16_MASK | REGS_MASK)) == INSTR_ADDIU_SP
+	    && (short) (i & IMM16_MASK) < 0) {
+	    /* we are at the beging of function, reserving stack */
+	    return ra;
+	}
+    }
+
+    for (instr = (unsigned *) pc - 1; instr > limit; --instr) {
+	if (fetch_u32(&i, instr, usermode))
+	    break;
+
+	if (i == INSTR_JR_RA || i == INSTR_JRHB_RA) {
+	    /* found prev func end */
+	    break;
+	} else if ((i & ~IMM16_MASK) == INSTR_SW_RA_SP) {
+	    /* remember where previous RA was stored */
+	    storedRA = (short) (i & IMM16_MASK);
+	} else if ((i & ~(IMM16_MASK | REGS_MASK)) == INSTR_ADDIU_SP) {
+	    if ((i & REGS_MASK) != TO_REGS(REG_SP)) {
+		/* not simple sp adjustment, probably switching stack here */
+		return 0;
+	    }
+
+	    imm = (short) (i & IMM16_MASK);
+	    if (imm >= 0) {
+		/* found prev func end (poping back stack frame),
+		   or end of our own func in other of it's threads (chunks) */
+		if (storedRA != -1)
+		    break;
+
+		instr = find_prev_branch(instr + 1, limit, usermode);
+		if (instr == 0) {
+		    /* no branch to us was found,
+		       it means we are at the begining of the frame */
+		    break;
+		}
+	    } else {
+		frameSize = -imm;
+		break;
+	    }
+	} else if (i == INSTR_MOVE_RA_ZERO) {
+	    /* we have come to the end of the world,
+	       __start() func sets up RA wrongly */
+	    return 0;
+	}
+    }
+
+    if (frameSize > 0) {
+	/* if we hit addiu sp,-X first, we have stack frame */
+
+	if (storedRA != -1) {
+	    if (fetch_u32(&ra, (char *) *sp + storedRA, usermode))
+		return 0;
+	    if (ra == 0)
+		return 0;
+	}
+	*sp += frameSize;
+	return ra;
+    }
+    return ra;
+}
+
+EXPORT_SYMBOL(find_prev_frame);
diff -puNrb linux-2.6.35/arch/mips/kernel/cevt-r4k.c linux/arch/mips/kernel/cevt-r4k.c
--- linux-2.6.35/arch/mips/kernel/cevt-r4k.c	2011-04-26 16:27:12.652476994 +0300
+++ linux/arch/mips/kernel/cevt-r4k.c	2011-05-02 10:08:24.832791075 +0300
@@ -108,12 +108,14 @@ static int c0_compare_int_pending(void)
  * works better in configurations with high CPU/bus clock ratios.
  */
 
+#define compare_delay() do { _ehb(); _ssnop(); _ssnop(); _ssnop(); } while (0)
+
 #define compare_change_hazard() \
 	do { \
-		irq_disable_hazard(); \
-		irq_disable_hazard(); \
-		irq_disable_hazard(); \
-		irq_disable_hazard(); \
+		compare_delay(); \
+		compare_delay(); \
+		compare_delay(); \
+		compare_delay(); \
 	} while (0)
 
 int c0_compare_int_usable(void)
diff -puNrb linux-2.6.35/arch/mips/kernel/Makefile linux/arch/mips/kernel/Makefile
--- linux-2.6.35/arch/mips/kernel/Makefile	2011-04-26 16:27:12.652476994 +0300
+++ linux/arch/mips/kernel/Makefile	2011-05-02 10:08:24.852900544 +0300
@@ -5,7 +5,7 @@
 extra-y		:= head.o init_task.o vmlinux.lds
 
 obj-y		+= cpu-probe.o branch.o entry.o genex.o irq.o process.o \
-		   ptrace.o reset.o setup.o signal.o syscall.o \
+		   ptrace.o reset.o setup.o signal.o syscall.o backtrace.o \
 		   time.o topology.o traps.o unaligned.o watch.o vdso.o
 
 ifdef CONFIG_FUNCTION_TRACER
diff -puNrb linux-2.6.35/arch/mips/kernel/module.c linux/arch/mips/kernel/module.c
--- linux-2.6.35/arch/mips/kernel/module.c	2011-04-26 16:27:12.652476994 +0300
+++ linux/arch/mips/kernel/module.c	2011-05-02 10:08:24.862790904 +0300
@@ -30,6 +30,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/spinlock.h>
+#include <linux/mm.h>
 #include <asm/pgtable.h>	/* MODULE_START */
 
 struct mips_hi16 {
@@ -43,6 +44,41 @@ static struct mips_hi16 *mips_hi16_list;
 static LIST_HEAD(dbe_list);
 static DEFINE_SPINLOCK(dbe_lock);
 
+static void *alloc_phys(unsigned long size)
+{
+	unsigned order;
+	struct page *page;
+	struct page *p;
+
+	size = PAGE_ALIGN(size);
+	order = get_order(size);
+
+	page = alloc_pages(
+		GFP_KERNEL | __GFP_NORETRY | __GFP_NOWARN | __GFP_THISNODE,
+		order);
+	if (!page)
+		return 0;
+
+	split_page(page, order);
+
+	for (p = page + (size >> PAGE_SHIFT); p < page + (1 << order); ++p)
+		__free_page(p);
+
+	return page_address(page);
+}
+
+static void free_phys(void *ptr, unsigned long size)
+{
+	struct page *page;
+	struct page *end;
+
+	page = virt_to_page(ptr);
+	end = page + (PAGE_ALIGN(size) >> PAGE_SHIFT);
+
+	for (; page < end; ++page)
+		__free_pages(page, 0);
+}
+
 void *module_alloc(unsigned long size)
 {
 #ifdef MODULE_START
@@ -58,15 +94,56 @@ void *module_alloc(unsigned long size)
 
 	return __vmalloc_area(area, GFP_KERNEL, PAGE_KERNEL);
 #else
+	unsigned addr;
+	void *ptr;
+
+	size = PAGE_ALIGN(size);
 	if (size == 0)
 		return NULL;
-	return vmalloc(size);
+
+	ptr = alloc_phys(size);
+	if (ptr)
+		return ptr;
+
+	/* try to allocate contiguos chunk of memory not spanning 256Mb
+	   range, so all jump instructions can work */
+	addr = VMALLOC_START;
+	while (addr < VMALLOC_END) {
+		unsigned end = ALIGN(addr + 1, 1u << 28);
+
+		if (addr + size <= end) {
+			struct vm_struct *area
+				= __get_vm_area(size, VM_ALLOC, addr, end);
+
+			if (area)
+				return __vmalloc_area(
+					area, GFP_KERNEL, PAGE_KERNEL);
+		}
+		addr = end;
+	}
+	return NULL;
 #endif
 }
 
+static inline int is_phys(void *ptr)
+{
+	unsigned addr = (unsigned) ptr;
+	return addr && (addr < VMALLOC_START || addr > VMALLOC_END);
+}
+
 /* Free memory returned from module_alloc */
 void module_free(struct module *mod, void *module_region)
 {
+	if (is_phys(module_region)) {
+		if (mod->module_init == module_region)
+			free_phys(module_region, mod->init_size);
+		else if (mod->module_core == module_region)
+			free_phys(module_region, mod->core_size);
+		else
+		    BUG();
+		return;
+	}
+
 	vfree(module_region);
 }
 
@@ -76,6 +153,102 @@ int module_frob_arch_sections(Elf_Ehdr *
 	return 0;
 }
 
+/* Get the potential trampolines size required of the init and
+   non-init sections */
+static unsigned get_plt_size(const Elf32_Ehdr *hdr,
+			     const Elf32_Shdr *sechdrs,
+			     const char *secstrings,
+			     unsigned symindex,
+			     int is_init)
+{
+	unsigned long ret = 0;
+	unsigned i, j;
+	Elf_Sym *syms;
+
+	/* Everything marked ALLOC (this includes the exported symbols) */
+	for (i = 1; i < hdr->e_shnum; ++i) {
+		unsigned int info = sechdrs[i].sh_info;
+
+		if (sechdrs[i].sh_type != SHT_REL
+		    && sechdrs[i].sh_type != SHT_RELA)
+			continue;
+
+		/* Not a valid relocation section? */
+		if (info >= hdr->e_shnum)
+			continue;
+
+		/* Don't bother with non-allocated sections */
+		if (!(sechdrs[info].sh_flags & SHF_ALLOC))
+			continue;
+
+		/* If it's called *.init*, and we're not init, we're
+                   not interested */
+		if ((strstr(secstrings + sechdrs[i].sh_name, ".init") != 0)
+		    != is_init)
+			continue;
+
+		syms = (Elf_Sym *) sechdrs[symindex].sh_addr;
+		if (sechdrs[i].sh_type == SHT_REL) {
+			Elf_Mips_Rel *rel = (void *) sechdrs[i].sh_addr;
+			unsigned size = sechdrs[i].sh_size / sizeof(*rel);
+
+			for (j = 0; j < size; ++j) {
+				Elf_Sym *sym;
+
+				if (ELF_MIPS_R_TYPE(rel[j]) != R_MIPS_26)
+					continue;
+				sym = syms + ELF_MIPS_R_SYM(rel[j]);
+				if (!is_init && sym->st_shndx != SHN_UNDEF)
+					continue;
+
+				ret += sizeof(unsigned[4]);
+			}
+		} else {
+			Elf_Mips_Rela *rela = (void *) sechdrs[i].sh_addr;
+			unsigned size = sechdrs[i].sh_size / sizeof(*rela);
+
+			for (j = 0; j < size; ++j) {
+				Elf_Sym *sym;
+
+				if (ELF_MIPS_R_TYPE(rela[j]) != R_MIPS_26)
+					continue;
+				sym = syms + ELF_MIPS_R_SYM(rela[j]);
+				if (!is_init && sym->st_shndx != SHN_UNDEF)
+					continue;
+
+				ret += sizeof(unsigned[4]);
+			}
+		}
+
+	}
+
+	return ret;
+}
+
+int module_relayout(Elf32_Ehdr *hdr,
+		    Elf32_Shdr *sechdrs,
+		    char *secstrings,
+		    unsigned symindex,
+		    struct module *me)
+{
+	unsigned core_plt_size = get_plt_size(
+	    hdr, sechdrs, secstrings, symindex, 0);
+	unsigned init_plt_size = get_plt_size(
+	    hdr, sechdrs, secstrings, symindex, 1);
+
+	if (core_plt_size > 0)
+		me->core_size = PAGE_ALIGN(me->core_size);
+	me->arch.core_plt_offset = me->core_size;
+	me->core_size += core_plt_size;
+
+	if (init_plt_size > 0)
+		me->init_size = ALIGN(me->init_size, 4);
+	me->arch.init_plt_offset = me->init_size;
+	me->init_size += init_plt_size;
+
+	return 0;
+}
+
 static int apply_r_mips_none(struct module *me, u32 *location, Elf_Addr v)
 {
 	return 0;
@@ -95,6 +268,42 @@ static int apply_r_mips_32_rela(struct m
 	return 0;
 }
 
+static Elf_Addr add_plt_entry_to(unsigned *plt_offset,
+				 void *start, unsigned size, Elf_Addr v)
+{
+	unsigned *tramp = start + *plt_offset;
+	if (*plt_offset == size) return 0;
+
+	*plt_offset += sizeof(unsigned[4]);
+
+	/* adjust carry for addiu */
+	if (v & 0x00008000) 
+		v += 0x10000;
+	
+	tramp[0] = 0x3c190000 | (v >> 16);	/* lui t9, hi16 */
+	tramp[1] = 0x27390000 | (v & 0xffff);	/* addiu t9, t9, lo16 */
+	tramp[2] = 0x03200008;			/* jr t9 */
+	tramp[3] = 0x00000000;			/* nop */
+	
+	return (Elf_Addr) tramp;
+}
+
+static Elf_Addr add_plt_entry(struct module *me, void *location, Elf_Addr v)
+{
+	if (within_module_core((unsigned long) location, me)) {
+		return add_plt_entry_to(&me->arch.core_plt_offset,
+					me->module_core, me->core_size, v);
+	} else if (within_module_init((unsigned long) location, me)) {
+		return add_plt_entry_to(&me->arch.init_plt_offset,
+					me->module_init, me->init_size, v);
+	} else {
+		printk(KERN_ERR "module %s: "
+		       "relocation to unknown segment %u\n",
+		       me->name, v);
+	}
+	return 0;
+}
+
 static int apply_r_mips_26_rel(struct module *me, u32 *location, Elf_Addr v)
 {
 	if (v % 4) {
@@ -104,11 +313,18 @@ static int apply_r_mips_26_rel(struct mo
 	}
 
 	if ((v & 0xf0000000) != (((unsigned long)location + 4) & 0xf0000000)) {
+		v = add_plt_entry(me, location,
+				  v + ((*location & 0x03ffffff) << 2));
+		if (v == 0) {
 		printk(KERN_ERR
 		       "module %s: relocation overflow\n",
 		       me->name);
 		return -ENOEXEC;
 	}
+		*location = (*location & ~0x03ffffff) |
+			    ((v >> 2) & 0x03ffffff);
+		return 0;
+	}
 
 	*location = (*location & ~0x03ffffff) |
 	            ((*location + (v >> 2)) & 0x03ffffff);
@@ -125,11 +341,14 @@ static int apply_r_mips_26_rela(struct m
 	}
 
 	if ((v & 0xf0000000) != (((unsigned long)location + 4) & 0xf0000000)) {
+		v = add_plt_entry(me, location, v);
+		if (v == 0) {
 		printk(KERN_ERR
 		       "module %s: relocation overflow\n",
 		       me->name);
 		return -ENOEXEC;
 	}
+	}
 
 	*location = (*location & ~0x03ffffff) | ((v >> 2) & 0x03ffffff);
 
@@ -400,6 +619,14 @@ int module_finalize(const Elf_Ehdr *hdr,
 		list_add(&me->arch.dbe_list, &dbe_list);
 		spin_unlock_irq(&dbe_lock);
 	}
+
+	if (me->arch.core_plt_offset < me->core_size
+	    && PAGE_ALIGN(me->arch.core_plt_offset) == me->arch.core_plt_offset
+	    && is_phys(me->module_core)) {
+		free_phys(me->module_core + me->arch.core_plt_offset,
+			  me->core_size - me->arch.core_plt_offset);
+		me->core_size = me->arch.core_plt_offset;
+	}
 	return 0;
 }
 
diff -puNrb linux-2.6.35/arch/mips/kernel/proc.c linux/arch/mips/kernel/proc.c
--- linux-2.6.35/arch/mips/kernel/proc.c	2011-04-26 16:27:12.672477343 +0300
+++ linux/arch/mips/kernel/proc.c	2011-05-02 10:08:24.872791070 +0300
@@ -12,12 +12,14 @@
 #include <asm/cpu-features.h>
 #include <asm/mipsregs.h>
 #include <asm/processor.h>
+#include <asm/time.h>
 
 unsigned int vced_count, vcei_count;
 
 static int show_cpuinfo(struct seq_file *m, void *v)
 {
 	unsigned long n = (unsigned long) v - 1;
+	unsigned cpu_khz = mips_hpt_frequency / 500;
 	unsigned int version = cpu_data[n].processor_id;
 	unsigned int fp_vers = cpu_data[n].fpu_id;
 	char fmt [64];
@@ -40,6 +42,8 @@ static int show_cpuinfo(struct seq_file 
 	seq_printf(m, fmt, __cpu_name[n],
 	                           (version >> 4) & 0x0f, version & 0x0f,
 	                           (fp_vers >> 4) & 0x0f, fp_vers & 0x0f);
+	seq_printf(m, "cpu MHz\t\t\t: %u.%03u\n",
+		   cpu_khz / 1000, (cpu_khz % 1000));
 	seq_printf(m, "BogoMIPS\t\t: %u.%02u\n",
 	              cpu_data[n].udelay_val / (500000/HZ),
 	              (cpu_data[n].udelay_val / (5000/HZ)) % 100);
diff -puNrb linux-2.6.35/arch/mips/kernel/time.c linux/arch/mips/kernel/time.c
--- linux-2.6.35/arch/mips/kernel/time.c	2011-04-26 16:27:12.652476994 +0300
+++ linux/arch/mips/kernel/time.c	2011-05-02 10:08:24.882790888 +0300
@@ -70,6 +70,7 @@ EXPORT_SYMBOL(perf_irq);
  */
 
 unsigned int mips_hpt_frequency;
+EXPORT_SYMBOL(mips_hpt_frequency);
 
 /*
  * This function exists in order to cause an error due to a duplicate
diff -puNrb linux-2.6.35/arch/mips/kernel/traps.c linux/arch/mips/kernel/traps.c
--- linux-2.6.35/arch/mips/kernel/traps.c	2011-04-26 16:27:12.672477343 +0300
+++ linux/arch/mips/kernel/traps.c	2011-05-02 10:08:24.902898011 +0300
@@ -90,6 +90,8 @@ void (*board_ejtag_handler_setup)(void);
 void (*board_bind_eic_interrupt)(int irq, int regset);
 
 
+#define CONFIG_RAWBACKTRACE
+#ifdef CONFIG_RAWBACKTRACE
 static void show_raw_backtrace(unsigned long reg29)
 {
 	unsigned long *sp = (unsigned long *)(reg29 & ~3);
@@ -140,6 +142,25 @@ static void show_backtrace(struct task_s
 	printk("\n");
 }
 
+#else
+
+static void show_backtrace(struct task_struct *task, const struct pt_regs *regs)
+{
+	unsigned long sp = regs->regs[29];
+	unsigned long ra = regs->regs[31];
+	unsigned long pc = regs->cp0_epc;
+	int depth = 16;
+
+	printk("Call Trace:\n");
+	while (depth-- && pc) {
+	    print_ip_sym(pc);
+	    pc = find_prev_frame(pc, ra, &sp, 0);
+	    ra = 0;
+	}
+	printk("\n");
+}
+#endif
+
 /*
  * This routine abuses get_user()/put_user() to reference pointers
  * with at least a bit of error checking ...
@@ -368,6 +389,7 @@ void __noreturn die(const char * str, st
 
 	notify_die(DIE_OOPS, str, (struct pt_regs *)regs, SIGSEGV, 0, 0);
 
+	oops_enter();
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
@@ -382,6 +404,7 @@ void __noreturn die(const char * str, st
 	show_registers(regs);
 	add_taint(TAINT_DIE);
 	spin_unlock_irq(&die_lock);
+	oops_exit();
 
 	if (in_interrupt())
 		panic("Fatal exception in interrupt");
@@ -1516,6 +1539,7 @@ void __cpuinit per_cpu_trap_init(void)
 	 *  o read IntCtl.IPTI to determine the timer interrupt
 	 *  o read IntCtl.IPPCI to determine the performance counter interrupt
 	 */
+#ifdef CONFIG_CPU_MIPSR2
 	if (cpu_has_mips_r2) {
 		cp0_compare_irq_shift = CAUSEB_TI - CAUSEB_IP;
 		cp0_compare_irq = (read_c0_intctl() >> INTCTLB_IPTI) & 7;
@@ -1523,11 +1547,17 @@ void __cpuinit per_cpu_trap_init(void)
 		if (cp0_perfcount_irq == cp0_compare_irq)
 			cp0_perfcount_irq = -1;
 	} else {
+#endif
 		cp0_compare_irq = CP0_LEGACY_COMPARE_IRQ;
 		cp0_compare_irq_shift = cp0_compare_irq;
 		cp0_perfcount_irq = -1;
+#ifdef CONFIG_CPU_MIPSR2
 	}
+#endif
 
+#ifdef CONFIG_MIPS_MIKROTIK
+	cp0_compare_irq = CP0_LEGACY_COMPARE_IRQ;
+#endif
 #ifdef CONFIG_MIPS_MT_SMTC
 	}
 #endif /* CONFIG_MIPS_MT_SMTC */
@@ -1612,7 +1642,7 @@ void __init trap_init(void)
 		ebase = (unsigned long)
 			__alloc_bootmem(size, 1 << fls(size), 0);
 	} else {
-		ebase = CKSEG0;
+		ebase = CAC_BASE;
 		if (cpu_has_mips_r2)
 			ebase += (read_c0_ebase() & 0x3ffff000);
 	}
diff -puNrb linux-2.6.35/arch/mips/kernel/unaligned.c linux/arch/mips/kernel/unaligned.c
--- linux-2.6.35/arch/mips/kernel/unaligned.c	2011-04-26 16:27:12.642477318 +0300
+++ linux/arch/mips/kernel/unaligned.c	2011-05-02 10:08:24.912790453 +0300
@@ -102,6 +102,24 @@ static u32 unaligned_action;
 #endif
 extern void show_registers(struct pt_regs *regs);
 
+#define RATE_BURST (10*5*HZ)
+#define RATE_COST (5*HZ)
+
+static int un_ratelimit(void) {
+	static unsigned toks = RATE_BURST;
+	static unsigned last_msg;
+
+	unsigned now = jiffies;
+	toks += now - last_msg;
+	if (toks > RATE_BURST) toks = RATE_BURST;
+
+	if (toks >= RATE_COST) {
+		toks -= RATE_COST;
+		return 1;
+	}
+	return 0;
+}
+
 static void emulate_load_store_insn(struct pt_regs *regs,
 	void __user *addr, unsigned int __user *pc)
 {
@@ -508,10 +526,22 @@ sigill:
 	force_sig(SIGILL, current);
 }
 
+extern asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
+				     unsigned long address);
+
 asmlinkage void do_ade(struct pt_regs *regs)
 {
 	unsigned int __user *pc;
 	mm_segment_t seg;
+	unsigned long badvaddr = regs->cp0_badvaddr;
+
+	/* We are running in VM protected enviroment and
+	   we hit KSEG0, or KSEG3 address */
+	if ((badvaddr & 3) == 0 && KSEGX(badvaddr) == KSEG3) {
+		do_page_fault(regs, (regs->cp0_cause & 0x7c) == 20,
+			      badvaddr);
+		return;
+	}
 
 	/*
 	 * Did we catch a fault trying to load an instruction?
@@ -528,6 +558,9 @@ asmlinkage void do_ade(struct pt_regs *r
 	else if (unaligned_action == UNALIGNED_ACTION_SHOW)
 		show_registers(regs);
 
+	if (!user_mode(regs) && un_ratelimit())
+		printk(KERN_WARNING "unaligned data access at %p\n", pc);
+
 	/*
 	 * Do branch emulation only if we didn't forward the exception.
 	 * This is all so but ugly ...
diff -puNrb linux-2.6.35/arch/mips/lib/iomap.c linux/arch/mips/lib/iomap.c
--- linux-2.6.35/arch/mips/lib/iomap.c	2011-04-26 16:27:13.322477307 +0300
+++ linux/arch/mips/lib/iomap.c	2011-05-02 10:08:24.922790517 +0300
@@ -25,6 +25,8 @@
 
 #define PIO_MASK	0x0ffffUL
 
+#ifndef CONFIG_MIPS_MIKROTIK
+
 unsigned int ioread8(void __iomem *addr)
 {
 	return readb(addr);
@@ -194,6 +196,8 @@ void iowrite32_rep(void __iomem *addr, c
 
 EXPORT_SYMBOL(iowrite32_rep);
 
+#endif
+
 /*
  * Create a virtual mapping cookie for an IO port range
  *
diff -puNrb linux-2.6.35/arch/mips/Makefile linux/arch/mips/Makefile
--- linux-2.6.35/arch/mips/Makefile	2011-04-26 16:27:15.962477571 +0300
+++ linux/arch/mips/Makefile	2011-05-02 10:08:24.942790523 +0300
@@ -49,7 +49,7 @@ ifneq ($(SUBARCH),$(ARCH))
 endif
 
 ifndef CONFIG_FUNCTION_TRACER
-cflags-y := -ffunction-sections
+#cflags-y := -ffunction-sections
 endif
 ifdef CONFIG_FUNCTION_GRAPH_TRACER
   ifndef KBUILD_MCOUNT_RA_ADDRESS
@@ -93,7 +93,7 @@ all-$(CONFIG_SYS_SUPPORTS_ZBOOT)+= vmlin
 cflags-y			+= -G 0 -mno-abicalls -fno-pic -pipe
 cflags-y			+= -msoft-float
 LDFLAGS_vmlinux			+= -G 0 -static -n -nostdlib
-MODFLAGS			+= -mlong-calls
+MODFLAGS			+= -mno-long-calls
 
 cflags-y += -ffreestanding
 
@@ -648,6 +648,22 @@ core-$(CONFIG_TOSHIBA_RBTX4938) += arch/
 core-$(CONFIG_TOSHIBA_RBTX4939) += arch/mips/txx9/rbtx4939/
 
 #
+# Mikrotik RB100/RB500 boards
+#
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/rb500/
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/rb100/
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/rb400/
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/cr/
+core-$(CONFIG_MIPS_MIKROTIK) += arch/mips/rb/vm/
+cflags-$(CONFIG_MIPS_MIKROTIK) += -I$(srctree)/arch/mips/include/asm/mach-rb
+ifdef CONFIG_MAPPED_KERNEL
+load-$(CONFIG_MIPS_MIKROTIK) += 0xffffffffc0101000
+OBJCOPYFLAGS += --change-addresses=0xc0000000
+else
+load-$(CONFIG_MIPS_MIKROTIK) += 0xffffffff80101000
+endif
+
 # Cavium Octeon
 #
 core-$(CONFIG_CPU_CAVIUM_OCTEON)	+= arch/mips/cavium-octeon/
diff -puNrb linux-2.6.35/arch/mips/mm/cache.c linux/arch/mips/mm/cache.c
--- linux-2.6.35/arch/mips/mm/cache.c	2011-04-26 16:27:15.792477518 +0300
+++ linux/arch/mips/mm/cache.c	2011-05-02 10:08:24.952790721 +0300
@@ -43,6 +43,7 @@ void (*flush_icache_all)(void);
 
 EXPORT_SYMBOL_GPL(local_flush_data_cache_page);
 EXPORT_SYMBOL(flush_data_cache_page);
+EXPORT_SYMBOL(flush_icache_range);
 
 #ifdef CONFIG_DMA_NONCOHERENT
 
diff -puNrb linux-2.6.35/arch/mips/mm/c-r4k.c linux/arch/mips/mm/c-r4k.c
--- linux-2.6.35/arch/mips/mm/c-r4k.c	2011-04-26 16:27:15.792477518 +0300
+++ linux/arch/mips/mm/c-r4k.c	2011-05-02 10:08:24.962899888 +0300
@@ -970,7 +970,9 @@ static void __cpuinit probe_pcache(void)
 		              c->dcache.linesz;
 		c->dcache.waybit = __ffs(dcache_size/c->dcache.ways);
 
+#ifdef CONFIG_CPU_HAS_PREFETCH
 		c->options |= MIPS_CPU_PREFETCH;
+#endif
 		break;
 	}
 
diff -puNrb linux-2.6.35/arch/mips/mm/dma-default.c linux/arch/mips/mm/dma-default.c
--- linux-2.6.35/arch/mips/mm/dma-default.c	2011-04-26 16:27:15.802477194 +0300
+++ linux/arch/mips/mm/dma-default.c	2011-05-02 10:08:24.982903934 +0300
@@ -14,6 +14,10 @@
 #include <linux/module.h>
 #include <linux/scatterlist.h>
 #include <linux/string.h>
+#ifdef CONFIG_MAPPED_KERNEL
+#include <linux/hardirq.h>
+#include <linux/sched.h>
+#endif
 #include <linux/gfp.h>
 
 #include <asm/cache.h>
@@ -104,7 +108,14 @@ void *dma_alloc_coherent(struct device *
 
 		if (!plat_device_is_coherent(dev)) {
 			dma_cache_wback_inv((unsigned long) ret, size);
+#ifndef CONFIG_MAPPED_KERNEL
+			ret = UNCAC_ADDR(ret);
+#else
+			if (!in_interrupt())
+				ret = ioremap((unsigned long) *dma_handle, size);
+			else
 			ret = UNCAC_ADDR(ret);
+#endif
 		}
 	}
 
@@ -131,10 +142,24 @@ void dma_free_coherent(struct device *de
 	if (dma_release_from_coherent(dev, order, vaddr))
 		return;
 
+#ifndef CONFIG_MAPPED_KERNEL
 	plat_unmap_dma_mem(dev, dma_handle, size, DMA_BIDIRECTIONAL);
 
 	if (!plat_device_is_coherent(dev))
 		addr = CAC_ADDR(addr);
+#else
+	if (!plat_device_is_coherent(dev)) {
+		pgd_t *pgd = init_mm.pgd + __pgd_offset(addr);
+		pud_t *pud = pud_offset(pgd, addr);
+		pmd_t *pmd = pmd_offset(pud, addr);
+		pte_t *pte = pte_offset(pmd, addr);
+		
+		if (pte_present(*pte)) {
+			addr = (unsigned long) pfn_to_kaddr(pte_pfn(*pte));
+			iounmap(vaddr);
+		}
+	}
+#endif
 
 	free_pages(addr, get_order(size));
 }
diff -puNrb linux-2.6.35/arch/mips/mm/fault.c linux/arch/mips/mm/fault.c
--- linux-2.6.35/arch/mips/mm/fault.c	2011-04-26 16:27:15.792477518 +0300
+++ linux/arch/mips/mm/fault.c	2011-05-02 10:08:24.992904379 +0300
@@ -71,6 +71,12 @@ asmlinkage void do_page_fault(struct pt_
 		goto VMALLOC_FAULT_TARGET;
 #endif
 
+#ifdef CONFIG_MAPPED_KERNEL
+	/* in case we touched other VM memory */
+	if (KSEGX(address) == KSEG2)
+		goto VMALLOC_FAULT_TARGET;
+#endif
+
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
diff -puNrb linux-2.6.35/arch/mips/mm/init.c linux/arch/mips/mm/init.c
--- linux-2.6.35/arch/mips/mm/init.c	2011-04-26 16:27:15.792477518 +0300
+++ linux/arch/mips/mm/init.c	2011-05-02 10:08:25.002900438 +0300
@@ -43,6 +43,10 @@
 #include <asm/tlb.h>
 #include <asm/fixmap.h>
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#include <asm/rb/boards.h>
+#endif
+
 /* Atomicity and interruptability */
 #ifdef CONFIG_MIPS_MT_SMTC
 
@@ -180,7 +184,7 @@ void *kmap_coherent(struct page *page, u
 
 #define UNIQUE_ENTRYHI(idx) (CKSEG0 + ((idx) << (PAGE_SHIFT + 1)))
 
-void kunmap_coherent(void)
+void kunmap_coherent()
 {
 #ifndef CONFIG_MIPS_MT_SMTC
 	unsigned int wired;
@@ -335,6 +339,10 @@ void __init paging_init(void)
 
 #ifdef CONFIG_ZONE_DMA
 	max_zone_pfns[ZONE_DMA] = MAX_DMA_PFN;
+#if defined(CONFIG_MIPS_MIKROTIK)
+	if (mips_machgroup != MACH_GROUP_MT_RB100)
+		max_zone_pfns[ZONE_DMA] = max_low_pfn;
+#endif
 #endif
 #ifdef CONFIG_ZONE_DMA32
 	max_zone_pfns[ZONE_DMA32] = MAX_DMA32_PFN;
diff -puNrb linux-2.6.35/arch/mips/mm/ioremap.c linux/arch/mips/mm/ioremap.c
--- linux-2.6.35/arch/mips/mm/ioremap.c	2011-04-26 16:27:15.802477194 +0300
+++ linux/arch/mips/mm/ioremap.c	2011-05-02 10:08:25.022897696 +0300
@@ -127,6 +127,7 @@ void __iomem * __ioremap(phys_t phys_add
 	if (!size || last_addr < phys_addr)
 		return NULL;
 
+#ifndef CONFIG_MAPPED_KERNEL
 	/*
 	 * Map uncached objects in the low 512mb of address space using KSEG1,
 	 * otherwise map using page tables.
@@ -149,6 +150,7 @@ void __iomem * __ioremap(phys_t phys_add
 			if(!PageReserved(page))
 				return NULL;
 	}
+#endif
 
 	/*
 	 * Mappings have to be page-aligned
diff -puNrb linux-2.6.35/arch/mips/mm/tlb-r4k.c linux/arch/mips/mm/tlb-r4k.c
--- linux-2.6.35/arch/mips/mm/tlb-r4k.c	2011-04-26 16:27:15.792477518 +0300
+++ linux/arch/mips/mm/tlb-r4k.c	2011-05-02 10:08:25.032903131 +0300
@@ -432,7 +432,9 @@ void __cpuinit tlb_init(void)
 	 *     be set to fixed-size pages.
 	 */
 	write_c0_pagemask(PM_DEFAULT_MASK);
+#ifndef CONFIG_MAPPED_KERNEL
 	write_c0_wired(0);
+#endif
 	if (current_cpu_type() == CPU_R10000 ||
 	    current_cpu_type() == CPU_R12000 ||
 	    current_cpu_type() == CPU_R14000)
diff -puNrb linux-2.6.35/arch/mips/oprofile/common.c linux/arch/mips/oprofile/common.c
--- linux-2.6.35/arch/mips/oprofile/common.c	2011-04-26 16:27:12.302477483 +0300
+++ linux/arch/mips/oprofile/common.c	2011-05-02 10:08:25.042688492 +0300
@@ -11,10 +11,16 @@
 #include <linux/init.h>
 #include <linux/oprofile.h>
 #include <linux/smp.h>
+#include <asm/ptrace.h>
 #include <asm/cpu-info.h>
+#include <asm/rb/boards.h>
 
 #include "op_impl.h"
 
+extern int __init rb100_oprofile_init(struct oprofile_operations *ops);
+extern int __init rb500_oprofile_init(struct oprofile_operations *ops);
+extern int __init hrtimer_oprofile_init(struct oprofile_operations *);
+
 extern struct op_mips_model op_model_mipsxx_ops __weak;
 extern struct op_mips_model op_model_rm9000_ops __weak;
 extern struct op_mips_model op_model_loongson2_ops __weak;
@@ -71,11 +77,39 @@ static void op_mips_stop(void)
 	on_each_cpu(model->cpu_stop, NULL, 1);
 }
 
+void op_mips_backtrace(struct pt_regs * const regs, unsigned int depth)
+{
+	unsigned long ra = regs->regs[31];
+	unsigned long pc = regs->cp0_epc;
+	unsigned long sp = regs->regs[29];
+	int usermode = user_mode(regs);
+
+	while (depth-- && pc) {
+	    pc = find_prev_frame(pc, ra, &sp, usermode);
+	    if (pc) oprofile_add_trace((unsigned long) pc);
+	    ra = 0;
+	}
+}
+
 int __init oprofile_arch_init(struct oprofile_operations *ops)
 {
 	struct op_mips_model *lmodel = NULL;
 	int res;
 
+	ops->backtrace = op_mips_backtrace;
+
+	if (hrtimer_oprofile_init(ops) == 0)
+		return 0;
+
+#ifdef CONFIG_MIPS_MIKROTIK
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB100:
+		return rb100_oprofile_init(ops);
+	case MACH_GROUP_MT_RB500:
+		return rb500_oprofile_init(ops);
+	}
+#endif
+
 	switch (current_cpu_type()) {
 	case CPU_5KC:
 	case CPU_20KC:
diff -puNrb linux-2.6.35/arch/mips/oprofile/Makefile linux/arch/mips/oprofile/Makefile
--- linux-2.6.35/arch/mips/oprofile/Makefile	2011-04-26 16:27:12.302477483 +0300
+++ linux/arch/mips/oprofile/Makefile	2011-05-02 10:08:25.052849380 +0300
@@ -1,4 +1,4 @@
-EXTRA_CFLAGS := -Werror
+EXTRA_CFLAGS := # -Werror
 
 obj-$(CONFIG_OPROFILE) += oprofile.o
 
@@ -6,6 +6,7 @@ DRIVER_OBJS = $(addprefix ../../../drive
 		oprof.o cpu_buffer.o buffer_sync.o \
 		event_buffer.o oprofile_files.o \
 		oprofilefs.o oprofile_stats.o \
+		hrtimer.o \
 		timer_int.o )
 
 oprofile-y				:= $(DRIVER_OBJS) common.o
@@ -15,4 +16,6 @@ oprofile-$(CONFIG_CPU_MIPS64)		+= op_mod
 oprofile-$(CONFIG_CPU_R10000)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_SB1)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_RM9000)		+= op_model_rm9000.o
+oprofile-$(CONFIG_MIPS_MIKROTIK)	+= op_rb100.o
+oprofile-$(CONFIG_MIPS_MIKROTIK)	+= op_rb500.o
 oprofile-$(CONFIG_CPU_LOONGSON2)	+= op_model_loongson2.o
diff -puNrb linux-2.6.35/arch/mips/oprofile/op_rb100.c linux/arch/mips/oprofile/op_rb100.c
--- linux-2.6.35/arch/mips/oprofile/op_rb100.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/oprofile/op_rb100.c	2011-05-02 10:08:25.062902583 +0300
@@ -0,0 +1,57 @@
+#include <linux/interrupt.h>
+#include <linux/oprofile.h>
+
+#define IRQ_TIMER 0
+
+#define SWCTRL_BASE 0x12000000
+#define ADM5120_SW_REG(reg) \
+        (*((volatile unsigned *) (KSEG1ADDR(SWCTRL_BASE + (reg)))))
+
+#define SW_TIMER_INT		0x00f0
+#define SW_TIMER		0x00f4
+
+#define CYCLES 100000
+#define OPROFILE_FREQ (175000000 / CYCLES)
+
+extern void rb100_enable_beeper(int enable);
+
+static irqreturn_t rb100_oprofile_irq(int irq, void *p)
+{
+	oprofile_add_sample(get_irq_regs(), 0);
+
+	ADM5120_SW_REG(SW_TIMER) = (1 << 16) | (1562500 / OPROFILE_FREQ);
+	ADM5120_SW_REG(SW_TIMER_INT) = 1;
+
+	return IRQ_HANDLED;
+}
+
+static int rb100_oprofile_start(void)
+{
+	rb100_enable_beeper(0);
+	request_irq(IRQ_TIMER, rb100_oprofile_irq, 0, "oprofile", 0);
+
+	ADM5120_SW_REG(SW_TIMER) = (1 << 16) | (1562500 / OPROFILE_FREQ);
+	ADM5120_SW_REG(SW_TIMER_INT) = 1;
+
+	return 0;
+}
+
+static void rb100_oprofile_stop(void)
+{
+	ADM5120_SW_REG(SW_TIMER_INT) = 1 << 16;
+	ADM5120_SW_REG(SW_TIMER) = 0;
+
+	free_irq(IRQ_TIMER, 0);
+	rb100_enable_beeper(1);
+}
+
+int __init rb100_oprofile_init(struct oprofile_operations *ops)
+{
+	ops->create_files = NULL;
+	ops->setup = NULL;
+	ops->shutdown = NULL;
+	ops->start = rb100_oprofile_start;
+	ops->stop = rb100_oprofile_stop;
+	ops->cpu_type = "timer";
+	return 0;
+}
diff -puNrb linux-2.6.35/arch/mips/oprofile/op_rb500.c linux/arch/mips/oprofile/op_rb500.c
--- linux-2.6.35/arch/mips/oprofile/op_rb500.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/oprofile/op_rb500.c	2011-05-02 10:08:25.082790590 +0300
@@ -0,0 +1,61 @@
+#include <linux/interrupt.h>
+#include <linux/oprofile.h>
+#include <asm/io.h>
+#include <asm/addrspace.h>
+
+#define TIMER_BASE     ((unsigned *) KSEG1ADDR(0x18028000))
+#define TIMER_COUNT0   (TIMER_BASE + 0)
+#define TIMER_COMPARE0 (TIMER_BASE + 1)
+#define TIMER_CTC0     (TIMER_BASE + 2)
+#define TIMER_CTCSEL0  (TIMER_BASE + 3)
+
+#define IRQ_TIMER 8
+
+#define CYCLES 100000
+
+extern unsigned int mips_hpt_frequency;
+
+extern void rb500_enable_beeper(int enable);
+
+static irqreturn_t rb500_oprofile_irq(int irq, void *p)
+{
+	oprofile_add_sample(get_irq_regs(), 0);
+
+	writel(1, TIMER_CTC0);
+
+	return IRQ_HANDLED;
+}
+
+static int rb500_oprofile_start(void)
+{
+	unsigned delay = mips_hpt_frequency / (CYCLES / 2);
+	
+	rb500_enable_beeper(0);
+	request_irq(IRQ_TIMER, rb500_oprofile_irq, 0, "oprofile", 0);
+
+	writel(0, TIMER_COUNT0);
+	writel(delay, TIMER_COMPARE0);
+	writel(0, TIMER_CTCSEL0);
+	writel(1, TIMER_CTC0);
+
+	return 0;
+}
+
+static void rb500_oprofile_stop(void)
+{
+	writel(0, TIMER_CTC0);
+
+	free_irq(IRQ_TIMER, 0);
+	rb500_enable_beeper(1);
+}
+
+int __init rb500_oprofile_init(struct oprofile_operations *ops)
+{
+	ops->create_files = NULL;
+	ops->setup = NULL;
+	ops->shutdown = NULL;
+	ops->start = rb500_oprofile_start;
+	ops->stop = rb500_oprofile_stop;
+	ops->cpu_type = "timer";
+	return 0;
+}
diff -puNrb linux-2.6.35/arch/mips/pci/Makefile linux/arch/mips/pci/Makefile
--- linux-2.6.35/arch/mips/pci/Makefile	2011-04-26 16:27:13.652482666 +0300
+++ linux/arch/mips/pci/Makefile	2011-05-02 10:08:25.092790996 +0300
@@ -7,12 +7,18 @@ obj-y				+= pci.o
 #
 # PCI bus host bridge specific code
 #
+obj-$(CONFIG_PCI_ADM5120)	+= ops-adm5120.o pci-adm5120.o
 obj-$(CONFIG_MIPS_BONITO64)	+= ops-bonito64.o
 obj-$(CONFIG_PCI_GT64XXX_PCI0)	+= ops-gt64xxx_pci0.o
 obj-$(CONFIG_MIPS_MSC)		+= ops-msc.o
 obj-$(CONFIG_MIPS_NILE4)	+= ops-nile4.o
 obj-$(CONFIG_SOC_TX3927)	+= ops-tx3927.o
 obj-$(CONFIG_PCI_VR41XX)	+= ops-vr41xx.o pci-vr41xx.o
+obj-$(CONFIG_MIPS_MIKROTIK)	+= pci-rb.o
+obj-$(CONFIG_MIPS_MIKROTIK)	+= ops-rb500.o
+obj-$(CONFIG_MIPS_MIKROTIK)	+= ops-rb400.o
+obj-$(CONFIG_MIPS_MIKROTIK)	+= ops-rb100.o
+obj-$(CONFIG_MIPS_MIKROTIK)	+= ops-rb700.o
 obj-$(CONFIG_NEC_MARKEINS)	+= ops-emma2rh.o pci-emma2rh.o fixup-emma2rh.o
 obj-$(CONFIG_PCI_TX4927)	+= ops-tx4927.o
 obj-$(CONFIG_BCM47XX)		+= pci-bcm47xx.o
diff -puNrb linux-2.6.35/arch/mips/pci/ops-rb100.c linux/arch/mips/pci/ops-rb100.c
--- linux-2.6.35/arch/mips/pci/ops-rb100.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/pci/ops-rb100.c	2011-05-02 10:08:25.102907060 +0300
@@ -0,0 +1,58 @@
+/*
+ *	Copyright (C) ADMtek Incorporated.
+ *	Copyright (C) 2005 Jeroen Vreeken (pe1rxq@amsat.org)
+ */
+
+#include <linux/types.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+
+volatile u32* pci_config_address_reg = (volatile u32*)KSEG1ADDR(0x115ffff0);
+volatile u32* pci_config_data_reg = (volatile u32*)KSEG1ADDR(0x115ffff8);
+
+#define PCI_ENABLE 0x80000000
+                          
+static int pci_config_read(struct pci_bus *bus, unsigned int devfn, int where,
+                           int size, uint32_t *val)
+{
+	*pci_config_address_reg = ((bus->number & 0xff) << 0x10) |
+	    ((devfn & 0xff) << 0x08) | (where & 0xfc) | PCI_ENABLE;
+	switch (size) {
+		case 1:
+			*val = ((*pci_config_data_reg)>>((where&3)<<3))&0xff;
+			break;
+		case 2:
+			*val = ((*pci_config_data_reg)>>((where&3)<<3))&0xffff;
+			break;
+		default:
+			*val = (*pci_config_data_reg);
+	}
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int pci_config_write(struct pci_bus *bus, unsigned int devfn, int where,
+                            int size, uint32_t val)
+{
+	*pci_config_address_reg = ((bus->number & 0xff) << 0x10) |
+	    ((devfn & 0xff) << 0x08) | (where & 0xfc) | PCI_ENABLE;
+	switch (size) {
+		case 1:
+			*(volatile u8 *)(((int)pci_config_data_reg) +
+			    (where & 3)) = val;
+			break;
+		case 2:
+			*(volatile u16 *)(((int)pci_config_data_reg) +
+			    (where & 2)) = (val);
+			break;
+		default:
+			*pci_config_data_reg = (val);
+	}
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+struct pci_ops rb100_pci_ops = {
+	.read	= pci_config_read,
+	.write	= pci_config_write,
+};
diff -puNrb linux-2.6.35/arch/mips/pci/ops-rb400.c linux/arch/mips/pci/ops-rb400.c
--- linux-2.6.35/arch/mips/pci/ops-rb400.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/pci/ops-rb400.c	2011-05-02 10:08:25.112848470 +0300
@@ -0,0 +1,204 @@
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <asm/traps.h>
+#include <asm/rb/rb400.h>
+
+#define RB400_PCI_REG(x)	((unsigned long) rb400_pci_base + (x))
+#define RB400_PCI_CRP_AD_CBE	RB400_PCI_REG(0x00)
+#define RB400_PCI_CRP_WRDATA	RB400_PCI_REG(0x04)
+#define RB400_PCI_CRP_RDDATA	RB400_PCI_REG(0x08)
+#define RB400_PCI_CFG_AD	RB400_PCI_REG(0x0c)
+#define RB400_PCI_CFG_CBE	RB400_PCI_REG(0x10)
+#define RB400_PCI_CFG_WRDATA	RB400_PCI_REG(0x14)
+#define RB400_PCI_CFG_RDDATA	RB400_PCI_REG(0x18)
+#define RB400_PCI_ERROR		RB400_PCI_REG(0x1c)
+#define RB400_PCI_ERROR_ADDR	RB400_PCI_REG(0x20)
+#define RB400_AHB_ERROR		RB400_PCI_REG(0x24)
+#define RB400_AHB_ERROR_ADDR	RB400_PCI_REG(0x28)
+
+#define CFG_CMD_READ         0x0000000a
+#define CFG_CMD_WRITE        0x0000000b
+
+void __iomem *rb400_pci_base;
+
+static inline unsigned bus_addr(struct pci_bus *bus, unsigned int devfn,
+				int where) {
+    if (bus->number) {
+	return 1 | (bus->number << 16) | (devfn << 8) | (where & 0xfc);
+    }
+    return (1 << PCI_SLOT(devfn)) | (PCI_FUNC(devfn) << 8) | (where & 0xfc);
+}
+
+static inline unsigned get_be(int addr, int size)
+{
+	return ~(((1 << size) - 1) << ((addr & 3) + 4)) & 0xf0;
+}
+
+static unsigned byte_mask[4] = { 0xff, 0xffff, 0, 0xffffffff };
+
+static int rb400_check_error(int verbose)
+{
+	unsigned pci_error, ahb_error;
+
+	pci_error = rb400_readl(RB400_PCI_ERROR) & 3;
+	if (pci_error) {
+		if (verbose)
+			printk("PCI error %d at PCI addr 0x%x\n",
+			       pci_error, rb400_readl(RB400_PCI_ERROR_ADDR));
+		rb400_writel(pci_error, RB400_PCI_ERROR);
+	}
+
+	ahb_error = rb400_readl(RB400_AHB_ERROR) & 1;
+	if (ahb_error) {
+		if (verbose)
+			printk("AHB error at AHB addr 0x%x\n",
+			       rb400_readl(RB400_AHB_ERROR_ADDR));
+		rb400_writel(ahb_error, RB400_AHB_ERROR);
+	}
+
+	return pci_error | ahb_error;
+}
+
+int rb400_be_handler(struct pt_regs *regs, int is_fixup)
+{
+	return !rb400_check_error(1) && is_fixup
+	    ? MIPS_BE_FIXUP : MIPS_BE_FATAL;
+}
+
+static int rb400_config_read(struct pci_bus *bus, unsigned int devfn,
+			     int where, 
+			     int size, uint32_t *value)
+{
+	uint32_t addr, data;
+
+	addr = bus_addr(bus, devfn, where);
+
+	if (bus->number != 0 || devfn != 0) {
+		rb400_writel(addr, RB400_PCI_CFG_AD);
+		rb400_writel(CFG_CMD_READ | get_be(where, size),
+			     RB400_PCI_CFG_CBE);
+	    
+		if (rb400_check_error(0)) {
+			*value = byte_mask[size - 1];
+			return PCIBIOS_DEVICE_NOT_FOUND;
+		}
+
+		data = rb400_readl(RB400_PCI_CFG_RDDATA);
+	} else {
+#ifdef SUPPORT_HOST_BRIDGE_CONFIG
+		rb400_writel(where & 0xfc, RB400_PCI_CRP_AD_CBE);
+		data = rb400_readl(RB400_PCI_CRP_RDDATA);
+#else
+		data = ~0;
+#endif
+	}
+
+	*value = (data >> (8 * (where & 3))) & byte_mask[size - 1];
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int rb400_config_write(struct pci_bus *bus,  unsigned int devfn,
+			      int where, 
+			      int size, uint32_t value)
+{
+	unsigned addr = bus_addr(bus, devfn, where);
+	unsigned data = value << (8 * (where & 3));
+
+	if (bus->number != 0 || devfn != 0) {
+		rb400_writel(addr, RB400_PCI_CFG_AD);
+		rb400_writel(CFG_CMD_WRITE | get_be(where, size),
+			     RB400_PCI_CFG_CBE);
+		rb400_writel(data, RB400_PCI_CFG_WRDATA);
+		rb400_readl(RB400_PCI_CFG_WRDATA);
+
+		if (rb400_check_error(0))
+			return PCIBIOS_DEVICE_NOT_FOUND;
+	} else {
+#ifdef SUPPORT_HOST_BRIDGE_CONFIG
+		rb400_writel(0x00010000 | (where & 0xfc) | get_be(where, size),
+			     RB400_PCI_CRP_AD_CBE);
+		rb400_writel(data, RB400_PCI_CRP_WRDATA);
+		rb400_readl(RB400_PCI_CRP_WRDATA);
+#endif
+	}
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+struct pci_ops rb400_pci_ops = {
+	.read =  rb400_config_read,
+	.write = rb400_config_write,
+};
+
+#define CFG_CMD_IO_READ      0x00000002
+#define CFG_CMD_IO_WRITE     0x00000003
+
+static unsigned rb400_pci_io_read(unsigned long ioaddr, int size)
+{
+	unsigned data;
+
+	rb400_writel(ioaddr, RB400_PCI_CFG_AD);
+	rb400_writel(CFG_CMD_IO_READ | get_be(ioaddr, size),
+		     RB400_PCI_CFG_CBE);
+	    
+	if (rb400_check_error(0))
+		return byte_mask[size - 1];
+
+	data = rb400_readl(RB400_PCI_CFG_RDDATA);
+	return (data >> (8 * (ioaddr & 3))) & byte_mask[size - 1];
+}
+
+static int rb400_pci_io_write(unsigned long ioaddr, int size, unsigned value)
+{
+	unsigned data = value << (8 * (ioaddr & 3));
+
+	rb400_writel(ioaddr, RB400_PCI_CFG_AD);
+	rb400_writel(CFG_CMD_IO_WRITE | get_be(ioaddr, size),
+		     RB400_PCI_CFG_CBE);
+	rb400_writel(data, RB400_PCI_CFG_WRDATA);
+	rb400_readl(RB400_PCI_CFG_WRDATA);
+
+	if (rb400_check_error(0))
+		return PCIBIOS_DEVICE_NOT_FOUND;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+unsigned _pci_inb(unsigned long port)
+{
+	return rb400_pci_io_read(port, 1);
+}
+
+unsigned _pci_inw(unsigned long port)
+{
+	return rb400_pci_io_read(port, 2);
+}
+
+unsigned _pci_inl(unsigned long port)
+{
+	return rb400_pci_io_read(port, 4);
+}
+
+void _pci_outb(unsigned char value, unsigned long port)
+{
+	rb400_pci_io_write(port, 1, value);
+}
+
+void _pci_outw(unsigned short value, unsigned long port)
+{
+	rb400_pci_io_write(port, 2, value);
+}
+
+void _pci_outl(unsigned value, unsigned long port)
+{
+	rb400_pci_io_write(port, 4, value);
+}
+
+EXPORT_SYMBOL(_pci_inb);
+EXPORT_SYMBOL(_pci_inw);
+EXPORT_SYMBOL(_pci_inl);
+EXPORT_SYMBOL(_pci_outb);
+EXPORT_SYMBOL(_pci_outw);
+EXPORT_SYMBOL(_pci_outl);
diff -puNrb linux-2.6.35/arch/mips/pci/ops-rb500.c linux/arch/mips/pci/ops-rb500.c
--- linux-2.6.35/arch/mips/pci/ops-rb500.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/pci/ops-rb500.c	2011-05-02 10:08:25.132897614 +0300
@@ -0,0 +1,77 @@
+#include <linux/types.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+
+#define PCI_BASE 0x18080000
+#define PCIB_REG(reg) (*(volatile u32 *) KSEG1ADDR(PCI_BASE + (reg)))
+
+#define PCIB_STATUS		0x4
+#define PCIB_CONF_ADDR          0xc
+#define PCIB_CONF_DATA          0x10
+
+#define STATUS_RLE		0x4000
+
+static inline unsigned bus_addr(struct pci_bus *bus, unsigned int devfn, int where) {
+	return 0x80000000 | (bus->number << 16) | (devfn << 8) | (where & 0xfc);
+}
+
+static int rb500_config_write(struct pci_bus *bus, unsigned int devfn, int where,
+			      int size, u32 val)
+{
+	u32 data = val;
+
+	PCIB_REG(PCIB_CONF_ADDR) = bus_addr(bus, devfn, where);
+	mb();
+
+	if (size != 4) {
+		data = PCIB_REG(PCIB_CONF_DATA);
+
+		if (size == 1) {
+			data = (data & ~(0xff << ((where & 3) << 3))) |
+				(val << ((where & 3) << 3));
+		}
+		else if (size == 2) {
+			data = (data & ~(0xffff << ((where & 3) << 3))) |
+				(val << ((where & 3) << 3));
+		}
+	}
+	PCIB_REG(PCIB_CONF_DATA) = data;
+
+	return 0;
+}
+
+static inline int rb500_config_read(struct pci_bus *bus, unsigned int devfn, int where,
+				    int size, u32 *val)
+{
+	u32 data;
+	unsigned i;
+
+	for (i = 0; i < 100; ++i) {
+	    PCIB_REG(PCIB_STATUS) = 0;
+
+	    PCIB_REG(PCIB_CONF_ADDR) = bus_addr(bus, devfn, where);
+	    mb();
+
+	    data = PCIB_REG(PCIB_CONF_DATA);
+
+	    if (!(PCIB_REG(PCIB_STATUS) & STATUS_RLE)) break;
+
+	    udelay(100);
+	}
+
+	if (size == 1)
+		*val = (data >> ((where & 3) << 3)) & 0xff;
+	else if (size == 2)
+		*val = (data >> ((where & 3) << 3)) & 0xffff;
+	else
+		*val = data;
+
+	return 0;
+}
+
+struct pci_ops rb500_pci_ops = {
+	.read = rb500_config_read,
+	.write = rb500_config_write,
+};
diff -puNrb linux-2.6.35/arch/mips/pci/ops-rb700.c linux/arch/mips/pci/ops-rb700.c
--- linux-2.6.35/arch/mips/pci/ops-rb700.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/pci/ops-rb700.c	2011-05-02 10:08:25.142903219 +0300
@@ -0,0 +1,116 @@
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <asm/delay.h>
+#include <asm/traps.h>
+#include <asm/rb/rb400.h>
+
+/*
+ * PCI cfg an I/O routines are done by programming a 
+ * command/byte enable register, and then read/writing
+ * the data from a data regsiter. We need to ensure
+ * these transactions are atomic or we will end up
+ * with corrupt data on the bus or in a driver.
+ */
+
+unsigned get_pci_crp(void) {
+    static unsigned base = 0;
+    if (!base) base = (unsigned) ioremap(0x180c0000, PAGE_SIZE);
+    return base;
+}
+
+unsigned get_pci_dev_cfgbase(void) {
+    static unsigned base = 0;
+    if (!base) base = (unsigned) ioremap(0x14000000, PAGE_SIZE);
+    return base;
+}
+
+#define RB700_PCI_CRP			get_pci_crp()
+#define RB700_PCI_DEV_CFGBASE		get_pci_dev_cfgbase()
+#define RB700_PCI_ERROR			RB700_PCI_CRP + 0x1c
+#define RB700_PCI_ERROR_ADDRESS		RB700_PCI_CRP + 0x20
+#define RB700_PCI_AHB_ERROR		RB700_PCI_CRP + 0x24
+#define RB700_PCI_AHB_ERROR_ADDRESS	RB700_PCI_CRP + 0x28
+
+static DEFINE_SPINLOCK(ar7100_pci_lock);
+
+static unsigned mask[4] = { 0xff, 0xffff, 0, 0xffffffff };
+
+static unsigned read_word(unsigned addr, int where) {
+    return rb400_readl(addr + (where & ~3));
+}
+
+static int read_config(unsigned addr, int where, int size, uint32_t *value) {
+    unsigned long flags;
+    spin_lock_irqsave(&ar7100_pci_lock, flags);
+    *value = (read_word(addr, where) >> (8 * (where & 3))) & mask[size - 1];
+    spin_unlock_irqrestore(&ar7100_pci_lock, flags);
+    return PCIBIOS_SUCCESSFUL;
+}
+
+static int rb700_local_read_config(int where, int size, uint32_t *value) {
+    return read_config(RB700_PCI_CRP, where, size, value);
+}
+
+static int write_config(unsigned addr, int where, int size, uint32_t value) {
+    unsigned long flags, word, shift;
+    spin_lock_irqsave(&ar7100_pci_lock, flags);    
+    shift = 8 * (where & 3);
+    word = (read_word(addr, where) & ~(mask[size - 1] << shift));
+    rb400_writel(word | (value << shift), addr + (where & ~3));
+    spin_unlock_irqrestore(&ar7100_pci_lock, flags);
+    return PCIBIOS_SUCCESSFUL;
+}
+
+int rb700_local_write_config(int where, int size, uint32_t value) {
+    return write_config(RB700_PCI_CRP, where, size, value);
+}
+
+static int rb700_pci_read_config(struct pci_bus *bus, unsigned int devfn,
+			  int where, int size, uint32_t *value) {
+    return devfn 
+	? PCIBIOS_DEVICE_NOT_FOUND
+	: read_config(RB700_PCI_DEV_CFGBASE, where, size, value);
+}
+
+static int rb700_pci_write_config(struct pci_bus *bus,  unsigned int devfn,
+				  int where, int size, uint32_t value) {
+    return devfn 
+	? PCIBIOS_DEVICE_NOT_FOUND
+	: write_config(RB700_PCI_DEV_CFGBASE, where, size, value);
+}
+
+struct pci_ops rb700_pci_ops = {
+	.read =  rb700_pci_read_config,
+	.write = rb700_pci_write_config,
+};
+
+int rb700_be_handler(struct pt_regs *regs, int is_fixup) {
+    int error = 0, status, trouble = 0;
+    error = rb400_readl(RB700_PCI_ERROR) & 3;
+
+    if (error) {
+        printk("PCI error %d at PCI addr 0x%x\n", 
+	       error, rb400_readl(RB700_PCI_ERROR_ADDRESS));
+        rb400_writel(error, RB700_PCI_ERROR);
+        rb700_local_read_config(PCI_STATUS, 2, &status);
+        printk("PCI status: %#x\n", status);
+        trouble = 1;
+    }
+
+    error = 0;
+    error = rb400_readl(RB700_PCI_AHB_ERROR) & 1;
+    
+    if (error) {
+        printk("AHB error at AHB address 0x%x\n", 
+	       rb400_readl(RB700_PCI_AHB_ERROR_ADDRESS));
+        rb400_writel(error, RB700_PCI_AHB_ERROR);
+        rb700_local_read_config(PCI_STATUS, 2, &status);
+        printk("PCI status: %#x\n", status);
+        trouble = 1;
+    }
+
+    printk("rb700 data bus error: cause %#x\n", read_c0_cause());
+    return (is_fixup ? MIPS_BE_FIXUP : MIPS_BE_FATAL);
+}
diff -puNrb linux-2.6.35/arch/mips/pci/pci-rb.c linux/arch/mips/pci/pci-rb.c
--- linux-2.6.35/arch/mips/pci/pci-rb.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/pci/pci-rb.c	2011-05-02 10:08:25.151716875 +0300
@@ -0,0 +1,516 @@
+#include <linux/types.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <asm/rb/rb400.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+
+#define PCI_BASE 0x18080000
+#define PCIB_REG(reg) (*(volatile u32 *) KSEG1ADDR(PCI_BASE + (reg)))
+
+#define PCIB_CONTROL		0x0
+#define PCIB_STATUS		0x4
+#define PCIB_STATUS_MASK	0x8
+#define PCIB_CONF_ADDR		0xc
+#define PCIB_CONF_DATA		0x10
+#define PCIB_LBA0		0x14
+#define PCIB_LBA0_CONTROL	0x18
+#define PCIB_LBA0_MAPPING	0x1c
+#define PCIB_LBA1		0x20
+#define PCIB_LBA1_CONTROL	0x24
+#define PCIB_LBA1_MAPPING	0x28
+#define PCIB_LBA2		0x2c
+#define PCIB_LBA2_CONTROL	0x30
+#define PCIB_LBA2_MAPPING	0x34
+#define PCIB_LBA3		0x38
+#define PCIB_LBA3_CONTROL	0x3c
+#define PCIB_LBA3_MAPPING	0x40
+#define PCIB_DA_CONTROL		0x44
+#define PCIB_DA_STATUS		0x48
+#define PCIB_DA_STATUS_MASK	0x4c
+#define PCIB_DA_DATA		0x50
+#define PCIB_TARGET_CONTROL	0x5c
+
+#define PCIC_EN  0x00000001
+#define PCIC_EAP 0x00000020
+#define PCIC_IGM 0x00000200
+
+#define PCIS_RIP 0x00020000
+
+#define PCILBA_SIZE_1MB  (20 << 2)
+#define PCILBA_SIZE_16MB (24 << 2)
+#define PCILBA_SIZE_64MB (26 << 2)
+#define PCILBA_MSI 1
+
+#define PCITC_RTIMER_DEF 16
+#define PCITC_DTIMER_DEF 8
+
+#define PCIDAS_DONE		0x1
+#define PCIDAS_BUSY		0x2
+#define PCIDAS_ERROR		0x4
+#define PCIDAS_OUT_FIFO_EMPTY	0x8
+
+#define RB400_RESET_BASE	0x18060000
+#define RB400_PCI_WINDOW_BASE	0x18000000
+#define RB400_RESET_REG(x)	((unsigned long) reset_base + (x))
+#define RB400_PCI_WINDOW_REG(x) ((unsigned long) window_base + (x))
+#define RB400_RESET		RB400_RESET_REG(0x24)
+#define RB400_PCI_WINDOW_OFFSET	RB400_PCI_WINDOW_REG(0x7c)
+
+#define RB400_PCI_BASE		0x17010000
+#define RB400_PCI_REG(x)	((unsigned long) rb400_pci_base + (x))
+#define RB400_PCI_CRP_AD_CBE	RB400_PCI_REG(0x00)
+#define RB400_PCI_CRP_WRDATA	RB400_PCI_REG(0x04)
+#define RB400_PCI_ERROR		RB400_PCI_REG(0x1c)
+#define RB400_PCI_AHB_ERROR	RB400_PCI_REG(0x24)
+
+extern struct pci_ops rb100_pci_ops;
+extern struct pci_ops rb400_pci_ops;
+extern struct pci_ops rb500_pci_ops;
+extern struct pci_ops rb700_pci_ops;
+
+int pci_decoupled_access = 0;
+
+static unsigned int bridge_bars[8] = {
+	0x00000d6a, /* 64Mb memory prefetch */
+	0x00000000,
+	0x00000051,
+	0x00000000,
+	0x00000055,
+	0x18000000,
+	0x00000000,
+	0x00000000,
+};
+
+struct resource rb500_res_pci_mem = {
+	.name = "PCI memory space",
+	.start = 0x50000000,
+	.end = 0x5FFFFFFF,
+	.flags = IORESOURCE_MEM,
+};
+
+struct resource rb500_res_pci_io = {
+	.name	= "PCI IO space",
+	.start = 0x18800000,
+	.end = 0x188FFFFF,
+	.flags = IORESOURCE_IO,
+};
+
+static struct pci_controller rb500_controller = {
+	.pci_ops = &rb500_pci_ops,
+	.io_resource = &rb500_res_pci_io,
+	.mem_resource = &rb500_res_pci_mem,
+	.io_map_base = KSEG1,
+};
+
+static struct resource rb400_res_pci_io = {
+	.name	= "PCI IO space",
+	.start	= 0x100,
+	.end	= 0xffff,
+	.flags	= IORESOURCE_IO
+};
+
+static struct resource rb400_res_pci_mem = {
+	.name	= "PCI memory space",
+	.start	= 0x10000000,
+	.end	= 0x17ffffff,
+	.flags	= IORESOURCE_MEM
+};
+
+static struct pci_controller rb400_controller = {
+	.pci_ops = &rb400_pci_ops,
+	.io_resource = &rb400_res_pci_io,
+	.mem_resource = &rb400_res_pci_mem,
+};
+
+struct resource rb100_pci_io_resource = {
+	.name = "PCI IO space", 
+	.start = 0x11500000,  
+	.end = 0x115ffff0-1,
+	.flags = IORESOURCE_IO,
+};
+
+struct resource rb100_pci_mem_resource = {
+	.name = "PCI memory space", 
+	.start = 0x11400000,
+	.end = 0x11500000-1,
+	.flags = IORESOURCE_MEM,
+};
+
+static struct pci_controller adm5120_controller = {
+	.pci_ops	= &rb100_pci_ops,
+	.io_resource	= &rb100_pci_io_resource,
+	.mem_resource	= &rb100_pci_mem_resource,
+	.io_map_base	= KSEG1,
+};
+
+static struct resource rb700_io_resource = {
+	.name = "PCI IO space",
+	.start = 0,
+	.end = 0,
+	.flags = IORESOURCE_IO
+};
+
+static struct resource rb700_mem_resource = {
+	.name = "PCI memory space",
+	.start = 0x10000000,
+	.end = 0x14000000 - 1,
+	.flags = IORESOURCE_MEM
+};
+
+static struct pci_controller rb700_controller = {
+	.pci_ops	= &rb700_pci_ops,
+	.mem_resource	= &rb700_mem_resource,
+	.io_resource	= &rb700_io_resource,
+};
+
+int is_rb500_pci_addr(volatile void __iomem *addr)
+{
+	unsigned prefix = CPHYSADDR(addr) & 0xfff00000;
+	return prefix == 0x18800000 || prefix == 0x50000000;
+}
+
+int pcibios_plat_dev_init(struct pci_dev *dev)
+{
+	return 0;
+}
+
+static int rb500_irq_map[12][4] = {
+	{ 0, 0, 0, 0 },
+	{ 0, 0, 0, 0 },
+	{ 2, 0, 0, 0 },
+	{ 3, 0, 0, 0 },
+	{ 2, 0, 0, 0 },
+	{ 3, 0, 0, 0 },
+	{ 0, 2, 1, 3 },		/* IDSEL AD16: (broken) RB564 daughterboard */
+	{ 0, 0, 0, 0 },
+	{ 0, 0, 0, 0 },
+	{ 0, 0, 0, 0 },
+	{ 0, 1, 0, 0 },
+	{ 1, 2, 0, 0 }
+};
+
+static int rb400_irq_map[7][4] = {
+	{ 50, -1, -1, -1 },
+	{ 48, 49, -1, -1 },
+	{ 49, 50, -1, -1 },
+	{ 50, 48, -1, -1 },
+	{ 48, -1, -1, -1 },
+	{ 49, 50, -1, -1 },
+	{ 50, 48, -1, -1 },
+};
+
+int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
+{
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB500: {
+		if (PCI_SLOT(dev->devfn) >= 12)
+			return -1;
+		return rb500_irq_map[slot][pin - 1] + 140;
+	}
+	case MACH_GROUP_MT_RB100:
+		if (slot < 1 || slot > 3) return -1;
+		return slot + 13;
+	case MACH_GROUP_MT_RB400:
+		if (slot < 17 || slot > 23) return -1;
+		return rb400_irq_map[slot - 17][pin - 1];
+	case MACH_GROUP_MT_RB700:
+		return 2;
+	}
+        return -1;
+}
+
+static void __init rb500_secondary_bridge_fixup(struct pci_dev *dev) {
+	/* enable i/o space & memory space and bus master control */
+	pci_write_config_word(dev, PCI_COMMAND, 7);
+
+	/* disable prefetched memory range */
+	pci_write_config_word(dev, PCI_PREF_MEMORY_LIMIT, 0);
+	pci_write_config_word(dev, PCI_PREF_MEMORY_BASE, 0x10);
+
+	pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 4);
+
+	printk("Enabled decoupled PCI access\n");
+	pci_decoupled_access = 1;
+}
+
+DECLARE_PCI_FIXUP_HEADER(0x3388, 0x0031, rb500_secondary_bridge_fixup);
+
+static void pci_bridge_fixup(struct pci_dev *dev)
+{
+	if (dev->devfn != 0)
+		return;
+
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB100:
+		pci_write_config_word(dev, PCI_COMMAND, 7);
+		pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 4);
+		pci_write_config_dword(dev, PCI_BASE_ADDRESS_0, 0);
+		pci_write_config_dword(dev, PCI_BASE_ADDRESS_1, 0);
+		break;
+	}
+}
+
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, pci_bridge_fixup);
+
+static int __init rb500_pci_init(void)
+{
+	int i;
+
+	printk("PCI: Initializing PCI\n");
+
+	PCIB_REG(PCIB_CONTROL) = 0;
+	mb();
+
+	for (i = 0; i < 100; ++i) {
+		if (!(PCIB_REG(PCIB_STATUS) & PCIS_RIP)) break;
+	}
+
+	PCIB_REG(PCIB_CONTROL) = PCIC_IGM | PCIC_EAP | PCIC_EN;
+
+	PCIB_REG(PCIB_STATUS) = 0;
+	PCIB_REG(PCIB_STATUS_MASK) = ~0;
+
+	/* disabled decoupled access */
+	PCIB_REG(PCIB_DA_CONTROL) = 0;
+	PCIB_REG(PCIB_DA_STATUS) = 0;
+	PCIB_REG(PCIB_DA_STATUS_MASK) = 0x7f;
+
+	PCIB_REG(PCIB_TARGET_CONTROL) = PCITC_RTIMER_DEF | (PCITC_DTIMER_DEF << 8);
+
+        /* setup PCI LBA0 as MEM */
+	PCIB_REG(PCIB_LBA0) = 0x50000000;
+	PCIB_REG(PCIB_LBA0_MAPPING) = 0x50000000;
+	PCIB_REG(PCIB_LBA0_CONTROL) = PCILBA_SIZE_64MB;
+
+        /* setup PCI LBA1 as IO */
+	PCIB_REG(PCIB_LBA1) = 0x18800000;
+	PCIB_REG(PCIB_LBA1_MAPPING) = 0x18800000;
+	PCIB_REG(PCIB_LBA1_CONTROL) = PCILBA_SIZE_1MB | PCILBA_MSI;
+
+	/* disable LBA2 & LBA3 */
+	PCIB_REG(PCIB_LBA2_CONTROL) = 0;
+	PCIB_REG(PCIB_LBA3_CONTROL) = 0;
+
+	for (i = 0; i < 8; ++i) {
+	    PCIB_REG(PCIB_CONF_ADDR) = 0x80000044 + i * 4;
+	    PCIB_REG(PCIB_CONF_DATA) = bridge_bars[i];
+	}
+
+	PCIB_REG(PCIB_CONF_ADDR) = 0x80000000 + (PCI_LATENCY_TIMER & ~3);
+	PCIB_REG(PCIB_CONF_DATA) |= 64 << 8;
+
+	mb();
+
+	/* give a time for some cards to read their eeproms */
+	mdelay(100);
+
+	register_pci_controller(&rb500_controller);
+
+	return 0;
+}
+
+static int __init rb100_pci_init(void)
+{
+	if (mips_machtype == MACH_MT_MR)
+		return 0;
+
+	/* Avoid ISA compat ranges.  */
+	PCIBIOS_MIN_IO = 0x00000000;
+	PCIBIOS_MIN_MEM = 0x00000000;
+
+	/* Set I/O resource limits.  */
+	ioport_resource.end = 0x1fffffff;
+	iomem_resource.end = 0xffffffff;	
+
+	register_pci_controller(&adm5120_controller);
+	return 0;
+}
+
+static int __init rb400_pci_init(void)
+{
+	void __iomem *reset_base;
+	void __iomem *window_base;
+	extern void __iomem *rb400_pci_base;
+	unsigned val;
+	unsigned i;
+
+	reset_base = ioremap(RB400_RESET_BASE, PAGE_SIZE);
+	window_base = ioremap(RB400_PCI_WINDOW_BASE, PAGE_SIZE);
+	rb400_pci_base = ioremap(RB400_PCI_BASE, PAGE_SIZE);
+
+	val = rb400_readl(RB400_RESET);
+	rb400_writel(val | 3, RB400_RESET);
+
+	if (mips_machtype == MACH_MT_RB450 ||
+	    mips_machtype == MACH_MT_RB450G)
+		return 0;
+
+	mdelay(100);
+	rb400_writel(val & ~3, RB400_RESET);
+	mdelay(100);
+
+	for (i = 0; i < 7; ++i)
+		rb400_writel(0x10000000 + 0x01000000 * i,
+			     RB400_PCI_WINDOW_OFFSET + i * 4);
+	rb400_writel(0x07000000, RB400_PCI_WINDOW_OFFSET + 7 * 4);
+
+	mdelay(100);
+
+	rb400_writel(0x00010000 | PCI_COMMAND, RB400_PCI_CRP_AD_CBE);
+	rb400_writel(0x356, RB400_PCI_CRP_WRDATA);
+
+        rb400_writel(3, RB400_PCI_ERROR);
+        rb400_writel(1, RB400_PCI_AHB_ERROR);
+
+	iounmap(reset_base);
+	iounmap(window_base);
+
+	register_pci_controller(&rb400_controller);
+
+	return 0;
+}
+
+int rb700_local_write_config(int where, int size, uint32_t value);
+
+static int __init rb700_pci_init(void) {
+	if (!(rb400_readl(0xb8050010) & 0x02000000)
+		&& rb400_readl(0xb80f0018) == 7) {
+	    uint32_t cmd = PCI_COMMAND_MEMORY
+		| PCI_COMMAND_MASTER
+		| PCI_COMMAND_INVALIDATE
+		| PCI_COMMAND_PARITY
+		| PCI_COMMAND_SERR
+		| PCI_COMMAND_FAST_BACK;
+
+	    rb700_local_write_config(PCI_COMMAND, 4, cmd);
+	    rb700_pci_ops.write(NULL, 0, PCI_COMMAND, 4, cmd);
+	    rb400_writel(rb400_readl(0xb80f0050) | (1 << 14), 0xb80f0050);
+	    if ((rb400_readl(0xb8060090) & 0xffffff00) == 0)
+		    rb700_controller.mem_offset = 0x10000000;
+	    register_pci_controller(&rb700_controller);
+	}
+
+	return 0;
+}
+
+static int __init rb_pci_init(void)
+{
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB500:
+		return rb500_pci_init();
+	case MACH_GROUP_MT_RB100:
+		return rb100_pci_init();
+	case MACH_GROUP_MT_RB400:
+		return rb400_pci_init();
+	case MACH_GROUP_MT_RB700:
+		return rb700_pci_init();
+	}
+	return 0;
+}
+
+arch_initcall(rb_pci_init);
+
+static inline unsigned rb500_read_word(volatile void __iomem *addr)
+{
+	unsigned long flags;
+	unsigned i;
+
+	local_irq_save(flags);
+
+	PCIB_REG(PCIB_DA_CONTROL) = 1;
+
+	for (i = 0; i < 10; ++i) {
+		unsigned status;
+		unsigned val;
+
+		PCIB_REG(PCIB_DA_STATUS) = 0;
+		val = *(volatile unsigned __force *) addr;
+
+		while (1) {
+			status = PCIB_REG(PCIB_DA_STATUS);
+			if (!(status & PCIDAS_BUSY)) break;
+		}
+		if (status & PCIDAS_DONE) {
+			val = ioswabl(addr, PCIB_REG(PCIB_DA_DATA));
+			PCIB_REG(PCIB_DA_CONTROL) = 0;
+			local_irq_restore(flags);
+			return val;
+		} else if (!(status & PCIDAS_ERROR)) {
+		    local_irq_restore(flags);
+		    BUG();
+		}
+	}
+	printk("via pci decoupled read failed\n");
+
+	PCIB_REG(PCIB_DA_CONTROL) = 0;
+
+	local_irq_restore(flags);
+	return 0;
+}
+
+unsigned rb500_readl(volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access || !is_rb500_pci_addr(addr))
+		return readl(addr);
+
+	return rb500_read_word(addr);
+}
+
+unsigned short rb500_readw(volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access || !is_rb500_pci_addr(addr))
+		return readw(addr);
+
+	return rb500_read_word((volatile void __iomem *) ((unsigned) addr & ~3))
+		>> (((unsigned) addr & 2) * 8);
+}
+
+unsigned char rb500_readb(volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access || !is_rb500_pci_addr(addr))
+		return readb(addr);
+
+	return rb500_read_word((volatile void __iomem *) ((unsigned) addr & ~3))
+ 		>> (((unsigned) addr & 3) * 8);
+}
+
+void rb500_writel(unsigned int b, volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access) {
+		writel(b, addr);
+	} else {
+		while (!(PCIB_REG(PCIB_DA_STATUS) & PCIDAS_OUT_FIFO_EMPTY));
+		*(volatile unsigned __force *) addr = b;
+	}
+}
+
+void rb500_writew(unsigned short b, volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access) {
+		writew(b, addr);
+	} else {
+		while (!(PCIB_REG(PCIB_DA_STATUS) & PCIDAS_OUT_FIFO_EMPTY));
+		*(volatile unsigned short __force *) addr = b;
+	}
+}
+
+void rb500_writeb(unsigned char b, volatile void __iomem *addr)
+{
+	if (!pci_decoupled_access) {
+		writeb(b, addr);
+	} else {
+		while (!(PCIB_REG(PCIB_DA_STATUS) & PCIDAS_OUT_FIFO_EMPTY));
+		*(volatile unsigned char __force *) addr = b;
+	}
+}
+
+EXPORT_SYMBOL(rb500_readl);
+EXPORT_SYMBOL(rb500_readw);
+EXPORT_SYMBOL(rb500_readb);
+
+EXPORT_SYMBOL(rb500_writel);
+EXPORT_SYMBOL(rb500_writew);
+EXPORT_SYMBOL(rb500_writeb);
diff -puNrb linux-2.6.35/arch/mips/rb/cr/irq.c linux/arch/mips/rb/cr/irq.c
--- linux-2.6.35/arch/mips/rb/cr/irq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/cr/irq.c	2011-05-02 10:08:25.162849763 +0300
@@ -0,0 +1,65 @@
+#include <linux/init.h>
+#include <linux/kernel_stat.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/pm.h>
+
+#include <asm/irq.h>
+#include <asm/mipsregs.h>
+#include <asm/irq_cpu.h>
+#include <asm/rb/cr.h>
+
+#define CR_MISR	0x20
+#define CR_MIMR 0x24
+
+static irqreturn_t cr_cascade_irq(int irq, void *dev_id)
+{
+	int pending;
+
+	pending = CR_CNTRL_REG(CR_MISR) & CR_CNTRL_REG(CR_MIMR) & 0xfd;
+	if (pending) {
+		do_IRQ(fls(pending) - 1 + CR_MISC_IRQ_BASE);
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+static void cr_unmask_irq(unsigned int irq)
+{
+	CR_CNTRL_REG(CR_MIMR) |= 1 << (irq - CR_MISC_IRQ_BASE);
+	CR_CNTRL_REG(CR_MIMR); /* flush write */
+}
+
+static void cr_mask_irq(unsigned int irq)
+{
+	CR_CNTRL_REG(CR_MIMR) &= ~(1 << (irq - CR_MISC_IRQ_BASE));
+	CR_CNTRL_REG(CR_MIMR); /* flush write */
+}
+
+static struct irq_chip cr_irq_type = {
+	.typename	= "CR",
+	.ack		= cr_mask_irq,
+	.mask		= cr_mask_irq,
+	.mask_ack	= cr_mask_irq,
+	.unmask		= cr_unmask_irq,
+	.eoi		= cr_unmask_irq,
+};
+
+static struct irqaction misc_irq = {
+	.handler	= cr_cascade_irq,
+	.name		= "cascade",
+};
+
+void __init cr_init_irq(void)
+{
+	int i;
+
+	mips_cpu_irq_init();
+	setup_irq(CR_MISC_IRQ, &misc_irq);
+	
+	for (i = CR_MISC_IRQ_BASE; i < CR_MISC_IRQ_BASE + 8; i++) {
+		set_irq_chip_and_handler(i, &cr_irq_type,
+					 handle_level_irq);
+	}
+}
diff -puNrb linux-2.6.35/arch/mips/rb/cr/Makefile linux/arch/mips/rb/cr/Makefile
--- linux-2.6.35/arch/mips/rb/cr/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/cr/Makefile	2011-05-02 10:08:25.172790971 +0300
@@ -0,0 +1,5 @@
+#
+# Makefile for the RB CR board specific parts of the kernel
+#
+
+obj-y	 := irq.o setup.o
diff -puNrb linux-2.6.35/arch/mips/rb/cr/setup.c linux/arch/mips/rb/cr/setup.c
--- linux-2.6.35/arch/mips/rb/cr/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/cr/setup.c	2011-05-02 10:08:25.192903998 +0300
@@ -0,0 +1,82 @@
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/serial.h>
+#include <linux/types.h>
+#include <linux/string.h>	/* for memset */
+#include <linux/ioport.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/serial_8250.h>
+
+#include <asm/reboot.h>
+#include <asm/io.h>
+#include <asm/time.h>
+#include <asm/pgtable.h>
+#include <asm/processor.h>
+#include <asm/system.h>
+#include <asm/rb/cr.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+
+static struct timer_list wdi_timer;
+#define WDI_INTERVAL	(10 * HZ)
+
+void cr_restart(char *command) {
+	CR_GPOUT() &= ~CR_GPIO_CRST;
+	CR_GPDIR() |= CR_GPIO_CRST;
+}
+
+void cr_halt(void) {
+        printk(KERN_NOTICE "\n** You can safely turn off the power\n");
+        while (1);
+}
+
+void __init cr_serial_console_init(void)
+{
+	struct uart_port port;
+
+	memset(&port, 0, sizeof(port));
+	port.type = PORT_16550;
+	port.uartclk =  mips_hpt_frequency;
+	port.membase = (unsigned char *) KSEG1ADDR(CR_UART_BASE);
+	port.irq = CR_UART_IRQ;
+	port.regshift = 2;
+	port.iotype = UPIO_MEM;
+	port.flags = UPF_BOOT_AUTOCONF | UPF_SKIP_TEST;
+
+	early_serial_setup(&port);
+}
+
+void __init cr_setup(void)
+{
+	cr_serial_console_init();
+
+	_machine_restart = cr_restart;
+	_machine_halt = cr_halt;
+}
+
+static void wdi_interrupt(unsigned long unused)
+{
+	local_irq_disable();
+	CR_GPOUT() ^= CR_GPIO_WDI;
+	local_irq_enable();
+
+	wdi_timer.expires = jiffies + WDI_INTERVAL;
+	add_timer(&wdi_timer);
+}
+
+static int __init wdi_setup(void)
+{
+	if (mips_machgroup != MACH_GROUP_MT_CR) return 0;
+
+	CR_GPDIR() |= CR_GPIO_WDI;	// enable as an output
+	memset(&wdi_timer, 0, sizeof(wdi_timer));
+	init_timer(&wdi_timer);
+	wdi_timer.function = wdi_interrupt;
+	wdi_interrupt(0);
+	return 0;
+}
+
+arch_initcall(wdi_setup);
diff -puNrb linux-2.6.35/arch/mips/rb/iomap.c linux/arch/mips/rb/iomap.c
--- linux-2.6.35/arch/mips/rb/iomap.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/iomap.c	2011-05-02 10:08:25.202899919 +0300
@@ -0,0 +1,263 @@
+#include <linux/module.h>
+#include <asm/io.h>
+
+#define ADM5120_CF_BASE		(void *) KSEG1ADDR(0x10E00000)
+#define ADM5120_CF_BASE2	(void *) KSEG1ADDR(0x10C00000)
+#define ADM5120_CF_SIZE		0x1000
+
+#ifdef CONFIG_SOFT_PCI_IO
+static inline int is_iorange(void *addr)
+{
+	return (unsigned long) addr < KSEG0;
+}
+#else
+static inline int is_iorange(void *addr)
+{
+        return 0;
+}
+#endif
+
+static int is_cf_region(void *addr)
+{
+	if (addr < ADM5120_CF_BASE) return 0;
+	return addr < ADM5120_CF_BASE + ADM5120_CF_SIZE;
+}
+
+static void *base2_addr(void *addr)
+{
+	return ADM5120_CF_BASE2 + ((unsigned) addr & (ADM5120_CF_SIZE - 1));
+}
+
+static u8 rb100_cf_readb(void *addr)
+{
+	unsigned long flags;
+	u8 val;
+
+	local_irq_save(flags);
+
+       	val = readb(addr);
+	readb(base2_addr(addr));
+
+	local_irq_restore(flags);
+	return val;
+}
+
+static void rb100_cf_writeb(u8 val, void *addr)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+
+       	writeb(val, addr);
+       	writeb(val, base2_addr(addr));
+
+	local_irq_restore(flags);
+}
+
+static void rb100_cf_readb_rep(void __iomem *addr, u8 *dst, unsigned count)
+{
+	unsigned long flags;
+	unsigned i;
+	void *addr2 = base2_addr(addr);
+	
+	local_irq_save(flags);
+	
+	for (i = 0; i < count; ++i) {
+	    *dst++ = readb(addr);
+	    readb(addr2);
+	}
+	
+	local_irq_restore(flags);
+}
+
+static void rb100_cf_writeb_rep(void __iomem *addr,
+				const u8 *src, unsigned count)
+{
+	unsigned long flags;
+	unsigned i;
+	void *addr2 = base2_addr(addr);
+	
+	local_irq_save(flags);
+	
+	for (i = 0; i < count; ++i) {
+	    writeb(*src, addr);
+	    writeb(*src, addr2);
+	    src++;
+	}
+
+	local_irq_restore(flags);
+}
+
+unsigned int ioread8(void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return inb((unsigned long) addr);
+	if (!is_cf_region(addr))
+		return rb500_readb(addr);
+	return rb100_cf_readb(addr);
+}
+
+EXPORT_SYMBOL(ioread8);
+
+unsigned int ioread16(void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return inw((unsigned long) addr);
+	return rb500_readw(addr);
+}
+
+EXPORT_SYMBOL(ioread16);
+
+unsigned int ioread16be(void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return be16_to_cpu(inw((unsigned long) addr));
+	return be16_to_cpu(rb500_readw(addr));
+}
+
+EXPORT_SYMBOL(ioread16be);
+
+unsigned int ioread32(void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return inl((unsigned long) addr);
+	return rb500_readl(addr);
+}
+
+EXPORT_SYMBOL(ioread32);
+
+unsigned int ioread32be(void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return be32_to_cpu(inl((unsigned long) addr));
+	return be32_to_cpu(rb500_readl(addr));
+}
+
+EXPORT_SYMBOL(ioread32be);
+
+void iowrite8(u8 val, void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return outb(val, (unsigned long) addr);
+	if (!is_cf_region(addr))
+		rb500_writeb(val, addr);
+	return rb100_cf_writeb(val, addr);
+}
+
+EXPORT_SYMBOL(iowrite8);
+
+void iowrite16(u16 val, void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return outw(val, (unsigned long) addr);
+	rb500_writew(val, addr);
+}
+
+EXPORT_SYMBOL(iowrite16);
+
+void iowrite16be(u16 val, void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return outw(cpu_to_be16(val), (unsigned long) addr);
+	rb500_writew(cpu_to_be16(val), addr);
+}
+
+EXPORT_SYMBOL(iowrite16be);
+
+void iowrite32(u32 val, void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return outl(val, (unsigned long) addr);
+	rb500_writel(val, addr);
+}
+
+EXPORT_SYMBOL(iowrite32);
+
+void iowrite32be(u32 val, void __iomem *addr)
+{
+	if (is_iorange(addr))
+		return outl(cpu_to_be16(val), (unsigned long) addr);
+	rb500_writel(cpu_to_be32(val), addr);
+}
+
+EXPORT_SYMBOL(iowrite32be);
+
+void ioread8_rep(void __iomem *addr, void *daddr, unsigned long count)
+{
+	u8 *dst = (u8 *) daddr;
+	unsigned i;
+
+	if (!is_cf_region(addr)) {
+		for (i = 0; i < count; ++i) {
+			*dst++ = rb500_readb(addr);
+		}
+	} else {
+		rb100_cf_readb_rep(addr, dst, count);
+	}
+}
+
+EXPORT_SYMBOL(ioread8_rep);
+
+void ioread16_rep(void __iomem *addr, void *daddr, unsigned long count)
+{
+	u16 *dst = (u16 *) daddr;
+	unsigned i;
+
+	for (i = 0; i < count; ++i) {
+		*dst++ = rb500_readw(addr);
+	}
+}
+
+EXPORT_SYMBOL(ioread16_rep);
+
+void ioread32_rep(void __iomem *addr, void *daddr, unsigned long count)
+{
+	u32 *dst = (u32 *) daddr;
+	unsigned i;
+
+	for (i = 0; i < count; ++i) {
+		*dst++ = rb500_readl(addr);
+	}
+}
+
+EXPORT_SYMBOL(ioread32_rep);
+
+void iowrite8_rep(void __iomem *addr, const void *saddr, unsigned long count)
+{
+	const u8 *src = (u8 *) saddr;
+	unsigned i;
+
+	if (!is_cf_region(addr)) {
+		for (i = 0; i < count; ++i) {
+			rb500_writeb(*src++, addr);
+		}
+	} else {
+		rb100_cf_writeb_rep(addr, src, count);
+	}
+}
+
+EXPORT_SYMBOL(iowrite8_rep);
+
+void iowrite16_rep(void __iomem *addr, const void *saddr, unsigned long count)
+{
+	const u16 *src = (u16 *) saddr;
+	unsigned i;
+
+	for (i = 0; i < count; ++i) {
+		rb500_writew(*src++, addr);
+	}
+}
+
+EXPORT_SYMBOL(iowrite16_rep);
+
+void iowrite32_rep(void __iomem *addr, const void *saddr, unsigned long count)
+{
+	const u32 *src = (u32 *) saddr;
+	unsigned i;
+
+	for (i = 0; i < count; ++i) {
+		rb500_writel(*src++, addr);
+	}
+}
+
+EXPORT_SYMBOL(iowrite32_rep);
+
diff -puNrb linux-2.6.35/arch/mips/rb/irq.c linux/arch/mips/rb/irq.c
--- linux-2.6.35/arch/mips/rb/irq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/irq.c	2011-05-02 10:08:25.212849809 +0300
@@ -0,0 +1,120 @@
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/bitops.h>
+#include <linux/module.h>
+#include <asm/signal.h>
+#include <asm/mipsregs.h>
+#include <asm/irq_cpu.h>
+#include <asm/bootinfo.h>
+#include <asm/vm.h>
+#include <asm/rb/boards.h>
+
+extern void rb500_init_irq(void);
+extern void rb100_init_irq(void);
+extern void rb400_init_irq(void);
+extern void cr_init_irq(void);
+
+asmlinkage void plat_irq_dispatch(void) {
+	unsigned pending = read_c0_status() & read_c0_cause() & 0xfe00;
+
+	if (pending)
+		do_IRQ(fls(pending) - (9 - MIPS_CPU_IRQ_BASE));
+}
+
+volatile unsigned long virqs;
+EXPORT_SYMBOL(virqs);
+
+static void ack_virq(unsigned int irq)
+{
+	clear_bit(irq - VIRQ_BASE, &virqs);
+}
+
+static inline void unmask_virq(unsigned int irq)
+{
+}
+
+static inline void mask_virq(unsigned int irq)
+{
+}
+
+static struct irq_chip virq_controller = {
+	.name	= "virq",
+	.ack	= ack_virq,
+	.unmask = unmask_virq,
+	.mask	= mask_virq,
+};
+
+static irqreturn_t virq_cascade_irq(int irq, void *dev_id)
+{
+	unsigned i;
+	unsigned irqs = virqs;
+
+	for (i = 0; irqs; ++i) {
+		if (irqs & (1 << i)) {
+			do_IRQ(i + VIRQ_BASE);
+			irqs ^= (1 << i);
+		}
+	}
+	return IRQ_HANDLED;
+}
+
+static struct irqaction virq_cascade  = {
+	.handler = virq_cascade_irq,
+	.name = "virq-cascade",
+};
+
+static void soft_irq_ack(unsigned int irq)
+{
+	clear_c0_cause(0x100 << (irq - MIPS_CPU_IRQ_BASE));
+}
+
+static inline void unmask_soft_irq(unsigned int irq)
+ {
+	set_c0_status(0x100 << (irq - MIPS_CPU_IRQ_BASE));
+	irq_enable_hazard();
+ }
+ 
+static inline void mask_soft_irq(unsigned int irq)
+{
+	clear_c0_status(0x100 << (irq - MIPS_CPU_IRQ_BASE));
+	irq_disable_hazard();
+}
+
+static struct irq_chip soft_irq_controller = {
+	.name	= "MIPS",
+	.ack	= soft_irq_ack,
+	.unmask = unmask_soft_irq,
+	.mask	= mask_soft_irq,
+};
+
+void __init arch_init_irq(void)
+{
+	unsigned i;
+
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB500:
+		rb500_init_irq();
+		break;
+	case MACH_GROUP_MT_RB100:
+		rb100_init_irq();
+		break;
+	case MACH_GROUP_MT_RB400:
+	case MACH_GROUP_MT_RB700:
+		rb400_init_irq();
+		break;
+	case MACH_GROUP_MT_CR:
+		cr_init_irq();
+		break;
+	case MACH_GROUP_MT_VM:
+		mips_cpu_irq_init();
+		break;
+	}
+
+	set_irq_chip_and_handler(1, &soft_irq_controller, handle_percpu_irq);
+	setup_irq(1, &virq_cascade);
+
+	for (i = VIRQ_BASE;  i < VIRQ_BASE + 32; ++i)
+		set_irq_chip_and_handler(i, &virq_controller, handle_edge_irq);
+}
diff -puNrb linux-2.6.35/arch/mips/rb/Makefile linux/arch/mips/rb/Makefile
--- linux-2.6.35/arch/mips/rb/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/Makefile	2011-05-02 10:08:25.222848661 +0300
@@ -0,0 +1 @@
+obj-y += prom.o platform.o irq.o iomap.o
diff -puNrb linux-2.6.35/arch/mips/rb/platform.c linux/arch/mips/rb/platform.c
--- linux-2.6.35/arch/mips/rb/platform.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/platform.c	2011-05-02 10:08:25.242908026 +0300
@@ -0,0 +1,830 @@
+#include <linux/platform_device.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/spi/spi.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#include <asm/serial.h>
+
+static struct platform_device rb100_uart_device = {
+	.name	= "rb100-uart",
+	.id	= -1,
+};
+
+static struct platform_device rb500_nand_device = {
+	.name	= "rb500-nand",
+	.id	= -1,
+};
+
+static struct platform_device rb500r5_nand_device = {
+	.name	= "rb500r5-nand",
+	.id	= -1,
+};
+
+static struct platform_device rb700_nand_device = {
+	.name	= "rb700-nand",
+	.id	= -1,
+	.dev	= {
+		.platform_data = (void *)0,
+	},
+};
+
+static struct platform_device rb700_nolatch_nand_device = {
+	.name	= "rb700-nand",
+	.id	= -1,
+	.dev	= {
+		.platform_data = (void *)1,
+	},
+};
+
+static struct platform_device rb700_tiny_nand_device = {
+	.name	= "rb700-nand",
+	.id	= -1,
+	.dev	= {
+		.platform_data = (void *)2,
+	},
+};
+
+static struct platform_device rb750g_nand_device = {
+	.name	= "rb750g-nand",
+	.id	= -1,
+};
+
+static struct platform_device rb100_nand_device = {
+	.name	= "rb100-nand",
+	.id	= -1,
+};
+
+static struct platform_device cr_nand_device = {
+	.name	= "cr-nand",
+	.id	= -1,
+};
+
+static struct platform_device mr_nand_device = {
+	.name	= "mr-nand",
+	.id	= -1,
+};
+
+static struct spi_board_info rb400_spi_misc = {
+	.modalias = "rb400-spi-misc",
+	.max_speed_hz = 10 * 1000 * 1000,
+	.bus_num = 0,
+	.chip_select = 0,
+	.mode = SPI_MODE_0,
+};
+static struct spi_board_info rb400_spi_nand = {
+	.modalias = "rb400-spi-nand",
+	.max_speed_hz = 33 * 1000 * 1000,
+	.bus_num = 0,
+	.chip_select = 1,
+	.mode = SPI_MODE_0,
+};
+static struct spi_board_info rb400_spi_microsd = {
+	.modalias = "mmc_spi",
+	.max_speed_hz = 10 * 1000 * 1000,
+	.bus_num = 0,
+	.chip_select = 2,
+	.mode = SPI_MODE_0,
+};
+
+static struct spi_board_info *rb400_spi_info[] = {
+	&rb400_spi_misc,
+	&rb400_spi_nand,
+	NULL
+};
+
+static struct spi_board_info *rb433_spi_info[] = {
+	&rb400_spi_misc,
+	&rb400_spi_nand,
+	&rb400_spi_microsd,
+	NULL
+};
+
+static struct spi_board_info *rb750_spi_info[] = {
+	&rb400_spi_misc,
+	NULL
+};
+
+static struct platform_device rb400_spi_device = {
+	.name	= "rb400-spi",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb400_spi_info,
+	},
+};
+
+static struct platform_device rb433_spi_device = {
+	.name	= "rb400-spi",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb433_spi_info,
+	},
+};
+
+static struct platform_device rb750_spi_device = {
+	.name	= "rb400-spi",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb750_spi_info,
+	},
+};
+
+static struct platform_device flash_nor_device = {
+	.name	= "flash-nor",
+	.id	= -1,
+};
+
+static struct platform_device flash_spi_device = {
+	.name	= "flash-spi",
+	.id	= -1,
+};
+
+static struct platform_device korina_device = {
+	.name	= "korina",
+	.id	= -1,
+};
+
+static struct platform_device rb100_led_device = {
+	.name	= "rb100-led",
+	.id	= -1,
+};
+
+static struct platform_device rb112_led_device = {
+	.name	= "rb112-led",
+	.id	= -1,
+};
+
+static int rb400_led_map[] = { 0x100, 0x14, 0x24, 0x44, 0x84, 0x1004, -1 };
+static struct platform_device rb400_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb400_led_map,
+	},
+};
+
+static int rb450g_led_map[] = { 0x100, 0x1004, -1 };
+static struct platform_device rb450g_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb450g_led_map,
+	},
+};
+
+static int rb493g_led_map[] = { 0x100, 0x14, 0x44, 0x24, 0x84, 0x1004, -1 };
+static struct platform_device rb493g_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb493g_led_map,
+	},
+};
+
+static int rb700_led_map[] = { 0x10007, -1 };
+static struct platform_device rb700_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb700_led_map,
+	},
+};
+
+static int sxt5d_led_map[] =
+	{ 0x10007, 0x20f, 0x40f, 0x80f, 0x100f, 0x200f, 0x8f, -1 };
+static struct platform_device sxt5d_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = sxt5d_led_map,
+	},
+};
+
+static int groove_led_map[] =
+	{ 0x10007, 0x200f, 0x100f, 0x80f, 0x40f, 0x20f, 0x8f, -1 };
+static struct platform_device groove_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = groove_led_map,
+	},
+};
+
+static int rb711_led_map[] =
+	{ 0x27, 0x10007, 0x20007, 0x40007, 0x80007, 0x100007, -1 };
+static struct platform_device rb711_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb711_led_map,
+	},
+};
+
+static int rb711r3_led_map[] =
+	{ 0x27, 0x10007, 0x40007, 0x80007, 0x100007, 0, 0x10f, -1 };
+static struct platform_device rb711r3_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb711r3_led_map,
+	},
+};
+
+static int rb750g_led_map[] = { 0x100, -1 };
+static struct platform_device rb750g_led_device = {
+	.name	= "rb400-led",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb750g_led_map,
+	},
+};
+
+static struct platform_device rb500_led_device = {
+	.name	= "rb500-led",
+	.id	= -1,
+};
+
+static struct platform_device cr_led_device = {
+	.name	= "cr-led",
+	.id	= -1,
+};
+
+static struct platform_device mr_led_device = {
+	.name	= "mr-led",
+	.id	= -1,
+};
+
+static int rb411_eth_port_map[] = { 1, 0, 1, -1 };
+static struct platform_device rb411_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb411_eth_port_map,
+	},
+};
+
+static int rb433_eth_port_map[] = { 2, 1, 4, -1, 0, 175, 1, 2, -1 };
+static struct platform_device rb433_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb433_eth_port_map,
+	},
+};
+
+
+
+
+static int rb450_eth_port_map[] = { 2, 1, 4, -1, 0, 175, 3, 2, 1, 0, -1 };
+static struct platform_device rb450_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb450_eth_port_map,
+	},
+};
+
+static int rb450g_eth_port_map[] = { 2, 1, 4, -1, 0, 8316, 0, 3, 2, 1, -1 };
+static struct platform_device rb450g_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb450g_eth_port_map,
+	},
+};
+
+static int rb711_eth_port_map[] = { 1, 0, 4, -1 };
+static struct platform_device rb711_eth_device = {
+	.name	= "ag7240",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb711_eth_port_map,
+	},
+};
+
+static int rb711r3_eth_port_map[] = { 1, 1, 7240, 0, -1 };
+static struct platform_device rb711r3_eth_device = {
+	.name	= "ag7240",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb711r3_eth_port_map,
+	},
+};
+
+static int rb750_eth_port_map[] = { 2, 0, 4, -1, 1, 7240, 3, 2, 1, 0, -1 };
+static struct platform_device rb750_eth_device = {
+	.name	= "ag7240",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb750_eth_port_map,
+	},
+};
+
+static int rb493g_eth_port_map[] = { 3, 0, 8316, 4, -1,
+				     1, 8316, 1, 2, 3, 0, -1,
+				     0, 8316, 1, 3, 2, 0, -1 };
+static struct platform_device rb493g_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb493g_eth_port_map,
+	},
+};
+
+static int rb750g_eth_port_map[] = { 1, 0, 8316, 0, 1, 2, 3, 4, -1 };
+static struct platform_device rb750g_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb750g_eth_port_map,
+	},
+};
+
+
+
+
+
+
+
+static int rb493_eth_port_map[] = { 2, 0, 1, -1,
+				    1, 178, 0, 1, 2, 3, 4, 5, 6, 7, -1 };
+static struct platform_device rb493_eth_device = {
+	.name	= "ag7100",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb493_eth_port_map,
+	},
+};
+
+static int rb112_eth_port_map[] = { -1, 0, -1 };
+
+static struct platform_device rb112_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb112_eth_port_map,
+	},
+};
+
+static int rb153_eth_port_map[] = { -1, 0, 4, 3, 2, 1, -1 };
+
+static struct platform_device rb153_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb153_eth_port_map,
+	},
+};
+
+static int rb133_eth_port_map[] = { -1, 2, 1, 0, -1 };
+
+static struct platform_device rb133_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb133_eth_port_map,
+	},
+};
+
+static int rb133c_eth_port_map[] = { -1, 2, -1 };
+
+static struct platform_device rb133c_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb133c_eth_port_map,
+	},
+};
+
+static int rb192_eth_port_map[] = { 5, 0, 4, 3, 2, 1, 101, 102, 103, 104, -1 };
+
+static struct platform_device rb192_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = rb192_eth_port_map,
+	},
+};
+
+static int mr_eth_port_map[] = { -1, 4, 3, 2, 1, 0, -1 };
+
+static struct platform_device mr_eth_device = {
+	.name	= "admtek",
+	.id	= -1,
+	.dev	= {
+		.platform_data = mr_eth_port_map,
+	},
+};
+
+static struct platform_device cr_eth_device = {
+	.name	= "cr-ether",
+	.id	= -1,
+};
+
+static struct platform_device cr_wlan_device = {
+	.name	= "cr-wlan",
+	.id	= -1,
+};
+
+static struct platform_device rb500_cf_device = {
+	.name	= "rb500-cf",
+	.id	= -1,
+};
+
+static struct platform_device rb100_cf_device = {
+	.name	= "rb100-cf",
+	.id	= -1,
+};
+
+static u64 dmamask = ~(u32) 0;
+
+static struct resource rb400_ohci_resources[] = {
+	[0] = {
+		.start		= 0x1c000000,
+		.end		= 0x1cffffff,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= 22,
+		.end		= 22,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device rb400_ohci_device = {
+	.name		= "rb400-ohci",
+	.id		= 0,
+	.dev		= {
+		.dma_mask		= &dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(rb400_ohci_resources),
+	.resource	= rb400_ohci_resources,
+};
+
+static struct resource rb400_ehci_resources[] = {
+	[0] = {
+		.start		= 0x1b000000,
+		.end		= 0x1bffffff,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= 3,
+		.end		= 3,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device rb400_ehci_device = {
+	.name		= "rb400-ehci",
+	.id		= 0,
+	.dev		= {
+		.dma_mask		= &dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(rb400_ehci_resources),
+	.resource	= rb400_ehci_resources,
+};
+
+static struct platform_device *rb112_devices[] = {
+	&rb100_uart_device,
+	&rb100_nand_device,
+	&rb112_eth_device,
+	&flash_nor_device,
+	&rb112_led_device,
+};
+
+static struct platform_device *rb153_devices[] = {
+	&rb100_uart_device,
+	&rb100_nand_device,
+	&rb153_eth_device,
+	&rb100_cf_device,
+	&flash_nor_device,
+	&rb100_led_device,
+};
+
+static struct platform_device *rb133_devices[] = {
+	&rb100_uart_device,
+	&rb100_nand_device,
+	&rb133_eth_device,
+	&flash_nor_device,
+	&rb100_led_device,
+};
+
+static struct platform_device *rb133c_devices[] = {
+	&rb100_uart_device,
+	&rb100_nand_device,
+	&rb133c_eth_device,
+	&flash_nor_device,
+	&rb100_led_device,
+};
+
+static struct platform_device *rb192_devices[] = {
+	&rb100_uart_device,
+	&rb100_nand_device,
+	&rb192_eth_device,
+	&flash_nor_device,
+	&rb100_led_device,
+};
+
+static struct platform_device *mr_devices[] = {
+	&rb100_uart_device,
+	&mr_nand_device,
+	&mr_eth_device,
+	&flash_nor_device,
+	&mr_led_device,
+};
+
+static struct platform_device *rb500_devices[] = {
+	&rb500_nand_device,
+	&korina_device,
+	&rb500_cf_device,
+	&flash_nor_device,
+	&rb500_led_device,
+};
+
+static struct platform_device *rb500r5_devices[] = {
+	&rb500r5_nand_device,
+	&korina_device,
+	&rb500_cf_device,
+	&flash_nor_device,
+	&rb500_led_device,
+};
+
+static struct platform_device *rb411_devices[] = {
+	&rb400_spi_device,
+	&rb411_eth_device,
+	&rb400_led_device,
+};
+
+static struct platform_device *rb411u_devices[] = {
+	&rb400_ohci_device,
+	&rb400_ehci_device,
+	&rb400_spi_device,
+	&rb411_eth_device,
+	&rb400_led_device,
+};
+
+static struct platform_device *rb433_devices[] = {
+	&rb433_spi_device,
+	&rb433_eth_device,
+	&rb400_led_device,
+};
+
+static struct platform_device *rb433u_devices[] = {
+	&rb400_ohci_device,
+	&rb400_ehci_device,
+	&rb433_spi_device,
+	&rb433_eth_device,
+	&rb400_led_device,
+};
+
+
+
+
+static struct platform_device *rb450_devices[] = {
+	&rb400_spi_device,
+	&rb450_eth_device,
+	&rb400_led_device,
+};
+
+static struct platform_device *rb450g_devices[] = {
+	&rb433_spi_device,
+	&rb450g_eth_device,
+	&rb450g_led_device,
+};
+
+static struct platform_device *rb493_devices[] = {
+	&rb400_spi_device,
+	&rb493_eth_device,
+	&rb400_led_device,
+};
+
+static struct platform_device *rb493g_devices[] = {
+	&rb400_ohci_device,
+	&rb400_ehci_device,
+	&rb433_spi_device,
+	&rb493g_eth_device,
+	&rb493g_led_device,
+};
+
+static struct platform_device *rb750g_devices[] = {
+	&rb750_spi_device,
+	&rb750g_nand_device,
+	&rb750g_eth_device,
+	&rb750g_led_device,
+};
+
+static struct platform_device *cr_devices[] = {
+	&cr_nand_device,
+	&cr_eth_device,
+	&cr_wlan_device,
+	&flash_spi_device,
+	&cr_led_device,
+};
+
+static struct resource rb700_ohci_resources[] = {
+	[0] = {
+		.start		= 0x1b000000,
+		.end		= 0x1bffffff,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= 3,
+		.end		= 3,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device rb700_ohci_device = {
+	.name		= "rb400-ohci",
+	.id		= 0,
+	.dev		= {
+		.dma_mask		= &dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(rb700_ohci_resources),
+	.resource	= rb700_ohci_resources,
+};
+
+static struct resource rb700_ehci_resources[] = {
+	[0] = {
+		.start		= 0x1b000000,
+		.end		= 0x1bffffff,
+		.flags		= IORESOURCE_MEM,
+	},
+	[1] = {
+		.start		= 3,
+		.end		= 3,
+		.flags		= IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device rb700_ehci_device = {
+	.name		= "rb400-ehci",
+	.id		= 0,
+	.dev		= {
+		.dma_mask		= &dmamask,
+		.coherent_dma_mask	= 0xffffffff,
+	},
+	.num_resources	= ARRAY_SIZE(rb700_ehci_resources),
+	.resource	= rb700_ehci_resources,
+};
+
+static struct platform_device *rb711_devices[] = {
+	&rb700_ohci_device,
+	&rb700_ehci_device,
+	&rb750_spi_device,
+	&rb700_nand_device,
+	&rb711_led_device,
+	&rb711_eth_device,
+};
+
+static struct platform_device *rb711r3_devices[] = {
+	&rb700_ohci_device,
+	&rb700_ehci_device,
+	&rb750_spi_device,
+	&rb700_nand_device,
+	&rb711r3_led_device,
+	&rb711r3_eth_device,
+};
+
+
+
+
+
+
+
+
+static struct platform_device *rb_sxt5d_devices[] = {
+	&rb700_ohci_device,
+	&rb700_ehci_device,
+	&rb750_spi_device,
+	&rb700_nolatch_nand_device,
+	&sxt5d_led_device,
+	&rb711r3_eth_device
+};
+
+static struct platform_device *rb_groove_devices[] = {
+	&rb700_ohci_device,
+	&rb700_ehci_device,
+	&rb750_spi_device,
+	&rb700_nolatch_nand_device,
+	&groove_led_device,
+	&rb711r3_eth_device
+};
+
+static struct platform_device *rb750_devices[] = {
+	&rb700_ohci_device,
+	&rb700_ehci_device,
+	&rb750_spi_device,
+	&rb700_tiny_nand_device,
+	&rb700_led_device,
+	&rb750_eth_device
+};
+
+static struct platform_driver fake_serial8250_driver = {
+	.driver = {
+		.name = "serial8250",
+	},
+};
+
+int rb_platform_init(void)
+{
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB100:
+		platform_driver_register(&fake_serial8250_driver);
+
+		switch (mips_machtype) {
+		case MACH_MT_RB100:
+			return platform_add_devices(
+			    rb112_devices, ARRAY_SIZE(rb112_devices));
+		case MACH_MT_RB150:
+			return platform_add_devices(
+			    rb153_devices, ARRAY_SIZE(rb153_devices));
+		case MACH_MT_RB133:
+			return platform_add_devices(
+			    rb133_devices, ARRAY_SIZE(rb133_devices));
+		case MACH_MT_RB133C:
+			return platform_add_devices(
+			    rb133c_devices, ARRAY_SIZE(rb133c_devices));
+		case MACH_MT_RB192:
+			return platform_add_devices(
+			    rb192_devices, ARRAY_SIZE(rb192_devices));
+		case MACH_MT_MR:
+			return platform_add_devices(
+			    mr_devices, ARRAY_SIZE(mr_devices));
+		}
+		break;
+	case MACH_GROUP_MT_RB500:
+		switch (mips_machtype) {
+		case MACH_MT_RB500:
+			return platform_add_devices(
+			    rb500_devices, ARRAY_SIZE(rb500_devices));
+		case MACH_MT_RB500R5:
+			return platform_add_devices(
+			    rb500r5_devices, ARRAY_SIZE(rb500r5_devices));
+		}
+		break;
+	case MACH_GROUP_MT_RB400:
+		switch (mips_machtype) {
+		case MACH_MT_RB411:
+			return platform_add_devices(
+				rb411_devices,  ARRAY_SIZE(rb411_devices));
+		case MACH_MT_RB411U:
+			return platform_add_devices(
+				rb411u_devices,  ARRAY_SIZE(rb411u_devices));
+		case MACH_MT_RB433:
+			return platform_add_devices(
+				rb433_devices,  ARRAY_SIZE(rb433_devices));
+		case MACH_MT_RB433U:
+			return platform_add_devices(
+				rb433u_devices,  ARRAY_SIZE(rb433u_devices));
+		case MACH_MT_RB450:
+			return platform_add_devices(
+				rb450_devices,  ARRAY_SIZE(rb450_devices));
+		case MACH_MT_RB450G:
+			return platform_add_devices(
+				rb450g_devices,  ARRAY_SIZE(rb450g_devices));
+		case MACH_MT_RB493:
+			return platform_add_devices(
+				rb493_devices,  ARRAY_SIZE(rb493_devices));
+		case MACH_MT_RB493G:
+			return platform_add_devices(
+				rb493g_devices,  ARRAY_SIZE(rb493g_devices));
+		case MACH_MT_RB750G:
+			return platform_add_devices(
+				rb750g_devices,  ARRAY_SIZE(rb750g_devices));
+		}
+		break;
+	case MACH_GROUP_MT_RB700:
+		switch (mips_machtype) {
+		case MACH_MT_RB711:
+			return platform_add_devices(
+				rb711_devices,  ARRAY_SIZE(rb711_devices));
+		case MACH_MT_RB711R3:
+			return platform_add_devices(
+				rb711r3_devices,  ARRAY_SIZE(rb711r3_devices));
+		case MACH_MT_RB_SXT5D:
+			return platform_add_devices(
+			    rb_sxt5d_devices,  ARRAY_SIZE(rb_sxt5d_devices));
+		case MACH_MT_RB_GROOVE:
+			return platform_add_devices(
+			    rb_groove_devices,  ARRAY_SIZE(rb_groove_devices));
+		case MACH_MT_RB750:
+			return platform_add_devices(
+				rb750_devices,  ARRAY_SIZE(rb750_devices));
+		}
+		break;
+	case MACH_GROUP_MT_CR:
+		return platform_add_devices(
+		    cr_devices, ARRAY_SIZE(cr_devices));
+	case MACH_GROUP_MT_VM:
+		return 0;
+	}
+
+	printk("ERROR: unknown RB version\n");
+	return 0;
+}
+
+arch_initcall(rb_platform_init);
diff -puNrb linux-2.6.35/arch/mips/rb/prom.c linux/arch/mips/rb/prom.c
--- linux-2.6.35/arch/mips/rb/prom.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/prom.c	2011-05-02 10:08:25.262897934 +0300
@@ -0,0 +1,305 @@
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/string.h>
+#include <linux/console.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#include <linux/bootmem.h>
+#include <linux/ioport.h>
+#include <linux/ctype.h>
+#include <linux/irq.h>
+#include <linux/initrd.h>
+
+#define FREQ_TAG   "HZ="
+#define BOARD_TAG  "board="
+
+#define SR_NMI	0x00180000
+
+extern void rb500_setup(void);
+extern void rb100_setup(void);
+extern void rb400_setup(void);
+extern void cr_setup(void);
+extern void rbvm_setup(void);
+
+extern char arcs_cmdline[COMMAND_LINE_SIZE];
+
+extern unsigned long totalram_pages;
+extern unsigned long mips_hpt_frequency;
+
+unsigned char mips_mac_address[6];
+
+unsigned long mips_machgroup __read_mostly = 0;
+EXPORT_SYMBOL(mips_machgroup);
+
+const char *get_system_type(void)
+{
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB100:
+		switch (mips_machtype) {
+		case MACH_MT_RB100:
+			return "Mikrotik RB100";
+		case MACH_MT_RB150:
+			return "Mikrotik RB150";
+		case MACH_MT_RB133:
+			return "Mikrotik RB133";
+		case MACH_MT_RB133C:
+			return "Mikrotik RB133C";
+		case MACH_MT_RB192:
+			return "Mikrotik RB192";
+		case MACH_MT_MR:
+			return "Mikrotik MR";
+		}
+		break;
+	case MACH_GROUP_MT_RB500:
+		switch (mips_machtype) {
+		case MACH_MT_RB500:
+			return "Mikrotik RB500";
+		case MACH_MT_RB500R5:
+			return "Mikrotik RB500r5";
+		}
+		break;
+	case MACH_GROUP_MT_RB400:
+		switch (mips_machtype) {
+		case MACH_MT_RB411:
+			return "Mikrotik RB411";
+		case MACH_MT_RB411U:
+			return "Mikrotik RB411U";
+		case MACH_MT_RB433:
+			return "Mikrotik RB433";
+		case MACH_MT_RB433U:
+			return "Mikrotik RB433U";
+		case MACH_MT_RB450:
+			return "Mikrotik RB450";
+		case MACH_MT_RB450G:
+			return "Mikrotik RB450G";
+		case MACH_MT_RB493:
+			return "Mikrotik RB493";
+		case MACH_MT_RB750G:
+			return "Mikrotik RB750G";
+		}
+		break;
+	case MACH_GROUP_MT_RB700:
+		switch (mips_machtype) {
+		case MACH_MT_RB711R3:
+		case MACH_MT_RB711:
+			return "Mikrotik RB711";
+		case MACH_MT_RB_SXT5D:
+			return "Mikrotik SXT-5D";
+		case MACH_MT_RB_GROOVE:
+			return "Mikrotik Groove-5H";
+		case MACH_MT_RB750:
+			return "Mikrotik RB750";
+		}
+		break;
+	case MACH_GROUP_MT_CR:
+		switch (mips_machtype) {
+		case MACH_MT_CR1:
+			return "Mikrotik CR";
+		}
+	case MACH_GROUP_MT_VM:
+		return "Mikrotik VM";
+	}
+	return "unknown routerboard";
+}
+
+void __init prom_init(void)
+{
+	int argc = fw_arg0;
+	char **argv = (char **) fw_arg1;
+	unsigned char board_type[16];
+
+	unsigned i, offset = 0;
+
+	set_io_port_base(KSEG1);
+
+	memset(board_type, 0, sizeof(board_type));
+
+	/* HZ must be parsed here because otherwise is too late */
+	for (i = 0; (i < argc && argv[i] != NULL); i++) {
+		if (strncmp(argv[i], FREQ_TAG, sizeof(FREQ_TAG) - 1) == 0) {
+			mips_hpt_frequency = 
+			    simple_strtoul(argv[i] + sizeof(FREQ_TAG) - 1, 0, 10);
+			continue;
+		}
+		if (strncmp(argv[i], BOARD_TAG, sizeof(BOARD_TAG) - 1) == 0) {
+			strncpy(board_type, argv[i] + sizeof(BOARD_TAG) - 1,
+				sizeof(board_type));
+		}
+		offset += snprintf(arcs_cmdline + offset, sizeof(arcs_cmdline) - offset,
+				   "%s ", argv[i]);
+	}
+
+	if (strncmp(board_type, "500r5", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB500;
+		mips_machtype = MACH_MT_RB500R5;
+	} else if (strncmp(board_type, "411", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB411;
+	} else if (strncmp(board_type, "750G", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB750G;
+	} else if (strncmp(board_type, "750i", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB750;
+	} else if (strncmp(board_type, "751", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB750;
+	} else if (strncmp(board_type, "711r3", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB711R3;
+	} else if (strncmp(board_type, "711", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB711;
+	} else if (strncmp(board_type, "groove", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB_SXT5D;
+	} else if (strncmp(board_type, "groove-5", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB700;
+		mips_machtype = MACH_MT_RB_GROOVE;
+	} else if (strncmp(board_type, "411U", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB411U;
+	} else if (strncmp(board_type, "433", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB433;
+	} else if (strncmp(board_type, "433U", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB433U;
+	} else if (strncmp(board_type, "450", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB450;
+	} else if (strncmp(board_type, "450G", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB450G;
+	} else if (strncmp(board_type, "493G", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB493G;
+	} else if (strncmp(board_type, "493", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB400;
+		mips_machtype = MACH_MT_RB493;
+	} else if (strncmp(board_type, "100", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_RB100;
+	} else if (strncmp(board_type, "150", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_RB150;
+	} else if (strncmp(board_type, "133", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_RB133;
+	} else if (strncmp(board_type, "133C", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_RB133C;
+	} else if (strncmp(board_type, "192", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_RB192;
+	} else if (strncmp(board_type, "mr", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_RB100;
+		mips_machtype = MACH_MT_MR;
+	} else if (strncmp(board_type, "cr", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_CR;
+		mips_machtype = MACH_MT_CR1;
+	} else if (strncmp(board_type, "vm", sizeof(board_type)) == 0) {
+		mips_machgroup = MACH_GROUP_MT_VM;
+		mips_machtype = 0;
+	} else {
+		mips_machgroup = MACH_GROUP_MT_RB500;
+		mips_machtype = MACH_MT_RB500;
+	}
+}
+
+void __init prom_free_prom_memory(void)
+{
+	unsigned long addr, end;
+	extern char _text;
+
+	/*
+	 * Free everything below the kernel itself but leave
+	 * the first page reserved for the exception handlers.
+	 */
+
+	end = __pa(&_text);
+	addr = PAGE_SIZE;
+
+	while (addr < end) {
+		ClearPageReserved(virt_to_page(__va(addr)));
+		init_page_count(virt_to_page(__va(addr)));
+		free_page((unsigned long)__va(addr));
+		addr += PAGE_SIZE;
+		++totalram_pages;
+	}
+}
+
+void __init plat_mem_setup(void)
+{
+#ifdef CONFIG_BLK_DEV_INITRD
+	extern int _end;
+	u32 *initrd_header;
+
+	initrd_header = __va(PAGE_ALIGN(__pa_symbol(&_end) + 8)) - 8;
+	if (initrd_header[0] == 0x494E5244) {
+		initrd_start = (unsigned long) (initrd_header + 2);
+                initrd_end = initrd_start + initrd_header[1];
+	}
+#endif    
+
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB500:
+		rb500_setup();
+		break;
+	case MACH_GROUP_MT_RB100:
+		rb100_setup();
+		break;
+	case MACH_GROUP_MT_RB400:
+	case MACH_GROUP_MT_RB700:
+		rb400_setup();
+		break;
+	case MACH_GROUP_MT_CR:
+		cr_setup();
+		break;
+	case MACH_GROUP_MT_VM:
+		rbvm_setup();
+		break;
+	}
+}
+
+void __init plat_time_init(void)
+{
+}
+
+static int __init setup_kmac(char *s)
+{
+	int i, j;
+	unsigned char result, value;
+
+	for (i = 0; i < 6; i++) {
+		if (s[0] == '\0' || s[1] == '\0') return 0;
+		if (i != 5 && s[2] != ':') return 0;
+
+		result = 0;
+		for (j = 0; j < 2; j++) {
+			if (!isxdigit(*s)) return 0;
+
+			value = isdigit(*s) ? *s - '0' :
+				toupper(*s) - 'A' + 10;
+			if (value >= 16) return 0;
+
+			result = result * 16 + value;
+                        s++;
+                }
+
+                s++;
+                mips_mac_address[i] = result;
+        }
+
+        return *s == '\0';
+}
+
+__setup("kmac=", setup_kmac);
+
+EXPORT_SYMBOL(mips_mac_address);
+
+unsigned long long sched_clock(void)
+{
+	return read_c0_count() * 1000000000 / mips_hpt_frequency;
+}
diff -puNrb linux-2.6.35/arch/mips/rb/rb100/irq.c linux/arch/mips/rb/rb100/irq.c
--- linux-2.6.35/arch/mips/rb/rb100/irq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb100/irq.c	2011-05-02 10:08:25.272844571 +0300
@@ -0,0 +1,84 @@
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <asm/irq_cpu.h>
+#include <asm/irq.h>
+
+#define MAX_IRQ_NR 10
+#define IRQ_BASE 8
+
+#define INTC_BASE 0x12200000
+
+#define ADM5120_INTC_REG(reg) \
+	(*((volatile unsigned *) (KSEG1ADDR(INTC_BASE + (reg)))))
+
+#define INTC_IRQ_STATUS 0x00
+#define INTC_IRQ_ENABLE 0x08
+#define INTC_IRQ_DISABLE 0x0c
+
+extern asmlinkage void rb100_IRQ(void);
+
+static void rb100_mask_irq(unsigned irq)
+{
+	ADM5120_INTC_REG(INTC_IRQ_DISABLE) = 1 << (irq - IRQ_BASE);
+}
+
+static void rb100_unmask_irq(unsigned irq)
+{
+	ADM5120_INTC_REG(INTC_IRQ_ENABLE) = 1 << (irq - IRQ_BASE);
+}
+
+void rb100_irqdispatch(void)
+{
+	unsigned pending = read_c0_status() & read_c0_cause() & 0xfc00;
+	unsigned long intsrc;
+	int i;
+
+	if (pending & CAUSEF_IP7) {
+	    do_IRQ(7);
+	    return;
+	}
+	if (!(pending & CAUSEF_IP2))
+	    return;
+
+	intsrc = ADM5120_INTC_REG(INTC_IRQ_STATUS) & ((1 << MAX_IRQ_NR) - 1);
+
+	/* do not run softirqs on timer & OProfile irq */
+	if (intsrc & 0x1) generic_handle_irq(IRQ_BASE + 0);
+
+	for (i = IRQ_BASE + 1; intsrc; intsrc >>= 1, i++)
+		if (intsrc & 0x2)
+			do_IRQ(i);
+}
+
+static struct irq_chip rb100_irq_controller = {
+	.typename	= "ADM5120",
+	.ack		= rb100_mask_irq,
+	.mask		= rb100_mask_irq,
+	.mask_ack	= rb100_mask_irq,
+	.unmask		= rb100_unmask_irq,
+};
+
+static struct irqaction cascade  = {
+	.handler = no_action,
+	.name = "cascade",
+};
+
+static struct irqaction beeper  = {
+	.handler = no_action,
+	.name = "beeper",
+};
+
+void __init rb100_init_irq(void)
+{
+	int i;
+
+	mips_cpu_irq_init();
+	set_except_vector(0, rb100_IRQ);
+	
+	for (i = IRQ_BASE; i < IRQ_BASE + MAX_IRQ_NR; i++)
+		set_irq_chip_and_handler(i, &rb100_irq_controller,
+					 handle_level_irq);
+
+	setup_irq(2, &cascade);
+	setup_irq(3, &beeper);
+}
diff -puNrb linux-2.6.35/arch/mips/rb/rb100/Makefile linux/arch/mips/rb/rb100/Makefile
--- linux-2.6.35/arch/mips/rb/rb100/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb100/Makefile	2011-05-02 10:08:25.282790376 +0300
@@ -0,0 +1 @@
+obj-y    := setup.o irq.o mipsIRQ.o
diff -puNrb linux-2.6.35/arch/mips/rb/rb100/mipsIRQ.S linux/arch/mips/rb/rb100/mipsIRQ.S
--- linux-2.6.35/arch/mips/rb/rb100/mipsIRQ.S	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb100/mipsIRQ.S	2011-05-02 10:08:25.292791082 +0300
@@ -0,0 +1,70 @@
+#define __ASSEMBLY__ 1
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/regdef.h>
+#include <asm/stackframe.h>
+#include <asm/irqflags.h>
+
+#define IRQ_ENABLE_REG	0xb2200008
+#define IRQ_DISABLE_REG	0xb220000c
+#define GPIO_CONF_REG	0xb20000b8
+#define TIMER_INT_REG	0xb20000f0
+#define TIMER_REG	0xb20000f4
+
+#define FIQ_INT		CAUSEF_IP3
+#define TIMER_IRQ	1
+#define GPIO6		(1 << 6)
+
+	.text
+	.set	noreorder
+	.set	noat
+	.align	5
+
+NESTED(rb100_IRQ, PT_SIZE, sp)
+#ifndef NO_BEEPER
+	/* beeper uses timer (IRQ_7) */
+	/* timer and only timer should generate FIQ (fast interrupt) */
+	mfc0	k0, CP0_CAUSE
+	nop
+	andi	k0, FIQ_INT
+	beq	k0, zero, 1f
+	nop
+
+	li	k1, GPIO_CONF_REG
+	lw	k0, 0(k1)
+	li	k1, GPIO6 << 24
+	xor	k0, k0, k1
+	li	k1, GPIO_CONF_REG
+	sw	k0, 0(k1)
+
+	la	k1, beep_delay
+	lw	k0, 0(k1)
+	li	k1, TIMER_REG
+	sw	k0, 0(k1)
+	li	k1, TIMER_INT_REG
+	li	k0, 1
+	sw	k0, 0(k1)
+
+	mfc0	k0, CP0_CAUSE
+	li	k1, ~FIQ_INT
+	and	k0, k0, k1
+	bne	k0, zero, 1f
+	nop
+	eret
+1:
+#endif
+	
+	SAVE_ALL
+	CLI
+	TRACE_IRQS_OFF
+	LONG_L	s0, TI_REGS($28)
+	LONG_S	sp, TI_REGS($28)
+	PTR_LA	ra, ret_from_irq
+
+	.set	at
+
+	j	rb100_irqdispatch
+	nop
+
+END(rb100_IRQ)
diff -puNrb linux-2.6.35/arch/mips/rb/rb100/setup.c linux/arch/mips/rb/rb100/setup.c
--- linux-2.6.35/arch/mips/rb/rb100/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb100/setup.c	2011-05-02 10:08:25.311589811 +0300
@@ -0,0 +1,108 @@
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/serial.h>
+#include <linux/types.h>
+#include <linux/module.h>
+
+#include <asm/bootinfo.h>
+#include <asm/reboot.h>
+#include <asm/io.h>
+#include <asm/time.h>
+#include <asm/pgtable.h>
+#include <asm/processor.h>
+#include <asm/system.h>
+
+#define INTC_BASE   0x12200000
+#define SWCTRL_BASE 0x12000000
+
+#define ADM5120_SW_REG(reg) \
+        (*((volatile unsigned *) (KSEG1ADDR(SWCTRL_BASE + (reg)))))
+#define ADM5120_INTC_REG(reg) \
+        (*((volatile unsigned *) (KSEG1ADDR(INTC_BASE + (reg)))))
+
+#define IRQ_TIMER 0
+
+#define INTC_IRQ_ENABLE		0x08
+#define INTC_IRQ_DISABLE	0x0c
+#define INTC_IRQ_MODE		0x14
+
+#define SW_SOFT_RESET		0x0004
+#define SW_CPU_PORT_CONF	0x0024
+#define SW_PORT_CONF0		0x0028
+#define SW_GPIO			0x00b8
+#define SW_TIMER_INT		0x00f0
+#define SW_TIMER		0x00f4
+
+#define GPIO6_OUTPUT_EN		0x00400000
+#define GPIO6_OUTPUT_HI		0x40000000
+
+#define SW_SOFTWARE_RESET 1
+
+#define SW_CPU_PORT_DISABLE 0x00000001
+
+#define SW_PORT_DISABLE_MASK 0x0000003F
+
+static int beeper_enabled = 1;
+unsigned beep_delay = 0;
+
+void rb100_restart(char *command) {
+	/* Disable All ports*/
+	ADM5120_SW_REG(SW_PORT_CONF0) |= SW_PORT_DISABLE_MASK;
+
+	/* Disable CPU port */
+	ADM5120_SW_REG(SW_CPU_PORT_CONF) |= SW_CPU_PORT_DISABLE;
+
+	/* Wait until switch DMA idle. At least 1ms is required! */
+	mdelay(1);
+
+	ADM5120_SW_REG(SW_SOFT_RESET) = SW_SOFTWARE_RESET;
+}
+
+void rb100_halt(void) {
+        printk(KERN_NOTICE "\n** You can safely turn off the power\n");
+        while (1);
+}
+
+void rb100_beep(unsigned freq) {
+    if (!beeper_enabled) return;
+
+    if (freq) {
+	/* limit to 23Hz-10kHz */
+	beep_delay =
+	    max_t(unsigned, min_t(unsigned, 1562500 / 2 / freq, 0xffff), 78u) | (1u << 16);
+
+	ADM5120_INTC_REG(INTC_IRQ_MODE) = (1 << IRQ_TIMER); /* enable FIQ */
+	ADM5120_INTC_REG(INTC_IRQ_ENABLE) = (1 << IRQ_TIMER);
+	
+	ADM5120_SW_REG(SW_TIMER) = beep_delay;
+	ADM5120_SW_REG(SW_TIMER_INT) = 1;
+
+	ADM5120_SW_REG(SW_GPIO) |= GPIO6_OUTPUT_EN | GPIO6_OUTPUT_HI;
+    } else {
+	beep_delay = 0;
+
+	ADM5120_INTC_REG(INTC_IRQ_MODE) = 0; /* disable FIQ */
+	ADM5120_INTC_REG(INTC_IRQ_DISABLE) = (1 << IRQ_TIMER);
+
+	ADM5120_SW_REG(SW_TIMER) = beep_delay;
+	ADM5120_SW_REG(SW_TIMER_INT) = 1 << 16;
+
+	ADM5120_SW_REG(SW_GPIO) &= ~(GPIO6_OUTPUT_EN | GPIO6_OUTPUT_HI);
+    }
+}
+
+void rb100_enable_beeper(int enable)
+{
+	if (!enable && beep_delay) rb100_beep(0);
+	beeper_enabled = enable;
+}
+EXPORT_SYMBOL(rb100_enable_beeper);
+
+void __init rb100_setup(void) {
+	_machine_restart = rb100_restart;
+	_machine_halt = rb100_halt;
+}
+
+EXPORT_SYMBOL(rb100_beep);
diff -puNrb linux-2.6.35/arch/mips/rb/rb400/irq.c linux/arch/mips/rb/rb400/irq.c
--- linux-2.6.35/arch/mips/rb/rb400/irq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb400/irq.c	2011-05-02 10:08:25.321588610 +0300
@@ -0,0 +1,167 @@
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#include <asm/rb/rb400.h>
+#include <asm/irq_cpu.h>
+
+#define REG_INT(x)		((unsigned) int_base + (x))
+#define REG_INT_STATUS		REG_INT(0x10)
+#define REG_INT_MASK		REG_INT(0x14)
+#define REG_PCI_INT_STATUS	REG_INT(0x18)
+#define REG_PCI_INT_MASK	REG_INT(0x1c)
+
+#define REG_DDR_PCI_FLUSH	((unsigned) flush_base + 0xa8)
+
+static void __iomem *int_base;
+static void __iomem *flush_base;
+
+static void rb400_ack_irq(unsigned int irq)
+{
+	rb400_writel(rb400_readl(REG_INT_STATUS) & ~(1 << (irq - IRQ_BASE)),
+		     REG_INT_STATUS);
+	rb400_readl(REG_INT_STATUS);
+}
+
+static void rb400_unmask_irq(unsigned int irq)
+{
+	rb400_writel(rb400_readl(REG_INT_MASK) | (1 << (irq - IRQ_BASE)),
+		     REG_INT_MASK);
+	rb400_readl(REG_INT_MASK);
+}
+
+static void rb400_mask_irq(unsigned int irq)
+{
+	rb400_writel(rb400_readl(REG_INT_MASK) & ~(1 << (irq - IRQ_BASE)),
+		     REG_INT_MASK);
+	rb400_readl(REG_INT_MASK);
+}
+
+static struct irq_chip rb700_irq_controller = {
+	.typename	= "RB700",
+	.ack		= rb400_ack_irq,
+	.mask		= rb400_mask_irq,
+	.unmask		= rb400_unmask_irq,
+	.eoi		= rb400_unmask_irq,
+};
+
+static struct irq_chip rb400_irq_controller = {
+	.typename	= "RB400",
+	.ack		= rb400_mask_irq,
+	.mask		= rb400_mask_irq,
+	.mask_ack	= rb400_mask_irq,
+	.unmask		= rb400_unmask_irq,
+	.eoi		= rb400_unmask_irq,
+};
+
+static irqreturn_t rb400_cascade_irq(int irq, void *dev_id)
+{
+	int pending;
+   
+	pending = rb400_readl(REG_INT_STATUS) 
+	    & rb400_readl(REG_INT_MASK) & 0xff;
+
+	if (pending) {
+		do_IRQ(fls(pending) - 1 + IRQ_BASE);
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+static struct irqaction cascade  = {
+	.handler = rb400_cascade_irq,
+	.name = "cascade",
+};
+
+static void rb400_pci_unmask_irq(unsigned int irq)
+{
+	rb400_writel(
+		rb400_readl(REG_PCI_INT_MASK) | (1 << (irq - PCI_IRQ_BASE)),
+		REG_PCI_INT_MASK);
+	rb400_readl(REG_PCI_INT_MASK);
+}
+
+static void rb400_pci_mask_irq(unsigned int irq)
+{
+	rb400_writel(
+		rb400_readl(REG_PCI_INT_MASK) & ~(1 << (irq - PCI_IRQ_BASE)),
+		REG_PCI_INT_MASK);
+	rb400_readl(REG_PCI_INT_MASK);
+}
+
+static struct irq_chip rb400_pci_irq_controller = {
+	.typename	= "RB400 PCI",
+	.ack		= rb400_pci_mask_irq,
+	.mask		= rb400_pci_mask_irq,
+	.mask_ack	= rb400_pci_mask_irq,
+	.unmask		= rb400_pci_unmask_irq,
+	.eoi		= rb400_pci_unmask_irq,
+};
+
+static inline void rb400_flush_pci_to_memory(void)
+{
+	rb400_writel(1, REG_DDR_PCI_FLUSH);
+	while ((rb400_readl(REG_DDR_PCI_FLUSH) & 0x1));
+	rb400_writel(1, REG_DDR_PCI_FLUSH);
+	while ((rb400_readl(REG_DDR_PCI_FLUSH) & 0x1));
+}
+
+static irqreturn_t rb400_pci_cascade_irq(int irq, void *dev_id)
+{
+	int pending;
+   
+	pending  = rb400_readl(REG_PCI_INT_STATUS) &
+	    rb400_readl(REG_PCI_INT_MASK) & 0x7;
+
+	rb400_flush_pci_to_memory();
+
+	if (pending) {
+		do_IRQ(fls(pending) - 1 + PCI_IRQ_BASE);
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+static struct irqaction pci_cascade  = {
+	.handler = rb400_pci_cascade_irq,
+	.name = "pci-cascade",
+};
+
+void rb700_enable_pci_irq(void);
+
+void __init rb400_init_irq(void)
+{
+	int i;
+	struct irq_chip *irq_controller = &rb400_irq_controller;
+
+	if (mips_machgroup == MACH_GROUP_MT_RB700) {
+	    irq_controller = &rb700_irq_controller;
+	}
+	mips_cpu_irq_init();
+
+	for (i = IRQ_BASE; i < IRQ_BASE + 8; i++)
+		set_irq_chip_and_handler(i, irq_controller, handle_level_irq);
+	setup_irq(6, &cascade);
+
+	if (mips_machgroup == MACH_GROUP_MT_RB400 &&
+	    mips_machtype != MACH_MT_RB450G &&
+	    mips_machtype != MACH_MT_RB450) {
+		for (i = PCI_IRQ_BASE; i < PCI_IRQ_BASE + 4; i++)
+			set_irq_chip_and_handler(i, &rb400_pci_irq_controller,
+						 handle_level_irq);
+		setup_irq(2, &pci_cascade);
+	}
+}
+
+static int __init base_init(void)
+{
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB400:
+	case MACH_GROUP_MT_RB700:
+		int_base = ioremap(0x18060000, PAGE_SIZE);
+		flush_base = ioremap(0x18000000, PAGE_SIZE);
+		break;
+	}
+	return 0;
+}
+arch_initcall(base_init);
diff -puNrb linux-2.6.35/arch/mips/rb/rb400/Makefile linux/arch/mips/rb/rb400/Makefile
--- linux-2.6.35/arch/mips/rb/rb400/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb400/Makefile	2011-05-02 10:08:25.331596632 +0300
@@ -0,0 +1,7 @@
+#
+# Makefile for the RB400 board specific parts of the kernel
+#
+
+obj-y	 := setup.o irq.o
+
+obj-$(CONFIG_SPI_RB400) += spi.o
diff -puNrb linux-2.6.35/arch/mips/rb/rb400/setup.c linux/arch/mips/rb/rb400/setup.c
--- linux-2.6.35/arch/mips/rb/rb400/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb400/setup.c	2011-05-02 10:08:25.341544781 +0300
@@ -0,0 +1,415 @@
+#include <linux/kernel.h>
+#include <linux/irq.h>
+#include <linux/serial_8250.h>
+#include <linux/serial.h>
+#include <linux/dma-mapping.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <asm/bootinfo.h>
+#include <asm/dma-mapping.h>
+#include <asm/reboot.h>
+#include <asm/addrspace.h>
+#include <asm/traps.h>
+#include <asm/rb/boards.h>
+#include <asm/rb/rb400.h>
+#include <asm/time.h>
+
+#define RESET_BASE	0x18060000
+#define RESET_REG(x)	((unsigned long) reset_base + (x))
+static unsigned RST_RESET = 0x24;
+#define REG_RESET		RESET_REG(RST_RESET)
+#define REG_TIMER		RESET_REG(0)
+#define REG_TIMER_RELOAD	RESET_REG(4)
+#define TIMER_IRQ_NUM	16
+#define RST_RESET_RB750		0x1C
+#define RESET_CPU		(1 << 24)
+#define RESET_USB_OHCI_DLL	(1 << 6)
+#define RESET_USB_HOST		(1 << 5)
+#define RESET_USB_PHY		(1 << 4)
+#define RESET_USB	(RESET_USB_OHCI_DLL | RESET_USB_HOST | RESET_USB_PHY)
+
+#define PLL_BASE	0x18050000
+
+#define USB_BASE	0x18030000
+#define USB_REG(x)	((unsigned long) usb_base + (x))
+#define REG_USB_FLADJ	USB_REG(0x00)
+#define REG_USB_CONFIG	USB_REG(0x04)
+
+#define SLIC_BASE	0x18090000
+#define SLIC_REG(x)	((unsigned long) slic_base + (x))
+#define REG_SLIC_CTRL	SLIC_REG(0x04)
+#define SLIC_CTRL_INIT	0x7
+#define REG_SLIC_FREQ	SLIC_REG(0x30)
+
+#define DMA_BASE	0x180a0000
+#define DMA_REG(x)	((unsigned long) dma_base + (x))
+#define REG_DMA_ADDR	DMA_REG(0x3c)
+#define REG_DMA_CFG	DMA_REG(0x40)
+#define DMA_CFG_INIT	0x170
+#define REG_DMA_UPD	DMA_REG(0x44)
+#define DMA_START	0x3
+#define REG_DMA_INT	DMA_REG(0x48)
+#define ENABLE_INT	0x2000
+
+#define GPIO_BASE	0x18040000
+#define GPIO_REG(x)	((unsigned long) gpio_base + (x))
+#define REG_GPIO_OUT	GPIO_REG(0x08)
+#define REG_GPIO_SET	GPIO_REG(0x0c)
+#define REG_GPIO_CLEAR	GPIO_REG(0x10)
+#define GPO_BEEP_RB700	(1 << 13)
+#define REG_GPIO_FN	GPIO_REG(0x28)
+#define GPIO_EN_I2S	0x20000
+
+#define STEREO_BASE	0x180b0000
+#define STEREO_REG(x)	((unsigned long) stereo_base + (x))
+#define REG_STEREO		STEREO_REG(0x00)
+#define  STEREO_ENABLE_AR71  0x010101ff
+#define REG_STEREO_VOL_AR71	STEREO_REG(0x04)
+#define  DMA_DESC_OWN	     (1<<31)
+
+#define SLIC_IRQ_NUM	23
+
+struct dma_beep_desc {
+	u32 size;
+	u32 addr;
+	u32 next;
+};
+
+static void __iomem *dma_base;
+static void __iomem *reset_base;
+static void __iomem *gpio_base;
+
+extern unsigned mips_hpt_frequency;
+extern struct plat_serial8250_port rb400_uart_data[];
+static unsigned ahb_freq = -1u;
+
+static char beep_xor;
+static unsigned beep_buf_size;       /* bufer size */
+static unsigned char *beep_buf;      /* for rewrite bufer and stop beep */
+struct dma_beep_desc *dma_audio;
+
+int rb400_be_handler(struct pt_regs *regs, int is_fixup);
+int rb700_be_handler(struct pt_regs *regs, int is_fixup);
+
+static void rb400_restart(char *command)
+{
+	while (1)
+		rb400_writel(RESET_CPU, REG_RESET);
+}
+
+static void rb400_halt(void)
+{
+	printk(KERN_NOTICE "\n** You can safely turn off the power\n");
+	while (1);
+}
+
+static irqreturn_t rb400_beep_int(int irq, void *data)
+{
+	if (mips_machgroup == MACH_GROUP_MT_RB400) {
+		if (mips_machtype == MACH_MT_RB750G) return IRQ_NONE;
+		rb400_writel(rb400_readl(REG_DMA_INT) & (~0xff), REG_DMA_INT);
+		rb400_writel(DMA_START, REG_DMA_UPD);    
+		return IRQ_HANDLED;
+	} else {
+		return IRQ_NONE;
+	}
+}
+
+static void set_nth_bit(unsigned char *buf, unsigned bit)
+{
+	buf[(bit >> 3) ^ beep_xor] |= (0x80 >> (bit & 0x7));
+}
+
+static void set_bit_range(unsigned char *buf, unsigned offset, unsigned bits)
+{
+	int i;
+	for (i = 0; i < bits; ++i) {
+		set_nth_bit(buf, offset + i);
+	}
+}
+
+static void fill_buffer(unsigned char *buf, const unsigned buf_size,
+			unsigned freq, const unsigned sample_freq)
+{
+	const unsigned num_samples = buf_size * 8;
+	unsigned loops = ((freq * num_samples + (sample_freq / 2))
+			  / sample_freq);
+	unsigned samples_added = 0;
+	unsigned i = 0;
+
+	memset(buf, 0, buf_size);
+	for (i = 1; i <= loops; ++i) {
+		unsigned samples_till_loop = i * num_samples / loops;
+		unsigned samples_to_add = samples_till_loop - samples_added;
+
+		set_bit_range(buf, samples_added, samples_to_add / 2);
+		samples_added += samples_to_add;
+	}
+}
+
+static int is_4xx_gpio_beep(void) {
+    return 0;
+}
+
+static int is_750(void) {
+    return (mips_machgroup == MACH_GROUP_MT_RB700
+	    && mips_machtype == MACH_MT_RB750);
+}
+
+static unsigned get_pin_num(void) {
+    if (is_4xx_gpio_beep()) {
+	return (1 << 9);
+    }
+    else {
+	return GPO_BEEP_RB700;
+    }
+}
+
+static irqreturn_t rb700_beep_int(int irq, void *data)
+{
+	unsigned beep_pin = get_pin_num();
+	if (rb400_readl(REG_GPIO_OUT) & beep_pin) {
+		rb400_writel(beep_pin, REG_GPIO_CLEAR);
+	}
+	else {
+		rb400_writel(beep_pin, REG_GPIO_SET);
+	}
+	return IRQ_HANDLED;
+}
+
+int __init rb400_beep_init(void)
+{
+	void __iomem *slic_base;
+	void __iomem *stereo_base;
+	int err;
+
+	if (mips_machgroup == MACH_GROUP_MT_RB400 && !is_4xx_gpio_beep()) {
+		if (mips_machtype == MACH_MT_RB750G) return 0;
+	} else if (mips_machgroup == MACH_GROUP_MT_RB700
+		   || is_4xx_gpio_beep()) {
+		if (is_750()) return 0;
+		rb400_writel(ahb_freq / 1000, REG_TIMER_RELOAD);
+		err = request_irq(TIMER_IRQ_NUM, &rb700_beep_int,
+				  0, "beeper", NULL);
+		if (err)
+			printk("beeper: could not request irq %d\n",
+			       TIMER_IRQ_NUM);
+		else
+			disable_irq_nosync(TIMER_IRQ_NUM);
+		return err;
+	} else {
+		return 0;
+	}
+
+	slic_base = ioremap(SLIC_BASE, PAGE_SIZE);
+	stereo_base = ioremap(STEREO_BASE, PAGE_SIZE);
+
+	rb400_writel(rb400_readl(REG_GPIO_FN) | GPIO_EN_I2S, REG_GPIO_FN);
+	rb400_writel(0x2, REG_SLIC_FREQ);
+	rb400_writel(SLIC_CTRL_INIT, REG_SLIC_CTRL);
+
+	if (mips_machgroup == MACH_GROUP_MT_RB400) {
+		beep_xor = 1;
+		beep_buf_size = 0x400;       /* bufer size for AR71 */
+		rb400_writel(STEREO_ENABLE_AR71, REG_STEREO);
+		rb400_writel(0, REG_STEREO_VOL_AR71);
+		rb400_writel(DMA_CFG_INIT, REG_DMA_CFG); 
+	}
+	iounmap(stereo_base);
+	iounmap(slic_base);
+
+	beep_buf = kmalloc(beep_buf_size, GFP_KERNEL);
+
+	err = request_irq(SLIC_IRQ_NUM, &rb400_beep_int,
+			  0, "beeper", (void *) 1);
+	if (err) 
+		printk("beeper: could not request irq %d\n", SLIC_IRQ_NUM);
+	return err;
+}
+device_initcall(rb400_beep_init);
+
+void rb400_beep(unsigned freq)
+{
+	static const unsigned sample_freq = 156800;
+	dma_addr_t phys;
+
+	printk("rb400_beep %u\n", freq);
+	if (mips_machgroup == MACH_GROUP_MT_RB400 && !is_4xx_gpio_beep()) {
+		if (mips_machtype == MACH_MT_RB750G) return;
+		if (freq == 0) {
+			rb400_writel(0, REG_DMA_INT);
+			memset(beep_buf, 0, beep_buf_size);
+			dma_map_single(NULL, beep_buf, beep_buf_size,
+				       DMA_TO_DEVICE);
+			return;
+		}
+		fill_buffer(beep_buf, beep_buf_size, freq, sample_freq);
+		phys = dma_map_single(NULL, beep_buf, beep_buf_size,
+				      DMA_TO_DEVICE);
+		rb400_writel((unsigned) phys, REG_DMA_ADDR);
+		rb400_writel(ENABLE_INT, REG_DMA_INT);
+		rb400_writel(DMA_START, REG_DMA_UPD);
+	} else if (mips_machgroup == MACH_GROUP_MT_RB700
+		   || is_4xx_gpio_beep()) {
+		static int running = 0;
+		if (freq == 0) {
+			if (running)
+				disable_irq_nosync(TIMER_IRQ_NUM);
+			rb400_writel(get_pin_num(), REG_GPIO_CLEAR);
+			running = 0;
+			return;
+		}
+		rb400_writel(ahb_freq / (freq * 2), REG_TIMER_RELOAD);
+		rb400_writel(0, REG_TIMER);
+		enable_irq(TIMER_IRQ_NUM);
+		running = 1;
+	}
+}
+EXPORT_SYMBOL(rb400_beep);
+
+static void __init rb400_ahb_freq_init(void)
+{
+	unsigned ahb_div;
+	void __iomem *pll;
+
+	pll = ioremap(PLL_BASE, PAGE_SIZE);
+	if (mips_machgroup != MACH_GROUP_MT_RB400) {
+		ahb_div = ((rb400_readl((unsigned long) pll) >> 19) & 0x1) + 1;
+	}
+	else {
+		ahb_div = ((rb400_readl((unsigned long) pll) >> 20) & 0x7) + 1;
+	}
+	ahb_freq = mips_hpt_frequency / ahb_div;
+
+	if (mips_machtype == MACH_MT_RB_SXT5D) {
+		/* lower PCI express frequency to avoid interference on SXT */
+		rb400_writel(0x00099722, 0x18 + (unsigned long) pll);
+		rb400_writel(0xc009a378, 0x14 + (unsigned long) pll);
+	}
+	iounmap(pll);
+}
+
+static void __init rb400_serial_console_init(void)
+{
+	struct uart_port port;
+	memset(&port, 0, sizeof(port));
+	port.type = PORT_16550;
+	port.uartclk =  ahb_freq;
+	port.mapbase = 0x18020000;
+	port.irq = 19;
+	port.regshift = 2;
+	port.iotype = UPIO_MEM;
+	port.flags = UPF_BOOT_AUTOCONF | UPF_SKIP_TEST | UPF_IOREMAP;
+
+	early_serial_setup(&port);
+}
+
+static void __init rb400_usb_reset(void)
+{
+	void __iomem *usb_base;
+	
+	if (mips_machgroup != MACH_GROUP_MT_RB400)
+		return;
+	if (mips_machtype == MACH_MT_RB433U) {
+	} else if (mips_machtype == MACH_MT_RB493G) {
+	} else if (mips_machtype == MACH_MT_RB411U) {
+	} else {
+		return;
+	}
+
+	usb_base = ioremap(USB_BASE, PAGE_SIZE);
+
+	rb400_writel(rb400_readl(REG_RESET) | RESET_USB, REG_RESET);
+	rb400_readl(REG_RESET);
+	mdelay(1000);
+	rb400_writel(rb400_readl(REG_RESET) & ~RESET_USB, REG_RESET);
+	rb400_readl(REG_RESET);
+
+	/* swap descriptors & data to big endian */
+	rb400_writel(0xf0000, REG_USB_CONFIG);
+	/* Adjust the duration between two SOFS */
+	rb400_writel(0x20c00, REG_USB_FLADJ);
+	rb400_readl(REG_USB_CONFIG);
+
+	mdelay(900);
+
+	iounmap(usb_base);
+}
+
+unsigned uart_enabled = 1;
+
+static int __init disable_uart(char *s) {
+    uart_enabled = 0;
+    return 1;
+}
+
+__setup("no-uart", disable_uart);
+
+#if 0
+static irqreturn_t rb400_perfirq(int irq, void *arg) {
+    return perf_irq();
+}
+
+static int __init rb400_setupperfirq(void) {
+	(void)request_irq(21, &rb400_perfirq, 0, "perf", NULL);
+	return 0;
+}
+device_initcall(rb400_setupperfirq);
+#endif
+
+static int __init rb400_postsetup(void)
+{
+	if (mips_machgroup == MACH_GROUP_MT_RB400) {
+	} else if (mips_machgroup == MACH_GROUP_MT_RB700) {
+		RST_RESET = RST_RESET_RB750;
+	} else {
+		return 0;
+	}
+
+	dma_base = ioremap(DMA_BASE, PAGE_SIZE);
+	reset_base = ioremap(RESET_BASE, PAGE_SIZE);
+	gpio_base = ioremap(GPIO_BASE, PAGE_SIZE);
+
+	rb400_ahb_freq_init();
+	if (uart_enabled) rb400_serial_console_init();
+	rb400_usb_reset();
+
+	return 0;
+}
+arch_initcall(rb400_postsetup);
+
+void __init rb400_setup(void)
+{
+	_machine_restart = rb400_restart;
+	_machine_halt = rb400_halt;
+	switch (mips_machgroup) {
+	case MACH_GROUP_MT_RB400:
+		board_be_handler = rb400_be_handler;
+		break;
+	case MACH_GROUP_MT_RB700:
+		board_be_handler = rb700_be_handler;
+		break;
+	}
+
+	set_io_port_base(0);
+}
+
+#define RST_VERSION		0x00000090
+
+int is_ar7240(void) {
+    unsigned rev = rb400_readl(RESET_REG(RST_VERSION)) & 0xfff0;
+    return rev == 0xc0;
+}
+EXPORT_SYMBOL(is_ar7240);
+
+int register_ag7100_driver(struct platform_driver *drv)
+{
+	return platform_driver_register(drv);
+}
+EXPORT_SYMBOL(register_ag7100_driver);
+
+void unregister_ag7100_driver(struct platform_driver *drv)
+{
+	return platform_driver_unregister(drv);
+}
+EXPORT_SYMBOL(unregister_ag7100_driver);
diff -puNrb linux-2.6.35/arch/mips/rb/rb400/spi.c linux/arch/mips/rb/rb400/spi.c
--- linux-2.6.35/arch/mips/rb/rb400/spi.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb400/spi.c	2011-05-02 10:08:25.361590578 +0300
@@ -0,0 +1,148 @@
+#include <linux/kernel.h>
+#include <linux/module.h>	/* for EXPORT_SYMBOL() */
+#include <linux/string.h>	/* for memcpy() */
+#include <linux/hardirq.h>	/* for in_atomic() */
+#include <linux/platform_device.h>
+#include <linux/spi/spi.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#include <asm/rb/rb400.h>
+
+#define REG_GPIO_SET	KSEG1ADDR(0x1804000C)
+#define REG_GPIO_CLR	KSEG1ADDR(0x18040010)
+
+static struct spi_device *spi = 0;
+
+struct spi_device *rb400_spi_get(void) {
+	return spi;
+}
+EXPORT_SYMBOL(rb400_spi_get);
+
+static void rb400_spi_async_complete(void *msg_buf) {
+	kfree(msg_buf);
+}
+
+static void rb400_spi_write_async(const uint8_t *buf, unsigned len) {
+	struct msg_async {
+		struct spi_message m;
+		struct spi_transfer t;
+		uint8_t data[];
+	};
+
+	struct msg_async *ma;
+		
+	ma = kzalloc(sizeof(*ma) + len, GFP_KERNEL);
+	if (ma == NULL) {
+		printk(KERN_ERR "rb400_spi_write_async failed: OOM\n");
+		return;
+	}
+	spi_message_init(&ma->m);
+	spi_message_add_tail(&ma->t, &ma->m);
+
+	ma->t.tx_buf = ma->data;
+	ma->t.len = len;
+	memcpy(ma->data, buf, len);
+
+	ma->m.context = ma;
+	ma->m.complete = rb400_spi_async_complete;
+
+	spi_async(spi, &ma->m);
+}
+
+void rb400_change_cfg(unsigned off, unsigned on) {
+	static unsigned cfg = (CFG_BIT_nLED1 | CFG_BIT_nLED2 |
+			       CFG_BIT_nLED3 | CFG_BIT_nLED4 |
+			       CFG_BIT_nLED5);
+	unsigned ocfg;
+	unsigned ncfg;
+
+	static DEFINE_SPINLOCK(lock);
+	unsigned long flags;
+
+	spin_lock_irqsave(&lock, flags);
+	ocfg = cfg;
+	cfg = (cfg & ~off) | on;
+	ncfg = cfg;
+	spin_unlock_irqrestore(&lock, flags);
+	/*
+	 * FIXME: it is possible to send CFG changes in wrong order
+	 *	  in case if task switch happens here:
+	 *		1) LED change gets interrupted here
+	 *		2) NAND_ALE change is finished, it gets interrupted
+	 *		3) LED change finishes, ALE change is lost at moment
+	 *		4) NAND write is done with missing ALE!!!
+	 */
+
+	if ((ncfg ^ ocfg) & 0xff) {
+		unsigned char buf[2] = { SPI_CMD_WRITE_CFG, ncfg };
+
+		if (in_atomic())
+			rb400_spi_write_async(buf, 2);
+		else
+			spi_write(spi, buf, 2);
+	}
+	if ((ncfg ^ ocfg) & CFG_BIT_nLED5) {
+		uint8_t cmd = ((ncfg & CFG_BIT_nLED5) ?
+			       SPI_CMD_LED5_OFF :
+			       SPI_CMD_LED5_ON);
+		rb400_spi_write_async(&cmd, 1);
+	}
+}
+EXPORT_SYMBOL(rb400_change_cfg);
+
+int rb400_spiflash_read_verify(unsigned addr,
+			       uint8_t *rdata, const uint8_t *vdata,
+			       unsigned cnt) {
+	const uint8_t cmd[5] = { SPI_CMD_READ_FAST,
+				 (addr >> 16) & 0xff,
+				 (addr >> 8) & 0xff,
+				 addr & 0xff,
+				 0
+	};
+	struct spi_transfer t[2] = {
+		{
+			.tx_buf = &cmd,
+			.len = 5,
+		},
+		{
+			.tx_buf = vdata,
+			.rx_buf = rdata,
+			.len = cnt,
+			.verify = (vdata != NULL),
+		},
+	};
+	struct spi_message m;
+
+	spi_message_init(&m);
+	m.fast_read = 1;
+	spi_message_add_tail(&t[0], &m);
+	spi_message_add_tail(&t[1], &m);
+	return spi_sync(spi, &m);
+}
+EXPORT_SYMBOL(rb400_spiflash_read_verify);
+
+int rb400_spi_sync(struct spi_message *message) {
+	return spi_sync(spi, message);
+}
+EXPORT_SYMBOL(rb400_spi_sync);
+
+static int rb400_spi_misc_probe(struct spi_device *_spi)
+{
+	printk("RB400 spi misc\n");
+	spi = _spi;
+	return 0;
+}
+
+static struct spi_driver rb400_spi_misc = {
+	.driver	= {
+		.name = "rb400-spi-misc",
+		.owner = THIS_MODULE,
+	},
+	.probe	= rb400_spi_misc_probe,
+};
+
+int __init rb400_spiboard_init(void) {
+	return spi_register_driver(&rb400_spi_misc);
+}
+
+module_init(rb400_spiboard_init);
diff -puNrb linux-2.6.35/arch/mips/rb/rb500/irq.c linux/arch/mips/rb/rb500/irq.c
--- linux-2.6.35/arch/mips/rb/rb500/irq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb500/irq.c	2011-05-02 10:08:25.371596851 +0300
@@ -0,0 +1,173 @@
+/*
+ * Copyright 2002 MontaVista Software Inc.
+ * Author: MontaVista Software, Inc.
+ *		stevel@mvista.com or source@mvista.com
+ *
+ *  This program is free software; you can redistribute	 it and/or modify it
+ *  under  the terms of	 the GNU General  Public License as published by the
+ *  Free Software Foundation;  either version 2 of the	License, or (at your
+ *  option) any later version.
+ *
+ *  THIS  SOFTWARE  IS PROVIDED	  ``AS	IS'' AND   ANY	EXPRESS OR IMPLIED
+ *  WARRANTIES,	  INCLUDING, BUT NOT  LIMITED  TO, THE IMPLIED WARRANTIES OF
+ *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN
+ *  NO	EVENT  SHALL   THE AUTHOR  BE	 LIABLE FOR ANY	  DIRECT, INDIRECT,
+ *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ *  NOT LIMITED	  TO, PROCUREMENT OF  SUBSTITUTE GOODS	OR SERVICES; LOSS OF
+ *  USE, DATA,	OR PROFITS; OR	BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ *  ANY THEORY OF LIABILITY, WHETHER IN	 CONTRACT, STRICT LIABILITY, OR TORT
+ *  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ *  THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *  You should have received a copy of the  GNU General Public License along
+ *  with this program; if not, write  to the Free Software Foundation, Inc.,
+ *  675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/kernel_stat.h>
+#include <linux/module.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/interrupt.h>
+#include <linux/ioport.h>
+#include <linux/timex.h>
+#include <linux/slab.h>
+#include <linux/random.h>
+#include <linux/delay.h>
+
+#include <asm/bitops.h>
+#include <asm/bootinfo.h>
+#include <asm/io.h>
+#include <asm/mipsregs.h>
+#include <asm/system.h>
+#include <asm/irq_cpu.h>
+#include <asm/irq.h>
+
+#define GPIO_BASE 0x18050000
+#define GPIO_REG(reg) (*(volatile u32 *) KSEG1ADDR(GPIO_BASE + (reg)))
+
+#define GPIO_INT_STATUS 0x10
+
+#define GROUP0_IRQ_BASE 8
+#define GROUP4_IRQ_BASE 136
+
+#define RB500_NR_IRQS  168
+
+#define INT_PEND(base) (*(volatile u32 *) base)
+#define INT_MASK(base) (*((volatile u32 *) base + 2))
+
+#define IRQ_TIMER 8
+
+extern asmlinkage void rbIRQ(void);
+
+struct intr_group {
+	u32 mask;
+	volatile u32 *base_addr;
+};
+
+static const struct intr_group intr_group[] = {
+	{ 0x0000efff, (u32 *) KSEG1ADDR(0x18038000) },
+	{ 0x00001fff, (u32 *) KSEG1ADDR(0x18038000 + 1 * 12) },
+	{ 0x00000007, (u32 *) KSEG1ADDR(0x18038000 + 2 * 12) },
+	{ 0x0003ffff, (u32 *) KSEG1ADDR(0x18038000 + 3 * 12) },
+	{ 0xffffffff, (u32 *) KSEG1ADDR(0x18038000 + 4 * 12) }
+};
+
+static void rb500_unmask_irq(unsigned irq)
+{
+	volatile unsigned int *addr;
+
+	irq -= GROUP0_IRQ_BASE;
+	addr = intr_group[irq >> 5].base_addr;
+	irq &= (1 << 5) - 1;
+	
+	INT_MASK(addr) &= ~(1 << irq);
+}
+
+static void rb500_mask_irq(unsigned irq)
+{
+	volatile unsigned int *addr;
+
+	irq -= GROUP0_IRQ_BASE;
+	addr = intr_group[irq >> 5].base_addr;
+	irq &= (1 << 5) - 1;
+	
+	INT_MASK(addr) |= 1 << irq;
+}
+
+static void rb500_gpio_unmask_irq(unsigned irq) {
+	GPIO_REG(GPIO_INT_STATUS) &= ~(1 << (irq - GROUP4_IRQ_BASE));
+	rb500_unmask_irq(irq);
+}
+
+static struct irq_chip rb500_irq_controller = {
+	.typename	= "RB500",
+	.ack		= rb500_mask_irq,
+	.mask		= rb500_mask_irq,
+	.mask_ack	= rb500_mask_irq,
+	.unmask		= rb500_unmask_irq,
+};
+
+static struct irq_chip rb500_gpio_irq_controller = {
+	.typename	= "RB500 GPIO",
+	.ack		= rb500_mask_irq,
+	.mask		= rb500_mask_irq,
+	.mask_ack	= rb500_mask_irq,
+	.unmask		= rb500_gpio_unmask_irq,
+};
+
+static struct irqaction cascade  = {
+	.handler = no_action,
+	.name = "cascade",
+};
+
+void rb500_irqdispatch(void)
+{
+	unsigned group;
+	volatile unsigned *addr;
+	unsigned irq;
+	unsigned pending = read_c0_status() & read_c0_cause() & 0xfc00;
+
+	if (!pending) return;
+
+	group = fls(pending) - 11;
+	irq = group + 2;
+
+	if (irq == 7) {
+	    do_IRQ(irq);
+	    return;
+	}
+
+	addr = intr_group[group].base_addr;
+
+	pending = INT_PEND(addr) & ~INT_MASK(addr);
+	if (!pending) return;
+	
+	irq = (group << 5) + (ffs(pending) - 1) + 8;
+	
+	if (irq != IRQ_TIMER)
+		do_IRQ(irq);
+	else
+		/* do not enable softirqs & friends for OProfile */
+		generic_handle_irq(irq);
+}
+
+void __init rb500_init_irq(void)
+{
+	int i;
+
+	mips_cpu_irq_init();
+	set_except_vector(0, rbIRQ);
+
+	for (i = 2; i <= 6; ++i)
+		setup_irq(i, &cascade);
+	for (i = GROUP0_IRQ_BASE; i < RB500_NR_IRQS; ++i)
+		set_irq_chip_and_handler(i, &rb500_irq_controller,
+					 handle_level_irq);
+	for (i = GROUP4_IRQ_BASE; i < GROUP4_IRQ_BASE + 14; ++i)
+		set_irq_chip_and_handler(i, &rb500_gpio_irq_controller,
+					 handle_level_irq);
+}
diff -puNrb linux-2.6.35/arch/mips/rb/rb500/latch.c linux/arch/mips/rb/rb500/latch.c
--- linux-2.6.35/arch/mips/rb/rb500/latch.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb500/latch.c	2011-05-02 10:08:25.391597136 +0300
@@ -0,0 +1,52 @@
+#include <linux/init.h>
+#include <linux/miscdevice.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <asm/uaccess.h>
+#include <linux/pci.h>
+#include <linux/module.h>
+#include <asm/rb/rb500.h>
+
+#define IDT434_REG_BASE ((volatile void *) KSEG1ADDR(0x18000000))
+
+unsigned char rb500_latch_state = RB500_LO_NCE | RB500_LO_FOFF;
+unsigned rb500_latch_addr;
+
+void set434Reg(unsigned regOffs, unsigned bit, unsigned len, unsigned val)
+{
+	unsigned long flags;
+	unsigned data;
+	unsigned i = 0;
+
+	local_irq_save(flags);
+
+	data = *(volatile unsigned *) (IDT434_REG_BASE + regOffs);
+	for (i = 0; i != len; ++i) {
+		if (val & (1 << i)) data |= (1 << (i + bit));
+		else data &= ~(1 << (i + bit));
+	}
+	*(volatile unsigned *) (IDT434_REG_BASE + regOffs) = data;
+
+	local_irq_restore(flags);
+}
+
+void changeLatchU5(unsigned char orMask, unsigned char nandMask)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	rb500_latch_state = (rb500_latch_state | orMask) & ~nandMask;
+	writeb(rb500_latch_state, (void *) rb500_latch_addr);
+
+	local_irq_restore(flags);
+}
+
+void __init rb500_init_latch(void)
+{
+	rb500_latch_addr = KSEG1ADDR(inl(0x18010030));
+	writeb(rb500_latch_state, (void *) rb500_latch_addr);
+}
+
+EXPORT_SYMBOL(set434Reg);
+EXPORT_SYMBOL(changeLatchU5);
diff -puNrb linux-2.6.35/arch/mips/rb/rb500/Makefile linux/arch/mips/rb/rb500/Makefile
--- linux-2.6.35/arch/mips/rb/rb500/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb500/Makefile	2011-05-02 10:08:25.401545315 +0300
@@ -0,0 +1,5 @@
+#
+# Makefile for the RB500 board specific parts of the kernel
+#
+
+obj-y	 := irq.o setup.o rbIRQ.o latch.o
diff -puNrb linux-2.6.35/arch/mips/rb/rb500/rbIRQ.S linux/arch/mips/rb/rb500/rbIRQ.S
--- linux-2.6.35/arch/mips/rb/rb500/rbIRQ.S	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb500/rbIRQ.S	2011-05-02 10:08:25.411546558 +0300
@@ -0,0 +1,77 @@
+/*
+ * Copyright 2001 MontaVista Software Inc.
+ * Author: stevel@mvista.com
+ *
+ * Interrupt dispatcher for RB500 board.
+ *
+ * This program is free software; you can redistribute	it and/or modify it
+ * under  the terms of	the GNU General	 Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#define __ASSEMBLY__ 1
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/regdef.h>
+#include <asm/stackframe.h>
+#include <asm/irqflags.h>
+
+#define INT_IPEND2	0x98038000
+#define TIMER_CTC0	0x98028008
+	
+	.text
+	.set	noreorder
+	.set	noat
+	.align	5
+NESTED(rbIRQ, PT_SIZE, sp)
+#ifndef NO_BEEPER
+	/* beeper uses timer0 (IRQ_8) */
+	/* NOTE: interrupts IRQ9..IRQ39 are treated as IRQ8 */
+	lui	k0, %hi(rb500_beeper_enabled)
+	lw	k0, %lo(rb500_beeper_enabled)(k0)
+	beq	k0, zero, 1f
+	
+	mfc0	k0, CP0_CAUSE
+	nop
+	andi	k0, CAUSEF_IP2
+	beq	k0, zero, 1f
+	nop
+
+	lui	k0, %hi(rb500_latch_state)
+	lbu	k1, %lo(rb500_latch_state)(k0)
+	xori	k1, 8
+	sb	k1, %lo(rb500_latch_state)(k0)
+	lui	k0, %hi(rb500_latch_addr)
+	lw	k0, %lo(rb500_latch_addr)(k0)
+	sb	k1, 0(k0)
+
+	lui	k0, %hi(TIMER_CTC0)
+	li	k1, 1
+	sw	k1, %lo(TIMER_CTC0)(k0)
+
+	mfc0	k0, CP0_CAUSE
+	li	k1, ~CAUSEF_IP2
+	and	k0, k0, k1
+	mtc0	k0, CP0_CAUSE
+	bne	k0, zero, 1f
+	nop
+	eret
+1:	
+#endif
+
+	SAVE_ALL
+	CLI
+	TRACE_IRQS_OFF
+	LONG_L	s0, TI_REGS($28)
+	LONG_S	sp, TI_REGS($28)
+	PTR_LA	ra, ret_from_irq
+	.set	at
+
+	j	rb500_irqdispatch
+	nop							
+
+END(rbIRQ)
+
+
diff -puNrb linux-2.6.35/arch/mips/rb/rb500/setup.c linux/arch/mips/rb/rb500/setup.c
--- linux-2.6.35/arch/mips/rb/rb500/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/rb500/setup.c	2011-05-02 10:08:25.421587767 +0300
@@ -0,0 +1,130 @@
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+#include <linux/irq.h>
+#include <linux/ioport.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/serial_8250.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#include <asm/io.h>
+#include <asm/mipsregs.h>
+#include <asm/pgtable.h>
+#include <asm/reboot.h>
+#include <asm/addrspace.h>
+
+#define RB500_UART_BASE 0x18058000
+#define RB500_UART_IRQ 104
+
+#define TIMER_BASE     ((unsigned *) KSEG1ADDR(0x18028000))
+#define TIMER_COUNT0   (TIMER_BASE + 0)
+#define TIMER_COMPARE0 (TIMER_BASE + 1)
+#define TIMER_CTC0     (TIMER_BASE + 2)
+#define TIMER_CTCSEL0  (TIMER_BASE + 3)
+
+extern unsigned int mips_hpt_frequency;
+
+extern void __init rb500_init_latch(void);
+
+int rb500_beeper_enabled = 1;
+
+static void rb_machine_restart(char *command)
+{
+	/* just jump to the reset vector */
+	* (volatile unsigned *) KSEG1ADDR(0x18008000) = 0x80000001;
+	
+	((void (*)(void)) KSEG1ADDR(0x1FC00000u))();
+}
+
+static void rb_machine_halt(void)
+{
+	printk("rb_machine_halt:  halted\n");
+	for(;;) continue;
+}
+
+static irqreturn_t rb500_beep_irq(int irq, void *p) {
+	return IRQ_HANDLED;
+}
+
+static int rb500_init_beep_irq(void) {
+	if (mips_machgroup == MACH_GROUP_MT_RB500
+	    && mips_machtype == MACH_MT_RB500R5) {
+		request_irq(8, rb500_beep_irq, 0, "beeper", 0);
+	}
+	return 0;
+}
+
+static void rb500_free_beep_irq(void) {
+	if (mips_machgroup == MACH_GROUP_MT_RB500
+	    && mips_machtype == MACH_MT_RB500R5) {
+		free_irq(8, 0);
+	}
+}
+
+arch_initcall(rb500_init_beep_irq);
+
+void rb500_beep(unsigned freq) {
+	if (!rb500_beeper_enabled) return;
+
+	if (freq) {
+		/* limit to 23Hz-10kHz */
+		unsigned delay = mips_hpt_frequency / 2 / min(max(freq, 23u), 10000u);
+
+		writel(0, TIMER_COUNT0);
+		writel(delay, TIMER_COMPARE0);
+		writel(0, TIMER_CTCSEL0);
+		writel(1, TIMER_CTC0);
+	} else {
+		writel(0, TIMER_CTC0);
+	}
+}
+
+EXPORT_SYMBOL(rb500_beep);
+
+void rb500_enable_beeper(int enable) {
+	if (rb500_beeper_enabled != enable) {
+		rb500_beeper_enabled = enable;
+		
+		if (enable) {
+			rb500_init_beep_irq();
+		} else {
+			rb500_beep(0);
+			rb500_free_beep_irq();
+		}
+	}
+}
+EXPORT_SYMBOL(rb500_enable_beeper);
+
+void __init rb500_serial_console_init(void)
+{
+	struct uart_port port;
+
+	memset(&port, 0, sizeof(port));
+	port.type = PORT_16550;
+	port.uartclk =  mips_hpt_frequency;
+	port.membase = (unsigned char *) KSEG1ADDR(RB500_UART_BASE);
+	port.irq = RB500_UART_IRQ;
+	port.regshift = 2;
+	port.iotype = UPIO_MEM;
+	port.flags = UPF_BOOT_AUTOCONF | UPF_SKIP_TEST;
+
+	early_serial_setup(&port);
+}
+
+void __init rb500_setup(void)
+{
+	rb500_serial_console_init();
+	rb500_init_latch();
+
+	/* enable beeper timer IRQ */
+	enable_irq(8);
+
+	_machine_restart = rb_machine_restart;
+	_machine_halt = rb_machine_halt;
+
+	ioport_resource.start = 0x18800000;
+	ioport_resource.end = 0x188FFFFF;
+	iomem_resource.start = 0x50000000;
+	iomem_resource.end = 0x5FFFFFFF;
+}
diff -puNrb linux-2.6.35/arch/mips/rb/vm/Makefile linux/arch/mips/rb/vm/Makefile
--- linux-2.6.35/arch/mips/rb/vm/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/vm/Makefile	2011-05-02 10:08:25.441589752 +0300
@@ -0,0 +1 @@
+obj-y	 := setup.o
diff -puNrb linux-2.6.35/arch/mips/rb/vm/setup.c linux/arch/mips/rb/vm/setup.c
--- linux-2.6.35/arch/mips/rb/vm/setup.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/mips/rb/vm/setup.c	2011-05-02 10:08:25.451593743 +0300
@@ -0,0 +1,142 @@
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <asm/reboot.h>
+#include <asm/vm.h>
+#include <asm/rb/boards.h>
+
+#define BUF_SIZE	256
+#define BUF_COUNT	4
+
+hypercall(vm_create_queue, 4, unsigned id, unsigned irq,
+		 unsigned tx, unsigned rx);
+hypercall(vm_release_queue, 5, unsigned id);
+hypercall(vm_running, 6, void);
+hypercall(vm_setup_irqs, 14, unsigned *irqs, unsigned count);
+
+static volatile struct vdma_descr tx_chain[BUF_COUNT];
+static volatile struct vdma_descr rx_chain[BUF_COUNT];
+static unsigned char tx_buffers[BUF_COUNT][BUF_SIZE];
+static unsigned char rx_buffers[BUF_COUNT][BUF_SIZE];
+
+static unsigned cur_tx;
+static unsigned cur_rx;
+
+static int send_message(const unsigned char *buf, int len)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* drop some data if full buffer */
+	while (tx_chain[cur_tx].size & DONE)
+		asm volatile ("wait");
+
+	len = min_t(int, len, BUF_SIZE);
+	memcpy(tx_buffers[cur_tx], buf, len);
+	tx_chain[cur_tx].size = len | DONE;
+
+	cur_tx = (cur_tx + 1) % BUF_COUNT;
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static int recv_message(char *buf, int len)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	if (!(rx_chain[cur_rx].size & DONE)) {
+		local_irq_restore(flags);
+		return 0;
+	}
+	
+	len = min_t(int, len, rx_chain[cur_rx].size & ~DONE);
+	memcpy(buf, rx_buffers[cur_rx], len);
+
+	rx_chain[cur_rx].size = BUF_SIZE;
+	cur_rx = (cur_rx + 1) % BUF_COUNT;
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static irqreturn_t ctrl_interrupt(int irq, void *dev_id)
+{
+	struct task_struct *init;
+	char buf[256];
+	int len;
+
+	len = recv_message(buf, sizeof(buf));
+	if (len <= 0)
+		return IRQ_HANDLED;
+
+	if (strncmp(buf, "restart", len) == 0) {
+		printk("RESTART\n");
+		init = find_task_by_pid_ns(1, &init_pid_ns);
+		if (init)
+			send_sig(SIGINT, init, 1);
+	} else if (strncmp(buf, "halt", len) == 0) {
+	    printk("HALT\n");
+		init = find_task_by_pid_ns(1, &init_pid_ns);
+		if (init)
+			send_sig(SIGWINCH, init, 1);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void rbvm_machine_restart(char *command)
+{
+	char msg[] = "restart";
+
+	send_message(msg, sizeof(msg));
+}
+
+static void rbvm_machine_halt(void)
+{
+	char msg[] = "halt";
+
+	send_message(msg, sizeof(msg));
+}
+
+void __init rbvm_setup(void)
+{
+	extern unsigned long virqs;
+	int i;
+
+	vm_setup_irqs((unsigned *) &virqs, 32);
+
+	for (i = 0; i < BUF_COUNT; ++i) {
+		rx_chain[i].addr = (unsigned) rx_buffers[i];
+		rx_chain[i].size = BUF_SIZE;
+		rx_chain[i].next = (unsigned) &rx_chain[i + 1];
+		
+		tx_chain[i].addr = (unsigned) tx_buffers[i];
+		tx_chain[i].size = 0;
+		tx_chain[i].next = (unsigned) &tx_chain[i + 1];
+	}
+	rx_chain[BUF_COUNT - 1].next = (unsigned) &rx_chain[0];
+	tx_chain[BUF_COUNT - 1].next = (unsigned) &tx_chain[0];
+
+	vm_create_queue(0, 0, (unsigned) &tx_chain[0],
+			(unsigned) &rx_chain[0]);
+
+	_machine_restart = rbvm_machine_restart;
+	_machine_halt = rbvm_machine_halt;
+}
+
+int __init init_ctrl_interrupt(void)
+{
+	if (mips_machgroup != MACH_GROUP_MT_VM)
+		return 0;
+
+	if (request_irq(VIRQ_BASE + 0, ctrl_interrupt, 0, "ctrl", (void *) 1))
+		return -EBUSY;
+	return 0;
+
+}
+arch_initcall(init_ctrl_interrupt);
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/dma-mapping.h linux/arch/powerpc/include/asm/dma-mapping.h
--- linux-2.6.35/arch/powerpc/include/asm/dma-mapping.h	2011-04-26 16:26:44.452476955 +0300
+++ linux/arch/powerpc/include/asm/dma-mapping.h	2011-05-02 10:08:25.462847615 +0300
@@ -79,7 +79,7 @@ static inline struct dma_map_ops *get_dm
 	 * in the floppy driver directly to get a device for us.
 	 */
 	if (unlikely(dev == NULL))
-		return NULL;
+		return &dma_direct_ops;
 
 	return dev->archdata.dma_ops;
 }
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/mtvic.h linux/arch/powerpc/include/asm/mtvic.h
--- linux-2.6.35/arch/powerpc/include/asm/mtvic.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/include/asm/mtvic.h	2011-05-02 10:08:25.472842320 +0300
@@ -0,0 +1,8 @@
+#ifndef _ASM_POWERPC_MTVIC_H
+#define _ASM_POWERPC_MTVIC_H
+
+void __init mtvic_init(int def);
+unsigned mtvic_get_irq(void);
+unsigned rb_get_irq(void);
+
+#endif
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/pgtable-ppc32.h linux/arch/powerpc/include/asm/pgtable-ppc32.h
--- linux-2.6.35/arch/powerpc/include/asm/pgtable-ppc32.h	2011-04-26 16:26:44.442479059 +0300
+++ linux/arch/powerpc/include/asm/pgtable-ppc32.h	2011-05-02 10:08:25.482923554 +0300
@@ -63,7 +63,7 @@ extern int icache_44x_need_flush;
 #ifdef CONFIG_HIGHMEM
 #define KVIRT_TOP	PKMAP_BASE
 #else
-#define KVIRT_TOP	(0xfe000000UL)	/* for now, could be FIXMAP_BASE ? */
+#define KVIRT_TOP	(0xf0000000UL)	/* for now, could be FIXMAP_BASE ? */
 #endif
 
 /*
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/processor.h linux/arch/powerpc/include/asm/processor.h
--- linux-2.6.35/arch/powerpc/include/asm/processor.h	2011-04-26 16:26:44.442479059 +0300
+++ linux/arch/powerpc/include/asm/processor.h	2011-05-02 10:08:25.502903932 +0300
@@ -161,14 +161,14 @@ struct thread_struct {
 #ifdef CONFIG_PPC32
 	void		*pgdir;		/* root of page-table tree */
 #endif
-#ifdef CONFIG_PPC_ADV_DEBUG_REGS
+#if defined(CONFIG_PPC_ADV_DEBUG_REGS) || defined(CONFIG_RB_PPC)
 	/*
 	 * The following help to manage the use of Debug Control Registers
 	 * om the BookE platforms.
 	 */
 	unsigned long	dbcr0;
 	unsigned long	dbcr1;
-#ifdef CONFIG_BOOKE
+#if defined(CONFIG_BOOKE) || defined(CONFIG_RB_PPC)
 	unsigned long	dbcr2;
 #endif
 	/*
@@ -186,17 +186,21 @@ struct thread_struct {
 	 */
 	unsigned long	iac1;
 	unsigned long	iac2;
+#ifdef CONFIG_PPC_ADV_DEBUG_IACS
 #if CONFIG_PPC_ADV_DEBUG_IACS > 2
 	unsigned long	iac3;
 	unsigned long	iac4;
 #endif
+#endif
 	unsigned long	dac1;
 	unsigned long	dac2;
+#ifdef CONFIG_PPC_ADV_DEBUG_DVCS
 #if CONFIG_PPC_ADV_DEBUG_DVCS > 0
 	unsigned long	dvc1;
 	unsigned long	dvc2;
 #endif
 #endif
+#endif
 	/* FP and VSX 0-31 register set */
 	double		fpr[32][TS_FPRWIDTH];
 	struct {
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/rb_aux.h linux/arch/powerpc/include/asm/rb_aux.h
--- linux-2.6.35/arch/powerpc/include/asm/rb_aux.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/include/asm/rb_aux.h	2011-05-02 10:08:25.522901675 +0300
@@ -0,0 +1,18 @@
+#ifndef _ASM_POWERPC_RB_AUX_H
+#define _ASM_POWERPC_RB_AUX_H
+
+#include <linux/seq_file.h>
+#include <linux/init.h>
+
+extern void __init rb_pic_init(void);
+extern void __init rb_init_pci(void);
+extern void rb_show_cpuinfo(struct seq_file *);
+extern void rb_restart(char *cmd);
+extern void rb_idle(void);
+extern void change_latch(unsigned char set, unsigned char clear);
+extern unsigned get_gpio_def(const char *name);
+
+void add_second_serial_of_node(void);
+void add_crypto_of_node(unsigned irq);
+
+#endif
diff -puNrb linux-2.6.35/arch/powerpc/include/asm/vm.h linux/arch/powerpc/include/asm/vm.h
--- linux-2.6.35/arch/powerpc/include/asm/vm.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/include/asm/vm.h	2011-05-02 10:08:25.532791198 +0300
@@ -0,0 +1,35 @@
+#ifndef MT_VM_H
+#define MT_VM_H
+
+#define hypercall(name, nr, ...)		\
+	asm(					\
+		".global " #name ";"		\
+		".align 2;"			\
+		".type " #name ",@function;"	\
+		#name ":;"			\
+		"li 0, " #nr ";"		\
+		"crset so;"			\
+		"mtspr 1023, 0;"		\
+		"bnslr;"			\
+		"li 3, -22;"			\
+		"blr"				\
+        );					\
+	asmlinkage extern int name(__VA_ARGS__);
+
+/* NOTE: do not allow vdma_descr to span multiple pages, so align it */
+struct vdma_descr {
+	unsigned addr;
+	unsigned size;
+	unsigned next;
+} __attribute__((aligned(16)));
+
+#define DONE		0x80000000
+
+unsigned get_virq_nr(unsigned hwirq);
+int vm_yield(void);
+int vm_running(void);
+
+#define hc_yield() vm_yield()
+
+
+#endif
diff -puNrb linux-2.6.35/arch/powerpc/kernel/legacy_serial.c linux/arch/powerpc/kernel/legacy_serial.c
--- linux-2.6.35/arch/powerpc/kernel/legacy_serial.c	2011-04-26 16:26:43.482504617 +0300
+++ linux/arch/powerpc/kernel/legacy_serial.c	2011-05-02 10:08:25.552900902 +0300
@@ -279,6 +279,7 @@ static int __init add_legacy_pci_port(st
 }
 #endif
 
+#if 0
 static void __init setup_legacy_serial_console(int console)
 {
 	struct legacy_serial_info *info =
@@ -295,6 +296,7 @@ static void __init setup_legacy_serial_c
 	DBG("default console speed = %d\n", info->speed);
 	udbg_init_uart(addr, info->speed, info->clock);
 }
+#endif
 
 /*
  * This is called very early, as part of setup_system() or eventually
@@ -380,8 +382,10 @@ void __init find_legacy_serial_ports(voi
 #endif
 
 	DBG("legacy_serial_console = %d\n", legacy_serial_console);
+#if 0
 	if (legacy_serial_console >= 0)
 		setup_legacy_serial_console(legacy_serial_console);
+#endif
 	DBG(" <- find_legacy_serial_port()\n");
 }
 
diff -puNrb linux-2.6.35/arch/powerpc/kernel/Makefile linux/arch/powerpc/kernel/Makefile
--- linux-2.6.35/arch/powerpc/kernel/Makefile	2011-04-26 16:26:43.502477784 +0300
+++ linux/arch/powerpc/kernel/Makefile	2011-05-02 10:08:25.562846105 +0300
@@ -115,8 +115,10 @@ obj-$(CONFIG_FSL_EMB_PERF_EVENT_E500) +=
 obj-$(CONFIG_8XX_MINIMAL_FPEMU) += softemu8xx.o
 
 ifneq ($(CONFIG_PPC_INDIRECT_IO),y)
+ifneq ($(CONFIG_RB_IOMAP),y)
 obj-y				+= iomap.o
 endif
+endif
 
 obj-$(CONFIG_PPC64)		+= $(obj64-y)
 obj-$(CONFIG_PPC32)		+= $(obj32-y)
diff -puNrb linux-2.6.35/arch/powerpc/kernel/pci-common.c linux/arch/powerpc/kernel/pci-common.c
--- linux-2.6.35/arch/powerpc/kernel/pci-common.c	2011-04-26 16:26:43.502477784 +0300
+++ linux/arch/powerpc/kernel/pci-common.c	2011-05-02 10:08:25.582904753 +0300
@@ -276,6 +276,7 @@ int pci_read_irq_line(struct pci_dev *pc
 
 	pr_debug(" Mapped to linux irq %d\n", virq);
 
+	pci_write_config_byte(pci_dev, PCI_INTERRUPT_LINE, virq);
 	pci_dev->irq = virq;
 
 	return 0;
diff -puNrb linux-2.6.35/arch/powerpc/kernel/prom.c linux/arch/powerpc/kernel/prom.c
--- linux-2.6.35/arch/powerpc/kernel/prom.c	2011-04-26 16:26:43.502477784 +0300
+++ linux/arch/powerpc/kernel/prom.c	2011-05-02 10:08:25.592791132 +0300
@@ -367,6 +367,14 @@ void __init early_init_dt_scan_chosen_ar
 {
 	unsigned long *lprop;
 
+#ifdef CONFIG_BLK_DEV_INITRD
+	lprop = of_get_flat_dt_prop(node, "linux,initrd", NULL);
+	if (lprop) {
+		initrd_start = (unsigned) __va(lprop[0]);
+		initrd_end = initrd_start + lprop[1];
+	}
+#endif
+
 #ifdef CONFIG_PPC64
 	/* check if iommu is forced on or off */
 	if (of_get_flat_dt_prop(node, "linux,iommu-off", NULL) != NULL)
@@ -686,6 +694,11 @@ void __init early_init_devtree(void *par
 	of_scan_flat_dt(early_init_dt_scan_root, NULL);
 	of_scan_flat_dt(early_init_dt_scan_memory_ppc, NULL);
 
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (initrd_start)
+		memblock_reserve(__pa(initrd_start), initrd_end - initrd_start);
+#endif
+
 	/* Save command line for /proc/cmdline and then parse parameters */
 	strlcpy(boot_command_line, cmd_line, COMMAND_LINE_SIZE);
 	parse_early_param();
diff -puNrb linux-2.6.35/arch/powerpc/kernel/time.c linux/arch/powerpc/kernel/time.c
--- linux-2.6.35/arch/powerpc/kernel/time.c	2011-04-26 16:26:43.482504617 +0300
+++ linux/arch/powerpc/kernel/time.c	2011-05-02 10:08:25.612903065 +0300
@@ -173,6 +173,7 @@ static long timezone_offset;
 unsigned long ppc_proc_freq;
 EXPORT_SYMBOL(ppc_proc_freq);
 unsigned long ppc_tb_freq;
+EXPORT_SYMBOL(ppc_tb_freq);
 
 static u64 tb_last_jiffy __cacheline_aligned_in_smp;
 static DEFINE_PER_CPU(u64, last_jiffy);
diff -puNrb linux-2.6.35/arch/powerpc/Makefile linux/arch/powerpc/Makefile
--- linux-2.6.35/arch/powerpc/Makefile	2011-04-26 16:26:48.151234374 +0300
+++ linux/arch/powerpc/Makefile	2011-05-02 10:08:25.632903659 +0300
@@ -94,7 +94,9 @@ else
 endif
 endif
 
+ifeq ($(CONFIG_OPTIMIZE_FOR_SIZE),y)
 LDFLAGS_MODULE	+= arch/powerpc/lib/crtsavres.o
+endif
 
 ifeq ($(CONFIG_TUNE_CELL),y)
 	KBUILD_CFLAGS += $(call cc-option,-mtune=cell)
diff -puNrb linux-2.6.35/arch/powerpc/mm/mem.c linux/arch/powerpc/mm/mem.c
--- linux-2.6.35/arch/powerpc/mm/mem.c	2011-04-26 16:26:47.812502844 +0300
+++ linux/arch/powerpc/mm/mem.c	2011-05-02 10:08:25.641340065 +0300
@@ -304,7 +304,8 @@ void __init paging_init(void)
 	max_zone_pfns[ZONE_DMA] = lowmem_end_addr >> PAGE_SHIFT;
 	max_zone_pfns[ZONE_HIGHMEM] = top_of_ram >> PAGE_SHIFT;
 #else
-	max_zone_pfns[ZONE_DMA] = top_of_ram >> PAGE_SHIFT;
+	max_zone_pfns[ZONE_DMA] = 0xf000000 >> PAGE_SHIFT;
+	max_zone_pfns[ZONE_NORMAL] = top_of_ram >> PAGE_SHIFT;
 #endif
 	free_area_init_nodes(max_zone_pfns);
 
diff -puNrb linux-2.6.35/arch/powerpc/oprofile/common.c linux/arch/powerpc/oprofile/common.c
--- linux-2.6.35/arch/powerpc/oprofile/common.c	2011-04-26 16:26:42.902208035 +0300
+++ linux/arch/powerpc/oprofile/common.c	2011-05-02 10:08:25.652791027 +0300
@@ -24,6 +24,8 @@
 #include <asm/oprofile_impl.h>
 #include <asm/firmware.h>
 
+extern int __init hrtimer_oprofile_init(struct oprofile_operations *);
+
 static struct op_powerpc_model *model;
 
 static struct op_counter_config ctr[OP_MAX_COUNTER];
@@ -192,6 +194,11 @@ static int op_powerpc_create_files(struc
 
 int __init oprofile_arch_init(struct oprofile_operations *ops)
 {
+	ops->backtrace = op_powerpc_backtrace;
+
+	if (hrtimer_oprofile_init(ops) == 0)
+		return 0;
+
 	if (!cur_cpu_spec->oprofile_cpu_type)
 		return -ENODEV;
 
diff -puNrb linux-2.6.35/arch/powerpc/oprofile/Makefile linux/arch/powerpc/oprofile/Makefile
--- linux-2.6.35/arch/powerpc/oprofile/Makefile	2011-04-26 16:26:42.902208035 +0300
+++ linux/arch/powerpc/oprofile/Makefile	2011-05-02 10:08:25.662791025 +0300
@@ -10,6 +10,7 @@ DRIVER_OBJS := $(addprefix ../../../driv
 		oprof.o cpu_buffer.o buffer_sync.o \
 		event_buffer.o oprofile_files.o \
 		oprofilefs.o oprofile_stats.o \
+		hrtimer.o \
 		timer_int.o )
 
 oprofile-y := $(DRIVER_OBJS) common.o backtrace.o
diff -puNrb linux-2.6.35/arch/powerpc/platforms/44x/Kconfig linux/arch/powerpc/platforms/44x/Kconfig
--- linux-2.6.35/arch/powerpc/platforms/44x/Kconfig	2011-04-26 16:26:46.472478152 +0300
+++ linux/arch/powerpc/platforms/44x/Kconfig	2011-05-02 10:08:25.682901633 +0300
@@ -1,3 +1,4 @@
+
 config PPC_47x
 	bool "Support for 47x variant"
 	depends on 44x
diff -puNrb linux-2.6.35/arch/powerpc/platforms/44x/Makefile linux/arch/powerpc/platforms/44x/Makefile
diff -puNrb linux-2.6.35/arch/powerpc/platforms/44x/ppc44x_simple.c linux/arch/powerpc/platforms/44x/ppc44x_simple.c
--- linux-2.6.35/arch/powerpc/platforms/44x/ppc44x_simple.c	2011-04-26 16:26:46.472478152 +0300
+++ linux/arch/powerpc/platforms/44x/ppc44x_simple.c	2011-05-02 10:08:25.701280254 +0300
@@ -80,6 +80,10 @@ static int __init ppc44x_probe(void)
 	return 0;
 }
 
+void change_latch(unsigned char set, unsigned char clear) {
+}
+EXPORT_SYMBOL(change_latch);
+
 define_machine(ppc44x_simple) {
 	.name = "PowerPC 44x Platform",
 	.probe = ppc44x_probe,
diff -puNrb linux-2.6.35/arch/powerpc/platforms/83xx/Kconfig linux/arch/powerpc/platforms/83xx/Kconfig
--- linux-2.6.35/arch/powerpc/platforms/83xx/Kconfig	2011-04-26 16:26:47.222478126 +0300
+++ linux/arch/powerpc/platforms/83xx/Kconfig	2011-05-02 10:08:25.712900401 +0300
@@ -30,6 +30,15 @@ config MPC832x_RDB
 	help
 	  This option enables support for the MPC8323 RDB board.
 
+config RB_PPC
+	bool "Mikrotik RB333/RB600"
+	select QUICC_ENGINE
+	select PPC_MPC832x
+	select PPC_MPC834x
+	select RB_IOMAP
+	help
+	  This option enables support for the Mikrotik RB333/RB600 board.
+
 config MPC834x_MDS
 	bool "Freescale MPC834x MDS"
 	select DEFAULT_UIMAGE
diff -puNrb linux-2.6.35/arch/powerpc/platforms/83xx/Makefile linux/arch/powerpc/platforms/83xx/Makefile
--- linux-2.6.35/arch/powerpc/platforms/83xx/Makefile	2011-04-26 16:26:47.232477803 +0300
+++ linux/arch/powerpc/platforms/83xx/Makefile	2011-05-02 10:08:25.722790478 +0300
@@ -11,6 +11,7 @@ obj-$(CONFIG_MPC834x_ITX)	+= mpc834x_itx
 obj-$(CONFIG_MPC836x_MDS)	+= mpc836x_mds.o
 obj-$(CONFIG_MPC836x_RDK)	+= mpc836x_rdk.o
 obj-$(CONFIG_MPC832x_MDS)	+= mpc832x_mds.o
+obj-$(CONFIG_RB_PPC)		+= rb_ppc.o
 obj-$(CONFIG_MPC837x_MDS)	+= mpc837x_mds.o
 obj-$(CONFIG_SBC834x)		+= sbc834x.o
 obj-$(CONFIG_MPC837x_RDB)	+= mpc837x_rdb.o
diff -puNrb linux-2.6.35/arch/powerpc/platforms/83xx/rb_ppc.c linux/arch/powerpc/platforms/83xx/rb_ppc.c
--- linux-2.6.35/arch/powerpc/platforms/83xx/rb_ppc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/platforms/83xx/rb_ppc.c	2011-05-02 10:08:25.742790982 +0300
@@ -0,0 +1,459 @@
+/*
+ * Copyright (C) Mikrotik 2007
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <linux/root_dev.h>
+#include <linux/initrd.h>
+#include <linux/interrupt.h>
+#include <asm/of_device.h>
+#include <asm/of_platform.h>
+#include <asm/time.h>
+#include <asm/ipic.h>
+#include <asm/udbg.h>
+#include <asm/qe.h>
+#include <asm/qe_ic.h>
+#include <sysdev/fsl_soc.h>
+#include <sysdev/fsl_pci.h>
+#include "mpc83xx.h"
+
+#define SYSCTL		0x100
+#define SICRL		0x014
+
+#define GTCFR2		0x04
+#define GTMDR4		0x22
+#define GTRFR4		0x26
+#define GTCNR4		0x2e
+#define GTVER4		0x36
+#define GTPSR4		0x3e
+
+#define GTCFR_BCM	0x40
+#define GTCFR_STP4	0x20
+#define GTCFR_RST4	0x10
+#define GTCFR_STP3	0x02
+#define GTCFR_RST3	0x01
+
+#define GTMDR_ORI	0x10
+#define GTMDR_FRR	0x08
+#define GTMDR_ICLK16	0x04
+
+#define SBIT(x) (0x80000000 >> (x))
+#define DBIT(x, y) ((y) << (32 - (((x % 16) + 1) * 2)))
+
+// rb300
+#define GPIO_DIR_RB300 (immrs + (0x1408 >> 2))
+#define GPIO_DATA_RB300 (immrs + (0x1404 >> 2))
+
+// rb600
+#define SICRL_RB600 (immrs + (0x114 >> 2))
+#define GPIO_DIR_RB600 (immrs + (0xc00 >> 2))
+#define GPIO_DATA_RB600 (immrs + (0xc08 >> 2))
+
+extern int par_io_data_set(u8 port, u8 pin, u8 val);
+extern int par_io_config_pin(u8 port, u8 pin, int dir, int open_drain,
+			     int assignment, int has_irq);
+
+static unsigned timer_freq;
+static void *gtm;
+
+static int beeper_irq;
+static unsigned beeper_gpio_pin[2];
+
+static __be32 __iomem *immrs;
+
+irqreturn_t rbppc_timer_irq(int irq, void *ptr)
+{
+	static int toggle = 0;
+
+	par_io_data_set(beeper_gpio_pin[0], beeper_gpio_pin[1], toggle);
+	toggle = !toggle;
+
+	/* ack interrupt */
+	out_be16(gtm + GTVER4, 3);
+
+	return IRQ_HANDLED;
+}
+
+void rbppc_beep(unsigned freq)
+{
+	unsigned gtmdr;
+
+	if (freq > 5000) freq = 5000;
+
+	if (!gtm)
+		return;
+	if (!freq) {
+		out_8(gtm + GTCFR2, GTCFR_STP4 | GTCFR_STP3);
+		return;
+	}
+
+	out_8(gtm + GTCFR2, GTCFR_RST4 | GTCFR_STP3);
+	out_be16(gtm + GTPSR4, 255);
+	gtmdr = GTMDR_FRR | GTMDR_ICLK16;
+	if (beeper_irq != NO_IRQ) gtmdr |= GTMDR_ORI;
+	out_be16(gtm + GTMDR4, gtmdr);
+	out_be16(gtm + GTVER4, 3);
+	
+	out_be16(gtm + GTRFR4, timer_freq / 16 / 256 / freq / 2);
+	out_be16(gtm + GTCNR4, 0);
+}
+EXPORT_SYMBOL(rbppc_beep);
+
+static void __init rbppc_setup_arch(void)
+{
+	struct device_node *np;
+
+	immrs = ioremap(get_immrbase(), 0x2000);
+
+	np = of_find_node_by_name(NULL, "serial");
+	if (np) {
+		timer_freq =
+		    *(unsigned *) of_get_property(np, "clock-frequency", NULL);
+		of_node_put(np);
+	}
+
+#ifdef CONFIG_PCI
+	np = of_find_node_by_type(np, "pci");
+	if (np) {
+		const u32 *reg = of_get_property(np, "reg", NULL);
+		if (reg) ((u32 *) reg)[0] = of_translate_address(np, reg);
+		if (np->parent) np->parent = np->parent->parent;
+		mpc83xx_add_bridge(np);
+	}
+#endif
+
+#ifdef CONFIG_QUICC_ENGINE
+	np = of_find_node_by_name(np, "par_io");
+	if (np) {
+		qe_reset();
+		par_io_init(np);
+		of_node_put(np);
+
+		np = NULL;
+		while (1) {
+			np = of_find_node_by_name(np, "ucc");
+			if (!np) break;
+			
+			par_io_of_config(np);
+		}
+	}
+#endif
+}
+
+void __init rbppc_init_irq(void)
+{
+	struct device_node *np;
+
+	np = of_find_node_by_type(NULL, "ipic");
+	if (np) {
+		ipic_init(np, 0);
+		ipic_set_default_priority();
+		of_node_put(np);
+	}
+
+#ifdef CONFIG_QUICC_ENGINE
+	np = of_find_node_by_type(NULL, "qeic");
+	if (np) {
+		qe_ic_init(np, 0,
+			   qe_ic_cascade_low_ipic, qe_ic_cascade_high_ipic);
+		of_node_put(np);
+	}
+#endif
+}
+
+static int __init rbppc_probe(void)
+{
+	char *model;
+
+	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
+
+	if (!model)
+		return 0;
+
+	if (strcmp(model, "RB333") == 0)
+		return 1;
+	
+	if (strcmp(model, "RB600") == 0)
+		return 1;
+	
+	return 0;
+}
+
+static void __init rbppc_beeper_init(struct device_node *beeper)
+{
+	    
+	struct resource res;
+	struct device_node *gpio;
+	const unsigned *pin;
+	const unsigned *gpio_id;
+
+	if (of_address_to_resource(beeper, 0, &res)) {
+		printk("beeper error: no region specified\n");
+		return;
+	}
+
+	pin = of_get_property(beeper, "gpio", NULL);
+	if (pin) {
+		gpio = of_find_node_by_phandle(pin[0]);
+
+		if (!gpio) {
+			printk("beeper error: gpio handle %x not found\n",
+			       pin[0]);
+			return;
+		}
+
+		gpio_id = of_get_property(gpio, "device-id", NULL);
+		if (!gpio_id) {
+			printk("beeper error: no device-id specified"
+			       " in gpio\n");
+			return;
+		}
+
+		beeper_gpio_pin[0] = *gpio_id;
+		beeper_gpio_pin[1] = pin[1];
+		    
+		par_io_config_pin(*gpio_id, pin[1], 1, 0, 0, 0);
+	} else {
+		void *sysctl;
+
+		sysctl = ioremap_nocache(get_immrbase() + SYSCTL, 0x100);
+		out_be32(sysctl + SICRL,
+			 in_be32(sysctl + SICRL) | (1 << (31 - 19)));
+		iounmap(sysctl);
+	}
+
+	gtm = ioremap_nocache(res.start, res.end - res.start + 1);
+	
+	beeper_irq = irq_of_parse_and_map(beeper, 0);
+	if (beeper_irq != NO_IRQ) {
+	    int e = request_irq(beeper_irq, rbppc_timer_irq, 0, "beeper", NULL);
+	    if (e) printk(KERN_ERR "Request of beeper irq failed!\n");
+	}
+}
+
+static void rb_restart(char *cmd)
+{
+    unsigned rb_model;
+    struct device_node *root;
+    unsigned int size;    
+
+    root = of_find_node_by_path("/");
+    if (root) {
+	const char *prop = (char *) of_get_property(root, "model", &size);
+	rb_model = prop[sizeof("RB") - 1] - '0';
+	of_node_put(root);
+	switch (rb_model) {
+	case 3:
+	    local_irq_disable();
+	    out_be32(GPIO_DIR_RB300,
+		     (in_be32(GPIO_DIR_RB300) & ~DBIT(4, 3)) | DBIT(4, 1));
+	    out_be32(GPIO_DATA_RB300, in_be32(GPIO_DATA_RB300) & ~SBIT(4));
+	    break;
+	case 6:
+	    local_irq_disable();
+	    out_be32(SICRL_RB600, in_be32(SICRL_RB600) & ~0x00800000);
+	    out_be32(GPIO_DIR_RB600, in_be32(GPIO_DIR_RB600) | SBIT(2));
+	    out_be32(GPIO_DATA_RB600, in_be32(GPIO_DATA_RB600) & ~SBIT(2));
+	    break;
+	default:
+	    mpc83xx_restart(cmd);
+	    break;
+	}
+    }
+    else mpc83xx_restart(cmd);
+    
+    for (;;) ;
+}
+
+static struct resource rbppc_led_resources[2] = {
+	[0] = {
+		.flags		= IORESOURCE_IO,
+	},
+	[1] = {
+		.name		= "user-led",
+	},
+};
+
+static const unsigned rb333_uled[2] = { 0x4003, 0x0f };
+static const unsigned rb600_uled[2] = { 0x400, 0x08 };
+
+static int __init rbppc_init_leds(void)
+{
+	struct device_node *np;
+	const unsigned *uled;
+
+	np = of_find_node_by_name(NULL, "led");
+	if (np) {
+		uled = of_get_property(np, "user_led", NULL);
+		of_node_put(np);
+		if (!uled) {
+			printk("rbppc led error: "
+			       "user_led property is missing\n");
+			return -1;
+		}
+	}
+	else {
+		/* detect routerboard type */
+		np = of_find_node_by_name(NULL, "qe");
+		if (np) {
+			of_node_put(np);
+			uled = rb333_uled;
+		}
+		else {
+			uled = rb600_uled;
+		}
+	}
+
+	rbppc_led_resources[1].start = uled[1];
+	rbppc_led_resources[1].end = uled[1];
+
+	np = of_find_node_by_phandle(uled[0]);
+	if (!np) {
+		printk("rbppc led error: no gpio<%x> node found\n", *uled);
+		return -1;
+	}
+	if (of_address_to_resource(np, 0, &rbppc_led_resources[0])) {
+		of_node_put(np);
+		printk("rbppc led error: no reg property in gpio found\n");
+		return -1;
+	}
+	of_node_put(np);
+
+	platform_device_register_simple("rbppc-led", 0,
+					rbppc_led_resources, 2);
+	return 0;
+}
+
+static struct of_device_id rbppc_ids[] = {
+	{ .type = "soc", },
+	{ .compatible = "soc", },
+	{ .type = "qe", },
+	{ .type = "mdio", },
+	{},
+};
+
+static int __init rbppc_declare_of_platform_devices(void)
+{
+	struct device_node *np;
+	unsigned idx;
+
+	of_platform_bus_probe(NULL, rbppc_ids, NULL);
+
+	/* fix MDIO region */
+	np = of_find_node_by_type(NULL, "mdio");
+	if (np) {
+		unsigned len;
+		unsigned *res;
+		const unsigned *eres;
+		struct device_node *ep;
+		
+		ep = of_find_compatible_node(NULL, "network", "ucc_geth");
+		if (ep) {
+			eres = of_get_property(ep, "reg", &len);
+			res = (unsigned *) of_get_property(np, "reg", &len);
+			if (res && eres)
+				res[0] = eres[0] + 0x120;;
+	    }
+	}
+
+	np = of_find_node_by_name(NULL, "nand");
+	if (np) of_platform_device_create(np, "nand", NULL);
+
+	idx = 0;
+	for_each_node_by_type(np, "rb,cf") {
+		char dev_name[12];
+		snprintf(dev_name, sizeof(dev_name), "cf.%u", idx);
+		of_platform_device_create(np, dev_name, NULL);
+		++idx;		
+	}
+
+	np = of_find_node_by_name(NULL, "beeper");
+	if (np) rbppc_beeper_init(np);
+
+	rbppc_init_leds();
+
+	return 0;
+}
+machine_device_initcall(rb333, rbppc_declare_of_platform_devices);
+
+static void rb_halt(void)
+{
+	while (1);
+}
+
+void rb_power_off(void)
+{
+	printk(KERN_EMERG "System Halted, OK to turn off power\n");
+	while (1) ;
+}
+
+define_machine(rb333) {
+	.name 		= "RB333/RB600",
+	.probe 		= rbppc_probe,
+	.setup_arch 	= rbppc_setup_arch,
+	.init_IRQ 	= rbppc_init_irq,
+	.get_irq 	= ipic_get_irq,
+	.restart 	= rb_restart,
+	.halt		= rb_halt,
+	.time_init 	= mpc83xx_time_init,
+	.calibrate_decr	= generic_calibrate_decr,
+	.power_off	= rb_power_off,
+};
+
+static void fixup_pci(struct pci_dev *dev)
+{
+	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI) {
+		/* let the kernel itself set right memory windows */
+		pci_write_config_word(dev, PCI_MEMORY_BASE, 0);
+		pci_write_config_word(dev, PCI_MEMORY_LIMIT, 0);
+		pci_write_config_word(dev, PCI_PREF_MEMORY_BASE, 0);
+		pci_write_config_word(dev, PCI_PREF_MEMORY_LIMIT, 0);
+		pci_write_config_byte(dev, PCI_IO_BASE, 0);
+		pci_write_config_byte(dev, PCI_IO_LIMIT, 4 << 4);
+
+		pci_write_config_byte(
+		    dev, PCI_COMMAND,
+		    PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY | PCI_COMMAND_IO);
+		pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 8);
+	} else {
+		pci_write_config_byte(dev, PCI_LATENCY_TIMER, 0x40);
+	}
+}
+
+static void fixup_rb604(struct pci_dev *dev)
+{
+	pci_write_config_byte(dev, 0xC0, 0x01);
+}
+
+void change_latch(unsigned char set, unsigned char clear) {
+    printk("Hello, I am dummy! (%02x %02x)\n", set, clear);
+}
+
+EXPORT_SYMBOL(change_latch);
+
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, fixup_pci)
+DECLARE_PCI_FIXUP_HEADER(0x3388, 0x0021, fixup_rb604)
+
+struct irq_host *virq_host;
+EXPORT_SYMBOL(virq_host);
+
+int vm_yield(void) { return -1; }
+EXPORT_SYMBOL(vm_yield);
+
+unsigned get_virq_nr(unsigned hwirq) { return hwirq; }
+EXPORT_SYMBOL(get_virq_nr);
+
+int vm_running(void) { return -1; }
+EXPORT_SYMBOL(vm_running);
+
+unsigned get_gpio_def(const char *name) {
+    return 0;
+}
+
+EXPORT_SYMBOL(get_gpio_def);
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/Kconfig linux/arch/powerpc/platforms/85xx/Kconfig
--- linux-2.6.35/arch/powerpc/platforms/85xx/Kconfig	2011-04-26 16:26:47.432511510 +0300
+++ linux/arch/powerpc/platforms/85xx/Kconfig	2011-05-02 10:08:25.752790593 +0300
@@ -56,6 +56,40 @@ config MPC85xx_DS
 	help
 	  This option enables support for the MPC85xx DS (MPC8544 DS) board
 
+config RB1000
+	bool "Mikrotik RB1000"
+	select MT_VIC
+	select RB_AUX
+	select RB_IOMAP
+	help
+	  This option enables support for the Mikrotik RB1000 board
+
+
+config RB800
+	bool "Mikrotik RB800"
+	select MT_VIC
+	select RB_AUX
+	select RB_PCI
+	select RB_IOMAP
+	help
+	  This option enables support for the Mikrotik RB800 board
+
+config RB1100
+	bool "Mikrotik RB1100"
+	select MT_VIC
+	select RB_AUX
+	select RB_PCI
+	select RB_IOMAP
+	help
+	  This option enables support for the Mikrotik RB1100 board
+
+	
+config METAROUTER
+	bool "Mikrotik MetaROUTER"
+	select MT_VIC
+	help
+	  This option enables support for the Mikrotik MetaROUTER
+
 config MPC85xx_RDB
 	bool "Freescale MPC85xx RDB"
 	select PPC_I8259
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/Makefile linux/arch/powerpc/platforms/85xx/Makefile
--- linux-2.6.35/arch/powerpc/platforms/85xx/Makefile	2011-04-26 16:26:47.442477777 +0300
+++ linux/arch/powerpc/platforms/85xx/Makefile	2011-05-02 10:08:25.762791044 +0300
@@ -9,6 +9,10 @@ obj-$(CONFIG_MPC85xx_CDS) += mpc85xx_cds
 obj-$(CONFIG_MPC8536_DS)  += mpc8536_ds.o
 obj-$(CONFIG_MPC85xx_DS)  += mpc85xx_ds.o
 obj-$(CONFIG_MPC85xx_MDS) += mpc85xx_mds.o
+obj-$(CONFIG_RB1000)	  += rb1000.o
+obj-$(CONFIG_RB800)	  += rb800.o
+obj-$(CONFIG_RB1100)	  += rb1100.o
+obj-$(CONFIG_METAROUTER)  += metarouter.o
 obj-$(CONFIG_MPC85xx_RDB) += mpc85xx_rdb.o
 obj-$(CONFIG_P4080_DS)    += p4080_ds.o corenet_ds.o
 obj-$(CONFIG_STX_GP3)	  += stx_gp3.o
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/metarouter.c linux/arch/powerpc/platforms/85xx/metarouter.c
--- linux-2.6.35/arch/powerpc/platforms/85xx/metarouter.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/platforms/85xx/metarouter.c	2011-05-02 10:08:25.772907242 +0300
@@ -0,0 +1,187 @@
+#include <linux/interrupt.h>
+#include <linux/of_platform.h>
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/mtvic.h>
+#include <asm/rb_aux.h>
+#include <asm/vm.h>
+
+#define BUF_SIZE	256
+#define BUF_COUNT	4
+
+hypercall(vm_create_queue, 4, unsigned id, unsigned irq,
+	  unsigned tx, unsigned rx);
+hypercall(vm_release_queue, 5, unsigned id);
+hypercall(vm_running, 6, void);
+
+hypercall(vm_setup_irqs, 14, unsigned *irqs, unsigned count);
+hypercall(_vm_yield, 16, void);
+
+int vm_yield(void) {
+	BUG_ON(raw_irqs_disabled());
+	return _vm_yield();
+}
+EXPORT_SYMBOL(vm_yield);
+
+static volatile struct vdma_descr tx_chain[BUF_COUNT];
+static volatile struct vdma_descr rx_chain[BUF_COUNT];
+static unsigned char tx_buffers[BUF_COUNT][BUF_SIZE];
+static unsigned char rx_buffers[BUF_COUNT][BUF_SIZE];
+
+static unsigned cur_tx;
+static unsigned cur_rx;
+
+static int send_message(const unsigned char *buf, int len)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	/* drop some data if full buffer */
+	while (tx_chain[cur_tx].size & DONE)
+		hc_yield();
+
+	len = min_t(int, len, BUF_SIZE);
+	memcpy(tx_buffers[cur_tx], buf, len);
+	tx_chain[cur_tx].size = len | DONE;
+
+	cur_tx = (cur_tx + 1) % BUF_COUNT;
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static int recv_message(char *buf, int len)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	if (!(rx_chain[cur_rx].size & DONE)) {
+		local_irq_restore(flags);
+		return 0;
+	}
+	
+	len = min_t(int, len, rx_chain[cur_rx].size & ~DONE);
+	memcpy(buf, rx_buffers[cur_rx], len);
+
+	rx_chain[cur_rx].size = BUF_SIZE;
+	cur_rx = (cur_rx + 1) % BUF_COUNT;
+
+	local_irq_restore(flags);
+
+	return len;
+}
+
+static irqreturn_t ctrl_interrupt(int irq, void *dev_id)
+{
+	struct task_struct *init;
+	char buf[256];
+	int len;
+
+	len = recv_message(buf, sizeof(buf));
+	if (len <= 0)
+		return IRQ_HANDLED;
+
+	if (strncmp(buf, "restart", len) == 0) {
+		printk("RESTART\n");
+		init = find_task_by_pid_ns(1, &init_pid_ns);
+		if (init)
+			send_sig(SIGINT, init, 1);
+	} else if (strncmp(buf, "halt", len) == 0) {
+	    printk("HALT\n");
+		init = find_task_by_pid_ns(1, &init_pid_ns);
+		if (init)
+			send_sig(SIGWINCH, init, 1);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void rbvm_restart(char *command)
+{
+	char msg[] = "restart";
+
+	send_message(msg, sizeof(msg));
+
+	local_irq_disable();
+	while (1);
+}
+
+static void rbvm_power_off(void)
+{
+	char msg[] = "halt";
+
+	send_message(msg, sizeof(msg));
+}
+
+static int __init rbvm_probe(void)
+{
+	char *model;
+
+	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
+
+	if (!model)
+		return 0;
+
+	return strcmp(model, "RB MetaROUTER") == 0;
+}
+
+static void __init rbvm_pic_init(void)
+{
+	extern struct irq_host *virq_host;
+
+	mtvic_init(1);
+	vm_setup_irqs(virq_host->host_data, 32);
+}
+
+static void rbvm_idle(void) {
+	local_irq_enable();
+	vm_yield();
+	local_irq_disable();
+}
+
+static void __init rbvm_setup_arch(void)
+{
+	unsigned i;
+
+	for (i = 0; i < BUF_COUNT; ++i) {
+		rx_chain[i].addr = (unsigned) rx_buffers[i];
+		rx_chain[i].size = BUF_SIZE;
+		rx_chain[i].next = (unsigned) &rx_chain[i + 1];
+		
+		tx_chain[i].addr = (unsigned) tx_buffers[i];
+		tx_chain[i].size = 0;
+		tx_chain[i].next = (unsigned) &tx_chain[i + 1];
+	}
+	rx_chain[BUF_COUNT - 1].next = (unsigned) &rx_chain[0];
+	tx_chain[BUF_COUNT - 1].next = (unsigned) &tx_chain[0];
+
+	vm_create_queue(0, 0, (unsigned) &tx_chain[0],
+			(unsigned) &rx_chain[0]);
+
+	ppc_md.power_save = rbvm_idle;
+}
+
+int __init init_ctrl_interrupt(void)
+{
+	if (request_irq(get_virq_nr(0), ctrl_interrupt,
+			0, "ctrl", (void *) 1));
+
+	return 0;
+}
+machine_device_initcall(rbvm, init_ctrl_interrupt);
+
+define_machine(rbvm) {
+	.name			= "RB MetaROUTER",
+	.probe			= rbvm_probe,
+	.setup_arch		= rbvm_setup_arch,
+	.show_cpuinfo		= rb_show_cpuinfo,
+	.get_irq		= mtvic_get_irq,
+	.init_IRQ		= rbvm_pic_init,
+	.calibrate_decr		= generic_calibrate_decr,
+	.restart		= rbvm_restart,
+	.power_off		= rbvm_power_off,
+	.halt			= rbvm_power_off,
+};
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/rb1000.c linux/arch/powerpc/platforms/85xx/rb1000.c
--- linux-2.6.35/arch/powerpc/platforms/85xx/rb1000.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/platforms/85xx/rb1000.c	2011-05-02 10:08:25.792902763 +0300
@@ -0,0 +1,132 @@
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/mpic.h>
+#include <asm/mtvic.h>
+#include <asm/of_platform.h>
+#include <sysdev/fsl_pci.h>
+#include <asm/rb_aux.h>
+
+#ifdef MT_DEBUG
+void rb1000_putc(char c)
+{
+
+        while (!(*(volatile unsigned char *) 0xe0004505 & 0x20));
+
+	*(char *) 0xe0004500 = c;
+}
+
+void rb1000_puts(char *str)
+{
+        while (*str) {
+	        if (*str == '\n') rb1000_putc('\r');
+		rb1000_putc(*str);
+		++str;
+	}
+}
+
+void rb1000_printk(const char *fmt, ...) {
+	va_list args;
+	char buf[256];
+
+	va_start(args, fmt);
+	vsnprintf(buf, sizeof(buf), fmt, args);
+	va_end(args);
+
+	rb1000_puts(buf);
+}
+
+void rb1000_init(void)
+{
+#if 0
+        if (inited) return;
+
+        settlbcam(3, 0xf0000000, 0xe0000000, 0x10000, _PAGE_IO, 0);
+	inited = 1;
+#endif
+}
+#endif
+
+static void __init rb1000_pic_init(void)
+{
+	struct device_node *np;
+	struct resource r;
+	struct mpic *mpic;
+	void *gcr;
+	unsigned i;
+
+	mtvic_init(0);
+
+	np = of_find_node_by_type(NULL, "open-pic");
+
+	if (!np)
+		return;
+
+	if (of_address_to_resource(np, 0, &r)) {
+		printk(KERN_ERR "mpic error: no region specified\n");
+		of_node_put(np);
+		return;
+	}
+
+	gcr = ioremap(r.start + 0x1020, 4);
+	out_be32(gcr, in_be32(gcr) | (1 << 29));
+	iounmap(gcr);
+
+	mpic = mpic_alloc(np, r.start,
+			  MPIC_PRIMARY | MPIC_WANTS_RESET | MPIC_BIG_ENDIAN,
+			  1, 0, " OpenPIC ");
+	
+	for (i = 0; i < 31; ++i) {
+		if (i == 11 || i == 12) {
+		    /* Ext IRQ4 and IRQ5 is mapped to 11 & 12 respectively */
+			mpic_assign_isu(mpic, i,
+					r.start + 0x10000 + (i - 11 + 4) * 0x20);
+		} else if (i == 30) {
+			mpic_assign_isu(mpic, i, r.start + 0x10000 + 7 * 0x20);
+		} else {
+			mpic_assign_isu(mpic, i, r.start + 0x10200 + i * 0x20);
+		}
+	}
+	mpic_assign_isu(mpic, 31, r.start + 0x1120);
+
+	of_node_put(np);
+	mpic_init(mpic);
+}
+
+static void __init rb1000_setup_arch(void)
+{
+	mtspr(SPRN_HID0, 1 << 14); /* set TBEN */
+	mb();
+
+	/* matches MPC8548E, MPC8547E, MPC8545E */
+	if ((mfspr(SPRN_SVR) >> 16) == 0x8039)
+		add_crypto_of_node(0x1d);
+
+	ppc_md.power_save = rb_idle;
+}
+
+static int __init rb1000_probe(void)
+{
+	char *model;
+
+	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
+
+	if (!model)
+		return 0;
+
+	return strcmp(model, "RB1000") == 0;
+}
+
+void rb_power_off(void);
+
+define_machine(rb1000) {
+	.name			= "RB1000",
+	.probe			= rb1000_probe,
+	.setup_arch		= rb1000_setup_arch,
+	.init_IRQ		= rb1000_pic_init,
+	.show_cpuinfo		= rb_show_cpuinfo,
+	.get_irq		= rb_get_irq,
+	.restart		= rb_restart,
+	.calibrate_decr		= generic_calibrate_decr,
+	.pcibios_fixup_bus	= fsl_pcibios_fixup_bus,
+	.power_off		= rb_power_off,
+};
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/rb1100.c linux/arch/powerpc/platforms/85xx/rb1100.c
--- linux-2.6.35/arch/powerpc/platforms/85xx/rb1100.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/platforms/85xx/rb1100.c	2011-05-02 10:08:25.802907028 +0300
@@ -0,0 +1,81 @@
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/mpic.h>
+#include <asm/mtvic.h>
+#include <asm/of_platform.h>
+#include <sysdev/fsl_pci.h>
+#include <asm/rb_aux.h>
+
+static unsigned char latch_status = 0x0C; // the way booter sets latch
+
+static u64 get_latch_address(void) {
+    u64 size;
+    u64 ret = 0;
+    unsigned flags;
+    struct device_node *latch_dev_node;
+    latch_dev_node = of_find_node_by_name(NULL, "latch");
+    if (latch_dev_node) {
+	const u32 *tmp = of_get_address(latch_dev_node, 0, &size, &flags);
+	ret = of_translate_address(latch_dev_node, tmp);	
+	printk("rb1100 latch address = %08x\n", (u32) ret);
+	of_node_put(latch_dev_node);
+    }
+    return ret;
+}
+
+static unsigned char *latch = NULL;
+void change_latch(unsigned char set, unsigned char clear) {
+    latch_status = (latch_status & ~clear) | set;
+    out_8(latch, latch_status);    
+}
+
+EXPORT_SYMBOL(change_latch);
+
+static void __init rb1100_setup_arch(void)
+{
+	latch = ioremap_nocache(get_latch_address(), 1);
+
+	mtspr(SPRN_HID0, 1 << 14); /* set TBEN */
+	mb();
+
+	if ((mfspr(SPRN_SVR) >> 16) == 0x803c)
+		add_crypto_of_node(0x2d);
+
+	ppc_md.power_save = rb_idle;
+
+#ifdef CONFIG_PCI
+	rb_init_pci();
+#endif
+}
+
+static void __init rb1100_init_early(void) {
+	add_second_serial_of_node();
+}
+
+static int __init rb1100_probe(void)
+{
+	char *model;
+
+	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
+
+	if (!model)
+		return 0;
+
+	return strcmp(model, "RB1100") == 0;
+}
+
+void rb_power_off(void);
+
+define_machine(rb1100) {
+	.name			= "RB1100",
+	.probe			= rb1100_probe,
+	.setup_arch		= rb1100_setup_arch,
+	.init_early		= rb1100_init_early,
+	.init_IRQ		= rb_pic_init,
+	.get_irq		= rb_get_irq,
+	.show_cpuinfo		= rb_show_cpuinfo,
+	.restart		= rb_restart,
+	.calibrate_decr		= generic_calibrate_decr,
+	.pcibios_fixup_bus	= fsl_pcibios_fixup_bus,
+	.power_off		= rb_power_off,
+};
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/rb800.c linux/arch/powerpc/platforms/85xx/rb800.c
--- linux-2.6.35/arch/powerpc/platforms/85xx/rb800.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/platforms/85xx/rb800.c	2011-05-02 10:08:25.812906721 +0300
@@ -0,0 +1,54 @@
+#include <asm/time.h>
+#include <asm/machdep.h>
+#include <asm/mpic.h>
+#include <asm/mtvic.h>
+#include <asm/of_platform.h>
+#include <sysdev/fsl_pci.h>
+#include <asm/rb_aux.h>
+
+static void __init rb800_setup_arch(void)
+{
+	mtspr(SPRN_HID0, 1 << 14); /* set TBEN */
+	mb();
+
+	if ((mfspr(SPRN_SVR) >> 16) == 0x803c)
+		add_crypto_of_node(0x2d);
+
+	ppc_md.power_save = rb_idle;
+
+#ifdef CONFIG_PCI
+	rb_init_pci();
+#endif
+}
+
+static int __init rb800_probe(void)
+{
+	char *model;
+
+	model = of_get_flat_dt_prop(of_get_flat_dt_root(), "model", NULL);
+
+	if (!model)
+		return 0;
+
+	return strcmp(model, "RB800") == 0;
+}
+
+void rb_power_off(void);
+
+static void __init rb800_init_early(void) {
+	add_second_serial_of_node();
+}
+
+define_machine(rb800) {
+	.name			= "RB800",
+	.probe			= rb800_probe,
+	.setup_arch		= rb800_setup_arch,
+	.init_early		= rb800_init_early,
+	.init_IRQ		= rb_pic_init,
+	.get_irq		= rb_get_irq,
+	.show_cpuinfo		= rb_show_cpuinfo,
+	.restart		= rb_restart,
+	.calibrate_decr		= generic_calibrate_decr,
+	.pcibios_fixup_bus	= fsl_pcibios_fixup_bus,
+	.power_off		= rb_power_off,
+};
diff -puNrb linux-2.6.35/arch/powerpc/platforms/85xx/smp.c linux/arch/powerpc/platforms/85xx/smp.c
--- linux-2.6.35/arch/powerpc/platforms/85xx/smp.c	2011-04-26 16:26:47.432511510 +0300
+++ linux/arch/powerpc/platforms/85xx/smp.c	2011-05-02 10:08:25.832898471 +0300
@@ -103,6 +103,8 @@ smp_85xx_setup_cpu(int cpu_nr)
 
 struct smp_ops_t smp_85xx_ops = {
 	.kick_cpu = smp_85xx_kick_cpu,
+	.give_timebase = smp_generic_give_timebase,
+	.take_timebase = smp_generic_take_timebase,
 };
 
 void __init mpc85xx_smp_init(void)
diff -puNrb linux-2.6.35/arch/powerpc/platforms/Kconfig linux/arch/powerpc/platforms/Kconfig
--- linux-2.6.35/arch/powerpc/platforms/Kconfig	2011-04-26 16:26:47.652478068 +0300
+++ linux/arch/powerpc/platforms/Kconfig	2011-05-02 10:08:25.842790982 +0300
@@ -68,6 +68,15 @@ config MPIC_WEIRD
 	bool
 	default n
 
+config MT_VIC
+	bool
+
+config RB_AUX
+	bool
+
+config RB_PCI
+	bool
+
 config PPC_I8259
 	bool
 	default n
@@ -147,6 +156,9 @@ config GENERIC_IOMAP
 	bool
 	default n
 
+config RB_IOMAP
+	bool
+
 source "drivers/cpufreq/Kconfig"
 
 menu "CPU Frequency drivers"
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/Makefile linux/arch/powerpc/sysdev/Makefile
--- linux-2.6.35/arch/powerpc/sysdev/Makefile	2011-04-26 16:26:48.141233821 +0300
+++ linux/arch/powerpc/sysdev/Makefile	2011-05-02 10:08:25.852903909 +0300
@@ -6,6 +6,7 @@ endif
 
 mpic-msi-obj-$(CONFIG_PCI_MSI)	+= mpic_msi.o mpic_u3msi.o mpic_pasemi_msi.o
 obj-$(CONFIG_MPIC)		+= mpic.o $(mpic-msi-obj-y)
+obj-$(CONFIG_MT_VIC)		+= mtvic.o
 fsl-msi-obj-$(CONFIG_PCI_MSI)	+= fsl_msi.o
 obj-$(CONFIG_PPC_MSI_BITMAP)	+= msi_bitmap.o
 
@@ -51,9 +52,14 @@ obj-$(CONFIG_PPC_DCR)		+= dcr.o
 obj-$(CONFIG_8xx)		+= mpc8xx_pic.o cpm1.o
 obj-$(CONFIG_UCODE_PATCH)	+= micropatch.o
 
+obj-$(CONFIG_RB_IOMAP)		+= rb_iomap.o
+obj-$(CONFIG_RB_AUX)		+= rb_aux.o
+obj-$(CONFIG_RB_PCI)		+= rb_pci.o
+
 obj-$(CONFIG_PPC_MPC512x)	+= mpc5xxx_clocks.o
 obj-$(CONFIG_PPC_MPC52xx)	+= mpc5xxx_clocks.o
 
 ifeq ($(CONFIG_SUSPEND),y)
 obj-$(CONFIG_6xx)		+= 6xx-suspend.o
 endif
+
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/mtvic.c linux/arch/powerpc/sysdev/mtvic.c
--- linux-2.6.35/arch/powerpc/sysdev/mtvic.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/sysdev/mtvic.c	2011-05-02 10:08:25.872898576 +0300
@@ -0,0 +1,73 @@
+#include <linux/module.h>
+#include <linux/irq.h>
+#include <asm/mpic.h>
+#include <asm/mtvic.h>
+
+struct irq_host *virq_host;
+EXPORT_SYMBOL(virq_host);
+
+unsigned get_virq_nr(unsigned hwirq)
+{
+	return irq_create_mapping(virq_host, hwirq);
+}
+EXPORT_SYMBOL(get_virq_nr);
+
+void mtvic_mask_irq(unsigned int irq)
+{
+}
+
+void mtvic_unmask_irq(unsigned int irq)
+{
+}
+
+static struct irq_chip softirq_chip = {
+	.mask	= mtvic_mask_irq,
+	.unmask	= mtvic_unmask_irq,
+};
+
+static int mtvic_map(struct irq_host *h, unsigned int virq, irq_hw_number_t hw)
+{
+	set_irq_chip_and_handler(virq, &softirq_chip, handle_simple_irq);
+	return 0;
+}
+
+static struct irq_host_ops mtvic_ops = {
+	.map = mtvic_map,
+};
+
+void __init mtvic_init(int def)
+{
+	static unsigned virqs;
+
+	virq_host = irq_alloc_host(NULL, IRQ_HOST_MAP_LINEAR, 32,
+				   &mtvic_ops, 32);
+	virq_host->host_data = &virqs;
+
+	if (def)
+		irq_set_default_host(virq_host);
+}
+
+unsigned mtvic_get_irq(void)
+{
+	static unsigned i = 0;
+	unsigned *irqs = virq_host->host_data;
+
+	if (!irqs)
+		return NO_IRQ;
+
+	for (i = (i + 1) & 31; *irqs; i = (i + 1) & 31) {
+		if (*irqs & (1 << i)) {
+			atomic_sub(1 << i, (atomic_t *) irqs);
+			return irq_linear_revmap(virq_host, i);
+		}
+	}
+	return NO_IRQ;
+}
+
+unsigned rb_get_irq(void)
+{
+	unsigned irq = mtvic_get_irq();
+	if (irq != NO_IRQ) return irq;
+
+	return mpic_get_irq();
+}
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/ppc4xx_pci.c linux/arch/powerpc/sysdev/ppc4xx_pci.c
--- linux-2.6.35/arch/powerpc/sysdev/ppc4xx_pci.c	2011-04-26 16:26:48.141233821 +0300
+++ linux/arch/powerpc/sysdev/ppc4xx_pci.c	2011-05-02 10:08:25.882905087 +0300
@@ -883,7 +883,7 @@ static int ppc460ex_pciex_init_port_hw(s
 
 	if (port->index == 0) {
 		val |= LNKW_X1 << 12;
-		utlset1 = 0x20000000;
+		utlset1 = 0x00000000;
 	} else {
 		val |= LNKW_X4 << 12;
 		utlset1 = 0x20101101;
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/ppc4xx_soc.c linux/arch/powerpc/sysdev/ppc4xx_soc.c
--- linux-2.6.35/arch/powerpc/sysdev/ppc4xx_soc.c	2011-04-26 16:26:48.151234374 +0300
+++ linux/arch/powerpc/sysdev/ppc4xx_soc.c	2011-05-02 10:08:25.892900361 +0300
@@ -63,7 +63,7 @@ static irqreturn_t l2c_error_handler(int
 	if (sr & (L2C_SR_CPE | L2C_SR_TPE)){
 		mtdcr(dcrbase_l2c + DCRN_L2C0_ADDR, 0);
 		mtdcr(dcrbase_l2c + DCRN_L2C0_CMD, L2C_CMD_CCP | L2C_CMD_CTE);
-	} else {
+	} else if (sr & L2C_SR_LRU) {
 		printk(KERN_EMERG "L2C: LRU error\n");
 	}
 
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/qe_lib/qe.c linux/arch/powerpc/sysdev/qe_lib/qe.c
--- linux-2.6.35/arch/powerpc/sysdev/qe_lib/qe.c	2011-04-26 16:26:48.063124148 +0300
+++ linux/arch/powerpc/sysdev/qe_lib/qe.c	2011-05-02 10:08:25.912903608 +0300
@@ -327,7 +327,7 @@ static int qe_sdma_init(void)
 	/* allocate 2 internal temporary buffers (512 bytes size each) for
 	 * the SDMA */
 	if (IS_ERR_VALUE(sdma_buf_offset)) {
-		sdma_buf_offset = qe_muram_alloc(512 * 2, 4096);
+		sdma_buf_offset = qe_muram_alloc(512 * 2, 64);
 		if (IS_ERR_VALUE(sdma_buf_offset))
 			return -ENOMEM;
 	}
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/rb_aux.c linux/arch/powerpc/sysdev/rb_aux.c
--- linux-2.6.35/arch/powerpc/sysdev/rb_aux.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/sysdev/rb_aux.c	2011-05-02 10:08:25.922905335 +0300
@@ -0,0 +1,379 @@
+#include <linux/module.h>
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/interrupt.h>
+#include <linux/seq_file.h>
+#include <linux/of_platform.h>
+#include <linux/of_gpio.h>
+#include <linux/gpio.h>
+#include <mm/mmu_decl.h>
+#include <asm/machdep.h>
+#include <asm/mpic.h>
+#include <asm/mtvic.h>
+#include <asm/vm.h>
+#include <asm/rb_aux.h>
+
+#define GPIO(x) (0x80000000 >> (x))
+static unsigned *gpio_data = NULL;
+static unsigned *picr = NULL;
+
+const unsigned *beep1;
+const unsigned *beep2;
+
+#define GT0_BASE_COUNT (picr + (0x1110 / 4))
+
+hypercall(hv_yield, 16, void);
+
+static void ioremap_from_node(const unsigned *property, unsigned **ptr) {
+    struct resource res;
+    struct device_node *nd;
+    
+    nd = of_find_node_by_phandle(property[0]);
+    if (!nd || of_address_to_resource(nd, 0, &res)) return;
+    of_node_put(nd);
+
+    *ptr = ioremap_nocache(res.start, res.end - res.start + 1);
+}
+
+irqreturn_t beeper_irq(int irq, void *ptr)
+{
+	static int toggle = 1;
+	if (toggle) {
+	    out_be32(gpio_data, in_be32(gpio_data) & ~GPIO(beep1[0]));
+	    out_be32(gpio_data, in_be32(gpio_data) & ~GPIO(beep2[0]));
+	}
+	else {
+	    out_be32(gpio_data, in_be32(gpio_data) | GPIO(beep1[0]));
+	    out_be32(gpio_data, in_be32(gpio_data) | GPIO(beep2[0]));
+	}
+	toggle ^= 1; 
+	return IRQ_HANDLED;
+}
+
+void consume(int x) { }
+
+extern unsigned long ppc_tb_freq;
+static unsigned long ppc_tb_freq_kHz;
+
+static void __init rb_beeper_init(void)
+{
+	struct device_node *beeper;
+	unsigned interrupt;
+	const unsigned *int_p;
+	const unsigned *gpio;
+	
+	beeper = of_find_node_by_name(NULL, "beeper");
+	if (!beeper)
+		return;
+
+	beep1 = of_get_property(beeper, "beep1", NULL);
+	beep2 = of_get_property(beeper, "beep2", NULL);
+	gpio  = of_get_property(beeper, "gpio", NULL);
+	int_p = of_get_property(beeper, "interrupt-parent", NULL);
+	
+	ioremap_from_node(gpio, &gpio_data);
+	ioremap_from_node(int_p, &picr);
+	
+	ppc_tb_freq_kHz = (ppc_tb_freq / 1000);
+	
+	interrupt = irq_of_parse_and_map(beeper, 0);
+	if (interrupt != NO_IRQ)
+		consume(request_irq(interrupt, beeper_irq, 
+				    IRQF_TRIGGER_RISING,
+				    "beeper", NULL));
+}
+
+void rbppc_beep(unsigned freq) {
+	if (!ppc_tb_freq_kHz)
+		return;
+
+	out_be32(GT0_BASE_COUNT,
+		 freq ? (500 * ppc_tb_freq_kHz) / freq : 0x80000000);
+}
+EXPORT_SYMBOL(rbppc_beep);
+
+static struct resource rb_led_resources[2] = {
+	[0] = {
+		.flags		= IORESOURCE_IO,
+	},
+	[1] = {
+		.name		= "user-led",
+	},
+};
+
+static const unsigned rb_uled[2] = { 0x400, 0x1c };
+
+static int __init rb_leds_init(void)
+{
+	struct device_node *np;
+	const unsigned *uled = rb_uled;
+
+	np = of_find_node_by_name(NULL, "led");
+	if (np) {
+		uled = of_get_property(np, "user_led", NULL);
+		of_node_put(np);
+		if (!uled) {
+			printk("rbppc led error: "
+			       "user_led property is missing\n");
+			return -1;
+		}
+	}
+
+	rb_led_resources[1].start = uled[1];
+	rb_led_resources[1].end = uled[1];
+
+	np = of_find_node_by_phandle(uled[0]);
+	if (!np) {
+		printk("rbppc led error: no gpio<%x> node found\n", *uled);
+		return -1;
+	}
+	if (of_address_to_resource(np, 0, &rb_led_resources[0])) {
+		of_node_put(np);
+		printk("rbppc led error: no reg property in gpio found\n");
+		return -1;
+	}
+	of_node_put(np);
+
+	platform_device_register_simple("rbppc-led", 0,
+					rb_led_resources, 2);
+	return 0;
+}
+
+static struct of_device_id __initdata of_bus_ids[] = {
+	{ .type = "soc", },
+	{},
+};
+
+static int __init rb_declare_of_platform_devices(void)
+{
+	struct device_node *np;
+	unsigned idx;
+
+	np = of_find_node_by_name(NULL, "nand");
+	if (np) of_platform_device_create(np, "nand", NULL);
+
+	np = of_find_node_by_name(NULL, "nand_fcm");
+	if (np) of_platform_device_create(np, "nand_fcm", NULL);
+
+	np = of_find_node_by_name(NULL, "spi");
+	if (np) of_platform_device_create(np, "spi", NULL);
+
+	idx = 0;
+	for_each_node_by_type(np, "rb,cf") {
+		char dev_name[12];
+		snprintf(dev_name, sizeof(dev_name), "cf.%u", idx);
+		of_platform_device_create(np, dev_name, NULL);
+		++idx;		
+	}
+
+	rb_beeper_init();
+	rb_leds_init();
+
+	of_platform_bus_probe(NULL, of_bus_ids, NULL);
+
+	return 0;
+}
+
+device_initcall(rb_declare_of_platform_devices);
+
+void __init rb_pic_init(void)
+{
+	struct device_node *np;
+	struct resource r;
+	struct mpic *mpic;
+	void *gcr;
+	unsigned i;
+
+	mtvic_init(0);
+
+	np = of_find_node_by_type(NULL, "open-pic");
+
+	if (!np)
+		return;
+
+	if (of_address_to_resource(np, 0, &r)) {
+		printk(KERN_ERR "mpic error: no region specified\n");
+		of_node_put(np);
+		return;
+	}
+
+	gcr = ioremap(r.start + 0x1020, 4);
+	out_be32(gcr, in_be32(gcr) | (1 << 29));
+	iounmap(gcr);
+
+	mpic = mpic_alloc(np, r.start, 
+			  MPIC_PRIMARY | MPIC_WANTS_RESET | MPIC_BIG_ENDIAN,
+			  4, 0, " OpenPIC ");
+	for (i = 0; i < 80; i += 4) {
+		/* 
+		 * each mpic_assign_isu call assigns 4 isus at once
+		 * (as it is specified in mpic_alloc call 4th argument)
+		 * therefore base address must be incremented by 0x80
+		 */
+		mpic_assign_isu(mpic, i / 4, r.start + 0x10000 + i * 0x20);
+	}
+	mpic_assign_isu(mpic, 80 / 4, r.start + 0x1120);
+
+	of_node_put(np);
+	mpic_init(mpic);
+}
+
+void rb_show_cpuinfo(struct seq_file *m)
+{
+	seq_printf(m, "Vendor\t\t: Mikrotik\n");
+	seq_printf(m, "Machine\t\t: %s\n", ppc_md.name);
+	seq_printf(m, "Memory\t\t: %u MB\n", total_memory / (1024 * 1024));
+}
+
+void rb_restart(char *cmd)
+{
+	local_irq_disable();
+
+	mtmsr(mfmsr() | 0x00000200);
+	mtspr(0x134, mfspr(0x134) | 0x70000000);
+}
+
+void rb_power_off(void)
+{
+	printk(KERN_EMERG "System Halted, OK to turn off power\n");
+	while (1) ;
+}
+
+void rb_idle(void) {
+	extern void e500_idle(void);
+	int err;
+
+	local_irq_enable();
+	err = hv_yield();
+	local_irq_disable();
+	if (err < 0) e500_idle();
+}
+
+struct of_prop {
+    const char *name;
+    unsigned size;
+    unsigned values[2];
+    struct property prop;
+};
+
+void add_of_property(struct device_node *np, struct property *pp,
+		     const char *name, unsigned size, void *value)
+{
+	memset(pp, 0, sizeof(struct property));
+	pp->name = (char *) name;
+	pp->length = size;
+	pp->value = value;
+
+	prom_add_property(np, pp);
+}
+
+struct of_prop serial_properties[] = {
+    { "reg", 8, { 0x4500, 0x100 } },
+    { "interrupts", 8,  { 0x2a, 2 } },
+    { "interrupt-parent", 4, { 0x700 } },
+    { NULL, 0, { 0 } }
+};
+
+/*
+ * The device tree is traversed in some funny order. If we just add second
+ * serial node (0x4600) then it is found as first and onboard serial connector
+ * is found as second which is no good because debug and console will
+ * show up on serial that is attaced to header pins. Therefore we add new node
+ * with offset (0x4500) and replace original node's offset with (0x4600)
+ */
+void add_second_serial_of_node(void)
+{
+	static struct device_node serial_node;
+	static struct property comp_prop;
+	static struct property clock_prop;
+	static unsigned clock = 0;
+
+	struct device_node *np;
+	struct device_node *sp;
+	struct of_prop *p;
+
+	sp = of_find_node_by_type(NULL, "serial");
+	if (!sp) return;
+
+	clock = * (unsigned *) of_get_property(sp, "clock-frequency", NULL);
+
+	np = &serial_node;
+	memset(np, 0, sizeof(struct device_node));
+	kref_init(&np->kref);
+
+	np->name = "serial-port";
+	np->type = of_get_property(sp, "device_type", NULL);
+
+	add_of_property(np, &comp_prop,  "compatible",      8, "ns16550");
+	add_of_property(np, &clock_prop, "clock-frequency", 4, &clock);
+
+	for (p = serial_properties; p->name; ++p) {
+		add_of_property(np, &p->prop, p->name, p->size, p->values);
+	}
+
+	/* change original node to 0x4600 */
+	np->full_name = sp->full_name;
+	sp->full_name = "/soc8544@e0000000/serial@4600";	
+	* (unsigned *) of_get_property(sp, "reg", NULL) = 0x4600;
+
+	np->parent = sp->parent;
+	of_attach_node(np);
+}
+
+struct of_prop crypto_properties[] = {
+    { "reg", 8, { 0x30000, 0x10000 } },
+    { "interrupts", 8,  { 0x1d, 2 } },
+    { "interrupt-parent", 4, { 0x700 } },
+    { "fsl,num-channels", 4, { 4 } },
+    { "fsl,channel-fifo-len", 4, { 24 } },
+    { "fsl,exec-units-mask", 4, { 0xfe } },
+    { "fsl,descriptor-types-mask", 4, { 0x12b0ebf } },
+    { NULL, 0, { 0 } }
+};
+
+void add_crypto_of_node(unsigned irq)
+{
+	static struct device_node crypto_node;
+	static struct property comp_prop;
+
+	struct device_node *np;
+	struct device_node *sp;
+	struct of_prop *p;
+
+	sp = of_find_node_by_type(NULL, "serial");
+	if (!sp)
+		return;
+
+	np = &crypto_node;
+	memset(np, 0, sizeof(struct device_node));
+	np->full_name = "crypto@30000";
+	kref_init(&np->kref);
+	
+	add_of_property(np, &comp_prop, "compatible", 11, "fsl,sec2.0");
+
+	for (p = crypto_properties; p->name; ++p) {
+		if (strcmp(p->name, "interrupts") == 0) {
+		    p->values[0] = irq;
+		}
+		add_of_property(np, &p->prop, p->name, p->size, p->values);
+	}
+
+	np->parent = sp->parent;
+	of_attach_node(np);
+}
+
+unsigned get_gpio_def(const char *name) {
+    unsigned pin = 0;
+    struct device_node *np, *child;	
+    np = of_find_node_by_name(NULL, "gpio-definitions");
+    if (!np) return 0;
+    for_each_child_of_node(np, child) {
+	if (strcmp(child->name, name) == 0) {
+	    pin = of_get_gpio(child, 0);
+	}
+    }
+    of_node_put(np);
+    return pin;
+}
+
+EXPORT_SYMBOL(get_gpio_def);
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/rb_iomap.c linux/arch/powerpc/sysdev/rb_iomap.c
--- linux-2.6.35/arch/powerpc/sysdev/rb_iomap.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/sysdev/rb_iomap.c	2011-05-02 10:08:25.932904166 +0300
@@ -0,0 +1,223 @@
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/mm.h>
+#include <asm/io.h>
+
+#define LOCALBUS_START		0x40000000
+#define LOCALBUS_MASK		0x007fffff
+#define LOCALBUS_REGMASK	0x001fffff
+
+static void __iomem *localbus_base;
+
+static inline int is_localbus(void __iomem *addr)
+{
+	return ((unsigned) addr & ~LOCALBUS_MASK) == LOCALBUS_START;
+}
+
+static inline unsigned localbus_regoff(unsigned reg) {
+	return (reg << 16) | (((reg ^ 8) & 8) << 17);
+}
+
+static inline void __iomem *localbus_addr(void __iomem *addr)
+{
+	return localbus_base
+	    + ((unsigned) addr & LOCALBUS_MASK & ~LOCALBUS_REGMASK)
+	    + localbus_regoff((unsigned) addr & LOCALBUS_REGMASK);
+}
+
+unsigned int ioread8(void __iomem *addr)
+{
+	if (is_localbus(addr))
+		return in_be16(localbus_addr(addr)) >> 8;
+	return readb(addr);
+}
+EXPORT_SYMBOL(ioread8);
+
+unsigned int ioread16(void __iomem *addr)
+{
+	if (is_localbus(addr))
+		return le16_to_cpu(in_be16(localbus_addr(addr)));
+	return readw(addr);
+}
+EXPORT_SYMBOL(ioread16);
+
+unsigned int ioread16be(void __iomem *addr)
+{
+	return in_be16(addr);
+}
+EXPORT_SYMBOL(ioread16be);
+
+unsigned int ioread32(void __iomem *addr)
+{
+	return readl(addr);
+}
+EXPORT_SYMBOL(ioread32);
+
+unsigned int ioread32be(void __iomem *addr)
+{
+	return in_be32(addr);
+}
+EXPORT_SYMBOL(ioread32be);
+
+void iowrite8(u8 val, void __iomem *addr)
+{
+	if (is_localbus(addr))
+		out_be16(localbus_addr(addr), ((u16) val) << 8);
+	else
+		writeb(val, addr);
+}
+EXPORT_SYMBOL(iowrite8);
+
+void iowrite16(u16 val, void __iomem *addr)
+{
+	if (is_localbus(addr))
+		out_be16(localbus_addr(addr), cpu_to_le16(val));
+	else
+		writew(val, addr);
+}
+EXPORT_SYMBOL(iowrite16);
+
+void iowrite16be(u16 val, void __iomem *addr)
+{
+	out_be16(addr, val);
+}
+EXPORT_SYMBOL(iowrite16be);
+
+void iowrite32(u32 val, void __iomem *addr)
+{
+	writel(val, addr);
+}
+EXPORT_SYMBOL(iowrite32);
+
+void iowrite32be(u32 val, void __iomem *addr)
+{
+	out_be32(addr, val);
+}
+EXPORT_SYMBOL(iowrite32be);
+
+void ioread8_rep(void __iomem *addr, void *dst, unsigned long count)
+{
+	if (is_localbus(addr)) {
+		unsigned i;
+		void *laddr = localbus_addr(addr);
+		u8 *buf = dst;
+		
+		for (i = 0; i < count; ++i) {
+			*buf++ = in_be16(laddr) >> 8;
+		}
+	} else {
+		_insb((u8 __iomem *) addr, dst, count);
+	}
+}
+EXPORT_SYMBOL(ioread8_rep);
+
+void ioread16_rep(void __iomem *addr, void *dst, unsigned long count)
+{
+	if (is_localbus(addr)) {
+		unsigned i;
+		void *laddr = localbus_addr(addr);
+		u16 *buf = dst;
+		
+		for (i = 0; i < count; ++i) {
+			*buf++ = in_be16(laddr);
+		}
+	} else {
+		_insw_ns((u16 __iomem *) addr, dst, count);
+	}
+}
+EXPORT_SYMBOL(ioread16_rep);
+
+void ioread32_rep(void __iomem *addr, void *dst, unsigned long count)
+{
+	_insl_ns((u32 __iomem *) addr, dst, count);
+}
+EXPORT_SYMBOL(ioread32_rep);
+
+void iowrite8_rep(void __iomem *addr, const void *src, unsigned long count)
+{
+	if (is_localbus(addr)) {
+		unsigned i;
+		void *laddr = localbus_addr(addr);
+		const u8 *buf = src;
+		
+		for (i = 0; i < count; ++i) {
+			out_be16(laddr, ((u16) *buf++) << 8);
+		}
+	} else {
+		_outsb((u8 __iomem *) addr, src, count);
+	}
+}
+EXPORT_SYMBOL(iowrite8_rep);
+
+void iowrite16_rep(void __iomem *addr, const void *src, unsigned long count)
+{
+	if (is_localbus(addr)) {
+		unsigned i;
+		void *laddr = localbus_addr(addr);
+		const u16 *buf = src;
+		
+		for (i = 0; i < count; ++i) {
+			out_be16(laddr, *buf++);
+		}
+	} else {
+		_outsw_ns((u16 __iomem *) addr, src, count);
+	}
+}
+EXPORT_SYMBOL(iowrite16_rep);
+
+void iowrite32_rep(void __iomem *addr, const void *src, unsigned long count)
+{
+	_outsl_ns((u32 __iomem *) addr, src, count);
+}
+EXPORT_SYMBOL(iowrite32_rep);
+
+void __iomem *ioport_map(unsigned long port, unsigned int len)
+{
+	return (void __iomem *) (port + _IO_BASE);
+}
+EXPORT_SYMBOL(ioport_unmap);
+
+void ioport_unmap(void __iomem *addr)
+{
+	/* Nothing to do */
+}
+EXPORT_SYMBOL(ioport_map);
+
+void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max)
+{
+	unsigned long start = pci_resource_start(dev, bar);
+	unsigned long len = pci_resource_len(dev, bar);
+	unsigned long flags = pci_resource_flags(dev, bar);
+
+	if (!len)
+		return NULL;
+	if (max && len > max)
+		len = max;
+	if (flags & IORESOURCE_IO)
+		return ioport_map(start, len);
+	if (flags & IORESOURCE_MEM)
+		return ioremap(start, len);
+	/* What? */
+	return NULL;
+}
+EXPORT_SYMBOL(pci_iomap);
+
+void pci_iounmap(struct pci_dev *dev, void __iomem *addr)
+{
+	/* Nothing to do */
+}
+EXPORT_SYMBOL(pci_iounmap);
+
+void __iomem *localbus_map(unsigned long addr, unsigned int len)
+{
+	if (!localbus_base)
+		localbus_base = ioremap(addr & ~LOCALBUS_MASK,
+					LOCALBUS_MASK + 1);
+	return (void *) (LOCALBUS_START + (addr & LOCALBUS_MASK));
+}
+EXPORT_SYMBOL(localbus_map);
+
+void localbus_unmap(void __iomem *addr)
+{
+}
+EXPORT_SYMBOL(localbus_unmap);
diff -puNrb linux-2.6.35/arch/powerpc/sysdev/rb_pci.c linux/arch/powerpc/sysdev/rb_pci.c
--- linux-2.6.35/arch/powerpc/sysdev/rb_pci.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/arch/powerpc/sysdev/rb_pci.c	2011-05-02 10:08:25.942902837 +0300
@@ -0,0 +1,78 @@
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <sysdev/fsl_pci.h>
+
+#ifdef CONFIG_PCI
+static int rb_exclude_device(struct pci_controller *hose,
+				 u_char bus, u_char devfn)
+{
+	return (bus == 0 && PCI_SLOT(devfn) == 0)
+	    ? PCIBIOS_SUCCESSFUL // PCIBIOS_DEVICE_NOT_FOUND
+	    : PCIBIOS_SUCCESSFUL;
+}
+#endif /* CONFIG_PCI */
+
+void __init rb_init_pci(void)
+{
+	struct device_node *np;
+
+	for_each_compatible_node(np, "pci", "fsl,mpc8540-pci")
+	    fsl_add_bridge(np, 1);
+
+	for_each_compatible_node(np, "pci", "fsl,mpc8540-pcie")
+	    fsl_add_bridge(np, 0);
+
+	ppc_md.pci_exclude_device = rb_exclude_device;
+}
+
+static void __init rb_secondary_bridge_fixup(struct pci_dev *dev) {
+	/* enable i/o space & memory space and bus master control */
+	pci_write_config_word(dev, PCI_COMMAND, 7);
+
+	/* disable prefetched memory range */
+	pci_write_config_word(dev, PCI_PREF_MEMORY_LIMIT, 0);
+	pci_write_config_word(dev, PCI_PREF_MEMORY_BASE, 0x10);
+
+	pci_write_config_word(dev, PCI_BASE_ADDRESS_0, 0);
+	pci_write_config_word(dev, PCI_BASE_ADDRESS_1, 0);
+
+	pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 8);
+
+	pci_write_config_byte(dev, 0xc0, 1);
+}
+
+DECLARE_PCI_FIXUP_HEADER(0x3388, 0x0021, rb_secondary_bridge_fixup);
+
+static void fixup_pci(struct pci_dev *dev)
+{
+	if ((dev->class >> 8) == PCI_CLASS_BRIDGE_PCI) {
+		/* let the kernel itself set right memory windows */
+		pci_write_config_word(dev, PCI_MEMORY_BASE, 0);
+		pci_write_config_word(dev, PCI_MEMORY_LIMIT, 0);
+		pci_write_config_word(dev, PCI_PREF_MEMORY_BASE, 0);
+		pci_write_config_word(dev, PCI_PREF_MEMORY_LIMIT, 0);
+		pci_write_config_byte(dev, PCI_IO_BASE, 0);
+		pci_write_config_byte(dev, PCI_IO_LIMIT, 4 << 4);
+
+		pci_write_config_byte(
+		    dev, PCI_COMMAND,
+		    PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY | PCI_COMMAND_IO);
+		pci_write_config_byte(dev, PCI_CACHE_LINE_SIZE, 8);
+	} else if (dev->vendor == 0x1957 &&
+		   (dev->device == 0x32 || dev->device == 0x33)) {
+		unsigned short val;
+		pci_read_config_word(dev, 0x44, &val);
+		pci_write_config_word(dev, 0x44, val | (1 << 10));
+		pci_write_config_byte(dev, PCI_LATENCY_TIMER, 0x00);
+	} else {
+		pci_write_config_byte(dev, PCI_LATENCY_TIMER, 0x40);
+	}
+}
+
+static void fixup_rb604(struct pci_dev *dev)
+{
+	pci_write_config_byte(dev, 0xC0, 0x01);
+}
+
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, fixup_pci)
+DECLARE_PCI_FIXUP_HEADER(0x3388, 0x0021, fixup_rb604)
diff -puNrb linux-2.6.35/arch/x86/oprofile/init.c linux/arch/x86/oprofile/init.c
--- linux-2.6.35/arch/x86/oprofile/init.c	2011-04-26 16:27:00.181233192 +0300
+++ linux/arch/x86/oprofile/init.c	2011-05-02 10:08:25.952790418 +0300
@@ -20,6 +20,7 @@ extern int op_nmi_init(struct oprofile_o
 extern int op_nmi_timer_init(struct oprofile_operations *ops);
 extern void op_nmi_exit(void);
 extern void x86_backtrace(struct pt_regs * const regs, unsigned int depth);
+extern int __init hrtimer_oprofile_init(struct oprofile_operations *);
 
 
 int __init oprofile_arch_init(struct oprofile_operations *ops)
@@ -28,6 +29,11 @@ int __init oprofile_arch_init(struct opr
 
 	ret = -ENODEV;
 
+	ops->backtrace = x86_backtrace;
+
+	if (hrtimer_oprofile_init(ops) == 0)
+		return 0;
+
 #ifdef CONFIG_X86_LOCAL_APIC
 	ret = op_nmi_init(ops);
 #endif
@@ -35,8 +41,6 @@ int __init oprofile_arch_init(struct opr
 	if (ret < 0)
 		ret = op_nmi_timer_init(ops);
 #endif
-	ops->backtrace = x86_backtrace;
-
 	return ret;
 }
 
diff -puNrb linux-2.6.35/arch/x86/oprofile/Makefile linux/arch/x86/oprofile/Makefile
--- linux-2.6.35/arch/x86/oprofile/Makefile	2011-04-26 16:27:00.181233192 +0300
+++ linux/arch/x86/oprofile/Makefile	2011-05-02 10:08:25.972790887 +0300
@@ -4,6 +4,7 @@ DRIVER_OBJS = $(addprefix ../../../drive
 		oprof.o cpu_buffer.o buffer_sync.o \
 		event_buffer.o oprofile_files.o \
 		oprofilefs.o oprofile_stats.o  \
+		hrtimer.o \
 		timer_int.o )
 
 oprofile-y				:= $(DRIVER_OBJS) init.o backtrace.o
diff -puNrb linux-2.6.35/drivers/ata/Kconfig linux/drivers/ata/Kconfig
--- linux-2.6.35/drivers/ata/Kconfig	2011-04-26 16:28:34.673205734 +0300
+++ linux/drivers/ata/Kconfig	2011-05-02 10:08:25.982791194 +0300
@@ -803,6 +803,31 @@ config PATA_WINBOND_VLB
 	  Support for the Winbond W83759A controller on Vesa Local Bus
 	  systems.
 
+config PATA_RBPPC
+	tristate "Mikrotik PowerPC Routerboard Compact Flash support"
+	depends on PPC
+	help
+	  This option enables support for a Compact Flash on
+          Mikrotik PowerPC Routerboards
+
+	  If unsure, say N.
+
+config PATA_RB500
+	tristate "Mikrotik RB500 Compact Flash support"
+	depends on MIPS_MIKROTIK
+	help
+	  This option enables support for a Compact Flash on Mikrotik RB500
+
+	  If unsure, say N.
+
+config PATA_RB100
+	tristate "Mikrotik RB100 Compact Flash support"
+	depends on MIPS_MIKROTIK
+	help
+	  This option enables support for a Compact Flash on Mikrotik RB100
+
+	  If unsure, say N.
+
 comment "Generic fallback / legacy drivers"
 
 config PATA_ACPI
diff -puNrb linux-2.6.35/drivers/ata/Makefile linux/drivers/ata/Makefile
--- linux-2.6.35/drivers/ata/Makefile	2011-04-26 16:28:34.673205734 +0300
+++ linux/drivers/ata/Makefile	2011-05-02 10:08:26.002901210 +0300
@@ -89,6 +89,9 @@ obj-$(CONFIG_PATA_RB532)	+= pata_rb532_c
 obj-$(CONFIG_PATA_RZ1000)	+= pata_rz1000.o
 obj-$(CONFIG_PATA_WINBOND_VLB)	+= pata_winbond.o
 
+obj-$(CONFIG_PATA_RB500)	+= pata_rb500.o
+obj-$(CONFIG_PATA_RB100)	+= pata_rb100.o
+obj-$(CONFIG_PATA_RBPPC)	+= pata_rb_ppc.o
 # Should be last but two libata driver
 obj-$(CONFIG_PATA_ACPI)		+= pata_acpi.o
 # Should be last but one libata driver
diff -puNrb linux-2.6.35/drivers/ata/pata_rb100.c linux/drivers/ata/pata_rb100.c
--- linux-2.6.35/drivers/ata/pata_rb100.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/ata/pata_rb100.c	2011-05-02 10:08:26.012793072 +0300
@@ -0,0 +1,229 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/libata.h>
+#include <linux/platform_device.h>
+
+#define DRV_NAME	"cf-rb100"
+
+#define ATA_REG_OFFSET	0x800
+#define ATA_DBUF_OFFSET	0xC00
+
+#define SWCTRL_BASE		0x12000000
+#define INTC_BASE		0x12200000
+
+/* Switch Control Registers */
+#define GPIO_conf0_REG		0x00B8
+#define GPIO_conf2_REG		0x00BC
+
+/* GPIO_conf2_REG */
+#define EXTIO_WAIT_EN		(0x1 << 6)
+#define EXTIO_CS1_INT1_EN	(0x1 << 5)
+
+/* CFRDY is connected to GPIO4/INTX_1 IRQ 5 */
+#define ADM5120_CF_GPIO_MASK	(1 << 4)
+#define ADM5120_IRQ_CFRDY	13
+#define ADM5120_IRQ_LEVEL	(1 << 5)
+#define IRQ_EN			EXTIO_CS1_INT1_EN
+#define ADM5120_CF_BASE		0x10E00000
+
+/* test registers */
+#define IRQ_LEVEL_REG		0x24	/* Read/Write */
+
+#define ADM5120_SW_REG(_reg)		\
+	(*((volatile unsigned long *)(KSEG1ADDR(SWCTRL_BASE + (_reg)))))
+
+#define ADM5120_INTC_REG(_reg)		\
+	(*((volatile unsigned long *)(KSEG1ADDR(INTC_BASE + (_reg)))))
+
+static int ignore_irq = 0;
+
+static void rb100_irq_disable(struct ata_port *ap)
+{
+	ignore_irq = 1;
+	DPRINTK("  ----  RB100 CF: disabled IRQ\n");
+}
+
+static void rb100_irq_enable(struct ata_port *ap)
+{
+	ignore_irq = 0;
+	DPRINTK("  ++++  RB100 CF: enabled IRQ\n");
+}
+
+static int rb100_cfrdy(void)
+{
+	return ADM5120_SW_REG(GPIO_conf0_REG) & (ADM5120_CF_GPIO_MASK << 8);
+}
+
+static irqreturn_t rb100_interrupt(int irq, void *dev_instance)
+{
+	if (rb100_cfrdy()) {
+		ADM5120_INTC_REG(IRQ_LEVEL_REG) |= ADM5120_IRQ_LEVEL;
+
+		DPRINTK("cfrdy ----> 1, ignore %d\n", ignore_irq);
+		if (!ignore_irq) {
+			if (ata_sff_interrupt(irq, dev_instance) == IRQ_NONE) {
+				DPRINTK("rb100 cf: unhandled IRQ\n");
+			}
+		}
+		DPRINTK("cfrdy %d ilevel %d st[4] %d st[8] %d\n",
+			rb100_cfrdy() ? 1 : 0,
+			(ADM5120_INTC_REG(IRQ_LEVEL_REG) & ADM5120_IRQ_LEVEL) ? 0 : 1,
+			(ADM5120_INTC_REG(0x04) & ADM5120_IRQ_LEVEL) ? 1 : 0,
+			(ADM5120_INTC_REG(0x08) & ADM5120_IRQ_LEVEL) ? 1 : 0
+			);
+	}
+	else {
+		/* irq on ready */
+		ADM5120_INTC_REG(IRQ_LEVEL_REG) &= ~ADM5120_IRQ_LEVEL;
+
+		DPRINTK("cfrdy ----> 0, ignore %d\n", ignore_irq);
+	}
+	return IRQ_HANDLED;
+}
+
+static void rb100_exec_command(struct ata_port *ap, const struct ata_taskfile *tf)
+{
+	DPRINTK("ata%u: cmd 0x%X\n", ap->id, tf->command);
+
+	DPRINTK("cfrdy %d ilevel %d st[4] %d st[8] %d\n",
+		rb100_cfrdy() ? 1 : 0,
+		(ADM5120_INTC_REG(IRQ_LEVEL_REG) & ADM5120_IRQ_LEVEL) ? 0 : 1,
+		(ADM5120_INTC_REG(0x04) & ADM5120_IRQ_LEVEL) ? 1 : 0,
+		(ADM5120_INTC_REG(0x08) & ADM5120_IRQ_LEVEL) ? 1 : 0
+		);
+
+	iowrite8(tf->command, ap->ioaddr.command_addr);
+	ata_sff_pause(ap);
+	/* irq on ready */
+	ADM5120_INTC_REG(IRQ_LEVEL_REG) &= ~ADM5120_IRQ_LEVEL;
+}
+
+static unsigned rb100_data_xfer(struct ata_device *adev, unsigned char *buf,
+				unsigned int buflen, int write_data)
+{
+	struct ata_port *ap = adev->link->ap;
+
+	if (write_data) {
+		iowrite8_rep((void __iomem *)ap->ioaddr.data_addr,
+			     buf, buflen);
+	} else {
+		ioread8_rep((void __iomem *)ap->ioaddr.data_addr, buf, buflen);
+	}
+
+	ata_sff_pause(ap);
+	/* irq on ready */
+	ADM5120_INTC_REG(IRQ_LEVEL_REG) &= ~ADM5120_IRQ_LEVEL;
+
+	return buflen;
+}
+
+static void rb100_dummy_noret(struct ata_port *ap) { }
+static int rb100_dummy_ret0(struct ata_port *ap) { return 0; }
+
+static struct scsi_host_template rb100_sht = {
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+#ifdef CONFIG_PM
+	.resume			= ata_scsi_device_resume,
+	.suspend		= ata_scsi_device_suspend,
+#endif
+};
+
+static struct ata_port_operations rb100_port_ops = {
+	.inherits		= &ata_sff_port_ops,
+
+//	.set_piomode		= rb100_set_piomode,	// TODO: implement?
+
+	.sff_exec_command	= rb100_exec_command,
+
+	.freeze			= rb100_irq_disable,
+	.thaw			= rb100_irq_enable,
+
+	.sff_data_xfer		= rb100_data_xfer,
+
+	.sff_irq_clear		= rb100_dummy_noret,
+
+	.port_start		= rb100_dummy_ret0,
+};
+
+static int rb100_probe(struct platform_device *pdev)
+{
+	struct ata_host *host;
+	struct ata_port *ap;
+	void *baddr;
+
+	printk(KERN_INFO "RB100 CF\n");
+
+	ADM5120_SW_REG(GPIO_conf2_REG) = IRQ_EN | EXTIO_WAIT_EN;
+
+	host = ata_host_alloc(&pdev->dev, 1);
+	if (!host)
+		return -ENOMEM;
+
+	baddr = (void *) KSEG1ADDR(ADM5120_CF_BASE);
+	host->iomap = baddr;
+
+	ap = host->ports[0];
+	ap->ops = &rb100_port_ops;
+	ap->pio_mask = 0x1F;	/* PIO modes 0-4 */
+	ap->flags = ATA_FLAG_NO_LEGACY;
+
+	ap->ioaddr.cmd_addr = baddr + ATA_REG_OFFSET;
+	ap->ioaddr.ctl_addr = baddr + ATA_REG_OFFSET + 0x0e;
+	ap->ioaddr.altstatus_addr = ap->ioaddr.ctl_addr;
+	ata_sff_std_ports(&ap->ioaddr);
+	ap->ioaddr.data_addr = baddr + ATA_DBUF_OFFSET;
+
+	return ata_host_activate(
+		host, ADM5120_IRQ_CFRDY, rb100_interrupt, IRQF_SHARED,
+		&rb100_sht);
+}
+
+static int rb100_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct ata_host *host = dev_get_drvdata(dev);
+
+	if (host == NULL) return -1;
+
+	ata_host_detach(host);
+	return 0;
+}
+
+static struct platform_driver rb100_cf_driver = {
+	.probe = rb100_probe,
+	.remove = rb100_remove,
+	.driver = {
+		.name = "rb100-cf",
+		.owner = THIS_MODULE,
+	}
+};
+
+static int __init rb100_init(void)
+{
+	return platform_driver_register(&rb100_cf_driver);
+}
+
+static void __exit rb100_exit(void)
+{
+	platform_driver_unregister(&rb100_cf_driver);
+}
+
+module_init(rb100_init);
+module_exit(rb100_exit);
+
+MODULE_LICENSE("GPL");
diff -puNrb linux-2.6.35/drivers/ata/pata_rb500.c linux/drivers/ata/pata_rb500.c
--- linux-2.6.35/drivers/ata/pata_rb500.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/ata/pata_rb500.c	2011-05-02 10:08:26.022790910 +0300
@@ -0,0 +1,435 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/libata.h>
+#include <linux/platform_device.h>
+#include <asm/time.h>
+#include <asm/rb/rb500.h>
+
+#define DRV_NAME	"cf-rb500"
+
+/* Compact Flash
+ *	OE = OR(CE,OE)			// 74LCX32: 1.5 .. 5.5 ns delay
+ *	REGX = OR(CE, MADDR11)		// 74LCX32: 1.5 .. 5.5 ns delay
+ *	ADDR0 = AND(MADDR0, REGX)	// NC7S08M5:  .. 35 ns delay
+ */
+
+/* CPU output delay is 0.4 - 4ns */
+#define CPU_TDO_MAX	(4 + 0.9)	/* +0.9 is to round up everything */
+#define CPU_TDO_MIN	0.4
+#define CPU_TDO_DELTA	(CPU_TDO_MAX - CPU_TDO_MIN)
+
+/* CPU data input setup time is 6ns, hold time is 0ns  */
+#define CPU_TSU_MIN	6
+
+/* 74LCX32MTCX (OR element) propogation delay is 1.5 - 5.5ns */
+#define OR_DELAY_MAX	5.5
+#define OR_DELAY_MIN	1.5
+#define OR_DELAY_DELTA	(OR_DELAY_MAX - OR_DELAY_MIN)
+
+/* NC7S08M5 (AND element) propogation delay is 0 - 35ns */
+#define AND_DELAY_MAX	34.5	      /* -0.5 to round down with OR_DELAY_MAX */
+
+/* combined delay by CPU and OR element together */
+#define CPU_OR_TDO_MAX		(CPU_TDO_MAX + OR_DELAY_MAX)
+#define CPU_OR_TDO_DELTA	(CPU_TDO_DELTA + OR_DELAY_DELTA)
+
+#define CF_ADDR_SETUP_MAX	(OR_DELAY_MAX + AND_DELAY_MAX)
+
+#define ATA_REG_OFFSET	0x800
+#define CFDEV_BUF_SIZE	0x1000
+#define ATA_DBUF_OFFSET	0xC00
+
+#define RB500_IRQ_CFRDY	(8 + 4 * 32 + RB500_GPIO_NUM_CFRDY)
+
+#define RB500_GPIO_BASE	0xb8050000
+typedef struct {
+	unsigned gpiofunc;
+	unsigned gpiocfg;
+	unsigned gpiod;
+	unsigned gpioilevel;
+	unsigned gpioistat;
+	unsigned gpionmien;
+} volatile *GPIO_t;
+static GPIO_t rcgpio = (GPIO_t) KSEG1ADDR(RB500_GPIO_BASE);
+
+#define RB500_DEVCTRL_BASE	0x18010000
+#define   DEV1BASE		0x00000010
+typedef struct {
+    unsigned base;
+    unsigned mask;
+    unsigned ctrl;
+    unsigned time;
+} volatile *DEV_t;
+static DEV_t rcdev = (DEV_t) KSEG1ADDR(RB500_DEVCTRL_BASE + DEV1BASE);
+
+#define RB500_CLOCK_BASE	0x18008000
+typedef struct {
+	unsigned reset;
+	unsigned cpumult:4, eclkdiv:2, bend:1, rstm:1,
+		 pcim:3, diswd:1, zero:20;
+} volatile *CLK_t;
+static CLK_t rcclk = (CLK_t) KSEG1ADDR(RB500_CLOCK_BASE);
+
+struct devxc_t {
+	unsigned ds:2, be:1, wp:1, csd:4, oed:4, bwd:4, 
+		rws:6, wws:6, bre:1, bwe:1, wam:1, zero1:1;
+};
+    
+struct devxtc_t {
+	unsigned prd:4, pwd:4, wdh:3, csh:2, zero2:19;
+};
+
+struct dev_timings_t {
+    unsigned bwd_ns;
+    unsigned oed_ns;
+    unsigned csd_ns;
+
+    unsigned wws_ns;
+    unsigned rws_ns;
+
+    unsigned csh_ns;
+    unsigned wdh_ns;
+    unsigned pwd_ns;
+    unsigned prd_ns;
+};
+
+static const struct devxc_t devxc_base = {
+	zero1         : 0,
+	wam           : 0,
+	bwe           : 0,
+	bre           : 0,
+	wws           : 1,
+	rws           : 1, 
+	bwd           : 0,
+	oed           : 0,
+	csd           : 0,
+	wp            : 0,
+	be            : 0,
+	ds            : 0,
+};
+
+static const struct devxtc_t devxtc_base = {
+	zero2	: 0,
+	csh	: 0,
+	wdh	: 0,
+	pwd	: 0,
+	prd	: 0,
+};
+
+static const struct dev_timings_t timing_base = {
+	/* additional timings based on CPU and logic delays */
+	bwd_ns        : CF_ADDR_SETUP_MAX,
+	oed_ns        : CF_ADDR_SETUP_MAX,
+	csd_ns        : 0,
+
+	wws_ns        : CPU_TDO_DELTA + CF_ADDR_SETUP_MAX,
+	rws_ns        : CPU_OR_TDO_MAX + CF_ADDR_SETUP_MAX,
+
+	csh_ns        : CPU_TDO_DELTA,
+	wdh_ns        : CPU_TDO_MAX,
+	pwd_ns        : CPU_TDO_DELTA,
+	prd_ns        : CPU_OR_TDO_MAX,
+};
+
+static const struct dev_timings_t timings[4] = {
+	{
+		/* 250 ns cycle time */
+		bwd_ns        : 30,		/* tsu(A) */
+		oed_ns        : 30,		/* tsu(A) */
+		csd_ns        : 0,		/* tsu(CE) */
+
+		wws_ns        : 30 + 150,	/* tsu(A) + tw(WE) */
+		rws_ns        : 30 + 125,	/* tsu(A) + ta(OE) */
+
+		csh_ns        : 20,		/* th(CE) */
+		wdh_ns        : 30,		/* th(D) */
+		pwd_ns        : 30,		/* trec(WE) */
+		prd_ns        : 100,		/* tdis(OE) */
+        },
+	{
+		/* 120 ns cycle time */
+		bwd_ns        : 15,
+		oed_ns        : 15,
+		csd_ns        : 0,
+
+		wws_ns        : 15 + 70,
+		rws_ns        : 15 + 60,
+
+		csh_ns        : 15,
+		wdh_ns        : 15,
+		pwd_ns        : 15,
+		prd_ns        : 60,
+        },
+	{
+		/* 100 ns cycle time */
+		bwd_ns        : 10,
+		oed_ns        : 10,
+		csd_ns        : 0,
+
+		wws_ns        : 10 + 60,
+		rws_ns        : 10 + 50,
+
+		csh_ns        : 15,
+		wdh_ns        : 10,
+		pwd_ns        : 15,
+		prd_ns        : 50,
+        },
+	{
+		/* 80 ns cycle time */
+		bwd_ns        : 10,
+		oed_ns        : 10,
+		csd_ns        : 0,
+
+		wws_ns        : 10 + 55,
+		rws_ns        : 10 + 45,
+
+		csh_ns        : 10,
+		wdh_ns        : 10,
+		pwd_ns        : 15,
+		prd_ns        : 45
+        }
+};
+
+static const unsigned pio2tidx[7] = {
+	0, 0, 0, 0, 1, 2, 3
+};
+
+static int ignore_irq = 0;
+
+static void rb500_irq_disable(struct ata_port *ap)
+{
+	ignore_irq = 1;
+	DPRINTK("  ----  RB500 CF: disabled IRQ\n");
+}
+
+static void rb500_irq_enable(struct ata_port *ap)
+{
+	ignore_irq = 0;
+	DPRINTK("  ++++  RB500 CF: enabled IRQ\n");
+}
+
+static int rb500_cfrdy(void)
+{
+	return rcgpio->gpiod & RB500_GPIO_CFRDY;
+}
+
+static irqreturn_t rb500_interrupt (int irq, void *dev_instance)
+{
+	unsigned long flags;
+
+	if (rb500_cfrdy()) {
+
+		local_irq_save(flags);
+		rcgpio->gpioilevel &= ~RB500_GPIO_CFRDY;    /* irq on busy */
+		rcgpio->gpioistat &= ~RB500_GPIO_CFRDY;     /* clear istat */
+		local_irq_restore(flags);
+
+		DPRINTK("cfrdy ----> 1, ignore %d\n", ignore_irq);
+		if (!ignore_irq) {
+			if (ata_sff_interrupt(irq, dev_instance) == IRQ_NONE) {
+				DPRINTK("rb500 cf: unhandled IRQ\n");
+			}
+		}
+		DPRINTK("cfrdy %d istat %d\n",
+			rb500_cfrdy() ? 1 : 0,
+			(rcgpio->gpioistat & RB500_GPIO_CFRDY) ? 1 : 0
+			);
+		local_irq_save(flags);
+		if (rcgpio->gpioistat & RB500_GPIO_CFRDY) {
+			/*
+			 * cfrdy changed to 0,
+			 * probably it is back to 1 already.
+			 * Have to change ilevel to 1 not to loose IRQ.
+			 */
+			rcgpio->gpioilevel |= RB500_GPIO_CFRDY;
+		}
+		local_irq_restore(flags);
+	}
+	else {
+		local_irq_save(flags);
+		rcgpio->gpioilevel |= RB500_GPIO_CFRDY;    /* irq on ready */
+		local_irq_restore(flags);
+
+		DPRINTK("cfrdy ----> 0, ignore %d\n", ignore_irq);
+	}
+	return IRQ_HANDLED;
+}
+
+#define CALC_CLK(clk, ns, clk_ps)	\
+	do {	\
+		unsigned res = clk + ((ns) * 1000 + clk_ps - 1) / clk_ps;  \
+		clk = res;						\
+		if (clk != res) {					\
+			clk = -1;					\
+			printk(KERN_WARNING				\
+			       "rb500 cf: %s overlapped %u -> %u\n",	\
+				#clk, res, clk);			\
+		}							\
+	} while(0)
+
+static unsigned get_clkps(void) {
+	unsigned eclk_div = 1 << rcclk->eclkdiv;
+	unsigned eclk_khz = mips_hpt_frequency / (1000 * eclk_div);
+	unsigned clk_ps = 1000000000 / eclk_khz;
+	printk(KERN_INFO "CF: ext clock %u kHz %u ps\n",
+	       eclk_khz, clk_ps);
+	return clk_ps;
+}
+
+static void rb500_set_piomode(struct ata_port *ap, struct ata_device *adev)
+{
+	int mode = adev->pio_mode - XFER_PIO_0;
+	const struct dev_timings_t *tptr;
+	struct devxc_t devxc = devxc_base;
+	struct devxtc_t devxtc = devxtc_base;
+	unsigned clk_ps;
+
+	DPRINTK("rb500_set_piomode PIO %d\n", mode);
+
+	if (mode < 0) mode = 0;
+	if (mode > 6) mode = 6;
+
+	tptr = &timings[pio2tidx[mode]];
+
+	clk_ps = get_clkps();
+
+	CALC_CLK(devxc.bwd, tptr->bwd_ns + timing_base.bwd_ns, clk_ps);
+	CALC_CLK(devxc.oed, tptr->oed_ns + timing_base.oed_ns, clk_ps);
+	CALC_CLK(devxc.csd, tptr->csd_ns + timing_base.csd_ns, clk_ps);
+	CALC_CLK(devxc.wws, tptr->wws_ns + timing_base.wws_ns, clk_ps);
+	CALC_CLK(devxc.rws, tptr->rws_ns + timing_base.rws_ns, clk_ps);
+	CALC_CLK(devxtc.csh, tptr->csh_ns + timing_base.csh_ns, clk_ps);
+	CALC_CLK(devxtc.wdh, tptr->wdh_ns + timing_base.wdh_ns, clk_ps);
+	CALC_CLK(devxtc.pwd, tptr->pwd_ns + timing_base.pwd_ns, clk_ps);
+	CALC_CLK(devxtc.prd, tptr->prd_ns + timing_base.prd_ns, clk_ps);
+
+	printk(KERN_INFO "CF old devxc 0x%08x devxtc 0x%04x\n",
+	       rcdev->ctrl, rcdev->time);
+
+	rcdev->ctrl = *(unsigned*)&devxc;
+	rcdev->time = *(unsigned*)&devxtc;
+
+	printk(KERN_INFO "CF new devxc 0x%08x devxtc 0x%04x\n",
+	       rcdev->ctrl, rcdev->time);
+
+	printk(KERN_INFO "CF PIO mode changed to %d\n", mode);
+}
+
+static void rb500_dummy_noret(struct ata_port *ap) { }
+static int rb500_dummy_ret0(struct ata_port *ap) { return 0; }
+
+static struct scsi_host_template rb500_sht = {
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+#ifdef CONFIG_PM
+	.resume			= ata_scsi_device_resume,
+	.suspend		= ata_scsi_device_suspend,
+#endif
+};
+
+static struct ata_port_operations rb500_port_ops = {
+	.inherits		= &ata_sff_port_ops,
+
+	.set_piomode		= rb500_set_piomode,
+
+	.freeze			= rb500_irq_disable,
+	.thaw			= rb500_irq_enable,
+
+	.sff_irq_clear		= rb500_dummy_noret,
+
+	.port_start		= rb500_dummy_ret0,
+};
+
+static int rb500_probe(struct platform_device *pdev)
+{
+	struct ata_host *host;
+	struct ata_port *ap;
+	void *baddr;
+	unsigned long flags;
+
+	printk(KERN_INFO "RB500 CF\n");
+
+	if (rcdev->mask == 0) {
+	    printk(KERN_ERR
+		   "DEV1 in Device Controller"
+		   " is not mapped anywhere!\n");
+	    return -EINVAL;
+	}
+
+	/* setup CFRDY GPIO as input */
+	local_irq_save(flags);
+	rcgpio->gpiofunc &= ~RB500_GPIO_CFRDY;
+	rcgpio->gpiocfg &= ~RB500_GPIO_CFRDY;
+	local_irq_restore(flags);
+
+	baddr = ioremap_nocache(rcdev->base, CFDEV_BUF_SIZE);
+
+	host = ata_host_alloc(&pdev->dev, 1);
+	if (!host)
+		return -ENOMEM;
+	host->iomap = baddr;
+
+	ap = host->ports[0];
+	ap->ops = &rb500_port_ops;
+	ap->pio_mask = 0x7F;	/* PIO modes 0-6 */
+	ap->flags = ATA_FLAG_NO_LEGACY | ATA_FLAG_MMIO;
+
+	ap->ioaddr.cmd_addr = baddr + ATA_REG_OFFSET;
+	ap->ioaddr.ctl_addr = baddr + ATA_REG_OFFSET + 0x0e;
+	ap->ioaddr.altstatus_addr = ap->ioaddr.ctl_addr;
+	ata_sff_std_ports(&ap->ioaddr);
+	ap->ioaddr.data_addr = baddr + ATA_DBUF_OFFSET;
+
+	return ata_host_activate(
+		host, RB500_IRQ_CFRDY, rb500_interrupt, IRQF_SHARED,
+		&rb500_sht);
+}
+
+static int rb500_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct ata_host *host = dev_get_drvdata(dev);
+
+	if (host == NULL) return -1;
+
+	ata_host_detach(host);
+	return 0;
+}
+
+static struct platform_driver rb500_cf_driver = {
+	.probe = rb500_probe,
+	.remove = rb500_remove,
+	.driver = {
+		.name = "rb500-cf",
+		.owner = THIS_MODULE,
+	}
+};
+
+static int __init rb500_init(void)
+{
+	return platform_driver_register(&rb500_cf_driver);
+}
+
+static void __exit rb500_exit(void)
+{
+	platform_driver_unregister(&rb500_cf_driver);
+}
+
+module_init(rb500_init);
+module_exit(rb500_exit);
+
+MODULE_LICENSE("GPL");
diff -puNrb linux-2.6.35/drivers/ata/pata_rb_ppc.c linux/drivers/ata/pata_rb_ppc.c
--- linux-2.6.35/drivers/ata/pata_rb_ppc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/ata/pata_rb_ppc.c	2011-05-02 10:08:26.042903005 +0300
@@ -0,0 +1,729 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/libata.h>
+#include <linux/of_platform.h>
+#include <linux/of_device.h>
+
+#define DEBUG_UPM	0
+
+#define DRV_NAME	"pata_rb_ppc"
+
+#define DEV2SEL_OFFSET	0x00100000
+
+#define IMMR_LBCFG_OFFSET	0x00005000
+#define IMMR_LBCFG_SIZE		0x00001000
+
+#define LOCAL_BUS_MCMR		0x00000078
+#define   MxMR_OP_MASK			0x30000000
+#define   MxMR_OP_NORMAL		0x00000000
+#define   MxMR_OP_WRITE			0x10000000
+#define   MxMR_OP_READ			0x20000000
+#define   MxMR_OP_RUN			0x30000000
+#define   MxMR_LUPWAIT_LOW		0x08000000
+#define   MxMR_LUPWAIT_HIGH		0x00000000
+#define   MxMR_LUPWAIT_ENABLE		0x00040000
+#define   MxMR_RLF_MASK			0x0003c000
+#define   MxMR_RLF_SHIFT			14
+#define   MxMR_WLF_MASK			0x00003c00
+#define   MxMR_WLF_SHIFT			10
+#define   MxMR_MAD_MASK			0x0000003f
+#define LOCAL_BUS_MDR		0x00000088
+#define LOCAL_BUS_LCRR		0x000000D4
+#define   LCRR_CLKDIV_MASK		0x0000000f
+
+#define LOOP_SIZE	4
+
+#define UPM_READ_SINGLE_OFFSET	0x00
+#define UPM_WRITE_SINGLE_OFFSET	0x18
+#define UPM_DATA_SIZE	0x40
+
+#define LBT_CPUIN_MIN		0
+#define LBT_CPUOUT_MIN		1
+#define LBT_CPUOUT_MAX		2
+#define LBT_EXTDEL_MIN		3
+#define LBT_EXTDEL_MAX		4
+#define LBT_SIZE		5
+
+/* UPM machine configuration bits */
+#define N_BASE	0x00f00000
+#define N_CS	0xf0000000
+#define N_CS_H1	0xc0000000
+#define N_CS_H2	0x30000000
+#define N_WE	0x0f000000
+#define N_WE_H1	0x0c000000
+#define N_WE_H2	0x03000000
+#define N_OE	0x00030000
+#define N_OE_H1	0x00020000
+#define N_OE_H2	0x00010000
+#define WAEN	0x00001000
+#define REDO_2	0x00000100
+#define REDO_3	0x00000200
+#define REDO_4	0x00000300
+#define LOOP	0x00000080
+#define NA	0x00000008
+#define UTA	0x00000004
+#define LAST	0x00000001
+
+#define REDO_VAL(mult)	(REDO_2 * ((mult) - 1))
+#define REDO_MAX_MULT	4
+
+#define READ_BASE	(N_BASE | N_WE)
+#define WRITE_BASE	(N_BASE | N_OE)
+#define EMPTY		(N_BASE | N_CS | N_OE | N_WE | LAST)
+
+#define EOF_UPM_SETTINGS	0
+#define ANOTHER_TIMING		1
+
+#define OA_CPUIN_MIN		0x01
+#define OA_CPUOUT_MAX		0x02
+#define OD_CPUOUT_MIN		0x04
+#define OA_CPUOUT_DELTA		0x06
+#define OA_EXTDEL_MAX		0x08
+#define OD_EXTDEL_MIN		0x10
+#define OA_EXTDEL_DELTA		0x18
+#define O_MIN_CYCLE_TIME	0x20
+#define O_MINUS_PREV		0x40
+#define O_HALF_CYCLE		0x80
+
+extern void __iomem *localbus_map(unsigned long addr, unsigned int len);
+extern void localbus_unmap(void __iomem *addr);
+
+struct rbppc_info {
+	unsigned lbcfg_addr;
+	unsigned clk_time_ps;
+	int cur_mode;
+	u32 lb_timings[LBT_SIZE];
+};
+static struct rbppc_info *rbinfo = NULL;
+
+struct upm_setting {
+	unsigned value;
+	unsigned ns[7];
+	unsigned clk_minus;
+	unsigned group_size;
+	unsigned options;
+};
+
+static const struct upm_setting cfUpmReadSingle[] = {
+	{ READ_BASE | N_OE,
+	  /* t1 - ADDR setup time */
+		{  70,  50,  30,  30,  25,  15,  10 }, 0, 0, (OA_CPUOUT_DELTA |
+							      OA_EXTDEL_MAX) },
+	{ READ_BASE | N_OE_H1,
+		{   0,   0,   0,   0,   0,   0,   0 }, 0, 0, O_HALF_CYCLE },
+	{ READ_BASE,
+	  /* t2 - OE0 time */
+		{ 290, 290, 290,  80,  70,  65,  55 }, 0, 2, (OA_CPUOUT_MAX |
+							      OA_CPUIN_MIN) },
+	{ READ_BASE | WAEN,
+		{   1,   1,   1,   1,   1,   0,   0 }, 0, 0, 0 },
+	{ READ_BASE | UTA,
+		{   1,   1,   1,   1,   1,   1,   1 }, 0, 0, 0 },
+	{ READ_BASE | N_OE,
+	  /* t9 - ADDR hold time */
+		{  20,  15,  10,  10,  10,  10,  10 }, 0, 0, (OA_CPUOUT_DELTA |
+							      OD_EXTDEL_MIN) },
+	{ READ_BASE | N_OE | N_CS_H2,
+		{   0,   0,   0,   0,   0,   0,   0 }, 0, 0, O_HALF_CYCLE },
+	{ READ_BASE | N_OE | N_CS,
+	  /* t6Z -IORD data tristate */
+		{  30,  30,  30,  30,  30,  20,  20 }, 1, 1, O_MINUS_PREV },
+	{ ANOTHER_TIMING,
+	  /* t2i -IORD recovery time */
+		{   0,   0,   0,  70,  25,  25,  20 }, 2, 0, 0 },
+	{ ANOTHER_TIMING,
+	  /* CS 0 -> 1 MAX */
+		{   0,   0,   0,   0,   0,   0,   0 }, 1, 0, (OA_CPUOUT_DELTA |
+							      OA_EXTDEL_MAX) },
+	{ READ_BASE | N_OE | N_CS | LAST,
+		{   1,   1,   1,   1,   1,   1,   1 }, 0, 0, 0 },
+	{ EOF_UPM_SETTINGS,
+	  /* min total cycle time - includes turnaround and ALE cycle */
+		{ 600, 383, 240, 180, 120, 100,  80 }, 2, 0, O_MIN_CYCLE_TIME },
+};
+
+static const struct upm_setting cfUpmWriteSingle[] = {
+	{ WRITE_BASE | N_WE,
+	  /* t1 - ADDR setup time */
+		{  70,  50,  30,  30,  25,  15,  10 }, 0, 0, (OA_CPUOUT_DELTA |
+							      OA_EXTDEL_MAX) },
+	{ WRITE_BASE | N_WE_H1,
+		{   0,   0,   0,   0,   0,   0,   0 }, 0, 0, O_HALF_CYCLE },
+	{ WRITE_BASE,
+	  /* t2 - WE0 time */
+		{ 290, 290, 290,  80,  70,  65,  55 }, 0, 1, OA_CPUOUT_DELTA },
+	{ WRITE_BASE | WAEN,
+		{   1,   1,   1,   1,   1,   0,   0 }, 0, 0, 0 },
+	{ WRITE_BASE | N_WE,
+	  /* t9 - ADDR hold time */
+		{  20,  15,  10,  10,  10,  10,  10 }, 0, 0, (OA_CPUOUT_DELTA |
+							      OD_EXTDEL_MIN) },
+	{ WRITE_BASE | N_WE | N_CS_H2,
+		{   0,   0,   0,   0,   0,   0,   0 }, 0, 0, O_HALF_CYCLE },
+	{ WRITE_BASE | N_WE | N_CS,
+	  /* t4 - DATA hold time */
+		{  30,  20,  15,  10,  10,  10,  10 }, 0, 1, O_MINUS_PREV },
+	{ ANOTHER_TIMING,
+	  /* t2i -IOWR recovery time */
+		{   0,   0,   0,  70,  25,  25,  20 }, 1, 0, 0 },
+	{ ANOTHER_TIMING,
+	  /* CS 0 -> 1 MAX */
+		{   0,   0,   0,   0,   0,   0,   0 }, 0, 0, (OA_CPUOUT_DELTA |
+							      OA_EXTDEL_MAX) },
+	{ WRITE_BASE | N_WE | N_CS | UTA | LAST,
+		{   1,   1,   1,   1,   1,   1,   1 }, 0, 0, 0 },
+	/* min total cycle time - includes ALE cycle */
+	{ EOF_UPM_SETTINGS,
+		{ 600, 383, 240, 180, 120, 100,  80 }, 1, 0, O_MIN_CYCLE_TIME },
+};
+
+
+static u8 rbppc_check_status(struct ata_port *ap)
+{
+	u8 val = ioread8(ap->ioaddr.status_addr);
+	if (val == 0xF9) val = 0x7F;
+	return val;
+}
+
+static u8 rbppc_check_altstatus(struct ata_port *ap)
+{
+	u8 val = ioread8(ap->ioaddr.altstatus_addr);
+	if (val == 0xF9) val = 0x7F;
+	return val;
+}
+
+static void rbppc_dummy_noret(struct ata_port *ap) { }
+static int rbppc_dummy_ret0(struct ata_port *ap) { return 0; }
+
+static int ps2clk(int ps, unsigned clk_time_ps) {
+	int psMaxOver;
+	if (ps <= 0) return 0;
+
+	/* round down if <= 2% over clk border, but no more than 1/4 clk cycle */
+	psMaxOver = ps * 2 / 100;
+	if (4 * psMaxOver > clk_time_ps) {
+		psMaxOver = clk_time_ps / 4;
+	}
+	return (ps + clk_time_ps - 1 - psMaxOver) / clk_time_ps;
+}
+
+static int upm_gen_ps_table(const struct upm_setting *upm,
+			    int mode, struct rbppc_info *info,
+			    int *psFinal) {
+	int uidx;
+	int lastUpmValIdx = 0;
+	int group_start_idx = -1;
+	int group_left_num = -1;
+	int clk_time_ps = info->clk_time_ps;
+
+	for (uidx = 0; upm[uidx].value != EOF_UPM_SETTINGS; ++uidx) {
+		const struct upm_setting *us = upm + uidx;
+		unsigned opt = us->options;
+		int ps = us->ns[mode] * 1000 - us->clk_minus * clk_time_ps;
+
+		if (opt & OA_CPUIN_MIN) ps += info->lb_timings[LBT_CPUIN_MIN];
+		if (opt & OD_CPUOUT_MIN) ps -= info->lb_timings[LBT_CPUOUT_MIN];
+		if (opt & OA_CPUOUT_MAX) ps += info->lb_timings[LBT_CPUOUT_MAX];
+		if (opt & OD_EXTDEL_MIN) ps -= info->lb_timings[LBT_EXTDEL_MIN];
+		if (opt & OA_EXTDEL_MAX) ps += info->lb_timings[LBT_EXTDEL_MAX];
+
+		if (us->value == ANOTHER_TIMING) {
+			/* use longest timing from alternatives */
+			if (psFinal[lastUpmValIdx] < ps) {
+				psFinal[lastUpmValIdx] = ps;
+			}
+			ps = 0;
+		}
+		else {
+			if (us->group_size) {
+				group_start_idx = uidx;
+				group_left_num = us->group_size;
+			}
+			else if (group_left_num > 0) {
+				/* group time is divided on all group members */
+				int clk = ps2clk(ps, clk_time_ps);
+				psFinal[group_start_idx] -= clk * clk_time_ps;
+				--group_left_num;
+			}
+			if ((opt & O_MINUS_PREV) && lastUpmValIdx > 0) {
+				int clk = ps2clk(psFinal[lastUpmValIdx],
+						 clk_time_ps);
+				ps -= clk * clk_time_ps;
+			}
+			lastUpmValIdx = uidx;
+		}
+		psFinal[uidx] = ps;
+	}
+	return uidx;
+}
+
+static int free_half(int ps, int clk, int clk_time_ps) {
+    if (clk < 2) return 0;
+    return (clk * clk_time_ps - ps) * 2 >= clk_time_ps;
+}
+
+static void upm_gen_clk_table(const struct upm_setting *upm,
+			      int mode, int clk_time_ps,
+			      int max_uidx, const int *psFinal, int *clkFinal) {
+	int clk_cycle_time;
+	int clk_total;
+	int uidx;
+
+	/* convert picoseconds to clocks */
+	clk_total = 0;
+	for (uidx = 0; uidx < max_uidx; ++uidx) {
+		int clk = ps2clk(psFinal[uidx], clk_time_ps);
+		clkFinal[uidx] = clk;
+		clk_total += clk;
+	}
+
+	/* check possibility of half cycle usage */
+	for (uidx = 1; uidx < max_uidx - 1; ++uidx) {
+		if ((upm[uidx].options & O_HALF_CYCLE) &&
+		    free_half(psFinal[uidx - 1], clkFinal[uidx - 1],
+			      clk_time_ps) &&
+		    free_half(psFinal[uidx + 1], clkFinal[uidx + 1],
+			      clk_time_ps)) {
+			++clkFinal[uidx];
+			--clkFinal[uidx - 1];
+			--clkFinal[uidx + 1];
+		}
+	}
+
+	if ((upm[max_uidx].options & O_MIN_CYCLE_TIME) == 0) return;
+
+	/* check cycle time, adjust timings if needed */
+	clk_cycle_time = (ps2clk(upm[max_uidx].ns[mode] * 1000, clk_time_ps) -
+			  upm[max_uidx].clk_minus);
+	uidx = 0;
+	while (clk_total < clk_cycle_time) {
+		/* extend all timings in round-robin to match cycle time */
+		if (clkFinal[uidx]) {
+#if DEBUG_UPM
+			printk(KERN_INFO "extending %u by 1 clk\n", uidx);
+#endif
+			++clkFinal[uidx];
+			++clk_total;
+		}
+		++uidx;
+		if (uidx == max_uidx) uidx = 0;
+	}
+}
+
+static void add_data_val(unsigned val, int *clkLeft, int maxClk,
+			unsigned *data, int *dataIdx) {
+	if (*clkLeft == 0) return;
+
+	if (maxClk == 0 && *clkLeft >= LOOP_SIZE * 2) {
+		int times;
+		int times1;
+		int times2;
+
+		times = *clkLeft / LOOP_SIZE;
+		if (times > REDO_MAX_MULT * 2) times = REDO_MAX_MULT * 2;
+		times1 = times / 2;
+		times2 = times - times1;
+
+		val |= LOOP;
+		data[*dataIdx] = val | REDO_VAL(times1);
+		++(*dataIdx);
+		data[*dataIdx] = val | REDO_VAL(times2);
+		++(*dataIdx);
+
+		*clkLeft -= times * LOOP_SIZE;
+		return;
+	}
+
+	if (maxClk < 1 || maxClk > REDO_MAX_MULT) maxClk = REDO_MAX_MULT;
+	if (*clkLeft < maxClk) maxClk = *clkLeft;
+
+	*clkLeft -= maxClk;
+	val |= REDO_VAL(maxClk);
+
+	data[*dataIdx] = val;
+	++(*dataIdx);
+}
+
+static int upm_gen_final_data(const struct upm_setting *upm,
+			       int max_uidx, int *clkFinal, unsigned *data) {
+	int dataIdx;
+	int uidx;
+
+	dataIdx = 0;
+	for (uidx = 0; uidx < max_uidx; ++uidx) {
+		int clk = clkFinal[uidx];
+		while (clk > 0) {
+			add_data_val(upm[uidx].value, &clk, 0,
+				     data, &dataIdx);
+		}
+	}
+	return dataIdx;
+}
+
+static int conv_upm_table(const struct upm_setting *upm,
+			  int mode, struct rbppc_info *info,
+			  unsigned *data) {
+#if DEBUG_UPM
+	int uidx;
+#endif
+	int psFinal[32];
+	int clkFinal[32];
+	int max_uidx;
+	int data_len;
+
+	max_uidx = upm_gen_ps_table(upm, mode, info, psFinal);
+
+	upm_gen_clk_table(upm, mode, info->clk_time_ps, max_uidx,
+			  psFinal, clkFinal);
+
+#if DEBUG_UPM
+	/* dump out debug info */
+	for (uidx = 0; uidx < max_uidx; ++uidx) {
+		if (clkFinal[uidx]) {
+			printk(KERN_INFO "idx %d val %08x clk %d ps %d\n",
+				uidx, upm[uidx].value,
+				clkFinal[uidx], psFinal[uidx]);
+		}
+	}
+#endif
+
+	data_len = upm_gen_final_data(upm, max_uidx, clkFinal, data);
+
+#if DEBUG_UPM
+	for (uidx = 0; uidx < data_len; ++uidx) {
+		printk(KERN_INFO "cf UPM x result: idx %d val %08x\n",
+		       uidx, data[uidx]);
+	}
+#endif
+	return 0;
+}
+
+static int gen_upm_data(int mode, struct rbppc_info *info, unsigned *data) {
+	int i;
+
+	for (i = 0; i < UPM_DATA_SIZE; ++i) {
+		data[i] = EMPTY;
+	}
+
+	if (conv_upm_table(cfUpmReadSingle, mode, info, 
+			   data + UPM_READ_SINGLE_OFFSET)) {
+		return -1;
+	}
+	if (conv_upm_table(cfUpmWriteSingle, mode, info,
+			   data + UPM_WRITE_SINGLE_OFFSET)) {
+		return -1;
+	}
+	return 0;
+}
+
+static void program_upm(void *upmMemAddr,
+			volatile void *lbcfg_mxmr, volatile void *lbcfg_mdr,
+			const unsigned *upmData,
+			unsigned offset, unsigned len) {
+    unsigned i;
+    unsigned mxmr;
+
+    mxmr = in_be32(lbcfg_mxmr);
+    mxmr &= ~(MxMR_OP_MASK | MxMR_MAD_MASK);
+    mxmr |= (MxMR_OP_WRITE | offset);
+    out_be32(lbcfg_mxmr, mxmr);
+    in_be32(lbcfg_mxmr);			/* flush MxMR write */
+
+    for (i = 0; i < len; ++i) {
+	int to;
+	unsigned data = upmData[i + offset];
+	out_be32(lbcfg_mdr, data);
+	in_be32(lbcfg_mdr);			/* flush MDR write */
+
+	iowrite8(1, upmMemAddr);	/* dummy write to any CF addr */
+
+	/* wait for dummy write to complete */
+	for (to = 10000; to >= 0; --to) {
+	    mxmr = in_be32(lbcfg_mxmr);
+	    if (((mxmr ^ (i + 1)) & MxMR_MAD_MASK) == 0) break;
+	    if (to == 0) {
+		printk(KERN_ERR "rbppc cf error: "
+		       "UPMx program error at 0x%x: timeout\n", i);
+	    }
+	}
+    }
+    mxmr &= ~(MxMR_OP_MASK | MxMR_RLF_MASK | MxMR_WLF_MASK);
+    mxmr |= (MxMR_OP_NORMAL |
+	     (LOOP_SIZE << MxMR_RLF_SHIFT) |
+	     (LOOP_SIZE << MxMR_WLF_SHIFT));
+    out_be32(lbcfg_mxmr, mxmr);
+}
+
+static int rbppc_update_piomode(struct ata_port *ap, int mode) {
+	struct rbppc_info *info = (struct rbppc_info *)ap->host->private_data;
+	void *lbcfgBase;
+	unsigned upmData[UPM_DATA_SIZE];
+
+	if (gen_upm_data(mode, info, upmData)) {
+		return -1;
+	}
+
+	lbcfgBase = ioremap_nocache(info->lbcfg_addr, IMMR_LBCFG_SIZE);
+
+	program_upm(ap->ioaddr.cmd_addr,
+		    ((char *)lbcfgBase) + LOCAL_BUS_MCMR,
+		    ((char *)lbcfgBase) + LOCAL_BUS_MDR,
+		    upmData, 0, UPM_DATA_SIZE);
+	iounmap(lbcfgBase);
+	return 0;
+}
+
+static void rbppc_set_piomode(struct ata_port *ap, struct ata_device *adev)
+{
+	struct rbppc_info *info = (struct rbppc_info *)ap->host->private_data;
+	int mode = adev->pio_mode - XFER_PIO_0;
+
+	DPRINTK("rbppc_set_piomode PIO %d\n", mode);
+	if (mode < 0) mode = 0;
+	if (mode > 6) mode = 6;
+
+	if (info->cur_mode < 0 || info->cur_mode > mode) {
+		if (rbppc_update_piomode(ap, mode) == 0) {
+			printk(KERN_INFO "CF PIO mode changed to %d\n", mode);
+			info->cur_mode = mode;
+		}
+	}
+}
+
+static irqreturn_t rbppc_interrupt(int irq, void *dev_instance)
+{
+	irqreturn_t ret = ata_sff_interrupt(irq, dev_instance);
+	if (ret == IRQ_RETVAL(0)) {
+		struct ata_host *host = dev_instance;
+		struct ata_port *ap = host->ports[0];
+
+		/* clear interrupt */
+		rbppc_check_status(ap);
+
+		printk(KERN_WARNING "ata%u: irq %d not handled\n",
+		       ap->print_id, irq);
+	}
+	return ret;
+}
+
+static struct scsi_host_template rbppc_sht = {
+	.module			= THIS_MODULE,
+	.name			= DRV_NAME,
+	.ioctl			= ata_scsi_ioctl,
+	.queuecommand		= ata_scsi_queuecmd,
+	.can_queue		= ATA_DEF_QUEUE,
+	.this_id		= ATA_SHT_THIS_ID,
+	.sg_tablesize		= LIBATA_MAX_PRD,
+	.cmd_per_lun		= ATA_SHT_CMD_PER_LUN,
+	.emulated		= ATA_SHT_EMULATED,
+	.use_clustering		= ATA_SHT_USE_CLUSTERING,
+	.proc_name		= DRV_NAME,
+	.dma_boundary		= ATA_DMA_BOUNDARY,
+	.slave_configure	= ata_scsi_slave_config,
+	.slave_destroy		= ata_scsi_slave_destroy,
+	.bios_param		= ata_std_bios_param,
+#ifdef CONFIG_PM
+	.resume			= ata_scsi_device_resume,
+	.suspend		= ata_scsi_device_suspend,
+#endif
+};
+
+static struct ata_port_operations rbppc_port_ops = {
+	.inherits		= &ata_sff_port_ops,
+
+	.set_piomode		= rbppc_set_piomode,
+
+	.sff_check_status	= rbppc_check_status,
+	.sff_check_altstatus	= rbppc_check_altstatus,
+
+	.sff_irq_clear		= rbppc_dummy_noret,
+
+	.port_start		= rbppc_dummy_ret0,
+};
+
+static int init_rbppc_info(struct of_device *pdev, struct rbppc_info *info) {
+	struct device_node *np;
+	struct resource res;
+	const u32 *u32ptr;
+	void *lbcfgBase;
+	void *lbcfg_lcrr;
+	unsigned lbc_clk_khz;
+	unsigned lbc_extra_divider = 1;
+	unsigned ccb_freq_hz;
+	unsigned lb_div;
+
+	u32ptr = of_get_property(pdev->dev.of_node, "lbc_extra_divider", NULL);
+	if (u32ptr && *u32ptr) {
+		lbc_extra_divider = *u32ptr;
+#if DEBUG_UPM
+		printk(KERN_INFO "CF: LBC extra divider %u\n",
+		       lbc_extra_divider);
+#endif
+	}
+
+	np = of_find_node_by_type(NULL, "serial");
+	if (!np) {
+		printk(KERN_ERR "rbppc cf error: no serial node found\n");
+		return -1;
+	}
+	u32ptr = of_get_property(np, "clock-frequency", NULL);
+	if (u32ptr == 0 || *u32ptr == 0) {
+		printk(KERN_ERR "rbppc cf error: "
+		       "serial does not have clock-frequency\n");
+		of_node_put(np);
+		return -1;
+	}
+	ccb_freq_hz = *u32ptr;
+	of_node_put(np);
+
+	np = of_find_node_by_type(NULL, "soc");
+	if (!np) {
+		printk(KERN_ERR "rbppc cf error: no soc node found\n");
+		return -1;
+	}
+	if (of_address_to_resource(np, 0, &res)) {
+		printk(KERN_ERR "rbppc cf error: soc does not have resource\n");
+		of_node_put(np);
+		return -1;
+	}
+	info->lbcfg_addr = res.start + IMMR_LBCFG_OFFSET;
+	of_node_put(np);
+
+	lbcfgBase = ioremap_nocache(info->lbcfg_addr, IMMR_LBCFG_SIZE);
+	lbcfg_lcrr = ((char*)lbcfgBase) + LOCAL_BUS_LCRR;
+	lb_div = (in_be32(lbcfg_lcrr) & LCRR_CLKDIV_MASK) * lbc_extra_divider;
+	iounmap(lbcfgBase);
+
+	lbc_clk_khz = ccb_freq_hz / (1000 * lb_div);
+	info->clk_time_ps = 1000000000 / lbc_clk_khz;
+	printk(KERN_INFO "CF: using Local-Bus clock %u kHz %u ps\n",
+	       lbc_clk_khz, info->clk_time_ps);
+
+	u32ptr = of_get_property(pdev->dev.of_node, "lb-timings", NULL);
+	if (u32ptr) {
+		memcpy(info->lb_timings, u32ptr, LBT_SIZE * sizeof(*u32ptr));
+#if DEBUG_UPM
+		printk(KERN_INFO "CF: got LB timings <%u %u %u %u %u>\n",
+		       u32ptr[0], u32ptr[1], u32ptr[2], u32ptr[3], u32ptr[4]);
+#endif
+	}
+	info->cur_mode = -1;
+	return 0;
+}
+
+static int rbppc_cf_probe(struct of_device *pdev,
+			  const struct of_device_id *match)
+{
+	struct ata_host *host;
+	struct ata_port *ap;
+	struct rbppc_info *info = NULL;
+	struct resource res;
+	void *baddr;
+	const u32 *u32ptr;
+	int irq_level = 0;
+	int err = -ENOMEM;
+
+	printk(KERN_INFO "RB_PPC CF\n");
+
+	if (rbinfo == NULL) {
+		info = kmalloc(sizeof(*info), GFP_KERNEL);
+		if (info == NULL) {
+			printk(KERN_ERR "rbppc_cf_probe: OOM\n");
+			goto err_info;
+		}
+		memset(info, 0, sizeof(*info));
+
+		if (init_rbppc_info(pdev, info)) {
+			goto err_info;
+		}
+		rbinfo = info;
+	}
+
+	u32ptr = of_get_property(pdev->dev.of_node, "interrupt-at-level", NULL);
+	if (u32ptr) {
+		irq_level = *u32ptr;
+		printk(KERN_INFO "CF: irq level %u\n", irq_level);
+	}
+
+	if (of_address_to_resource(pdev->dev.of_node, 0, &res)) {
+	    printk(KERN_ERR "rbppc cf error: no reg property found\n");
+	    goto err_info;
+	}
+
+	host = ata_host_alloc(&pdev->dev, 1);
+	if (!host)
+	    goto err_info;
+
+	baddr = localbus_map(res.start, res.end - res.start + 1);
+	host->iomap = baddr;
+	host->private_data = rbinfo;
+
+	ap = host->ports[0];
+	ap->ops = &rbppc_port_ops;
+	ap->pio_mask = 0x7F;	/* PIO modes 0-6 */
+	ap->flags = ATA_FLAG_NO_LEGACY;
+	ap->mwdma_mask = 0;
+
+	ap->ioaddr.cmd_addr = baddr;
+	ata_sff_std_ports(&ap->ioaddr);
+	ap->ioaddr.ctl_addr = ap->ioaddr.cmd_addr + 14;
+	ap->ioaddr.altstatus_addr = ap->ioaddr.ctl_addr;
+	ap->ioaddr.bmdma_addr = 0;
+
+	err = ata_host_activate(
+		host,
+		irq_of_parse_and_map(pdev->dev.of_node, 0), rbppc_interrupt,
+		irq_level ? IRQF_TRIGGER_HIGH : IRQF_TRIGGER_LOW,
+		&rbppc_sht);
+	if (!err) return 0;
+
+	localbus_unmap(baddr);
+err_info:
+	if (info) {
+		kfree(info);
+		rbinfo = NULL;
+	}
+	return err;
+}
+
+static int rbppc_cf_remove(struct of_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct ata_host *host = dev_get_drvdata(dev);
+
+	if (host == NULL) return -1;
+
+	ata_host_detach(host);
+	return 0;
+}
+
+static struct of_device_id rbppc_cf_ids[] = {
+	{ .name = "cf" },
+	{}
+};
+
+static struct of_platform_driver rbppc_cf_driver = {
+	.driver = {
+		.name   = "cf-rbppc",
+		.owner = THIS_MODULE,
+		.of_match_table = rbppc_cf_ids,
+	},
+	.probe	= rbppc_cf_probe,
+	.remove = rbppc_cf_remove,
+};
+
+static int __init rbppc_init(void)
+{
+	of_register_platform_driver(&rbppc_cf_driver);
+	return 0;
+}
+
+static void __exit rbppc_exit(void)
+{
+	of_unregister_platform_driver(&rbppc_cf_driver);
+}
+
+module_init(rbppc_init);
+module_exit(rbppc_exit);
+
diff -puNrb linux-2.6.35/drivers/char/hvc_meta.c linux/drivers/char/hvc_meta.c
--- linux-2.6.35/drivers/char/hvc_meta.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/char/hvc_meta.c	2011-05-02 10:08:26.052790447 +0300
@@ -0,0 +1,135 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/slab.h>
+#include <asm/vm.h>
+#include <asm/irq.h>
+#include "hvc_console.h"
+
+extern int vm_create_queue(unsigned id, unsigned irq,
+			   unsigned tx, unsigned rx);
+extern int vm_release_queue(unsigned id);
+
+#define BUF_SIZE	4096
+
+static volatile struct vdma_descr tx_descr;
+static volatile struct vdma_descr rx_descr;
+
+static unsigned rx_offset;
+static DEFINE_SPINLOCK(lock);
+
+static int put_chars(u32 vtermno, const char *buf, int count)
+{
+	unsigned long flags;
+	int i;
+
+	spin_lock_irqsave(&lock, flags);
+
+#ifdef __powerpc__
+	for (i = 0; i < 2000000; ++i) {
+#else
+	for (i = 0; i < 2; ++i) {
+#endif
+		unsigned size = xchg(&tx_descr.size, 0);
+
+		if (!(size & DONE)) {
+			count = min(count, BUF_SIZE);
+			memcpy((char *) tx_descr.addr, buf, count);
+			tx_descr.size = count | DONE;
+
+			spin_unlock_irqrestore(&lock, flags);
+			return count;
+		}
+
+		if (size == (BUF_SIZE | DONE)) {
+			if (i == 0) {
+				tx_descr.size = size;
+				hc_yield();
+				continue;
+			} else {
+				unsigned drop = BUF_SIZE / 4;
+				size = BUF_SIZE - drop;
+				memcpy((char *) tx_descr.addr,
+				       (char *) tx_descr.addr + drop,
+				       size);
+			}
+		}
+
+		size &= ~DONE;
+		count = min(BUF_SIZE - (int) size, count);
+		memcpy((char *) tx_descr.addr + size, buf, count);
+		tx_descr.size = (size + count) | DONE;
+
+		spin_unlock_irqrestore(&lock, flags);
+		return count;
+	}
+
+	spin_unlock_irqrestore(&lock, flags);
+	return 0;
+}
+
+static int get_chars(u32 vtermno, char *buf, int count)
+{
+	unsigned long flags;
+	unsigned size;
+
+	spin_lock_irqsave(&lock, flags);
+
+	if (!(rx_descr.size & DONE)) {
+		spin_unlock_irqrestore(&lock, flags);
+		return -EAGAIN;
+	}
+	
+	size = (rx_descr.size & ~DONE) - rx_offset;
+	count = min(count, (int) size);
+
+	memcpy(buf, (char *) rx_descr.addr + rx_offset, count);
+
+	if (count == size) {
+		rx_descr.size = BUF_SIZE;
+		rx_offset = 0;
+	} else {
+		rx_offset += count;
+	}
+
+	spin_unlock_irqrestore(&lock, flags);
+	return count;
+}
+
+static struct hv_ops cons = {
+	.put_chars = put_chars,
+	.get_chars = get_chars,
+	.notifier_add = notifier_add_irq,
+	.notifier_del = notifier_del_irq,
+};
+
+static int __init cons_init(void)
+{
+	if (vm_running() != 0)
+		return 0;
+
+	rx_descr.addr = (unsigned) kmalloc(BUF_SIZE, GFP_KERNEL);
+	rx_descr.size = BUF_SIZE;
+	rx_descr.next = (unsigned) &rx_descr;
+	
+	tx_descr.addr = (unsigned) kmalloc(BUF_SIZE, GFP_KERNEL);
+	tx_descr.size = 0;
+	tx_descr.next = (unsigned) &tx_descr;
+
+	vm_create_queue(1, 1,
+			(unsigned) &tx_descr, (unsigned) &rx_descr);
+
+	return hvc_instantiate(0, 0, &cons);
+}
+console_initcall(cons_init);
+
+int vm_init(void)
+{
+	if (vm_running() == 0) 
+		hvc_alloc(0, get_virq_nr(1), &cons, 256);
+	return 0;
+}
+module_init(vm_init);
diff -puNrb linux-2.6.35/drivers/char/Kconfig linux/drivers/char/Kconfig
--- linux-2.6.35/drivers/char/Kconfig	2011-04-26 16:28:06.112477616 +0300
+++ linux/drivers/char/Kconfig	2011-05-02 10:08:26.062790842 +0300
@@ -661,6 +661,13 @@ config HVC_XEN
 	help
 	  Xen virtual console device driver
 
+config HVC_META
+	bool "MetaROUTER Hypervisor Console support"
+	depends on METAROUTER || MIPS_MIKROTIK
+	select HVC_DRIVER
+	select HVC_IRQ
+	default y
+
 config HVC_UDBG
        bool "udbg based fake hypervisor console"
        depends on PPC && EXPERIMENTAL
diff -puNrb linux-2.6.35/drivers/char/Makefile linux/drivers/char/Makefile
--- linux-2.6.35/drivers/char/Makefile	2011-04-26 16:28:06.132476985 +0300
+++ linux/drivers/char/Makefile	2011-05-02 10:08:26.082791142 +0300
@@ -51,6 +51,7 @@ obj-$(CONFIG_HVC_BEAT)		+= hvc_beat.o
 obj-$(CONFIG_HVC_DRIVER)	+= hvc_console.o
 obj-$(CONFIG_HVC_IRQ)		+= hvc_irq.o
 obj-$(CONFIG_HVC_XEN)		+= hvc_xen.o
+obj-$(CONFIG_HVC_META)		+= hvc_meta.o
 obj-$(CONFIG_HVC_IUCV)		+= hvc_iucv.o
 obj-$(CONFIG_HVC_UDBG)		+= hvc_udbg.o
 obj-$(CONFIG_VIRTIO_CONSOLE)	+= virtio_console.o
diff -puNrb linux-2.6.35/drivers/char/n_tty.c linux/drivers/char/n_tty.c
--- linux-2.6.35/drivers/char/n_tty.c	2011-04-26 16:28:06.112477616 +0300
+++ linux/drivers/char/n_tty.c	2011-05-02 10:08:26.102903575 +0300
@@ -858,7 +858,7 @@ static void eraser(unsigned char c, stru
 		/* process_output('\a', tty); */ /* what do you think? */
 		return;
 	}
-	if (c == ERASE_CHAR(tty))
+	if (c == ERASE_CHAR(tty) || c == 8)
 		kill_type = ERASE;
 	else if (c == WERASE_CHAR(tty))
 		kill_type = WERASE;
@@ -1202,7 +1202,7 @@ send_signal:
 		c = '\r';
 
 	if (tty->icanon) {
-		if (c == ERASE_CHAR(tty) || c == KILL_CHAR(tty) ||
+		if (c == ERASE_CHAR(tty) || c == 8 || c == KILL_CHAR(tty) ||
 		    (c == WERASE_CHAR(tty) && L_IEXTEN(tty))) {
 			eraser(c, tty);
 			process_echoes(tty);
@@ -1480,6 +1480,7 @@ static void n_tty_set_termios(struct tty
 			set_bit('\n', tty->process_char_map);
 
 		if (L_ICANON(tty)) {
+			set_bit(8, tty->process_char_map);
 			set_bit(ERASE_CHAR(tty), tty->process_char_map);
 			set_bit(KILL_CHAR(tty), tty->process_char_map);
 			set_bit(EOF_CHAR(tty), tty->process_char_map);
diff -puNrb linux-2.6.35/drivers/char/random.c linux/drivers/char/random.c
--- linux-2.6.35/drivers/char/random.c	2011-04-26 16:28:06.152481058 +0300
+++ linux/drivers/char/random.c	2011-05-02 10:08:26.122902903 +0300
@@ -1550,6 +1550,7 @@ __u32 secure_tcp_sequence_number(__be32 
 
 	return seq;
 }
+EXPORT_SYMBOL_GPL(secure_tcp_sequence_number);
 
 /* Generate secure starting point for ephemeral IPV4 transport port search */
 u32 secure_ipv4_port_ephemeral(__be32 saddr, __be32 daddr, __be16 dport)
diff -puNrb linux-2.6.35/drivers/crypto/amcc/crypto4xx_reg_def.h linux/drivers/crypto/amcc/crypto4xx_reg_def.h
--- linux-2.6.35/drivers/crypto/amcc/crypto4xx_reg_def.h	2011-04-26 16:28:06.442477391 +0300
+++ linux/drivers/crypto/amcc/crypto4xx_reg_def.h	2011-05-02 10:08:26.141336638 +0300
@@ -120,7 +120,22 @@
 #define PPC4XX_INPUT_THRESHOLD			2
 #define PPC4XX_PD_SIZE				6
 #define PPC4XX_CTX_DONE_INT			0x2000
-#define PPC4XX_PD_DONE_INT			0x8000
+/*
+ * in original kernel source PPC4XX_PD_DONE_INT was 0x8000
+ * and no interrupts were happening, PPC460EX/EXr/GT manual states that
+ * register CRYPTO4XX_INT_EN bit 15 (DESC) is:
+ *      "Specified number of Descriptors (163) have
+ *       completed processing. Also occurs if a Descriptor
+ *       has just been processed and there are no more
+ *       input Descriptors available.
+ * but bit 14 (DESCRD) is described as:
+ *      "Command to the Packet Engine to fetch the next
+ *       Packet Descriptor from the PDR."
+ * while for INT MASK/UNMASK registers mnemonics DESC for bit 15 
+ * and DESCRD for bit 14 are the same, but the descriptions are swapped
+ * (probably this is copy paste bug in manual)
+ */
+#define PPC4XX_PD_DONE_INT			0x4000
 #define PPC4XX_BYTE_ORDER			0x22222
 #define PPC4XX_INTERRUPT_CLR			0x3ffff
 #define PPC4XX_PRNG_CTRL_AUTO_EN		0x3
diff -puNrb linux-2.6.35/drivers/crypto/talitos.c linux/drivers/crypto/talitos.c
--- linux-2.6.35/drivers/crypto/talitos.c	2011-04-26 16:28:06.522478068 +0300
+++ linux/drivers/crypto/talitos.c	2011-05-02 10:08:26.162899826 +0300
@@ -2326,7 +2326,7 @@ static int talitos_remove(struct of_devi
 		kfree(t_alg);
 	}
 
-	if (hw_supports(dev, DESC_HDR_SEL0_RNG))
+	if (hw_supports(dev, DESC_HDR_SEL0_RNG) && priv->rng.priv)
 		talitos_unregister_rng(dev);
 
 	for (i = 0; i < priv->num_channels; i++)
@@ -2518,6 +2518,7 @@ static int talitos_probe(struct of_devic
 		err = talitos_register_rng(dev);
 		if (err) {
 			dev_err(dev, "failed to register hwrng: %d\n", err);
+			priv->rng.priv = 0;
 			goto err_out;
 		} else
 			dev_info(dev, "hwrng\n");
diff -puNrb linux-2.6.35/drivers/hid/hid-core.c linux/drivers/hid/hid-core.c
--- linux-2.6.35/drivers/hid/hid-core.c	2011-04-26 16:28:03.582477143 +0300
+++ linux/drivers/hid/hid-core.c	2011-05-02 10:08:26.172790349 +0300
@@ -1294,7 +1294,10 @@ static const struct hid_device_id hid_bl
 	{ HID_USB_DEVICE(USB_VENDOR_ID_CYPRESS, USB_DEVICE_ID_CYPRESS_MOUSE) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_DRAGONRISE, 0x0006) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_DWAV, USB_DEVICE_ID_DWAV_EGALAX_MULTITOUCH) },
+#ifdef CONFIG_HID_EZKEY
+	/* better keyboard with broken wheel than no keyboard at all */
 	{ HID_USB_DEVICE(USB_VENDOR_ID_EZKEY, USB_DEVICE_ID_BTC_8193) },
+#endif
 	{ HID_USB_DEVICE(USB_VENDOR_ID_GAMERON, USB_DEVICE_ID_GAMERON_DUAL_PSX_ADAPTOR) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_GAMERON, USB_DEVICE_ID_GAMERON_DUAL_PCS_ADAPTOR) },
 	{ HID_USB_DEVICE(USB_VENDOR_ID_GREENASIA, 0x0003) },
diff -puNrb linux-2.6.35/drivers/hwmon/lm87.c linux/drivers/hwmon/lm87.c
--- linux-2.6.35/drivers/hwmon/lm87.c	2011-04-26 16:28:22.122169416 +0300
+++ linux/drivers/hwmon/lm87.c	2011-05-02 10:08:26.192897356 +0300
@@ -76,6 +76,8 @@ static const unsigned short normal_i2c[]
 
 enum chips { lm87, adm1024 };
 
+static const int force_temp3 = 1;
+
 /*
  * The LM87 registers
  */
@@ -119,12 +121,12 @@ static u8 LM87_REG_TEMP_LOW[3] = { 0x3A,
  * The LM87 uses signed 8-bit values for temperatures.
  */
 
-#define IN_FROM_REG(reg,scale)	(((reg) * (scale) + 96) / 192)
+#define IN_FROM_REG(reg,scale)	((reg) > 0xff ? -1 : ((reg) * (scale) + 96) / 192)
 #define IN_TO_REG(val,scale)	((val) <= 0 ? 0 : \
 				 (val) * 192 >= (scale) * 255 ? 255 : \
 				 ((val) * 192 + (scale)/2) / (scale))
 
-#define TEMP_FROM_REG(reg)	((reg) * 1000)
+#define TEMP_FROM_REG(reg)	((reg) > 0xff ? -1 : ((s8)reg) * 1000)
 #define TEMP_TO_REG(val)	((val) <= -127500 ? -128 : \
 				 (val) >= 126500 ? 127 : \
 				 (((val) < 0 ? (val)-500 : (val)+500) / 1000))
@@ -196,16 +198,16 @@ struct lm87_data {
 	u8 channel;		/* register value */
 	u8 config;		/* original register value */
 
-	u8 in[8];		/* register value */
-	u8 in_max[8];		/* register value */
-	u8 in_min[8];		/* register value */
+	u16 in[8];		/* register value */
+	u16 in_max[8];		/* register value */
+	u16 in_min[8];		/* register value */
 	u16 in_scale[8];
 
-	s8 temp[3];		/* register value */
-	s8 temp_high[3];	/* register value */
-	s8 temp_low[3];		/* register value */
-	s8 temp_crit_int;	/* min of two register values */
-	s8 temp_crit_ext;	/* min of two register values */
+	u16 temp[3];		/* register value */
+	u16 temp_high[3];	/* register value */
+	u16 temp_low[3];	/* register value */
+	u16 temp_crit_int;	/* min of two register values */
+	u16 temp_crit_ext;	/* min of two register values */
 
 	u8 fan[2];		/* register value */
 	u8 fan_min[2];		/* register value */
@@ -235,19 +237,19 @@ static inline int lm87_write_value(struc
 static ssize_t show_in##offset##_input(struct device *dev, struct device_attribute *attr, char *buf) \
 { \
 	struct lm87_data *data = lm87_update_device(dev); \
-	return sprintf(buf, "%u\n", IN_FROM_REG(data->in[offset], \
+	return sprintf(buf, "%d\n", IN_FROM_REG(data->in[offset], \
 		       data->in_scale[offset])); \
 } \
 static ssize_t show_in##offset##_min(struct device *dev, struct device_attribute *attr, char *buf) \
 { \
 	struct lm87_data *data = lm87_update_device(dev); \
-	return sprintf(buf, "%u\n", IN_FROM_REG(data->in_min[offset], \
+	return sprintf(buf, "%d\n", IN_FROM_REG(data->in_min[offset], \
 		       data->in_scale[offset])); \
 } \
 static ssize_t show_in##offset##_max(struct device *dev, struct device_attribute *attr, char *buf) \
 { \
 	struct lm87_data *data = lm87_update_device(dev); \
-	return sprintf(buf, "%u\n", IN_FROM_REG(data->in_max[offset], \
+	return sprintf(buf, "%d\n", IN_FROM_REG(data->in_max[offset], \
 		       data->in_scale[offset])); \
 } \
 static DEVICE_ATTR(in##offset##_input, S_IRUGO, \
@@ -840,6 +842,10 @@ static void lm87_init_client(struct i2c_
 	} else {
 		data->channel = lm87_read_value(client, LM87_REG_CHANNEL_MODE);
 	}
+	if (force_temp3 && !(data->channel & CHAN_TEMP3)) {
+		data->channel |= CHAN_TEMP3;
+		lm87_write_value(client, LM87_REG_CHANNEL_MODE, data->channel);
+	}
 	data->config = lm87_read_value(client, LM87_REG_CONFIG) & 0x6F;
 
 	if (!(data->config & 0x01)) {
diff -puNrb linux-2.6.35/drivers/i2c/busses/scx200_acb.c linux/drivers/i2c/busses/scx200_acb.c
--- linux-2.6.35/drivers/i2c/busses/scx200_acb.c	2011-04-26 16:28:35.233102875 +0300
+++ linux/drivers/i2c/busses/scx200_acb.c	2011-05-02 10:08:26.202791063 +0300
@@ -232,9 +232,23 @@ static void scx200_acb_poll(struct scx20
 {
 	u8 status;
 	unsigned long timeout;
+	unsigned loops = 0;
 
 	timeout = jiffies + POLL_TIMEOUT;
 	while (1) {
+		/*
+		 * LM87 chip will reset its serial bus interface,
+		 * if SMBCLK will be low for >= 25ms.
+		 * if yield() takes more than 25ms, then our session is lost.
+		 * Up to 112 loops can happen under regular LM87 usage.
+		 */
+		if (loops > 250) {
+			/* something is wrong or it is not LM87 */
+			cpu_relax();
+			cond_resched();
+		}
+		++loops;
+
 		status = inb(ACBST);
 
 		/* Reset the status register to avoid the hang */
@@ -246,8 +260,6 @@ static void scx200_acb_poll(struct scx20
 		}
 		if (time_after(jiffies, timeout))
 			break;
-		cpu_relax();
-		cond_resched();
 	}
 
 	dev_err(&iface->adapter.dev, "timeout in state %s\n",
diff -puNrb linux-2.6.35/drivers/ide/ide-generic.c linux/drivers/ide/ide-generic.c
--- linux-2.6.35/drivers/ide/ide-generic.c	2011-04-26 16:28:26.902789911 +0300
+++ linux/drivers/ide/ide-generic.c	2011-05-02 10:08:26.212791042 +0300
@@ -56,6 +56,12 @@ static void ide_generic_check_pci_legacy
 	struct pci_dev *p = NULL;
 	u16 val;
 
+#ifdef CONFIG_X86
+	/* disable secondary IDE on Geode LX, it's irq conflicts with USB */
+	if (current_cpu_data.x86 == 5 && current_cpu_data.x86_model == 10)
+		*secondary = 1;
+#endif
+
 	for_each_pci_dev(p) {
 		if (pci_resource_start(p, 0) == 0x1f0)
 			*primary = 1;
diff -puNrb linux-2.6.35/drivers/ide/sc1200.c linux/drivers/ide/sc1200.c
--- linux-2.6.35/drivers/ide/sc1200.c	2011-04-26 16:28:26.922791147 +0300
+++ linux/drivers/ide/sc1200.c	2011-05-02 10:08:26.232902615 +0300
@@ -297,6 +297,7 @@ static const struct ide_port_info sc1200
 	.dma_ops	= &sc1200_dma_ops,
 	.host_flags	= IDE_HFLAG_SERIALIZE |
 			  IDE_HFLAG_POST_SET_MODE |
+			  IDE_HFLAG_NO_DMA |
 			  IDE_HFLAG_ABUSE_DMA_MODES,
 	.pio_mask	= ATA_PIO4,
 	.mwdma_mask	= ATA_MWDMA2,
diff -puNrb linux-2.6.35/drivers/leds/Kconfig linux/drivers/leds/Kconfig
--- linux-2.6.35/drivers/leds/Kconfig	2011-04-26 16:28:21.072476969 +0300
+++ linux/drivers/leds/Kconfig	2011-05-02 10:08:26.242790548 +0300
@@ -148,6 +148,21 @@ config LEDS_GPIO
 	  defined as platform devices and/or OpenFirmware platform devices.
 	  The code to use these bindings can be selected below.
 
+config LEDS_RB400
+	tristate "LED Support for RB400/RB700"
+	depends on LEDS_CLASS && MIPS_MIKROTIK
+
+config LEDS_RB_MIPSEL
+	tristate "LED Support for RB500/RB100/CR"
+	depends on LEDS_CLASS && MIPS_MIKROTIK
+
+config LEDS_RB_PPC
+	tristate "LED Support for RB300/RB600/RB1000"
+	depends on LEDS_CLASS && (RB_PPC || RB1000)
+
+config LEDS_CM_X270
+	tristate "LED Support for the CM-X270 LEDs"
+	depends on LEDS_CLASS && MACH_ARMCORE
 config LEDS_GPIO_PLATFORM
 	bool "Platform device bindings for GPIO LEDs"
 	depends on LEDS_GPIO
diff -puNrb linux-2.6.35/drivers/leds/leds-cr.c linux/drivers/leds/leds-cr.c
--- linux-2.6.35/drivers/leds/leds-cr.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-cr.c	2011-05-02 10:08:26.252791089 +0300
@@ -0,0 +1,44 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/platform_device.h>
+#include <asm/rb/cr.h>
+
+static void cr_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	if (brightness)
+		CR_GPOUT() |= CR_GPIO_ULED;
+	else
+		CR_GPOUT() &= ~CR_GPIO_ULED;
+}
+
+static struct led_classdev cr_led = {
+       .name = "user-led",
+       .brightness_set = cr_led_set_user,
+};
+
+static int cr_led_probe(struct platform_device *pdev)
+{
+	return led_classdev_register(&pdev->dev, &cr_led);
+}
+
+static struct platform_driver cr_led_driver = {
+	.probe	= cr_led_probe,
+	.driver	= {
+		.name = "cr-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init cr_led_init(void)
+{
+	return platform_driver_register(&cr_led_driver);
+}
+
+static void __exit cr_led_exit(void)
+{
+	platform_driver_unregister(&cr_led_driver);
+}
+
+module_init(cr_led_init);
+module_exit(cr_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/leds-mr.c linux/drivers/leds/leds-mr.c
--- linux-2.6.35/drivers/leds/leds-mr.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-mr.c	2011-05-02 10:08:26.262450676 +0300
@@ -0,0 +1,41 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb100.h>
+
+static void mr_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	rb100_set_port_led2(MR_PORT_USER_LED, brightness);
+}
+
+static struct led_classdev mr_led = {
+       .name = "user-led",
+       .brightness_set = mr_led_set_user,
+};
+
+static int mr_led_probe(struct platform_device *pdev)
+{
+	return led_classdev_register(&pdev->dev, &mr_led);
+}
+
+static struct platform_driver mr_led_driver = {
+	.probe	= mr_led_probe,
+	.driver	= {
+		.name = "mr-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init mr_led_init(void)
+{
+	return platform_driver_register(&mr_led_driver);
+}
+
+static void __exit mr_led_exit(void)
+{
+	platform_driver_unregister(&mr_led_driver);
+}
+
+module_init(mr_led_init);
+module_exit(mr_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/leds-rb100.c linux/drivers/leds/leds-rb100.c
--- linux-2.6.35/drivers/leds/leds-rb100.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-rb100.c	2011-05-02 10:08:26.282898098 +0300
@@ -0,0 +1,74 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb100.h>
+
+static void rb100_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	if (brightness)
+		RB100_GPIO() |= RB100_GPOUT(RB100_GPIO_ULED);
+	else
+		RB100_GPIO() &= ~RB100_GPOUT(RB100_GPIO_ULED);
+}
+
+static void rb112_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	if (brightness)
+		RB100_GPIO() |= RB100_GPOUT(RB112_GPIO_ULED);
+	else
+		RB100_GPIO() &= ~RB100_GPOUT(RB112_GPIO_ULED);
+}
+
+static struct led_classdev rb100_led = {
+       .name = "user-led",
+       .brightness_set = rb100_led_set_user,
+};
+
+static struct led_classdev rb112_led = {
+       .name = "user-led",
+       .brightness_set = rb112_led_set_user,
+};
+
+static int rb100_led_probe(struct platform_device *pdev)
+{
+	return led_classdev_register(&pdev->dev, &rb100_led);
+}
+
+static int rb112_led_probe(struct platform_device *pdev)
+{
+	return led_classdev_register(&pdev->dev, &rb112_led);
+}
+
+static struct platform_driver rb100_led_driver = {
+	.probe	= rb100_led_probe,
+	.driver	= {
+		.name = "rb100-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static struct platform_driver rb112_led_driver = {
+	.probe	= rb112_led_probe,
+	.driver	= {
+		.name = "rb112-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init rb100_led_init(void)
+{
+	platform_driver_register(&rb100_led_driver);
+	platform_driver_register(&rb112_led_driver);
+	return 0;
+}
+
+static void __exit rb100_led_exit(void)
+{
+	platform_driver_unregister(&rb100_led_driver);
+	platform_driver_unregister(&rb112_led_driver);
+}
+
+module_init(rb100_led_init);
+module_exit(rb100_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/leds-rb400.c linux/drivers/leds/leds-rb400.c
--- linux-2.6.35/drivers/leds/leds-rb400.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-rb400.c	2011-05-02 10:08:26.292899717 +0300
@@ -0,0 +1,126 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb400.h>
+
+#define REG_GPIO_SET	KSEG1ADDR(0x1804000C)
+#define REG_GPIO_CLR	KSEG1ADDR(0x18040010)
+#define   GPIO_LIGHT	0x010
+
+struct rb_led_data {
+	struct led_classdev cdev;
+	unsigned mask;
+};
+static struct rb_led_data rb_leds[] = {
+	{ .cdev = { .name = "user-led" } },
+	{ .cdev = { .name = "led1" } },
+	{ .cdev = { .name = "led2" } },
+	{ .cdev = { .name = "led3" } },
+	{ .cdev = { .name = "led4" } },
+	{ .cdev = { .name = "led5" } },
+	{ .cdev = { .name = "usb-power-off" } },
+	{ .cdev = { .name = NULL } },
+};
+
+static void (*set_wifi_gpo)(void *obj, unsigned off, unsigned on) = NULL;
+static void *set_wifi_gpo_obj = NULL;
+static unsigned wifi_gpo_mask = 0;
+
+unsigned register_wifi_gpo(void *obj,
+			   void (*set_gpo)(void *, unsigned, unsigned)) {
+	set_wifi_gpo_obj = obj;
+	set_wifi_gpo = set_gpo;
+	return wifi_gpo_mask;
+}
+EXPORT_SYMBOL(register_wifi_gpo);
+
+static void rb_led_set_wifi(struct led_classdev *led_cdev,
+			    enum led_brightness brightness)
+{
+	unsigned mask = container_of(led_cdev, struct rb_led_data, cdev)->mask;
+	if (set_wifi_gpo == NULL) return;
+	if (brightness)
+		(*set_wifi_gpo)(set_wifi_gpo_obj, mask & 0xffff, mask >> 16);
+	else
+		(*set_wifi_gpo)(set_wifi_gpo_obj, mask >> 16, mask & 0xffff);
+}
+
+static void rb_led_set_gpo(struct led_classdev *led_cdev,
+			   enum led_brightness brightness)
+{
+	unsigned mask = container_of(led_cdev, struct rb_led_data, cdev)->mask;
+	if (brightness)
+		rb400_writel(mask, REG_GPIO_SET);
+	else
+		rb400_writel(mask, REG_GPIO_CLR);
+}
+
+static void rb_led_set_rb400(struct led_classdev *led_cdev,
+			     enum led_brightness brightness)
+{
+	unsigned mask = container_of(led_cdev, struct rb_led_data, cdev)->mask;
+	if (brightness)
+		rb400_change_cfg(mask, 0);
+	else
+		rb400_change_cfg(0, mask);
+}
+
+static void rb_led_set_rb700(struct led_classdev *led_cdev,
+			     enum led_brightness brightness)
+{
+	unsigned mask = container_of(led_cdev, struct rb_led_data, cdev)->mask;
+	if (brightness)
+		rb700_change_gpo(mask, 0);
+	else
+		rb700_change_gpo(0, mask);
+}
+
+static void *rb_led_set[0x10] = {
+	rb_led_set_gpo, NULL, NULL, NULL,
+	rb_led_set_rb400,
+	NULL,
+	NULL,
+	rb_led_set_rb700, NULL,
+	NULL,
+	NULL, NULL, NULL, NULL, NULL,
+	rb_led_set_wifi
+};
+
+static int rb400_led_probe(struct platform_device *pdev)
+{
+	int *map = (int *)pdev->dev.platform_data;
+	struct rb_led_data *data = rb_leds;
+
+	for ( ; *map >= 0 && data->cdev.name != NULL; ++map, ++data) {
+		data->mask = *map >> 4;
+		data->cdev.brightness_set = rb_led_set[*map & 0xf];
+		if (data->mask != 0 && data->cdev.brightness_set != NULL) {
+			led_classdev_register(&pdev->dev, &data->cdev);
+			if (data->cdev.brightness_set == rb_led_set_wifi) {
+				wifi_gpo_mask |= data->mask;
+			}
+		}
+	}
+	return 0;
+}
+
+static struct platform_driver rb400_led_driver = {
+	.probe	= rb400_led_probe,
+	.driver	= {
+		.name = "rb400-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init rb400_led_init(void)
+{
+	return platform_driver_register(&rb400_led_driver);
+}
+
+static void __exit rb400_led_exit(void)
+{
+	platform_driver_unregister(&rb400_led_driver);
+}
+
+module_init(rb400_led_init);
+module_exit(rb400_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/leds-rb500.c linux/drivers/leds/leds-rb500.c
--- linux-2.6.35/drivers/leds/leds-rb500.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-rb500.c	2011-05-02 10:08:26.302849227 +0300
@@ -0,0 +1,44 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb500.h>
+
+static void rb500_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	if (brightness)
+		changeLatchU5(RB500_LO_ULED, 0);
+	else
+		changeLatchU5(0, RB500_LO_ULED);
+}
+
+static struct led_classdev rb500_led = {
+       .name = "user-led",
+       .brightness_set = rb500_led_set_user,
+};
+
+static int rb500_led_probe(struct platform_device *pdev)
+{
+	return led_classdev_register(&pdev->dev, &rb500_led);
+}
+
+static struct platform_driver rb500_led_driver = {
+	.probe	= rb500_led_probe,
+	.driver	= {
+		.name = "rb500-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init rb500_led_init(void)
+{
+	return platform_driver_register(&rb500_led_driver);
+}
+
+static void __exit rb500_led_exit(void)
+{
+	platform_driver_unregister(&rb500_led_driver);
+}
+
+module_init(rb500_led_init);
+module_exit(rb500_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/leds-rbppc.c linux/drivers/leds/leds-rbppc.c
--- linux-2.6.35/drivers/leds/leds-rbppc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/leds/leds-rbppc.c	2011-05-02 10:08:26.312900803 +0300
@@ -0,0 +1,56 @@
+#include <linux/init.h>
+#include <linux/leds.h>
+#include <linux/of_platform.h>
+#include <linux/of_device.h>
+#include <asm/io.h>
+
+struct led_config {
+	u32 *addr;
+	u32 bitmask;
+};
+
+static struct led_config ulcfg;
+
+static void rbppc_led_set_user(struct led_classdev *led_cdev,
+			       enum led_brightness brightness)
+{
+	if (brightness)
+		setbits32(ulcfg.addr, ulcfg.bitmask);
+	else
+		clrbits32(ulcfg.addr, ulcfg.bitmask);
+}
+
+static struct led_classdev rbppc_led = {
+       .name = "user-led",
+       .brightness_set = rbppc_led_set_user,
+};
+
+static int rbppc_led_probe(struct platform_device *pdev)
+{
+	struct resource *res = &pdev->resource[0];
+	ulcfg.addr = ioremap_nocache(res->start, res->end - res->start + 1);
+	ulcfg.bitmask = 1 << (31 - pdev->resource[1].start);
+
+	return led_classdev_register(&pdev->dev, &rbppc_led);
+}
+
+static struct platform_driver rbppc_led_driver = {
+	.probe	= rbppc_led_probe,
+	.driver	= {
+		.name = "rbppc-led",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init rbppc_led_init(void)
+{
+	return platform_driver_register(&rbppc_led_driver);
+}
+
+static void __exit rbppc_led_exit(void)
+{
+	platform_driver_unregister(&rbppc_led_driver);
+}
+
+module_init(rbppc_led_init);
+module_exit(rbppc_led_exit);
diff -puNrb linux-2.6.35/drivers/leds/Makefile linux/drivers/leds/Makefile
--- linux-2.6.35/drivers/leds/Makefile	2011-04-26 16:28:21.072476969 +0300
+++ linux/drivers/leds/Makefile	2011-05-02 10:08:26.322904511 +0300
@@ -22,6 +22,11 @@ obj-$(CONFIG_LEDS_COBALT_RAQ)		+= leds-c
 obj-$(CONFIG_LEDS_SUNFIRE)		+= leds-sunfire.o
 obj-$(CONFIG_LEDS_PCA9532)		+= leds-pca9532.o
 obj-$(CONFIG_LEDS_GPIO)			+= leds-gpio.o
+obj-$(CONFIG_LEDS_RB400)		+= leds-rb400.o
+obj-$(CONFIG_LEDS_RB_MIPSEL)		+= leds-rb500.o leds-cr.o
+obj-$(CONFIG_LEDS_RB_MIPSEL)		+= leds-rb100.o leds-mr.o
+obj-$(CONFIG_LEDS_RB_PPC)		+= leds-rbppc.o
+obj-$(CONFIG_LEDS_CM_X270)              += leds-cm-x270.o
 obj-$(CONFIG_LEDS_LP3944)		+= leds-lp3944.o
 obj-$(CONFIG_LEDS_CLEVO_MAIL)		+= leds-clevo-mail.o
 obj-$(CONFIG_LEDS_HP6XX)		+= leds-hp6xx.o
diff -puNrb linux-2.6.35/drivers/mmc/core/core.c linux/drivers/mmc/core/core.c
--- linux-2.6.35/drivers/mmc/core/core.c	2011-04-26 16:27:43.392184181 +0300
+++ linux/drivers/mmc/core/core.c	2011-05-02 10:08:26.342899388 +0300
@@ -44,7 +44,7 @@ static struct workqueue_struct *workqueu
  * performance cost, and for other reasons may not always be desired.
  * So we allow it it to be disabled.
  */
-int use_spi_crc = 1;
+int use_spi_crc = 0;
 module_param(use_spi_crc, bool, 0);
 
 /*
diff -puNrb linux-2.6.35/drivers/mmc/host/mmc_spi.c linux/drivers/mmc/host/mmc_spi.c
--- linux-2.6.35/drivers/mmc/host/mmc_spi.c	2011-04-26 16:27:43.732169377 +0300
+++ linux/drivers/mmc/host/mmc_spi.c	2011-05-02 10:08:26.352846413 +0300
@@ -1332,12 +1332,17 @@ static int mmc_spi_probe(struct spi_devi
 
 	status = spi_setup(spi);
 	if (status < 0) {
+		spi->mode = SPI_MODE_3;
+		status = spi_setup(spi);
+	}
+	if (status < 0) {
 		dev_dbg(&spi->dev, "needs SPI mode %02x, %d KHz; %d\n",
 				spi->mode, spi->max_speed_hz / 1000,
 				status);
 		return status;
 	}
 
+#ifdef FIXME
 	/* We can use the bus safely iff nobody else will interfere with us.
 	 * Most commands consist of one SPI message to issue a command, then
 	 * several more to collect its response, then possibly more for data
@@ -1363,6 +1368,7 @@ static int mmc_spi_probe(struct spi_devi
 
 		dev_warn(&spi->dev, "ASSUMING SPI bus stays unshared!\n");
 	}
+#endif
 
 	/* We need a supply of ones to transmit.  This is the only time
 	 * the CPU touches these, so cache coherency isn't a concern.
diff -puNrb linux-2.6.35/drivers/mtd/nand/Kconfig linux/drivers/mtd/nand/Kconfig
--- linux-2.6.35/drivers/mtd/nand/Kconfig	2011-04-26 16:27:33.632789906 +0300
+++ linux/drivers/mtd/nand/Kconfig	2011-05-02 10:08:26.362898415 +0300
@@ -447,6 +447,25 @@ config MTD_ALAUDA
 	  These two (and possibly other) Alauda-based cardreaders for
 	  SmartMedia and xD allow raw flash access.
 
+config MTD_NAND_RB500
+	bool "Support for RB500/RB100 nand"
+	depends on MTD_NAND && MTD_PARTITIONS && MIPS_MIKROTIK
+	select MTD_NAND_RB
+
+config MTD_NAND_RB400
+	bool "Support for RB400 nand"
+	depends on MTD_NAND && MTD_PARTITIONS && MIPS_MIKROTIK && SPI_RB400
+	select MTD_NAND_RB
+
+config MTD_NAND_RB_PPC
+	bool "Support for RB333/RB600/RB1000 nand"
+	depends on MTD_NAND && MTD_PARTITIONS && (RB_PPC || RB1000)
+	select MTD_NAND_RB
+
+
+config MTD_NAND_RB
+	tristate
+
 config MTD_NAND_ORION
 	tristate "NAND Flash support for Marvell Orion SoC"
 	depends on PLAT_ORION && MTD_NAND
diff -puNrb linux-2.6.35/drivers/mtd/nand/Makefile linux/drivers/mtd/nand/Makefile
--- linux-2.6.35/drivers/mtd/nand/Makefile	2011-04-26 16:27:33.642795772 +0300
+++ linux/drivers/mtd/nand/Makefile	2011-05-02 10:08:26.382903196 +0300
@@ -3,7 +3,7 @@
 #
 
 obj-$(CONFIG_MTD_NAND)			+= nand.o
-obj-$(CONFIG_MTD_NAND_ECC)		+= nand_ecc.o
+obj-$(CONFIG_MTD_NAND_ECC)		+= nand_ecc.o nand_ecc_mlc.o
 obj-$(CONFIG_MTD_NAND_IDS)		+= nand_ids.o
 obj-$(CONFIG_MTD_SM_COMMON) 		+= sm_common.o
 
@@ -33,6 +33,12 @@ obj-$(CONFIG_MTD_NAND_PXA3xx)		+= pxa3xx
 obj-$(CONFIG_MTD_NAND_TMIO)		+= tmio_nand.o
 obj-$(CONFIG_MTD_NAND_PLATFORM)		+= plat_nand.o
 obj-$(CONFIG_MTD_ALAUDA)		+= alauda.o
+obj-$(CONFIG_MTD_NAND_RB)		+= rb.o
+obj-$(CONFIG_MTD_NAND_RB500)		+= rb500nand.o
+obj-$(CONFIG_MTD_NAND_RB400)		+= rb400_nand.o
+obj-$(CONFIG_MTD_NAND_RB400)		+= rb700_nand.o
+obj-$(CONFIG_MTD_NAND_RB400)		+= rb750g_nand.o
+obj-$(CONFIG_MTD_NAND_RB_PPC)		+= rb_ppc.o
 obj-$(CONFIG_MTD_NAND_PASEMI)		+= pasemi_nand.o
 obj-$(CONFIG_MTD_NAND_ORION)		+= orion_nand.o
 obj-$(CONFIG_MTD_NAND_FSL_ELBC)		+= fsl_elbc_nand.o
diff -puNrb linux-2.6.35/drivers/mtd/nand/nand_base.c linux/drivers/mtd/nand/nand_base.c
--- linux-2.6.35/drivers/mtd/nand/nand_base.c	2011-04-26 16:27:33.652812104 +0300
+++ linux/drivers/mtd/nand/nand_base.c	2011-05-02 10:08:26.392849032 +0300
@@ -42,6 +42,7 @@
 #include <linux/mtd/mtd.h>
 #include <linux/mtd/nand.h>
 #include <linux/mtd/nand_ecc.h>
+#include <linux/mtd/nand_ecc_mlc.h>
 #include <linux/mtd/compatmac.h>
 #include <linux/interrupt.h>
 #include <linux/bitops.h>
@@ -65,10 +66,12 @@ static struct nand_ecclayout nand_oob_8 
 
 static struct nand_ecclayout nand_oob_16 = {
 	.eccbytes = 6,
-	.eccpos = {0, 1, 2, 3, 6, 7},
+	.eccpos = {8, 9, 10, 13, 14, 15},
 	.oobfree = {
-		{.offset = 8,
-		 . length = 8}}
+		{.offset = 0,
+		 .length = 8},
+		{.offset = 11,
+		 .length = 2}}
 };
 
 static struct nand_ecclayout nand_oob_64 = {
@@ -96,6 +99,22 @@ static struct nand_ecclayout nand_oob_12
 		 .length = 78}}
 };
 
+/*
+ * fake MLC layout
+ * used by yaffs to see correct oobfree amount (oobfree as in MLC layout)
+ * used for reading if data is written using slc ecc (eccpos as in SLC layout)
+ */
+static struct nand_ecclayout nand_oob_64_mlc = {
+	.eccbytes = 24,
+	.eccpos = {
+		   40, 41, 42, 43, 44, 45, 46, 47,
+		   48, 49, 50, 51, 52, 53, 54, 55,
+		   56, 57, 58, 59, 60, 61, 62, 63},
+	.oobfree = {
+		{.offset = 2,
+		 .length = 22}}
+};
+
 static int nand_get_device(struct nand_chip *chip, struct mtd_info *mtd,
 			   int new_state);
 
@@ -108,6 +127,37 @@ static int nand_do_write_oob(struct mtd_
  */
 DEFINE_LED_TRIGGER(nand_led_trigger);
 
+static int mlc_ecc_allowed = 0;
+
+static int __init on_setup_mlc(char *str)
+{
+	mlc_ecc_allowed = (str[0] != '0');
+	return 1;
+}
+__setup("mlc=", on_setup_mlc);
+
+static int is_nand_mlc(struct nand_chip *chip) {
+	return chip->cellinfo & NAND_CI_CELLTYPE_MSK;
+}
+
+static void set_ecc_mlc(struct nand_chip *chip) {
+	chip->oob_poi[ECC_ID_OFFSET] = 0;
+}
+
+static int is_ecc_mlc(struct nand_chip *chip) {
+	int bits = 0;
+	unsigned char ecc_id;
+	if (chip->page_shift <= 9) return 0;	/* small page nand */
+
+	ecc_id = chip->oob_poi[ECC_ID_OFFSET];
+	if (ecc_id == 0) return 1;
+	if (ecc_id == 0xff) return 0;
+
+	for ( ; ecc_id; ecc_id >>= 1)
+		bits += ecc_id & 0x01;
+	return bits < 4;
+}
+
 static int check_offs_len(struct mtd_info *mtd,
 					loff_t ofs, uint64_t len)
 {
@@ -272,6 +322,25 @@ static int nand_verify_buf(struct mtd_in
 	return 0;
 }
 
+static int nand_verify_buf_mlc(struct mtd_info *mtd, struct nand_chip *chip,
+			       const uint8_t *buf, int len)
+{
+	/* ignore one-bit error */
+	unsigned char rbuf[len];
+	int i;
+	unsigned errors = 0;
+
+	chip->read_buf(mtd, rbuf, len);
+	for (i = 0; i < len; ++i) {
+		unsigned char err = rbuf[i] ^ buf[i];
+		for (; err != 0; err /= 2) {
+			errors += (err & 1);
+			if (errors > 1) return -EFAULT;
+		}
+	}
+	return 0;
+}
+
 /**
  * nand_write_buf16 - [DEFAULT] write buffer to chip
  * @mtd:	MTD device structure
@@ -385,6 +454,21 @@ static int nand_block_bad(struct mtd_inf
 	return res;
 }
 
+static int nand_block_bad_mlc(struct mtd_info *mtd, loff_t ofs, int getchip)
+{
+	int res = nand_block_bad(mtd, ofs, getchip);
+	if (res == 0) {
+		/*
+		 * MLC nand initially (from factory)
+		 * contains bad block info at last page within block
+		 */
+		ofs = ((ofs & ~(mtd->erasesize - 1)) +
+		       mtd->erasesize - mtd->writesize);
+		res = nand_block_bad(mtd, ofs, getchip);
+	}
+	return res;
+}
+
 /**
  * nand_default_block_markbad - [DEFAULT] mark a block bad
  * @mtd:	MTD device structure
@@ -421,6 +505,17 @@ static int nand_default_block_markbad(st
 		chip->ops.oobbuf = buf;
 		chip->ops.ooboffs = chip->badblockpos & ~0x01;
 
+		if (is_nand_mlc(chip)) {
+			/*
+			 * MLC nand supports only one write to page after erase
+			 * make sure our write succeeds
+			 * by erasing whole block before write
+			 */
+			int page = (int)(ofs >> chip->page_shift);
+			chip->erase_cmd(mtd, page & chip->pagemask);
+			ret = chip->waitfunc(mtd, chip);
+		}
+
 		ret = nand_do_write_oob(mtd, ofs, &chip->ops);
 		nand_release_device(mtd);
 	}
@@ -518,6 +613,60 @@ void nand_wait_ready(struct mtd_info *mt
 }
 EXPORT_SYMBOL_GPL(nand_wait_ready);
 
+static int get_backup_page(struct mtd_info *mtd, int page, int allow_bad) {
+#ifdef MIPSEL
+	struct nand_chip *chip = mtd->priv;
+	int page_offset = chip->backup_offset >> chip->page_shift;
+
+	if (page < page_offset) {
+		int page_backup = page + page_offset;
+		loff_t ofs_backup = ((loff_t) page_backup) << chip->page_shift;
+		if (allow_bad || !nand_block_checkbad(mtd, ofs_backup, 0, 1)) {
+			return page_backup;
+		}
+	}
+#endif
+	return -1;
+}
+
+static void nand_backup_merge(struct mtd_info *mtd, uint8_t *orig, int len) {
+	for ( ; len > 0; --len, ++orig) {
+		uint8_t byte = nand_read_byte(mtd);
+		*orig &= byte;
+	}
+}
+
+static int check_backup_oob(struct mtd_info *mtd, struct nand_chip *chip,
+			    int bpage) {
+	int differ = 0;
+	uint8_t ff = 0xff;
+	uint8_t *optr;
+	uint8_t *oend;
+
+	/* check that OOB areas are equal or backup is empty */
+	*(uint32_t*)(&chip->oob_poi[BACKUP_4xFF_OFFSET]) = 0xffffffff;
+	nand_wait_ready(mtd);
+	chip->cmdfunc(mtd, NAND_CMD_READOOB, 0, bpage);
+
+	optr = chip->oob_poi;
+	oend = optr + mtd->oobsize;
+	for ( ; optr < oend; ++optr) {
+		uint8_t byte = nand_read_byte(mtd);
+		ff &= byte;
+		if (byte != *optr) {
+			*optr &= byte;
+			differ = 1;
+		}
+	}
+	return differ && ff != 0xff;
+}
+
+static int read_page_raw_dummy(struct mtd_info *mtd, struct nand_chip *chip,
+			       uint8_t *buf, int page)
+{
+	return 0;
+}
+
 /**
  * nand_command - [DEFAULT] Send command to NAND device
  * @mtd:	MTD device structure
@@ -1116,6 +1265,18 @@ static int nand_read_page_swecc(struct m
 
 	chip->ecc.read_page_raw(mtd, chip, buf, page);
 
+	if (is_ecc_mlc(chip)) {
+		for (i = 0; i < 4; ++i, p += 0x200) {
+			unsigned char *ecc = chip->oob_poi + 24 + 10 * i;
+			int stat = nand_correct_data_mlc(p, ecc);
+			if (stat < 0)
+				mtd->ecc_stats.failed++;
+			else
+				mtd->ecc_stats.corrected += stat;
+		}
+		return 0;
+	}
+
 	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize)
 		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
 
@@ -1459,6 +1620,7 @@ static int nand_do_read_ops(struct mtd_i
 
 		/* Is the current page in the buffer ? */
 		if (realpage != chip->pagebuf || oob) {
+			int bpage = get_backup_page(mtd, page, 0);
 			bufpoi = aligned ? buf : chip->buffers->databuf;
 
 			if (likely(sndcmd)) {
@@ -1470,11 +1632,41 @@ static int nand_do_read_ops(struct mtd_i
 			if (unlikely(ops->mode == MTD_OOB_RAW))
 				ret = chip->ecc.read_page_raw(mtd, chip,
 							      bufpoi, page);
+#ifdef FIXME
+			/* disable subpage reads - not supported with mlc ecc */
 			else if (!aligned && NAND_SUBPAGE_READ(chip) && !oob)
 				ret = chip->ecc.read_subpage(mtd, chip, col, bytes, bufpoi);
+#endif
 			else
 				ret = chip->ecc.read_page(mtd, chip, bufpoi,
 							  page);
+
+			if (bpage >= 0) {
+				int use_backup = (mtd->ecc_stats.failed
+						  - stats.failed
+						  + mtd->ecc_stats.corrected
+						  - stats.corrected);
+				if (!use_backup) {
+					use_backup = check_backup_oob(mtd, chip,
+								      bpage);
+				}
+				sndcmd = 1;
+				if (use_backup) {
+					void *rptr;
+					chip->cmdfunc(mtd, NAND_CMD_READ0,
+						      0x00, bpage);
+					nand_backup_merge(mtd, bufpoi,
+							  mtd->writesize);
+
+					rptr = chip->ecc.read_page_raw;
+					chip->ecc.read_page_raw =
+						read_page_raw_dummy;
+					ret = chip->ecc.read_page(
+						mtd, chip, bufpoi, page);
+					chip->ecc.read_page_raw = rptr;
+				}
+			}
+
 			if (ret < 0)
 				break;
 
@@ -1601,11 +1793,20 @@ static int nand_read(struct mtd_info *mt
 static int nand_read_oob_std(struct mtd_info *mtd, struct nand_chip *chip,
 			     int page, int sndcmd)
 {
+	int bpage = get_backup_page(mtd, page, 0);
+
 	if (sndcmd) {
 		chip->cmdfunc(mtd, NAND_CMD_READOOB, 0, page);
 		sndcmd = 0;
 	}
 	chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
+
+	if (bpage >= 0) {
+		nand_wait_ready(mtd);
+		chip->cmdfunc(mtd, NAND_CMD_READOOB, 0, bpage);
+		nand_backup_merge(mtd, chip->oob_poi, mtd->oobsize);
+		sndcmd = 1;
+	}
 	return sndcmd;
 }
 
@@ -1938,6 +2139,16 @@ static void nand_write_page_swecc(struct
 	const uint8_t *p = buf;
 	uint32_t *eccpos = chip->ecc.layout->eccpos;
 
+	if (chip->ecc.layout == &nand_oob_64_mlc) {
+		set_ecc_mlc(chip);
+		nand_calculate_ecc_mlc(p + 0x000, chip->oob_poi + 24);
+		nand_calculate_ecc_mlc(p + 0x200, chip->oob_poi + 34);
+		nand_calculate_ecc_mlc(p + 0x400, chip->oob_poi + 44);
+		nand_calculate_ecc_mlc(p + 0x600, chip->oob_poi + 54);
+		chip->ecc.write_page_raw(mtd, chip, buf);
+		return;
+	}
+
 	/* Software ecc calculation */
 	for (i = 0; eccsteps; eccsteps--, i += eccbytes, p += eccsize)
 		chip->ecc.calculate(mtd, p, &ecc_calc[i]);
@@ -2033,7 +2244,17 @@ static int nand_write_page(struct mtd_in
 			   const uint8_t *buf, int page, int cached, int raw)
 {
 	int status;
+	int bpage = get_backup_page(mtd, page, 1);
+
+	if (bpage >= 0) {
+		loff_t bofs = ((loff_t) bpage) << chip->page_shift;
+		if (nand_block_checkbad(mtd, bofs, 0, 1))
+			return -EIO;
 
+		*(uint32_t*)(&chip->oob_poi[BACKUP_4xFF_OFFSET]) = 0;
+		*(uint32_t*)(&chip->oob_poi[ALWAYS_4x00_OFFSET]) = 0;
+	}
+write_again:
 	chip->cmdfunc(mtd, NAND_CMD_SEQIN, 0x00, page);
 
 	if (unlikely(raw))
@@ -2070,9 +2291,27 @@ static int nand_write_page(struct mtd_in
 	/* Send command to read back the data */
 	chip->cmdfunc(mtd, NAND_CMD_READ0, 0, page);
 
-	if (chip->verify_buf(mtd, buf, mtd->writesize))
+	if (chip->verify_buf(mtd, buf, mtd->writesize)) {
+		if (chip->ecc.layout != &nand_oob_64_mlc) {
 		return -EIO;
+		}
+		chip->cmdfunc(mtd, NAND_CMD_READ0, 0, page);
+		if (nand_verify_buf_mlc(mtd, chip, buf, mtd->writesize)) {
+			return -EIO;
+		}
+		++mtd->ecc_stats.corrected;
+	}
 #endif
+	if (bpage >= 0) {
+		page = bpage;
+		bpage = -2;
+		*(uint32_t*)(&chip->oob_poi[BACKUP_4xFF_OFFSET]) = 0xffffffff;
+		if (chip->ecc.mode == NAND_ECC_SOFT) {
+			// ECC is already calculated, do not recalculate it
+			raw = 1;
+		}
+		goto write_again;
+	}
 	return 0;
 }
 
@@ -2181,8 +2420,7 @@ static int nand_do_write_ops(struct mtd_
 	    (chip->pagebuf << chip->page_shift) < (to + ops->len))
 		chip->pagebuf = -1;
 
-	/* If we're not given explicit OOB data, let it be 0xFF */
-	if (likely(!oob))
+	/* make sure unused OOB bytes are written as 0xFF */
 		memset(chip->oob_poi, 0xff, mtd->oobsize);
 
 	/* Don't allow multipage oob writes with offset */
@@ -2496,6 +2734,7 @@ int nand_erase_nand(struct mtd_info *mtd
 		    int allowbbt)
 {
 	int page, status, pages_per_block, ret, chipnr;
+	int erase_bad = 0;
 	struct nand_chip *chip = mtd->priv;
 	loff_t rewrite_bbt[NAND_MAX_CHIPS]={0};
 	unsigned int bbt_masked_page = 0xffffffff;
@@ -2505,6 +2744,11 @@ int nand_erase_nand(struct mtd_info *mtd
 				__func__, (unsigned long long)instr->addr,
 				(unsigned long long)instr->len);
 
+	if (instr->len == 0xDeadBeef) {
+		instr->len = (1 << chip->phys_erase_shift);
+		erase_bad = 1;
+	}
+
 	if (check_offs_len(mtd, instr->addr, instr->len))
 		return -EINVAL;
 
@@ -2546,6 +2790,18 @@ int nand_erase_nand(struct mtd_info *mtd
 	instr->state = MTD_ERASING;
 
 	while (len) {
+		int opage = page;
+		int bpage = get_backup_page(mtd, page, 1);
+	erase_again:
+		/*
+		 * try to erase bad block
+		 */
+		if (erase_bad && chip->bbt) {
+			loff_t ofs = ((loff_t) page) << chip->page_shift;
+			int block = ofs >> chip->bbt_erase_shift;
+			chip->bbt[block / 4] &= ~(0x03 << ((block & 0x03) * 2));
+		}
+
 		/*
 		 * heck if we have a bad block, we do not erase bad blocks !
 		 */
@@ -2596,6 +2852,15 @@ int nand_erase_nand(struct mtd_info *mtd
 			    rewrite_bbt[chipnr] =
 					((loff_t)page << chip->page_shift);
 
+		/* erase backup page as well */
+		if (bpage >= 0) {
+			if (page != bpage) {
+				page = bpage;
+				goto erase_again;
+			}
+			page = opage;
+		}
+		
 		/* Increment page address and decrement length */
 		len -= (1 << chip->phys_erase_shift);
 		page += pages_per_block;
@@ -2805,6 +3070,7 @@ static struct nand_flash_dev *nand_get_f
 	 * not match, ignore the device completely.
 	 */
 
+	chip->cmdfunc(mtd, NAND_CMD_RESET, -1, -1);
 	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
 
 	/* Read entire ID string */
@@ -2850,6 +3116,7 @@ static struct nand_flash_dev *nand_get_f
 		 * Check for wraparound + Samsung ID + nonzero 6th byte
 		 * to decide what to do.
 		 */
+		id_data[6] = 0;		// XXX: force old style for K9F4G08U0B
 		if (id_data[0] == id_data[6] && id_data[1] == id_data[7] &&
 				id_data[0] == NAND_MFR_SAMSUNG &&
 				id_data[5] != 0x00) {
@@ -2965,6 +3232,32 @@ static struct nand_flash_dev *nand_get_f
 	return type;
 }
 
+int nand_lock_and_callback(struct mtd_info *mtd,
+			   int (*callback)(struct mtd_info *, void *),
+			   void *priv)
+{
+	int ret;
+	struct nand_chip *chip = mtd->priv;
+	if (chip == NULL) {
+		/* this is partition - get a master */
+		mtd = *(struct mtd_info **)(mtd + 1);
+		chip = mtd->priv;
+	}
+
+	/* Grab the lock and see if the device is available */
+	nand_get_device(chip, mtd , FL_READING);
+
+	chip->select_chip(mtd, 0);
+
+	ret = (*callback)(mtd, priv);
+
+	chip->select_chip(mtd, -1);
+
+	/* Deselect and wake up anyone waiting on the device */
+	nand_release_device(mtd);
+	return ret;
+}
+
 /**
  * nand_scan_ident - [NAND Interface] Scan for the NAND device
  * @mtd:	     MTD device structure
@@ -3062,6 +3355,7 @@ int nand_scan_tail(struct mtd_info *mtd)
 		default:
 			printk(KERN_WARNING "No oob scheme defined for "
 			       "oobsize %d\n", mtd->oobsize);
+			return -ENODEV;
 			BUG();
 		}
 	}
@@ -3069,6 +3363,15 @@ int nand_scan_tail(struct mtd_info *mtd)
 	if (!chip->write_page)
 		chip->write_page = nand_write_page;
 
+	if (is_nand_mlc(chip)) {
+		if (chip->block_bad == nand_block_bad)
+			chip->block_bad = nand_block_bad_mlc;
+		if (mlc_ecc_allowed)
+			chip->ecc.layout = &nand_oob_64_mlc;
+		else
+			printk("WARNING: mlc nand with slc ecc\n");
+	}
+
 	/*
 	 * check ECC mode, default to software if 3byte/512byte hardware ECC is
 	 * selected and we have 256 byte pagesize fallback to software ECC
@@ -3142,6 +3445,7 @@ int nand_scan_tail(struct mtd_info *mtd)
 		chip->ecc.read_page_raw = nand_read_page_raw;
 		chip->ecc.write_page_raw = nand_write_page_raw;
 		chip->ecc.read_oob = nand_read_oob_std;
+		if (!chip->ecc.write_oob)
 		chip->ecc.write_oob = nand_write_oob_std;
 		if (!chip->ecc.size)
 			chip->ecc.size = 256;
diff -puNrb linux-2.6.35/drivers/mtd/nand/nand_bbt.c linux/drivers/mtd/nand/nand_bbt.c
--- linux-2.6.35/drivers/mtd/nand/nand_bbt.c	2011-04-26 16:27:33.652812104 +0300
+++ linux/drivers/mtd/nand/nand_bbt.c	2011-05-02 10:08:26.412847148 +0300
@@ -346,28 +346,14 @@ static int scan_block_full(struct mtd_in
 static int scan_block_fast(struct mtd_info *mtd, struct nand_bbt_descr *bd,
 			   loff_t offs, uint8_t *buf, int len)
 {
-	struct mtd_oob_ops ops;
+	struct nand_chip *chip = mtd->priv;
 	int j, ret;
 
-	ops.ooblen = mtd->oobsize;
-	ops.oobbuf = buf;
-	ops.ooboffs = 0;
-	ops.datbuf = NULL;
-	ops.mode = MTD_OOB_PLACE;
-
 	for (j = 0; j < len; j++) {
-		/*
-		 * Read the full oob until read_oob is fixed to
-		 * handle single byte reads for 16 bit
-		 * buswidth
-		 */
-		ret = mtd->read_oob(mtd, offs, &ops);
+		ret = chip->block_bad(mtd, offs, 1);
 		if (ret)
 			return ret;
 
-		if (check_short_pattern(buf, bd))
-			return 1;
-
 		offs += mtd->writesize;
 	}
 	return 0;
diff -puNrb linux-2.6.35/drivers/mtd/nand/nand_ecc_mlc.c linux/drivers/mtd/nand/nand_ecc_mlc.c
--- linux-2.6.35/drivers/mtd/nand/nand_ecc_mlc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/nand_ecc_mlc.c	2011-05-02 10:08:26.422843123 +0300
@@ -0,0 +1,361 @@
+#ifndef ECC_TEST_CODE
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mtd/nand_ecc_mlc.h>
+#include <asm/byteorder.h>
+#endif
+
+/*
+ * (C) 2009 MikroTik
+ * This is an implementation of a BCH(4174,4096,13) code.
+ * 
+ * Bits in the following coder are reversed, that is,
+ *   bit 0x01 of byte 0 is the most significant data bit,
+ *   bit 0x80 of byte 517 is the least significant data bit.
+ * prime is the primitive polynomial with bits reversed (and without the
+ *   highest order term, i.e. without x^13):
+ *   bit 0x1 is the 13th bit (most significant, x^12 term)
+ *   bit 0x1000 is the 1st bit (least significant, x^0 term)
+ * (gen3 << 64) | (gen2 << 32) | gen1 is generating polynomial,
+ *   with bits reversed, and multiplied by 2 (that is, the
+ *   original polynomial is divided by 2, then reversed), so that
+ *   it can be xor'ed before shifting the intermediate reminder sum, not after.
+ * inside encode() function (sum3 << 64) | (sum2 << 32) | sum1 is the computed
+ *   reminder (also with bits reversed) of dividing reversed data by the
+ *   reversed g. first (most significant) two bits are always 0, so only
+ *   518 full bytes are divided.
+ * encode(), syndrome() and chien() are optimized for speed on a MIPS system.
+ */
+
+#define PRIME 0x1B00
+#define gen1 0x86499E7E
+#define gen2 0xCE9D8793
+#define gen3 0x00005F46
+#define POLY_SIZE 13
+/* this is the length of error location polynomial and root vector.
+ * it is longer than necessary, but since it does not make coding use
+ * noticably more time or memory, it's better to be safe here.
+ */
+#define LPOLY_SIZE POLY_SIZE + 2
+#define CODE_BITS (522 * 8 - 2)
+#define CODE_BYTES 522
+#define DATA_BITS (512 * 8)
+#define DATA_BYTES 512
+#define CHECK_BYTES 10
+#define UNIT_SHIFT 13
+#define MODULO ((1 << UNIT_SHIFT) - 1)
+#define bch_assert(x) do {;} while (0)
+
+/* Type tpnum_t is used for tabular values from the "mod PRIME(x)" group. */
+typedef short tpnum_t;
+/* Type pnum_t is used for temporary values from the "mod PRIME(x)" group.
+ * smallest number that can hold 13 bit unsigned values is short.
+ * On some architectures, int is faster than short.
+ */
+typedef int pnum_t;
+
+/* pow[x] == a**x; pow[MODULO] = 0 (exponentiation table) */
+static tpnum_t pow[MODULO + 1];
+/* log[x] == i, where a**i == x; log[0] == MODULO (logarithm table) */
+static tpnum_t log[MODULO + 1];
+
+/* Compute reminder from dividing data bytes by generator polynomial and
+ * place it into dst. result is 10 bytes, 78 significant bits.
+ * unrolled for best perfomance on MIPS
+ * assumes d is aligned to two bytes
+ */
+static void encode(const unsigned char *d, unsigned char *dst) {
+    const unsigned *i;
+    unsigned sum1 = 0, sum2 = 0, sum3 = 0;
+
+    for (i = (void *) d; i != (void *) (d + DATA_BYTES); i += 1) {
+	sum1 ^= le32_to_cpu(*i);
+#define SHR(h, l, b) (b) ? (((h) << b) | ((l) >> (32 - b))) : (h)
+#define STEP(b) \
+	if (sum1 & (1 << (b))) { \
+	    sum1 ^= SHR(gen1, 0, b); \
+	    sum2 ^= SHR(gen2, gen1, b); \
+	    sum3 ^= SHR(gen3, gen2, b); \
+	}
+#define SHIFT(N) \
+	sum1 >>= N; \
+	sum1 |= sum2 << (32 - N); \
+	sum2 >>= N; \
+	sum2 |= sum3 << (32 - N); \
+	sum3 >>= N
+#define CHUNK \
+	STEP(0); STEP(1); STEP(2); STEP(3); \
+	STEP(4); STEP(5); STEP(6); STEP(7); \
+	STEP(8); STEP(9); STEP(10); STEP(11); \
+	STEP(12); STEP(13); STEP(14); STEP(15); \
+	SHIFT(16)
+	CHUNK; CHUNK;
+#undef STEP
+#undef SHR
+    }
+#define SAVE(n, i) *(dst++) = (sum##n >> i * 8) & 0xff
+    SAVE(1, 0); SAVE(1, 1); SAVE(1, 2); SAVE(1, 3);
+    SAVE(2, 0); SAVE(2, 1); SAVE(2, 2); SAVE(2, 3);
+    SAVE(3, 0); SAVE(3, 1);
+#undef SAVE
+    bch_assert(!(sum3 & 0xC000));
+}
+
+static void precalc(void) {
+    int i;
+    pnum_t a = 1 << (UNIT_SHIFT - 1);
+
+    memset(pow, 0, sizeof(pow));
+    memset(log, 0, sizeof(log));
+    for (i = 0; i != MODULO; ++i) {
+	bch_assert(!log[a]);
+	bch_assert(a <= MODULO);
+        pow[i] = a;
+        log[a] = i;
+        if (a & 1) a ^= PRIME << 1;
+        a >>= 1;
+    }
+    bch_assert(a == (1 << (UNIT_SHIFT - 1)));
+    log[0] = MODULO;
+}
+
+static void syndrome(unsigned char *d1, unsigned char *d2, tpnum_t *s) {
+    int i;
+
+    s[0] = MODULO;
+    for (i = 1; i != POLY_SIZE; i += 2) {
+        pnum_t syn0 = 0;
+        pnum_t syn1 = 0;
+        pnum_t si0 = (i * CODE_BITS) % MODULO;
+        pnum_t si1 = ((i + 1) * CODE_BITS) % MODULO;
+        unsigned char *i2;
+
+        for (i2 = d1; i2 != d2 + CHECK_BYTES - 1; ++i2) {
+	    unsigned char b;
+
+	    if (i2 == d1 + DATA_BYTES) i2 = d2;
+            b = *i2;
+#define STEP(n) \
+            if (si0 < i) si0 += MODULO; \
+            si0 -= i; \
+            if (si1 <= i) si1 += MODULO; \
+            si1 -= i + 1; \
+            if (b & (1 << (n))) { \
+                syn0 ^= pow[si0]; \
+                syn1 ^= pow[si1]; \
+            }
+
+            STEP(0); STEP(1); STEP(2); STEP(3);
+            STEP(4); STEP(5); STEP(6); STEP(7);
+        }
+        { /* last byte only has 6 significant bits */
+            unsigned char b = *i2;
+
+            STEP(0); STEP(1); STEP(2); STEP(3);
+            STEP(4); STEP(5);
+        }
+#undef STEP
+	bch_assert(!si0);
+	bch_assert(!si1);
+        s[i] = log[syn0];
+        s[i + 1] = log[syn1];
+    }
+}
+
+/* if S_j / S_j+1 == a^-k for all 0<=j<2t-1, then
+ * there is single error at the positon k.
+ * Clark & Cain book, pg 209..210
+ */
+static int fix_single(unsigned char *d, tpnum_t *s) {
+    pnum_t dif = s[1];
+    int i;
+
+    if (dif == MODULO) return 0;
+    /* do not need to check for division by zero inside loop because
+     * MODULE 2^13-1 is prime (i.e. has no factor <= POLY_SIZE)
+     */
+    for (i = 2; i != POLY_SIZE; ++i) {
+        pnum_t t = s[i] - s[i - 1];
+
+        if (t < 0) t += MODULO;
+        if (t != dif) return 0;
+    }
+    if (dif >= CODE_BITS) return 0;
+    dif = CODE_BITS - 1 - dif;
+    if (dif < DATA_BITS) d[dif / 8] ^= 1 << (dif % 8);
+//    printk("MLC single fix (orig %d pos %d)\n",
+//	   (d[dif / 8] >> (dif % 8)) & 1, (int)dif);
+    return 1;
+}
+
+static inline pnum_t logmul(pnum_t x1, pnum_t x2) {
+    bch_assert(x1 <= MODULO);
+    bch_assert(x2 <= MODULO);
+    if (x1 == MODULO || x2 == MODULO) return MODULO; /* multiplication by 0 */
+    x1 += x2;
+    if (x1 >= MODULO) x1 -= MODULO;
+    bch_assert(x1 < MODULO);
+    return x1;
+}
+
+/* Berlekamp Massey
+ * This Implementation follows algorithm as presented in
+ * "Error-correction Coding for Digital Communications"
+ * by George Cyril Clark, J. Bibb Cain, 1981 Plenum Press, New York
+ * page 206.
+ * 
+ * NOTE: this function takes so little time compared to chien() or
+ * syndrome(), that it makes no sense to optimize it for speed.
+ */
+static int bm(tpnum_t *s, tpnum_t *l) {
+    int n, i;
+    int k = -1;
+    int len = 0;
+    pnum_t d;
+    tpnum_t dif[LPOLY_SIZE];
+
+    for (i = 0; i != LPOLY_SIZE; ++i) l[i] = dif[i] = MODULO;
+    l[0] = dif[1] = 0;
+
+    for (n = 0; n < POLY_SIZE - 1; n += 1) {
+	d = 0;
+	for (i = 0; i <= len; ++i) d ^= pow[logmul(s[n - i + 1], l[i])];
+	if (n & 1) bch_assert(!d);
+	if (!d) {
+	    for (i = LPOLY_SIZE - 1; i != 0; --i) dif[i] = dif[i - 1];
+	    dif[0] = MODULO;
+	    continue;
+	}
+	d = log[d];
+	if (len < n - k) {
+	    int len1 = n - k;
+	    k = n - len;
+	    len = len1;
+
+	    for (i = LPOLY_SIZE - 1; i >= 0; --i) {
+		pnum_t t = (i > 0) ? t = l[i - 1] : MODULO;
+		if (d) t = logmul(t, MODULO - d);
+		l[i] = log[pow[l[i]] ^ pow[logmul(d, dif[i])]];
+		dif[i] = t;
+	    }
+	}
+	else {
+	    for (i = LPOLY_SIZE - 1; i >= 0; --i) {
+		l[i] = log[pow[l[i]] ^ pow[logmul(d, dif[i])]];
+		dif[i] = (i > 0) ? dif[i - 1] : MODULO;
+	    }
+	}
+    }
+    return len;
+}
+
+static int chien(tpnum_t *l, tpnum_t *roots) {
+    int i, ret, max, num;
+    tpnum_t poly[LPOLY_SIZE];
+    tpnum_t step[LPOLY_SIZE];
+    pnum_t i2 = 0;
+
+    ret = 0;
+    max = 0;
+    num = 0;
+    for (i = 0; i != LPOLY_SIZE; ++i) {
+        poly[i] = MODULO;
+        step[i] = MODULO;
+        if (l[i] != MODULO) {
+            if (i) {
+                poly[num] = l[i];
+                step[num] = i;
+                ++num;
+            }
+            max = i + 1;
+        }
+    }
+    if (max < 1) return 0;
+    for (i2 = 0; i2 != MODULO; ++i2) {
+        pnum_t val = pow[l[0]];
+        pnum_t x;
+
+#define STEP(n) \
+        x = poly[n]; \
+        val ^= pow[x]; \
+        x += step[n]; \
+        if (x >= MODULO) x -= MODULO; \
+        poly[n] = x; \
+
+        STEP(0); STEP(1); STEP(2);
+
+        for (i = 3; i < num; ++i) {
+            x = poly[i];
+            val ^= pow[x];
+            x += step[i];
+            if (x >= MODULO) x -= MODULO;
+            poly[i] = x;
+        }
+        if (!val) {
+            roots[ret++] = i2;
+            /* break out when all roots are found */
+            if (ret == max - 1) break;
+        }
+    }
+    return ret;
+}
+
+
+int nand_calculate_ecc_mlc(const unsigned char *dat, unsigned char *ecc_code)
+{
+        encode(dat, ecc_code);
+	return 0;
+}
+
+static int ecc_fix_mult(unsigned char *dat, tpnum_t s[POLY_SIZE]) {
+    tpnum_t roots[POLY_SIZE];
+    int rnum;
+    int i;
+    {
+        tpnum_t l[LPOLY_SIZE];
+        int len = bm(s, l);
+
+        rnum = chien(l, roots);
+        if (rnum != len) {
+		printk("MLC failed to fix %d vs %d\n", rnum, len);
+		return -1;
+	}
+    }
+    for (i = 0; i != rnum; ++i) {
+        int pos = roots[i] - (MODULO - CODE_BITS) - 1;
+
+        if (pos < 0) pos += MODULO;
+	bch_assert(pos < CODE_BITS);
+        if (pos >= CODE_BITS) {
+		printk("MLC failed to fix %d/%d pos %d\n", i, rnum, pos);
+		return -1;
+	}
+	if (pos < DATA_BITS) {
+		dat[pos / 8] ^= 1 << (pos % 8);
+//		printk("MLC mult fix (orig %d pos %d)\n",
+//		       (dat[pos / 8] >> (pos % 8)) & 1, pos);
+	}
+    }
+//    printk("MLC fixed %d\n", rnum);
+    return rnum;
+}
+
+static int ecc_fix(unsigned char *dat, unsigned char *read_ecc) {
+    tpnum_t s[POLY_SIZE];
+    syndrome(dat, read_ecc, s);
+    if (fix_single(dat, s)) {
+	    return 1;
+    }
+    return ecc_fix_mult(dat, s);
+}
+
+int nand_correct_data_mlc(unsigned char *dat, unsigned char *read_ecc)
+{
+    unsigned char calc_ecc[CHECK_BYTES];
+    encode(dat, calc_ecc);
+    read_ecc[9] &= 0x3F;
+    if (!memcmp(read_ecc, calc_ecc, CHECK_BYTES)) return 0;
+    if (!*pow) precalc();
+    return ecc_fix(dat, read_ecc);
+}
diff -puNrb linux-2.6.35/drivers/mtd/nand/nand_ids.c linux/drivers/mtd/nand/nand_ids.c
--- linux-2.6.35/drivers/mtd/nand/nand_ids.c	2011-04-26 16:27:33.652812104 +0300
+++ linux/drivers/mtd/nand/nand_ids.c	2011-05-02 10:08:26.442848304 +0300
@@ -109,7 +109,7 @@ struct nand_flash_dev nand_flash_ids[] =
 	{"NAND 2GiB 3,3V 8-bit",	0xD5, 0, 2048, 0, LP_OPTIONS},
 	{"NAND 2GiB 1,8V 16-bit",	0xB5, 0, 2048, 0, LP_OPTIONS16},
 	{"NAND 2GiB 3,3V 16-bit",	0xC5, 0, 2048, 0, LP_OPTIONS16},
-
+#if 0
 	/*
 	 * Renesas AND 1 Gigabit. Those chips do not support extended id and
 	 * have a strange page/block layout !  The chosen minimum erasesize is
@@ -124,7 +124,7 @@ struct nand_flash_dev nand_flash_ids[] =
 	 NAND_IS_AND | NAND_NO_AUTOINCR |NAND_NO_READRDY | NAND_4PAGE_ARRAY |
 	 BBT_AUTO_REFRESH
 	},
-
+#endif
 	{NULL,}
 };
 
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb400_nand.c linux/drivers/mtd/nand/rb400_nand.c
--- linux-2.6.35/drivers/mtd/nand/rb400_nand.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb400_nand.c	2011-05-02 10:08:26.452850105 +0300
@@ -0,0 +1,207 @@
+#include <linux/init.h>
+#include <linux/mtd/nand.h>
+#include <linux/platform_device.h>
+#include <linux/spi/spi.h>
+#include <asm/rb/rb400.h>
+
+extern int rb_nand_probe(struct nand_chip *nand, int booter);
+
+static struct nand_chip rnand;
+
+static struct spi_device *spi = 0;
+
+#define GPIO_BASE	0x18040000
+#define GPIO_OE_REG	    0x0000
+#define GPIO_IN_REG	    0x0004
+#define GPIO_O1_REG	    0x0008
+#define GPIO_S1_REG	    0x000c
+#define GPIO_S0_REG	    0x0010
+#define GPIO_FN_REG	    0x0028
+
+#define GPIO_REG(x)	(*(volatile unsigned *)((unsigned) gpio_base + (x)))
+
+static void __iomem *gpio_base;
+
+/* ------------------ RB400 SPI nand driver -------------------- */
+
+#define   GPI_NAND_RDY		(1 << 5)
+
+static int rb400_dev_ready(struct mtd_info *mtd) {
+	return GPIO_REG(GPIO_IN_REG) & GPI_NAND_RDY;
+}
+
+static void rb400_nandio_write(const uint8_t *data, unsigned cnt) {
+	static const uint8_t cmd = SPI_CMD_WRITE_NAND;
+	struct spi_transfer t[3] = {
+		{
+			.tx_buf = &cmd,
+			.len = 1,
+		},
+		{
+			.tx_buf = data,
+			.len = cnt,
+			.fast_write = 1,
+		},
+		{
+			.len = 1,
+			.fast_write = 1,
+		},
+	};
+	struct spi_message m;
+
+	spi_message_init(&m);
+	spi_message_add_tail(&t[0], &m);
+	spi_message_add_tail(&t[1], &m);
+	spi_message_add_tail(&t[2], &m);
+	spi_sync(spi, &m);
+}
+
+static int rb400_nandio_read_verify_slow(uint8_t *rdata, const uint8_t *vdata,
+					 unsigned cnt) {
+	static const uint8_t cmd[2] = { SPI_CMD_READ_NAND, 0 };
+	struct spi_transfer t[2] = {
+		{
+			.tx_buf = &cmd,
+			.len = 2,
+		},
+		{
+			.tx_buf = vdata,
+			.rx_buf = rdata,
+			.len = cnt,
+			.verify = (vdata != NULL),
+		},
+	};
+	struct spi_message m;
+
+	spi_message_init(&m);
+	spi_message_add_tail(&t[0], &m);
+	spi_message_add_tail(&t[1], &m);
+	return spi_sync(spi, &m);
+}
+
+static int rb400_nandio_read_verify(uint8_t *rdata, const uint8_t *vdata,
+				    unsigned cnt) {
+	unsigned size32 = cnt & ~31;
+	if (size32) {
+		unsigned addr = SPI_READ_NAND_OFS;
+		if (rb400_spiflash_read_verify(addr, rdata, vdata, size32)) {
+			return -1;
+		}
+		cnt -= size32;
+		if (cnt == 0) return 0;
+		if (rdata) rdata += size32;
+		if (vdata) vdata += size32;
+	}
+	return rb400_nandio_read_verify_slow(rdata, vdata, cnt);
+}
+
+static void rb400_hwcontrol(struct mtd_info *mtd, int cmd,
+			    unsigned int ctrl) {
+	static uint8_t data[8];
+	static unsigned dlen = 0;
+
+	if (ctrl & NAND_CTRL_CHANGE) {
+		uint8_t cfg = 0;
+
+		if (ctrl & NAND_CLE) {
+			cfg |= CFG_BIT_CLE;
+		}
+		if (ctrl & NAND_ALE) {
+			cfg |= CFG_BIT_ALE;
+		}
+		if (!(ctrl & NAND_NCE)) {
+			cfg |= CFG_BIT_nCE;
+		}
+		if (dlen) {
+			rb400_nandio_write(data, dlen);
+			dlen = 0;
+		}
+		rb400_change_cfg(CFG_BIT_nCE | CFG_BIT_CLE | CFG_BIT_ALE,
+				 cfg);
+	}
+
+	if (cmd != NAND_CMD_NONE) {
+		data[dlen] = cmd;
+		++dlen;
+		if (dlen == sizeof(data)) {
+			rb400_nandio_write(data, dlen);
+			dlen = 0;
+		}
+	}
+}
+
+static uint8_t rb400_read_byte(struct mtd_info *mtd)
+{
+	uint8_t byte = 0;
+	rb400_nandio_read_verify(&byte, NULL, 1);
+	return byte;
+}
+
+static void rb400_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	rb400_nandio_write(buf, len);
+}
+
+static void rb400_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	rb400_nandio_read_verify(buf, NULL, len);
+}
+
+static int rb400_verify_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	if (rb400_nandio_read_verify(NULL, buf, len))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int rb400_spi_nand_probe(struct spi_device *_spi)
+{
+	printk("RB400 spi nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+
+	if (!gpio_base) {
+		gpio_base = ioremap_nocache(GPIO_BASE, PAGE_SIZE);
+		if (!gpio_base)
+			return -ENOMEM;
+	}
+
+	GPIO_REG(GPIO_OE_REG) &= ~GPI_NAND_RDY;
+
+	spi = _spi;
+
+	rnand.cmd_ctrl = rb400_hwcontrol;
+	rnand.dev_ready = rb400_dev_ready;
+	rnand.read_byte = rb400_read_byte;
+	rnand.write_buf = rb400_write_buf;
+	rnand.read_buf = rb400_read_buf;
+	rnand.verify_buf = rb400_verify_buf;
+
+	return rb_nand_probe(&rnand, 1);
+}
+
+static struct spi_driver rb400_spi_nand_driver = {
+	.probe	= rb400_spi_nand_probe,
+	.driver	= {
+		.name = "rb400-spi-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+/* ------------------ common init/exit code -------------------- */
+
+static int __init rb400_nand_init(void)
+{
+	return spi_register_driver(&rb400_spi_nand_driver);
+}
+
+static void __exit rb400_nand_exit(void)
+{
+	if (gpio_base)
+		iounmap(gpio_base);
+
+	spi_unregister_driver(&rb400_spi_nand_driver);
+}
+
+module_init(rb400_nand_init);
+module_exit(rb400_nand_exit);
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb500nand.c linux/drivers/mtd/nand/rb500nand.c
--- linux-2.6.35/drivers/mtd/nand/rb500nand.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb500nand.c	2011-05-02 10:08:26.462849174 +0300
@@ -0,0 +1,299 @@
+#include <linux/init.h>
+#include <linux/mtd/nand.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/rb/rb100.h>
+#include <asm/rb/rb500.h>
+#include <asm/rb/cr.h>
+#include <asm/rb/boards.h>
+#include <asm/bootinfo.h>
+
+#define IDT434_REG_BASE ((volatile void *) KSEG1ADDR(0x18000000))
+
+#define RB500_GPIOD 0x050008
+#define RB500_DEV2BASE 0x010020
+
+#define ADMTEK_NAND_BASE ((volatile void *) KSEG1ADDR(0x10000000))
+#define MR_NAND_BASE ((volatile void *) KSEG1ADDR(0x1FC00000))
+
+#define ADMTEK_NAND_SET_CEn	0x1	//CE# low
+#define ADMTEK_NAND_CLR_CEn	0x2	//CE# high
+#define ADMTEK_NAND_CLR_CLE	0x3	//CLE low
+#define ADMTEK_NAND_SET_CLE	0x4	//CLE high
+#define ADMTEK_NAND_CLR_ALE	0x5	//ALE low
+#define ADMTEK_NAND_SET_ALE	0x6	//ALE high
+#define ADMTEK_NAND_SET_SPn	0x7	//SP# low (use spare area)
+#define ADMTEK_NAND_CLR_WPn	0xA	//WP# high
+#define ADMTEK_NAND_STS_REG	0xB	//Status register
+
+#define MEM32(x) *((volatile unsigned *) (x))
+#define MEM8(x) *((volatile unsigned char *) (x))
+
+static int rb500_dev_ready(struct mtd_info *mtd) {
+    return MEM32(IDT434_REG_BASE + RB500_GPIOD) & RB500_GPIO_NANDRDY;
+}
+static int rb100_dev_ready(struct mtd_info *mtd) {
+    return MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_STS_REG) & 0x80; /* found out by experiment */
+}
+static int mr_dev_ready(struct mtd_info *mtd) {
+    return RB100_GPIO() & RB100_GPIN(MR_GPIO_NAND_RDY);
+}
+static int cr_dev_ready(struct mtd_info *mtd) {
+    return CR_GPIN() & CR_GPIO_NANDRDY;
+}
+
+static void rbmips_hwcontrol500(struct mtd_info *mtd, int cmd, unsigned int ctrl) {
+    struct nand_chip *chip = mtd->priv;
+
+    if (ctrl & NAND_CTRL_CHANGE) {
+	unsigned sbits = 0;
+	unsigned cbits = RB500_LO_CLE | RB500_LO_ALE;
+
+	if (ctrl & NAND_CLE) {
+	    sbits |= RB500_LO_CLE;
+	    cbits &= ~RB500_LO_CLE;
+	}
+	if (ctrl & NAND_ALE) {
+	    sbits |= RB500_LO_ALE;
+	    cbits &= ~RB500_LO_ALE;
+	}
+	changeLatchU5(sbits, cbits);
+    }
+
+    if (cmd != NAND_CMD_NONE) writeb(cmd, chip->IO_ADDR_W);
+}
+
+static void rbmips_hwcontrol500r5(struct mtd_info *mtd, int cmd, unsigned int ctrl)
+{
+    struct nand_chip *chip = mtd->priv;
+
+    if (ctrl & NAND_CTRL_CHANGE) {
+	unsigned sbits = 0;
+	unsigned cbits = RB500_LO_CLE | RB500_LO_ALE | RB500_LO_NCE;
+
+	if (ctrl & NAND_CLE) {
+	    sbits |= RB500_LO_CLE;
+	    cbits &= ~RB500_LO_CLE;
+	}
+	if (ctrl & NAND_ALE) {
+	    sbits |= RB500_LO_ALE;
+	    cbits &= ~RB500_LO_ALE;
+	}
+	if (!(ctrl & NAND_NCE)) {
+	    sbits |= RB500_LO_NCE;
+	    cbits &= ~RB500_LO_NCE;
+	}
+	changeLatchU5(sbits, cbits);
+    }
+
+    if (cmd != NAND_CMD_NONE) writeb(cmd, chip->IO_ADDR_W);
+}
+
+static void rbmips_hwcontrol100(struct mtd_info *mtd, int cmd, unsigned int ctrl) {
+    struct nand_chip *chip = mtd->priv;
+
+    if (ctrl & NAND_CTRL_CHANGE) {
+	if (ctrl & NAND_CLE) {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_SET_CLE) = 0x01; 
+	} else {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_CLR_CLE) = 0x01; 
+	}
+	if (ctrl & NAND_ALE) {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_SET_ALE) = 0x01; 
+	} else {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_CLR_ALE) = 0x01; 
+	}
+	if (ctrl & NAND_NCE) {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_SET_CEn) = 0x01; 
+	} else {
+	    MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_CLR_CEn) = 0x01; 
+	}
+    }
+
+    if (cmd != NAND_CMD_NONE) writeb(cmd, chip->IO_ADDR_W);
+}
+
+static void rbmips_hwcontrol_mr(struct mtd_info *mtd, int cmd, unsigned int ctrl) {
+    struct nand_chip *chip = mtd->priv;
+
+    if (ctrl & NAND_CTRL_CHANGE) {
+	rb100_set_port_led2(MR_PORT_NAND_CLE, ctrl & NAND_CLE);
+	rb100_set_port_led2(MR_PORT_NAND_ALE, ctrl & NAND_ALE);
+
+	if (ctrl & NAND_NCE) {
+	    RB100_GPIO() &= ~RB100_GPOUT(MR_GPIO_NAND_NCE);
+	} else {
+	    RB100_GPIO() |= RB100_GPOUT(MR_GPIO_NAND_NCE);
+	}
+	RB100_GPIO();	// flush write
+    }
+
+    if (cmd != NAND_CMD_NONE) writeb(cmd, chip->IO_ADDR_W);
+}
+
+static void rbmips_hwcontrol_cr(struct mtd_info *mtd, int cmd, unsigned int ctrl) {
+    struct nand_chip *nc = mtd->priv;
+
+    if (ctrl & NAND_CTRL_CHANGE) {
+	unsigned long addr = KSEG1ADDR(CR_LB_BASE + CR_LB_PIO);
+
+	if (ctrl & NAND_CLE) {
+	    addr |= CR_LB_ADDR_CLE;
+	}
+	if (ctrl & NAND_ALE) {
+	    addr |= CR_LB_ADDR_ALE;
+	}
+
+	if (ctrl & NAND_NCE) {
+	    CR_GPOUT() &= ~CR_GPIO_NCE;
+	} else {
+	    CR_GPOUT() |= CR_GPIO_NCE;
+	}
+
+	nc->IO_ADDR_R = (void *)addr;
+	nc->IO_ADDR_W = (void *)addr;
+    }
+
+    if (cmd != NAND_CMD_NONE) writeb(cmd, nc->IO_ADDR_W);
+}
+
+static struct nand_chip rnand;
+
+extern int rb_nand_probe(struct nand_chip *nand, int booter);
+
+static int rb500_nand_probe(struct platform_device *pdev)
+{
+	printk("RB500 nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+	changeLatchU5(RB500_LO_WPX, RB500_LO_ALE | RB500_LO_CLE);
+	rnand.cmd_ctrl = rbmips_hwcontrol500;
+    
+	rnand.dev_ready = rb500_dev_ready;
+	rnand.IO_ADDR_W = (unsigned char *)
+	    KSEG1ADDR(MEM32(IDT434_REG_BASE + RB500_DEV2BASE));
+	rnand.IO_ADDR_R = rnand.IO_ADDR_W;
+
+	return rb_nand_probe(&rnand, 0);
+}
+
+static struct platform_driver rb500_nand_driver = {
+	.probe	= rb500_nand_probe,
+	.driver	= {
+		.name = "rb500-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int rb500r5_nand_probe(struct platform_device *pdev)
+{
+	printk("RB500r5 nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+	changeLatchU5(RB500_LO_NCE, RB500_LO_ALE | RB500_LO_CLE);
+	rnand.cmd_ctrl = rbmips_hwcontrol500r5;
+    
+	rnand.dev_ready = rb500_dev_ready;
+	rnand.IO_ADDR_W = (unsigned char *)
+	    KSEG1ADDR(MEM32(IDT434_REG_BASE + RB500_DEV2BASE));
+	rnand.IO_ADDR_R = rnand.IO_ADDR_W;
+
+	return rb_nand_probe(&rnand, 0);
+}
+
+static struct platform_driver rb500r5_nand_driver = {
+	.probe	= rb500r5_nand_probe,
+	.driver	= {
+		.name = "rb500r5-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int rb100_nand_probe(struct platform_device *pdev)
+{
+	printk("RB100 nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+	/* enable NAND flash */
+	MEM32(0xB2000064) = 0x100;
+	/* boot done */
+	MEM32(0xB2000008) = 0x1;
+	MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_SET_SPn) = 0x01; 
+	MEM8(ADMTEK_NAND_BASE + ADMTEK_NAND_CLR_WPn) = 0x01; 
+	rnand.IO_ADDR_R = (unsigned char *) KSEG1ADDR(ADMTEK_NAND_BASE);
+	rnand.IO_ADDR_W = rnand.IO_ADDR_R;
+	rnand.cmd_ctrl = rbmips_hwcontrol100;
+	rnand.dev_ready = rb100_dev_ready;
+
+	return rb_nand_probe(&rnand, 0);
+}
+
+static struct platform_driver rb100_nand_driver = {
+	.probe	= rb100_nand_probe,
+	.driver	= {
+		.name = "rb100-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int cr_nand_probe(struct platform_device *pdev)
+{
+	printk("Crossroads nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+	rnand.IO_ADDR_R = (void *)KSEG1ADDR(CR_LB_BASE + CR_LB_PIO);
+	rnand.IO_ADDR_W = rnand.IO_ADDR_R;
+	rnand.cmd_ctrl = rbmips_hwcontrol_cr;
+	rnand.dev_ready = cr_dev_ready;
+
+	return rb_nand_probe(&rnand, 0);
+}
+
+static struct platform_driver cr_nand_driver = {
+	.probe	= cr_nand_probe,
+	.driver	= {
+		.name = "cr-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int mr_nand_probe(struct platform_device *pdev)
+{
+	printk("miniROUTER nand\n");
+	memset(&rnand, 0, sizeof(rnand));
+	
+	rnand.IO_ADDR_R = (unsigned char *) KSEG1ADDR(MR_NAND_BASE + (1u << 19));
+	rnand.IO_ADDR_W = rnand.IO_ADDR_R;
+	rnand.cmd_ctrl = rbmips_hwcontrol_mr;
+	rnand.dev_ready = mr_dev_ready;
+
+	return rb_nand_probe(&rnand, 0);
+}
+
+static struct platform_driver mr_nand_driver = {
+	.probe	= mr_nand_probe,
+	.driver	= {
+		.name = "mr-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init rbmips_init(void)
+{
+	platform_driver_register(&rb500_nand_driver);
+	platform_driver_register(&rb500r5_nand_driver);
+	platform_driver_register(&rb100_nand_driver);
+	platform_driver_register(&cr_nand_driver);
+	platform_driver_register(&mr_nand_driver);
+
+	return 0;
+}
+
+static void __exit rbmips_exit(void)
+{
+	platform_driver_unregister(&rb500_nand_driver);
+	platform_driver_unregister(&rb500r5_nand_driver);
+	platform_driver_unregister(&rb100_nand_driver);
+	platform_driver_unregister(&cr_nand_driver);
+	platform_driver_unregister(&mr_nand_driver);
+}
+							     
+module_init(rbmips_init);
+module_exit(rbmips_exit);
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb700_nand.c linux/drivers/mtd/nand/rb700_nand.c
--- linux-2.6.35/drivers/mtd/nand/rb700_nand.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb700_nand.c	2011-05-02 10:08:26.472852109 +0300
@@ -0,0 +1,404 @@
+#include <linux/init.h>
+#include <linux/mtd/nand.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb400.h>
+
+extern int rb_nand_probe(struct nand_chip *nand, int booter);
+
+static struct nand_chip rnand;
+
+#define GPIO_BASE	0x18040000
+#define GPIO_OE_REG	    0x0000
+#define GPIO_IN_REG	    0x0004
+#define GPIO_O1_REG	    0x0008
+#define GPIO_S1_REG	    0x000c
+#define GPIO_S0_REG	    0x0010
+#define GPIO_FN_REG	    0x0028
+
+#define GPIO_REG(x)	(*(volatile unsigned *)((unsigned) gpio_base + (x)))
+
+static void __iomem *gpio_base;
+static int no_latch = 0;
+static int has_tiny = 0;
+static void nolatch_select_chip(struct mtd_info *mtd, int chipnr);
+
+/* ------------------ RB700 nand driver -------------------- */
+
+#define NAND_tDS	20
+#define NAND_tDH	10
+#define NAND_tWP	25
+#define NAND_tWH	15
+
+#define NAND_tREA	30
+#define NAND_tRP	25
+#define NAND_tREH	15
+
+#define   GPO_RB700_NAND_nCE	(1 << 11)
+#define   GPI_RB700_NAND_RDY	(1 << 12)
+#define   GPO_RB700_NAND_CLE	(1 << 14)
+#define   GPO_RB700_NAND_ALE	(1 << 15)
+#define   GPO_RB700_NAND_nRE	(1 << 16)
+#define   GPO_RB700_NAND_nWE	(1 << 17)
+
+#define   GPO_NAND_DATA(x) ((x) << 1)
+#define   GPI_NAND_DATA(x) ((x) >> 1)
+
+#define GPFN_RB700_JTAG_DISABLE	(1 << 0)
+#define GPFN_RB700_UART_EN	((1 << 1) | (1 << 15))
+#define GPFN_RB700_ETH_LEDS_EN	(0x1f << 3)
+#define GPFN_RB700_SPI_EN	(1 << 18)
+#define GPFN_RB700_SPI_CS2_EN	(1 << 14)
+
+#define GPO_BEEPLED_MISSING	(1 << 30)
+static unsigned gpo_beepled = GPO_BEEPLED_MISSING;
+
+void rb700_beepled(int on) {
+	if (gpo_beepled == GPO_BEEPLED_MISSING) return;
+	if (on) {
+		gpo_beepled = (GPO_RB700_nULED |
+			       GPO_RB700_nLINK0 |
+			       GPO_RB700_nLINK1 |
+			       GPO_RB700_nLINK2 |
+			       GPO_RB700_nLINK3 |
+			       GPO_RB700_nLINK4);
+	}
+	else {
+		gpo_beepled = 0;
+	}
+	rb700_change_gpo(0, 0);
+}
+EXPORT_SYMBOL(rb700_beepled);
+
+int rb700_change_gpo(unsigned _off, unsigned _on) {
+	static unsigned on = (GPO_RB700_LATCH_EN |
+			      GPO_RB700_nULED |
+			      GPO_RB700_nLINK0 |
+			      GPO_RB700_nLINK1 |
+			      GPO_RB700_nLINK2 |
+			      GPO_RB700_nLINK3 |
+			      GPO_RB700_nLINK4);
+	static unsigned off = 0;
+	static unsigned oe = 0;
+	static DEFINE_SPINLOCK(lock);
+	unsigned long flags;
+
+	spin_lock_irqsave(&lock, flags);
+
+	on = (on | _on) & ~_off;
+	off = (off | _off) & ~_on;
+	if (!oe) oe = GPIO_REG(GPIO_OE_REG);
+
+	if (no_latch) {
+		if ((on ^ gpo_beepled) & GPO_RB700_nULED) {
+			GPIO_REG(GPIO_OE_REG) &= ~GPO_RB700_NOLATCH_nULED;
+		}
+		else {
+			GPIO_REG(GPIO_OE_REG) |= GPO_RB700_NOLATCH_nULED;
+			GPIO_REG(GPIO_S0_REG) = GPO_RB700_NOLATCH_nULED;
+		}
+		GPIO_REG(GPIO_S1_REG) = on & (GPO_RB700_MON_SEL |
+					      GPO_RB700_USB_nPWROFF);
+		GPIO_REG(GPIO_S0_REG) = off & (GPO_RB700_MON_SEL |
+					       GPO_RB700_USB_nPWROFF);
+	}
+	else if (on & GPO_RB700_LATCH_EN) {
+		GPIO_REG(GPIO_OE_REG) |= oe | _on | _off;
+		GPIO_REG(GPIO_S0_REG) = off ^ gpo_beepled;
+		GPIO_REG(GPIO_S1_REG) = on ^ gpo_beepled;
+	}
+	else if (_off & GPO_RB700_LATCH_EN) {
+		oe = GPIO_REG(GPIO_OE_REG);
+		GPIO_REG(GPIO_S0_REG) = GPO_RB700_LATCH_EN;
+		GPIO_REG(GPIO_S0_REG);			/* flush */
+	}
+
+	spin_unlock_irqrestore(&lock, flags);
+	return 1;
+}
+EXPORT_SYMBOL(rb700_change_gpo);
+
+static void rb700_gpio_init(void) {
+	int o1 = GPIO_REG(GPIO_O1_REG);
+	GPIO_REG(GPIO_S1_REG) = (GPO_RB700_NAND_nCE |
+				 GPO_RB700_NAND_nWE |
+				 GPO_RB700_NAND_nRE);
+	GPIO_REG(GPIO_S0_REG) = (GPO_RB700_NAND_CLE |
+				 GPO_RB700_NAND_ALE);
+
+	GPIO_REG(GPIO_OE_REG) &= ~(GPI_RB700_NAND_RDY |
+				   GPO_NAND_DATA(0xff));
+	GPIO_REG(GPIO_OE_REG) |= (GPO_RB700_NAND_CLE |
+				  GPO_RB700_NAND_ALE |
+				  GPO_RB700_NAND_nCE |
+				  GPO_RB700_NAND_nWE |
+				  GPO_RB700_NAND_nRE);
+	/* keep power led the same as it came from BIOS */
+	rb700_change_gpo((~o1) & GPO_RB700_nPLED,
+			 o1 & GPO_RB700_nPLED);
+}
+
+static int rb700_dev_ready(struct mtd_info *mtd) {
+	return GPIO_REG(GPIO_IN_REG) & GPI_RB700_NAND_RDY;
+}
+
+static void rb700_write_bytes_gpio(const uint8_t *data, unsigned cnt) {
+	int i;
+	unsigned gpo;
+
+	GPIO_REG(GPIO_OE_REG) |= GPO_NAND_DATA(0xff);
+	gpo = GPIO_REG(GPIO_O1_REG) & ~(GPO_RB700_NAND_nWE |
+					GPO_NAND_DATA(0xff));
+	/* XXX: any GPIO output val change in parallel (for led) may get lost */
+
+	for (i = 0; i < cnt; ++i) {
+		unsigned val = data[i];
+		unsigned gpov = gpo | GPO_NAND_DATA(val);
+
+		GPIO_REG(GPIO_O1_REG) = gpov;
+		GPIO_REG(GPIO_O1_REG);
+//		ndelay(max(NAND_tDS, NAND_tWP));
+
+		GPIO_REG(GPIO_O1_REG) = gpov | GPO_RB700_NAND_nWE;
+		GPIO_REG(GPIO_O1_REG);
+//		ndelay(max(NAND_tDH, NAND_tWH));
+	}
+
+	GPIO_REG(GPIO_OE_REG) &= ~GPO_NAND_DATA(0xff);
+	GPIO_REG(GPIO_OE_REG);
+}
+
+static int rb700_read_bytes_gpio(uint8_t *data, unsigned cnt,
+				  const uint8_t *verify) {
+	int i;
+	for (i = 0; i < cnt; ++i) {
+		uint8_t val;
+
+		GPIO_REG(GPIO_S0_REG) = GPO_RB700_NAND_nRE;
+		GPIO_REG(GPIO_S0_REG);
+//		ndelay(NAND_tREA);
+
+		val = GPI_NAND_DATA(GPIO_REG(GPIO_IN_REG));
+
+//		if (NAND_tRP > NAND_tREA) ndelay(NAND_tRP - NAND_tREA);
+		GPIO_REG(GPIO_S1_REG) = GPO_RB700_NAND_nRE;
+//		GPIO_REG(GPIO_S1_REG);	/* XXX: works without this */
+//		ndelay(NAND_tREH);
+
+		if (data) {
+			data[i] = val;
+		}
+		else if (verify) {
+			if (verify[i] != val) return -EFAULT;
+		}
+	}
+	return 0;
+}
+
+static void rb700_select_chip(struct mtd_info *mtd, int chipnr)
+{
+	unsigned fn = GPIO_REG(GPIO_FN_REG);
+	if (chipnr >= 0) {
+		/* enable NAND functionality */
+		rb700_change_gpo(GPO_RB700_LATCH_EN, 0);
+		fn |= GPFN_RB700_JTAG_DISABLE;
+		fn &= ~(GPFN_RB700_ETH_LEDS_EN |
+			GPFN_RB700_SPI_EN |
+			GPFN_RB700_SPI_CS2_EN);
+		GPIO_REG(GPIO_FN_REG) = fn;
+		GPIO_REG(GPIO_FN_REG);
+		GPIO_REG(GPIO_OE_REG) &= ~(GPI_RB700_NAND_RDY |
+					   GPO_NAND_DATA(0xff));
+		GPIO_REG(GPIO_S1_REG) = GPO_RB700_NAND_nRE | GPO_RB700_NAND_nWE;
+		GPIO_REG(GPIO_S1_REG);
+
+		/* nCE -> low */
+		GPIO_REG(GPIO_S0_REG) = GPO_RB700_NAND_nCE;
+	}
+	else {
+		/* nCE -> high */
+		GPIO_REG(GPIO_S1_REG) = GPO_RB700_NAND_nCE;
+		GPIO_REG(GPIO_S1_REG);
+
+		/* disable NAND functionality */
+		GPIO_REG(GPIO_OE_REG) |= (GPO_RB700_nULED | GPO_RB700_nPLED);
+		fn &= ~GPFN_RB700_JTAG_DISABLE;
+		fn |= GPFN_RB700_SPI_EN;
+		if (has_tiny) fn |= GPFN_RB700_SPI_CS2_EN;
+		GPIO_REG(GPIO_FN_REG) = fn;
+		GPIO_REG(GPIO_FN_REG);
+		rb700_change_gpo(0, GPO_RB700_LATCH_EN);
+	}
+}
+
+static void rb700_hwcontrol(struct mtd_info *mtd, int cmd,
+			     unsigned int ctrl) {
+	if (ctrl & NAND_CTRL_CHANGE) {
+		unsigned gpo = GPIO_REG(GPIO_O1_REG);
+		gpo &= ~(GPO_RB700_NAND_ALE |
+			 GPO_RB700_NAND_CLE);
+
+		if (ctrl & NAND_CLE) {
+			gpo |= GPO_RB700_NAND_CLE;
+		}
+		if (ctrl & NAND_ALE) {
+			gpo |= GPO_RB700_NAND_ALE;
+		}
+		GPIO_REG(GPIO_O1_REG) = gpo;
+		GPIO_REG(GPIO_O1_REG);		/* flush */
+	}
+
+	if (cmd != NAND_CMD_NONE) {
+		uint8_t data = cmd;
+		rb700_write_bytes_gpio(&data, 1);
+	}
+}
+
+static uint8_t rb700_read_byte(struct mtd_info *mtd)
+{
+	uint8_t data;
+	rb700_read_bytes_gpio(&data, 1, NULL);
+	return data;
+}
+
+static void rb700_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	rb700_write_bytes_gpio(buf, len);
+}
+
+static void rb700_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	rb700_read_bytes_gpio(buf, len, NULL);
+}
+
+static int rb700_verify_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	return rb700_read_bytes_gpio(NULL, len, buf);
+}
+
+#ifdef DEBUG_SPEED
+static void rb700_test_speed(void) {
+	char buf[1024];
+	unsigned long ticks;
+	unsigned kb;
+
+	rb700_select_chip(NULL, 0);
+	GPIO_REG(GPIO_S1_REG) = GPO_RB700_NAND_nCE;
+	GPIO_REG(GPIO_S1_REG);
+
+	/* wait for "start of" clock tick */
+	kb = 0;
+	ticks = jiffies;
+	while (ticks == jiffies)
+		/* nothing */;
+	ticks = jiffies + HZ / 10;
+
+	while ((long)(jiffies - ticks) < 0) {
+		rb700_read_bytes_gpio(buf, 1024, NULL);
+		++kb;
+	}
+	printk("read speed is %u KB/s\n", kb * 10);
+
+	/* wait for "start of" clock tick */
+	kb = 0;
+	ticks = jiffies;
+	while (ticks == jiffies)
+		/* nothing */;
+	ticks = jiffies + HZ / 10;
+
+	while ((long)(jiffies - ticks) < 0) {
+		rb700_write_bytes_gpio(buf, 1024);
+		++kb;
+	}
+	printk("write speed is %u KB/s\n", kb * 10);
+	rb700_select_chip(NULL, -1);
+}
+#endif
+
+static int rb700_nand_probe(struct platform_device *pdev)
+{
+	unsigned long options = (unsigned long)pdev->dev.platform_data;
+	printk("RB700 nand %lu\n", options);
+	no_latch = options & 1;
+	has_tiny = options & 2;
+	gpo_beepled = 0;
+	rb700_gpio_init();
+#ifdef DEBUG_SPEED
+	rb700_test_speed();
+#endif
+	memset(&rnand, 0, sizeof(rnand));
+
+	rnand.select_chip = no_latch ? nolatch_select_chip : rb700_select_chip;
+	rnand.cmd_ctrl = rb700_hwcontrol;
+	rnand.dev_ready = rb700_dev_ready;
+	rnand.read_byte = rb700_read_byte;
+	rnand.write_buf = rb700_write_buf;
+	rnand.read_buf = rb700_read_buf;
+	rnand.verify_buf = rb700_verify_buf;
+
+	return rb_nand_probe(&rnand, 1);
+}
+
+static struct platform_driver rb700_nand_driver = {
+	.probe	= rb700_nand_probe,
+	.driver	= {
+		.name = "rb700-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+/* ---------------- support for RB700 nand without latch ------------------ */
+
+#define   GPO_NOLATCH_NAND_nCE	(1 << 0)
+
+static void nolatch_select_chip(struct mtd_info *mtd, int chipnr)
+{
+	unsigned fn = GPIO_REG(GPIO_FN_REG);
+	if (chipnr >= 0) {
+		/* enable NAND functionality */
+		fn |= GPFN_RB700_JTAG_DISABLE;
+		fn &= ~(GPFN_RB700_ETH_LEDS_EN |
+			GPFN_RB700_SPI_EN |
+			GPFN_RB700_SPI_CS2_EN);
+		GPIO_REG(GPIO_FN_REG) = fn;
+		GPIO_REG(GPIO_FN_REG);
+		GPIO_REG(GPIO_OE_REG) &= ~(GPI_RB700_NAND_RDY |
+					   GPO_NAND_DATA(0xff));
+		GPIO_REG(GPIO_S1_REG) = GPO_RB700_NAND_nRE | GPO_RB700_NAND_nWE;
+		GPIO_REG(GPIO_S1_REG);
+
+		/* nCE -> low */
+		GPIO_REG(GPIO_S0_REG) = GPO_NOLATCH_NAND_nCE;
+	}
+	else {
+		/* nCE -> high */
+		GPIO_REG(GPIO_S1_REG) = GPO_NOLATCH_NAND_nCE;
+		GPIO_REG(GPIO_S1_REG);
+
+		/* disable NAND functionality */
+		fn &= ~GPFN_RB700_JTAG_DISABLE;
+		fn |= GPFN_RB700_SPI_EN | GPFN_RB700_SPI_CS2_EN;
+		GPIO_REG(GPIO_FN_REG) = fn;
+		GPIO_REG(GPIO_FN_REG);
+	}
+}
+
+/* ------------------ common init/exit code -------------------- */
+
+static int __init rb700_nand_init(void)
+{
+	gpio_base = ioremap_nocache(GPIO_BASE, PAGE_SIZE);
+	if (!gpio_base)
+		return -ENOMEM;
+
+	return platform_driver_register(&rb700_nand_driver);
+}
+
+static void __exit rb700_nand_exit(void)
+{
+	iounmap(gpio_base);
+
+	platform_driver_unregister(&rb700_nand_driver);
+}
+
+module_init(rb700_nand_init);
+module_exit(rb700_nand_exit);
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb750g_nand.c linux/drivers/mtd/nand/rb750g_nand.c
--- linux-2.6.35/drivers/mtd/nand/rb750g_nand.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb750g_nand.c	2011-05-02 10:08:26.492902915 +0300
@@ -0,0 +1,224 @@
+#include <linux/init.h>
+#include <linux/mtd/nand.h>
+#include <linux/platform_device.h>
+
+extern int rb_nand_probe(struct nand_chip *nand, int booter);
+
+static struct nand_chip rnand;
+
+#define GPIO_BASE	0x18040000
+#define GPIO_OE_REG	    0x0000
+#define GPIO_IN_REG	    0x0004
+#define GPIO_O1_REG	    0x0008
+#define GPIO_S1_REG	    0x000c
+#define GPIO_S0_REG	    0x0010
+#define GPIO_FN_REG	    0x0028
+
+#define GPIO_REG(x)	(*(volatile unsigned *)((unsigned) gpio_base + (x)))
+
+static void __iomem *gpio_base;
+
+/* ------------------ RB750G nand driver -------------------- */
+
+
+#define GPO_NAND_nCE		(1 << 0)
+#define GPO_NAND_READ		(1 << 1)
+#define GPO_NAND_ALE		(1 << 2)
+#define GPO_NAND_CLE		(1 << 3)
+#define GPIO_NAND_RDY		(1 << 5)
+#define GPO_SSR_STRB		(1 << 6)
+#define GPO_NAND_nRW		(1 << 8)
+#define GPO_LATCH_EN		(1 << 11)
+
+#define GPO_NAND_DATA(x) ((x) & 0xff)
+#define GPI_NAND_DATA(x) ((x) & 0xff)
+
+#define ENABLE_GPIO0_SPI	0x01000
+#define ENABLE_GPIO1_SPI	0x02000
+#define ENABLE_GPIO1_I2S	0x20000
+
+static void rb750g_gpio_init(void) {
+	GPIO_REG(GPIO_S1_REG) = (GPO_NAND_nCE
+				 | GPO_NAND_nRW
+				 | GPO_SSR_STRB
+				 | GPO_LATCH_EN);
+	GPIO_REG(GPIO_S0_REG) = (GPO_NAND_READ 
+				 | GPO_NAND_CLE
+				 | GPO_NAND_ALE);
+	GPIO_REG(GPIO_OE_REG) |= (GPO_NAND_nCE
+				  | GPO_NAND_READ 
+				  | GPO_NAND_CLE 
+				  | GPO_NAND_ALE 
+				  | GPO_NAND_nRW 
+				  | GPO_SSR_STRB
+				  | GPO_LATCH_EN);
+	GPIO_REG(GPIO_FN_REG) &= ~(ENABLE_GPIO1_I2S |
+				   ENABLE_GPIO1_SPI |
+				   ENABLE_GPIO0_SPI);
+}
+
+static int rb750g_dev_ready(struct mtd_info *mtd) {
+	return GPIO_REG(GPIO_IN_REG) & GPIO_NAND_RDY;
+}
+
+static void rb750g_write_bytes_gpio(const uint8_t *data, unsigned cnt) {
+	int i;
+	unsigned gpo;
+	unsigned gpo_orig = GPIO_REG(GPIO_O1_REG);
+	
+	GPIO_REG(GPIO_S0_REG) = GPO_NAND_READ;
+	GPIO_REG(GPIO_S0_REG);
+	GPIO_REG(GPIO_S0_REG) = GPO_LATCH_EN;
+	GPIO_REG(GPIO_S0_REG);
+	GPIO_REG(GPIO_OE_REG) |= GPO_NAND_DATA(0xff);
+	gpo = GPIO_REG(GPIO_O1_REG) & ~(GPO_NAND_nRW | GPO_NAND_DATA(0xff));
+
+	for (i = 0; i < cnt; ++i) {
+		unsigned val = data[i];
+		unsigned gpov = gpo | GPO_NAND_DATA(val);
+
+		GPIO_REG(GPIO_O1_REG) = gpov;
+		GPIO_REG(GPIO_O1_REG);
+		GPIO_REG(GPIO_O1_REG) = gpov | GPO_NAND_nRW;
+		GPIO_REG(GPIO_O1_REG);
+	}
+	
+	GPIO_REG(GPIO_OE_REG) &= ~GPIO_NAND_RDY;
+	GPIO_REG(GPIO_O1_REG) = gpo_orig;
+	GPIO_REG(GPIO_O1_REG);
+	GPIO_REG(GPIO_S1_REG) = GPO_LATCH_EN;
+	GPIO_REG(GPIO_S1_REG);
+}
+
+static int rb750g_read_bytes_gpio(uint8_t *data, unsigned cnt,
+				  const uint8_t *verify) {
+
+	int i;
+	int ret = 0;
+	unsigned gpo_orig = GPIO_REG(GPIO_O1_REG);
+
+	GPIO_REG(GPIO_S1_REG) = GPO_NAND_READ;
+	GPIO_REG(GPIO_S1_REG);
+	GPIO_REG(GPIO_S0_REG) = GPO_LATCH_EN;
+	GPIO_REG(GPIO_S0_REG);
+	GPIO_REG(GPIO_OE_REG) &= ~GPO_NAND_DATA(0xff);
+	
+	for (i = 0; i < cnt; ++i) {
+		unsigned char val;
+		GPIO_REG(GPIO_S0_REG) = GPO_NAND_nRW;
+		GPIO_REG(GPIO_S0_REG);
+		
+		val = GPI_NAND_DATA(GPIO_REG(GPIO_IN_REG));
+		GPIO_REG(GPIO_S1_REG) = GPO_NAND_nRW;
+		GPIO_REG(GPIO_S1_REG);
+
+		if (data) {
+			data[i] = val;
+		}
+		else if (verify) {
+			if (verify[i] != val) {
+				ret = -EFAULT;
+				break;
+			}
+		}
+	}	
+
+	GPIO_REG(GPIO_OE_REG) |= (GPO_NAND_DATA(0xff) ^ GPIO_NAND_RDY);
+	GPIO_REG(GPIO_O1_REG) = gpo_orig;
+	GPIO_REG(GPIO_O1_REG);
+	GPIO_REG(GPIO_S1_REG) = GPO_LATCH_EN;
+	GPIO_REG(GPIO_S1_REG);
+	return ret;
+}
+
+static void rb750g_hwcontrol(struct mtd_info *mtd, int cmd,
+			     unsigned int ctrl) {
+	if (ctrl & NAND_CTRL_CHANGE) {
+		unsigned gpo = GPIO_REG(GPIO_O1_REG);
+		gpo &= ~(GPO_NAND_ALE | GPO_NAND_CLE | GPO_NAND_nCE);
+
+		if (ctrl & NAND_CLE) {
+			gpo |= GPO_NAND_CLE;
+		}
+		if (ctrl & NAND_ALE) {
+			gpo |= GPO_NAND_ALE;
+		}
+		if (!(ctrl & NAND_NCE)) {
+			gpo |= GPO_NAND_nCE;
+		}
+		GPIO_REG(GPIO_O1_REG) = gpo;
+		GPIO_REG(GPIO_O1_REG);		/* flush */
+	}
+
+	if (cmd != NAND_CMD_NONE) {
+		uint8_t data = cmd;
+		rb750g_write_bytes_gpio(&data, 1);
+	}
+}
+
+static uint8_t rb750g_read_byte(struct mtd_info *mtd)
+{
+	uint8_t data;
+	rb750g_read_bytes_gpio(&data, 1, NULL);
+	return data;
+}
+
+static void rb750g_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	rb750g_write_bytes_gpio(buf, len);
+}
+
+static void rb750g_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	rb750g_read_bytes_gpio(buf, len, NULL);
+}
+
+static int rb750g_verify_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	return rb750g_read_bytes_gpio(NULL, len, buf);
+}
+
+static int rb750g_nand_probe(struct platform_device *pdev)
+{
+	printk("RB750G nand\n");
+	rb750g_gpio_init();
+	memset(&rnand, 0, sizeof(rnand));
+
+	rnand.cmd_ctrl = rb750g_hwcontrol;
+	rnand.dev_ready = rb750g_dev_ready;
+	rnand.read_byte = rb750g_read_byte;
+	rnand.write_buf = rb750g_write_buf;
+	rnand.read_buf = rb750g_read_buf;
+	rnand.verify_buf = rb750g_verify_buf;
+
+	return rb_nand_probe(&rnand, 1);
+}
+
+static struct platform_driver rb750g_nand_driver = {
+	.probe	= rb750g_nand_probe,
+	.driver	= {
+		.name = "rb750g-nand",
+		.owner = THIS_MODULE,
+	},
+};
+
+/* ------------------ common init/exit code -------------------- */
+
+static int __init rb750g_nand_init(void)
+{
+	gpio_base = ioremap_nocache(GPIO_BASE, PAGE_SIZE);
+	if (!gpio_base)
+		return -ENOMEM;
+
+	return platform_driver_register(&rb750g_nand_driver);
+}
+
+static void __exit rb750g_nand_exit(void)
+{
+	iounmap(gpio_base);
+
+	platform_driver_unregister(&rb750g_nand_driver);
+}
+
+module_init(rb750g_nand_init);
+module_exit(rb750g_nand_exit);
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb.c linux/drivers/mtd/nand/rb.c
--- linux-2.6.35/drivers/mtd/nand/rb.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb.c	2011-05-02 10:08:26.501587927 +0300
@@ -0,0 +1,169 @@
+#include <linux/mtd/nand.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+
+static struct mtd_partition partition_info[] = {
+    {
+        name: "RouterBoard NAND Boot",
+        offset: 0,
+	size: 4 * 1024 * 1024
+    },
+    {
+        name: "RouterBoard NAND Main",
+	offset: MTDPART_OFS_NXTBLK,
+	size: MTDPART_SIZ_FULL
+    }
+};
+
+static struct mtd_partition partition_info_booter[] = {
+    {
+        name: "RouterBoard NAND Boot",
+        offset: 256 * 1024,
+	size: 4 * 1024 * 1024 - 256 * 1024,
+    },
+    {
+        name: "RouterBoard NAND Main",
+	offset: MTDPART_OFS_NXTBLK,
+	size: MTDPART_SIZ_FULL,
+    },
+    {
+        name: "RouterBoard NAND Booter",
+	offset: 0,
+	size: 256 * 1024,
+    }
+};
+
+static struct mtd_info rmtd;
+static int rmtd_valid = 0;
+
+extern int nand_lock_and_callback(struct mtd_info *mtd,
+				  int (*callback)(struct mtd_info *, void *),
+				  void *priv);
+
+int nand_custom_cmd(int (*cmd)(struct mtd_info *mtd, void *priv),
+		    void *priv) {
+	if (!rmtd_valid) return -ENODEV;
+	return nand_lock_and_callback(&rmtd, cmd, priv);
+}
+EXPORT_SYMBOL(nand_custom_cmd);
+
+#ifdef MIPSEL
+static int nand_is_bad = 0;
+
+static int check_nand(struct mtd_info *mtd, void *priv) {
+	struct nand_chip *chip = mtd->priv;
+	unsigned char ids[4];
+
+	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
+	ids[0] = chip->read_byte(mtd);
+	ids[1] = chip->read_byte(mtd);
+	ids[2] = chip->read_byte(mtd);
+	ids[3] = chip->read_byte(mtd);
+
+	nand_is_bad = (ids[0] == 0xad &&
+		       ids[1] == 0xf1 &&
+		       ids[2] == 0x80 &&
+		       ids[3] == 0x1d) ? 1 : 0;
+	return 0;
+}
+
+int is_nand_bad(void) {
+	return nand_is_bad;
+}
+EXPORT_SYMBOL(is_nand_bad);
+
+static int nand_supports_backup(struct mtd_info *mtd) {
+	unsigned ofs;
+
+	for (ofs = mtd->size / 2; ofs < mtd->size; ofs += mtd->erasesize) {
+		struct mtd_oob_ops ops;
+		uint32_t oobdata;
+
+		ops.ooblen = 4;
+		ops.oobbuf = (uint8_t *)&oobdata;
+		ops.ooboffs = BACKUP_4xFF_OFFSET;
+		ops.datbuf = NULL;
+		ops.mode = MTD_OOB_RAW;
+
+		if (mtd->block_isbad(mtd, ofs)) {
+			continue;
+		}
+		if (mtd->read_oob(mtd, ofs, &ops)) {
+			printk(KERN_INFO "nand backup disabled - "
+			       "read error at block %u\n",
+			       ofs / mtd->erasesize);
+			return 0;
+		}
+		if (oobdata != 0xffffffff) {
+			printk(KERN_INFO "nand backup disabled - "
+			       "backup area not empty at block %u\n",
+			       ofs / mtd->erasesize);
+			return 0;
+		}
+	}
+
+	printk(KERN_INFO "nand backup enabled\n");
+	return 1;
+}
+
+int nand_enable_backup(struct mtd_info *mtd_part) {
+	struct nand_chip *chip = rmtd.priv;
+	if (!rmtd_valid) return 0;
+	if (chip->backup_offset) return 0;
+	if (!is_nand_bad()) return 0;
+	if (!nand_supports_backup(&rmtd)) return 0;
+
+	chip->backup_offset = rmtd.size / 2;
+	partition_info[1].size = (chip->backup_offset -
+				  partition_info[0].size);
+	if (mtd_part && mtd_part != &rmtd) {
+		// reduce mtd partition size
+		mtd_part->size -= chip->backup_offset;
+	}
+	return 1;
+}
+EXPORT_SYMBOL(nand_enable_backup);
+#endif
+
+static int rb_nand_scan(struct mtd_info *mtd, int maxchips)
+{
+	struct nand_chip *chip = mtd->priv;
+	int ret;
+
+	ret = nand_scan_ident(mtd, maxchips, NULL);
+	chip->options &= ~NAND_BB_LAST_PAGE;
+	
+	if (!ret)
+		ret = nand_scan_tail(mtd);
+	return ret;
+}
+
+int rb_nand_probe(struct nand_chip *nand, int booter)
+{
+	memset(&rmtd, 0, sizeof(rmtd));
+
+	nand->ecc.mode = NAND_ECC_SOFT;
+	nand->chip_delay = 25;
+	nand->options |= NAND_NO_AUTOINCR;
+	rmtd.priv = nand;
+
+	if (rb_nand_scan(&rmtd, 1) && rb_nand_scan(&rmtd, 1)
+	    && rb_nand_scan(&rmtd, 1)  && rb_nand_scan(&rmtd, 1)) {
+		printk("RBxxx nand device not found\n");
+		return -ENXIO;
+	}
+	rmtd_valid = 1;
+
+#ifdef MIPSEL
+	nand_custom_cmd(&check_nand, NULL);
+	nand_enable_backup(NULL);
+#endif
+
+	if (booter) {
+		add_mtd_partitions(&rmtd, partition_info_booter, 3);
+	}
+	else {
+		add_mtd_partitions(&rmtd, partition_info, 2);
+	}
+	return 0;
+}
diff -puNrb linux-2.6.35/drivers/mtd/nand/rb_ppc.c linux/drivers/mtd/nand/rb_ppc.c
--- linux-2.6.35/drivers/mtd/nand/rb_ppc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/mtd/nand/rb_ppc.c	2011-05-02 10:08:26.511232324 +0300
@@ -0,0 +1,189 @@
+#include <linux/init.h>
+#include <linux/mtd/nand.h>
+#include <linux/of_platform.h>
+#include <linux/of_device.h>
+#include <asm/io.h>
+
+extern int rb_nand_probe(struct nand_chip *nand, int booter);
+
+static struct nand_chip rnand;
+
+struct rbppc_info {
+	void *gpi;
+	void *gpo;
+	void *localbus;
+
+	unsigned gpio_rdy;
+	unsigned gpio_nce;
+	unsigned gpio_cle;
+	unsigned gpio_ale;
+	unsigned gpio_ctrls;
+};
+
+static int rbppc_nand_ready(struct mtd_info *mtd) {
+	struct nand_chip *chip = mtd->priv;
+	struct rbppc_info *priv = chip->priv;
+
+	return in_be32(priv->gpi) & priv->gpio_rdy;
+}
+
+static void rbppc_nand_hwcontrol(struct mtd_info *mtd,
+				 int cmd, unsigned int ctrl) {
+	struct nand_chip *chip = mtd->priv;
+	struct rbppc_info *priv = chip->priv;
+
+	if (ctrl & NAND_CTRL_CHANGE) {
+		unsigned val = in_be32(priv->gpo);
+		if (!(val & priv->gpio_nce)) {
+			/* make sure Local Bus has done NAND operations */
+			readb(priv->localbus);
+		}
+
+		if (ctrl & NAND_CLE) {
+			val |= priv->gpio_cle;
+		} else {
+			val &= ~priv->gpio_cle;
+		}
+		if (ctrl & NAND_ALE) {
+			val |= priv->gpio_ale;
+		} else {
+			val &= ~priv->gpio_ale;
+		}
+		if (!(ctrl & NAND_NCE)) {
+			val |= priv->gpio_nce;
+		} else {
+			val &= ~priv->gpio_nce;
+		}
+		out_be32(priv->gpo, val);
+
+		/* make sure GPIO output has changed */
+		val ^= in_be32(priv->gpo);
+		if (val & priv->gpio_ctrls) {
+			printk(KERN_ERR
+			       "NAND GPO change failed 0x%08x\n", val);
+		}
+	}
+
+	if (cmd != NAND_CMD_NONE) writeb(cmd, chip->IO_ADDR_W);
+}
+
+static void rbppc_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = mtd->priv;
+	memcpy(buf, chip->IO_ADDR_R, len);
+}
+
+static int rbppc_nand_probe(struct of_device *pdev,
+			    const struct of_device_id *match)
+{
+	struct device_node *gpio;
+	struct device_node *nnand;
+	struct resource res;
+	struct rbppc_info *info;
+	void *baddr;
+	const unsigned *rdy, *nce, *cle, *ale;
+
+	printk("RB_PPC NAND\n");
+
+	info = kmalloc(sizeof(*info), GFP_KERNEL);
+
+	rdy = of_get_property(pdev->dev.of_node, "rdy", NULL);
+	nce = of_get_property(pdev->dev.of_node, "nce", NULL);
+	cle = of_get_property(pdev->dev.of_node, "cle", NULL);
+	ale = of_get_property(pdev->dev.of_node, "ale", NULL);
+
+	if (!rdy || !nce || !cle || !ale) {
+		printk("rbppc nand error: gpios properties are missing\n");
+		goto err;
+	}
+	if (rdy[0] != nce[0] || rdy[0] != cle[0] || rdy[0] != ale[0]) {
+		printk("rbppc nand error: "
+		       "different gpios are not supported\n");
+		goto err;
+	}
+
+	gpio = of_find_node_by_phandle(rdy[0]);
+	if (!gpio) {
+		printk("rbppc nand error: no gpio<%x> node found\n", *rdy);
+		goto err;
+	}
+	if (of_address_to_resource(gpio, 0, &res)) {
+		printk("rbppc nand error: no reg property in gpio found\n");
+		goto err;
+	}
+	info->gpo = ioremap_nocache(res.start, res.end - res.start + 1);
+
+	if (!of_address_to_resource(gpio, 1, &res)) {
+		info->gpi = ioremap_nocache(res.start, res.end - res.start + 1);
+	} else {
+		info->gpi = info->gpo;
+	}
+	of_node_put(gpio);
+
+	info->gpio_rdy = 1 << (31 - rdy[1]);
+	info->gpio_nce = 1 << (31 - nce[1]);
+	info->gpio_cle = 1 << (31 - cle[1]);
+	info->gpio_ale = 1 << (31 - ale[1]);
+	info->gpio_ctrls = info->gpio_nce | info->gpio_cle | info->gpio_ale;
+
+	nnand = of_find_node_by_name(NULL, "nnand");
+	if (!nnand) {
+		printk("rbppc nand error: no nnand found\n");
+		goto err;
+	}
+	if (of_address_to_resource(nnand, 0, &res)) {
+		printk("rbppc nand error: no reg property in nnand found\n");
+		goto err;
+	}
+	of_node_put(nnand);
+	info->localbus = ioremap_nocache(res.start, res.end - res.start + 1);
+	
+	if (of_address_to_resource(pdev->dev.of_node, 0, &res)) {
+	    printk("rbppc nand error: no reg property found\n");
+	    goto err;
+	}
+	baddr = ioremap_nocache(res.start, res.end - res.start + 1);
+
+	memset(&rnand, 0, sizeof(rnand));
+	rnand.cmd_ctrl = rbppc_nand_hwcontrol;
+    	rnand.dev_ready = rbppc_nand_ready;
+    	rnand.read_buf = rbppc_read_buf;
+	rnand.IO_ADDR_W = baddr;
+	rnand.IO_ADDR_R = baddr;
+	rnand.priv = info;
+
+	return rb_nand_probe(&rnand, 0);
+
+  err:
+	kfree(info);
+	return -1;
+}
+
+/* common for all NAND chips */
+							     
+static struct of_device_id rbppc_nand_ids[] = {
+	{ .name = "nand" },
+	{}
+};
+
+static struct of_platform_driver rbppc_nand_driver = {
+	.driver	= {
+		.name = "rbppc-nand",
+		.owner = THIS_MODULE,
+		.of_match_table = rbppc_nand_ids,
+	},
+	.probe	= rbppc_nand_probe,
+};
+
+static int __init rbppc_nand_init(void)
+{
+	return of_register_platform_driver(&rbppc_nand_driver);
+}
+
+static void __exit rbppc_nand_exit(void)
+{
+	of_unregister_platform_driver(&rbppc_nand_driver);
+}
+							     
+module_init(rbppc_nand_init);
+module_exit(rbppc_nand_exit);
diff -puNrb linux-2.6.35/drivers/net/admtek.c linux/drivers/net/admtek.c
--- linux-2.6.35/drivers/net/admtek.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/net/admtek.c	2011-05-02 10:08:26.531588538 +0300
@@ -0,0 +1,1633 @@
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/etherdevice.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/delay.h>
+#include <linux/if_arp.h>
+#include <linux/platform_device.h>
+#include <linux/if_switch.h>
+
+#define ADMTEK_REG_BASE		0x12000000
+
+// register offsets
+#define Boot_done_REG	0x08
+#define SWReset_REG	0x0C
+#define PHY_st_REG	0x14
+#define Port_st_REG	0x18
+#define SW_conf_REG	0x20
+#define CPUp_conf_REG	0x24
+#define Port_conf0_REG	0x28
+#define Port_conf1_REG	0x2C
+#define Port_conf2_REG	0x30
+#define VLAN_G1_REG	0x40
+#define VLAN_G2_REG	0x44
+#define Send_trig_REG	0x48
+#define Srch_cmd_REG	0x4C
+#define ADDR_st0_REG	0x50
+#define ADDR_st1_REG	0x54
+#define MAC_wt0_REG	0x58
+#define MAC_wt1_REG	0x5C
+#define BW_cntl0_REG	0x60
+#define BW_cntl1_REG	0x64
+#define PHY_cntl0_REG	0x68
+#define PHY_cntl1_REG	0x6C
+#define PHY_cntl2_REG	0x7C
+#define PHY_cntl3_REG	0x80
+#define Empty_cnt	0xA4
+#define SW_Int_st_REG	0xB0
+#define SW_Int_mask_REG	0xB4
+#define GPIO_CONF0_REG	0xB8
+#define GPIO_CONF2_REG	0xBC
+#define Send_HBaddr_REG	0xD0
+#define Send_LBaddr_REG	0xD4
+#define Recv_HBaddr_REG	0xD8
+#define Recv_LBaddr_REG	0xDC
+#define Send_HWaddr_REG	0xE0
+#define Send_LWaddr_REG	0xE4
+#define Recv_HWaddr_REG	0xE8
+#define Recv_LWaddr_REG	0xEC
+
+#define ADMTEK_REG(reg) \
+    (*((volatile unsigned long *)(KSEG1ADDR(ADMTEK_REG_BASE + (reg)))))
+
+
+// CPUp_conf_REG
+#define SW_CPU_PORT_DISABLE	0x00000001
+#define SW_PADING_CRC		0x00000002
+#define SW_BRIDGE_MODE		0x00000004
+
+// Port_conf0_REG
+#define SW_DISABLE_PORT_MASK	0x0000003F
+
+// MAC_wt0_REG
+#define SW_MAC_WRITE		0x00000001
+#define SW_MAC_WRITE_DONE	0x00000002
+#define SW_MAC_VLANID_EN	0x00000040
+#define SW_MAC_VLANID_SHIFT	3
+#define SW_MAC_PORT_SHIFT	3
+
+// SW_Int_st_REG & SW_Int_mask_REG
+#define TX_H_INT		0x00000001
+#define TX_L_INT		0x00000002
+#define RX_H_INT		0x00000004
+#define RX_L_INT		0x00000008
+#define RX_H_DESC_FULL_INT	0x00000010
+#define RX_L_DESC_FULL_INT	0x00000020
+#define CPU_QUEUE_FULL_INT	0x00002000
+#define GLOBAL_QUEUE_FULL_INT	0x00004000
+#define MUST_DROP_INT		0x00008000
+#define PORT_STATUS_CHANGE_INT	0x00040000
+#define RX_DESC_ERR_INT		0x00400000
+#define TX_DESC_ERR_INT	        0x00800000
+#define SWITCH_INT_MASK		0x01C4EFFF
+
+#define INT_MASK (TX_L_INT | RX_L_INT | RX_L_DESC_FULL_INT)
+
+// descriptor bits
+#define DESC_OWN           0x80000000
+#define DESC_RING_END      0x10000000
+#define DESC_ADDR_MASK     0x00ffffff
+#define DESC_LEN_MASK      0x07ff0000
+#define DESC_LEN_SHIFT     16
+
+// rx descr status
+#define DESC_RX_PORT_MASK  0x00007000
+#define DESC_RX_PORT_SHIFT 12
+#define DESC_RX_CSUM_ERR   0x00000008
+#define DESC_RX_VLAN_TAG   0x00000004
+
+
+#define RX_BUF_SIZE 1550
+#define SW_IRQ 17
+#define EMPTY_THRESH 0x100
+#define RX_DESC_COUNT 128
+#define ADMTEK_PORT_COUNT 5
+#define ICPLUS_PORT_COUNT 5
+#define PORT_COUNT (ADMTEK_PORT_COUNT + ICPLUS_PORT_COUNT)
+#define TX_ENA_THRESHOLD 24
+
+#define ADMTEK_PORT(x) (x->num < 100)
+#define ICPLUS_PORT(x) (x->num >= 100)
+
+#define UP_PORT 5
+
+static unsigned icplus_read_reg(unsigned phy, unsigned reg) {
+    unsigned ret;
+    ADMTEK_REG(PHY_cntl0_REG) = phy | reg << 8 | BIT(14);
+    while (1) {
+	ret = ADMTEK_REG(PHY_cntl1_REG);
+	if (ret & BIT(1)) break;
+    }
+
+    ret >>= 16;
+//    printk("icplus read %x %x %04x\n", phy, reg, ret);
+    return ret;
+}
+
+static void icplus_write_reg(unsigned phy, unsigned reg, unsigned value) {
+    unsigned ret;
+//    printk("icplus write %x %x %04x\n", phy, reg, value);
+    ADMTEK_REG(PHY_cntl0_REG) = phy | reg << 8 | BIT(13) | value << 16;
+    while (1) {
+	ret = ADMTEK_REG(PHY_cntl1_REG);
+	if (ret & BIT(0)) break;
+    }
+}
+
+/*
+static void icplus_dump_regs(void) {
+    unsigned i, j;
+    unsigned v;
+
+    printk("icplus regs:\n");
+
+//    for (i = 0; i < 6; ++i) {
+//	for (j = 0; j < 6; ++j) {
+//	    printk("reg %d %d: %04x\n", i, j, icplus_read_reg(i, j));
+//	}
+//    }
+
+    i = 29;
+    for (j = 18; j < 32; ++j) {
+	v = icplus_read_reg(i, j);
+	printk("reg %d %d: %04x\n", i, j, v);
+    }
+    i = 30;
+    for (j = 0; j < 32; ++j) {
+	v = icplus_read_reg(i, j);
+	printk("reg %d %d: %04x\n", i, j, v);
+    }
+    i = 31;
+    for (j = 0; j < 7; ++j) {
+	v = icplus_read_reg(i, j);
+	printk("reg %d %d: %04x\n", i, j, v);
+    }
+}
+*/
+
+static void icplus_stop_engine(void) {
+}
+
+static void icplus_init_engine(void) {
+    icplus_write_reg(29, 31, 0x175C);
+    icplus_write_reg(30, 10, 0);
+    icplus_write_reg(30, 0, 0x175C);
+    mdelay(2);
+
+//    icplus_write_reg(29, 18, 0xcc0c);
+    icplus_write_reg(29, 19, BIT(15) | BIT(7));
+    icplus_write_reg(29, 20, BIT(15) | BIT(7));
+    icplus_write_reg(29, 21, BIT(15));
+    icplus_write_reg(29, 23, (0x1F << 6) | BIT(1));
+    icplus_write_reg(29, 24, 0xffff);
+    icplus_write_reg(29, 25, 0xffff);
+    icplus_write_reg(29, 26, 0xffff);
+    icplus_write_reg(29, 27, 0xffff);
+    icplus_write_reg(29, 28, 0xffff);
+    icplus_write_reg(29, 30, 0xffff);
+
+//    icplus_write_reg(30, 1, 0x3f3f);
+//    icplus_write_reg(30, 2, 0x3f3f);
+//    icplus_write_reg(30, 3, 0x3f3f);
+//    icplus_write_reg(30, 4, 0x3f3f);
+//    icplus_write_reg(30, 5, 0x3f3f);
+//    icplus_write_reg(30, 6, 0x3f3f);
+//    icplus_write_reg(30, 7, 0x3f3f);
+//    icplus_write_reg(30, 8, 0x1f00);
+
+//    icplus_write_reg(30, 9, BIT(7) | BIT(3) | 5);
+    icplus_write_reg(30, 9, 5);
+    icplus_write_reg(30, 12, BIT(7) | BIT(5) | BIT(1));
+    icplus_write_reg(30, 13, 0xf);
+    icplus_write_reg(30, 16, BIT(13) | BIT(7) | 0x1f);
+    icplus_write_reg(30, 18, BIT(11) | BIT(8));
+    icplus_write_reg(30, 26, 0);
+    icplus_write_reg(31, 0, 0);
+    icplus_write_reg(31, 1, 0);
+    icplus_write_reg(31, 2, 0);
+    icplus_write_reg(31, 6, BIT(14) | BIT(1) | BIT(0));
+
+//    icplus_dump_regs();
+}
+
+
+struct admtek_rx_desc {
+    unsigned long buf1;
+    unsigned long buf2;
+    unsigned long len;
+    unsigned long status;
+};
+
+struct admtek_tx_desc {
+    unsigned long buf1;
+    unsigned long buf2;
+    unsigned long len;
+    unsigned long ctrl;
+};
+
+struct admtek_port {
+    struct net_device *dev;
+    struct mii_if_info mii_info;
+
+    int num;
+    struct admtek_port *master;
+    int master_count;
+    int master_ports;
+    int master_links;
+
+    int in_transmit;
+    int link;
+
+    struct timer_list pause_timer;
+};
+
+struct tx_head {
+    unsigned char macs[12];
+    unsigned char vlan0;
+    unsigned char vlan1;
+    unsigned char vlan2;
+    unsigned char vlan3;
+} __attribute__((packed));
+
+struct admtek_switch {
+    struct admtek_rx_desc *rx_descs;
+    struct admtek_tx_desc *tx_descs;
+    dma_addr_t rx_descs_dma;
+    dma_addr_t tx_descs_dma;
+
+    struct sk_buff **rx_skbs;
+    struct sk_buff **tx_skbs;
+    struct tx_head *tx_heads;
+
+    unsigned cur_rx;
+    unsigned cur_tx, dirty_tx;
+
+    struct napi_struct napi;
+    struct net_device *dum_dev;
+    struct admtek_port *devs[PORT_COUNT];
+    struct admtek_port *admtek_devs[ADMTEK_PORT_COUNT];
+    struct admtek_port *icplus_devs[ICPLUS_PORT_COUNT];
+    unsigned master_port;
+
+    unsigned tx_desc_per_port;
+    unsigned tx_desc_count;
+
+    spinlock_t lock;
+    spinlock_t linklock;
+
+    unsigned link_status;
+    unsigned open_admtek_devs;
+    unsigned open_icplus_devs;
+};
+static struct admtek_switch sw;
+
+extern unsigned char mips_mac_address[6];
+
+/*
+static void admtek_dump_macs(void) {
+    unsigned st0;
+    unsigned st1;
+    printk("ADMTEK macs:\n");
+    ADMTEK_REG(Srch_cmd_REG) = BIT(0);
+    udelay(100);
+    while (1) {
+	while (1) {
+	    if (!(ADMTEK_REG(Srch_cmd_REG) & 3)) break;
+	}
+	while (1) {
+	    udelay(100);
+	    st0 = ADMTEK_REG(ADDR_st0_REG);
+	    if (st0 & (BIT(0) | BIT(1))) break;
+	}
+	if (st0 & BIT(1)) break;
+	st1 = ADMTEK_REG(ADDR_st1_REG);
+
+	printk("filter: %d vlan: %d %d port: %d age: %d %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       (st0 >> 2) & 1,
+	       (st0 >> 6) & 1,
+	       (st0 >> 3) & 0x7,
+	       (st0 >> 7) & 0x3F,
+	       (st0 >> 13) & 0x7,
+	       (st0 >> 16) & 0xFF,
+	       (st0 >> 24) & 0xFF,
+	       (st1 >> 0) & 0xFF,
+	       (st1 >> 8) & 0xFF,
+	       (st1 >> 16) & 0xFF,
+	       (st1 >> 24) & 0xFF
+	    );
+
+	ADMTEK_REG(Srch_cmd_REG) = BIT(1);
+	udelay(100);
+    }
+}
+*/
+
+static void admtek_dump(void) {
+//    unsigned i;
+
+    printk("CPUp_conf:  %08lx\n", ADMTEK_REG(CPUp_conf_REG));
+    printk("Port_conf0: %08lx\n", ADMTEK_REG(Port_conf0_REG));
+    printk("Port_conf1: %08lx\n", ADMTEK_REG(Port_conf1_REG));
+    printk("Port_conf2: %08lx\n", ADMTEK_REG(Port_conf2_REG));
+    printk("VLAN_GI:    %08lx\n", ADMTEK_REG(VLAN_G1_REG));
+    printk("VLAN_GII:   %08lx\n", ADMTEK_REG(VLAN_G2_REG));
+    printk("BW_cntl0:   %08lx\n", ADMTEK_REG(BW_cntl0_REG));
+    printk("BW_cntl1:   %08lx\n", ADMTEK_REG(BW_cntl1_REG));
+
+/*
+    printk("empty_cnt: %08lx\n", ADMTEK_REG(Empty_cnt));
+    printk("working: %lx %lx %lx %lx\n",
+	   ADMTEK_REG(Recv_LWaddr_REG), ADMTEK_REG(Recv_HWaddr_REG),
+	   ADMTEK_REG(Send_LWaddr_REG), ADMTEK_REG(Send_HWaddr_REG)
+	);
+    printk("base:    %lx %lx %lx %lx\n",
+	   ADMTEK_REG(Recv_LBaddr_REG), ADMTEK_REG(Recv_HBaddr_REG),
+	   ADMTEK_REG(Send_LBaddr_REG), ADMTEK_REG(Send_HBaddr_REG)
+	);
+
+    printk("cur_rx %d, cur_tx %u, dirty_tx %u\n", sw.cur_rx, sw.cur_tx,
+           sw.dirty_tx);
+    printk("mask 0x%lx, status 0x%lx\n",
+           ADMTEK_REG(SW_Int_mask_REG),
+           ADMTEK_REG(SW_Int_st_REG));
+*/
+
+/*
+    for (i = 0; i < 255; i += 4) {
+	if (!(i % 16)) printk("\n");
+	printk("%08lx ", ADMTEK_REG(i));
+    }
+    printk("\n");
+*/
+
+/*
+    for (i = 0; i < RX_DESC_COUNT; ++i) {
+	printk("%08lx ", sw.rx_descs[i].buf1);
+        if ((i + 1) % 8 == 0) printk("\n");
+    }
+*/
+/*
+    for (i = 0; i < RX_DESC_COUNT; ++i) {
+	printk("rx %08lx %lx %08lx %lx   %08lx %08lx %08lx\n",
+	       sw.rx_descs[i].buf1,
+	       sw.rx_descs[i].buf2,
+	       sw.rx_descs[i].len,
+	       sw.rx_descs[i].status,
+	       sw.rx_skbs[i],
+	       sw.rx_skbs[i] ? sw.rx_skbs[i]->len : 0,
+	       sw.rx_skbs[i] ? (sw.rx_skbs[i]->end - sw.rx_skbs[i]->head) : 0
+	    );
+    }
+*/
+/*
+    for (i = 0; i < sw.tx_desc_count; ++i) {
+	printk("tx %08lx %08lx %08lx %08lx   %08lx\n",
+	       sw.tx_descs[i].buf1,
+	       sw.tx_descs[i].buf2,
+	       sw.tx_descs[i].len,
+	       sw.tx_descs[i].ctrl,
+	       sw.tx_skbs[i] ? sw.tx_skbs[i]->data : 0
+	    );
+    }
+*/
+}
+
+static void admtek_rx_fixup(void) {
+    unsigned i;
+
+    for (i = 0; i < RX_DESC_COUNT; ++i) {
+	unsigned b = DESC_OWN;
+	if (i == RX_DESC_COUNT - 1) b |= DESC_RING_END;
+
+	if (sw.rx_skbs[i]) {
+	    sw.rx_descs[i].buf2 = 0;
+	    sw.rx_descs[i].len = RX_BUF_SIZE;
+	    sw.rx_descs[i].status = 0;
+	    sw.rx_descs[i].buf1 =
+		((unsigned long)sw.rx_skbs[i]->data & DESC_ADDR_MASK) | b;
+	}
+	else {
+	    sw.rx_descs[i].buf1 = b;
+	}
+    }
+}
+
+static void admtek_init_descs(void) {
+    admtek_rx_fixup();
+
+    memset(sw.tx_descs, 0, sizeof(struct admtek_tx_desc) * sw.tx_desc_count);
+    sw.tx_descs[sw.tx_desc_count - 1].buf1 |= DESC_RING_END;
+    memset(sw.tx_skbs, 0, sizeof(struct sk_buff *) * sw.tx_desc_count);
+
+    sw.cur_rx = 0;
+    sw.cur_tx = 0;
+    sw.dirty_tx = 0;
+}
+
+static void admtek_stop_engine(void) {
+    unsigned i;
+    printk("admtek_stop_engine\n");
+//    admtek_dump();
+
+    icplus_stop_engine();
+    ADMTEK_REG(SW_Int_mask_REG) |= SWITCH_INT_MASK; 
+    ADMTEK_REG(Port_conf0_REG) |= SW_DISABLE_PORT_MASK; 
+    ADMTEK_REG(Port_conf2_REG) = 0x2 | BIT(3);
+//    ADMTEK_REG(Boot_done_REG) = 1;
+//    ADMTEK_REG(PHY_cntl2_REG) &= ~(0x1F << 20);
+//    ADMTEK_REG(SWReset_REG) = 1;
+//    ADMTEK_REG(PHY_cntl2_REG) = (1 << 31 | 0x1F << 20 | 0x1F << 25 |
+//				 0x1F << 10 | 0x1F << 5 | 0x1F << 0);
+
+    for (i = 0; i < sw.tx_desc_count; ++i) {
+	if (sw.tx_skbs[i]) {
+	    dev_kfree_skb(sw.tx_skbs[i]);
+	    sw.tx_skbs[i] = NULL;
+	}
+    }
+
+    for (i = 0; i < PORT_COUNT; ++i) {
+	if (!sw.devs[i]) continue;
+	sw.devs[i]->in_transmit = 0;
+    }
+}
+
+static void admtek_clear_mac(unsigned char *addr) {
+    unsigned reg;
+
+    ADMTEK_REG(MAC_wt1_REG) =
+	(addr[5] << 24) | (addr[4] << 16) | (addr[3] << 8) | addr[2];
+    reg = (addr[1] << 24) | (addr[0] << 16);
+    reg |= SW_MAC_WRITE;
+
+    ADMTEK_REG(MAC_wt0_REG) = reg;
+
+    while (!(ADMTEK_REG(MAC_wt0_REG) & SW_MAC_WRITE_DONE));
+}
+
+static void admtek_init_engine(void) {
+    printk("admtek_init_engine\n");
+
+    // remove mac address set by bios
+    admtek_clear_mac(mips_mac_address);
+
+    admtek_stop_engine();
+    admtek_init_descs();
+
+    ADMTEK_REG(0x78) = 0xE8DC1818;
+    ADMTEK_REG(0x64) = 0x700;
+
+    icplus_init_engine();
+
+    // initialize engine
+    ADMTEK_REG(CPUp_conf_REG) =
+	SW_CPU_PORT_DISABLE | SW_PADING_CRC | SW_BRIDGE_MODE;
+    ADMTEK_REG(Port_conf0_REG) = SW_DISABLE_PORT_MASK | 0x3F << 8;
+
+    ADMTEK_REG(SW_Int_mask_REG) |= SWITCH_INT_MASK;
+    ADMTEK_REG(SW_Int_st_REG) |= SWITCH_INT_MASK;
+    ADMTEK_REG(Send_LBaddr_REG) = sw.tx_descs_dma;
+    ADMTEK_REG(Send_HBaddr_REG) = 0;
+    ADMTEK_REG(Recv_LBaddr_REG) = sw.rx_descs_dma;
+    ADMTEK_REG(Recv_HBaddr_REG) = 0;
+    ADMTEK_REG(CPUp_conf_REG) &= ~SW_CPU_PORT_DISABLE;
+
+    ADMTEK_REG(SW_Int_mask_REG) &=
+	~(INT_MASK | PORT_STATUS_CHANGE_INT);
+}
+
+static int admtek_rx(int budget) {
+    struct admtek_rx_desc *desc;
+    unsigned num;
+    struct net_device *dev = NULL;
+    struct admtek_port *port;
+    unsigned len;
+    struct sk_buff *skb;
+    int works = 0;
+
+    while (1) {
+	desc = sw.rx_descs + sw.cur_rx;
+	if (desc->buf1 & DESC_OWN) break;
+
+	num = (desc->status & DESC_RX_PORT_MASK) >> DESC_RX_PORT_SHIFT;
+	len = ((desc->status & DESC_LEN_MASK) >> DESC_LEN_SHIFT) - 4;
+
+	port = sw.admtek_devs[num];
+
+//	printk("rx: %08lx, p%u, len: %u\n", desc->status, num, len);
+	if (!len || len > RX_BUF_SIZE || desc->status & DESC_RX_CSUM_ERR) {
+	    printk("admtek: rx error\n");
+	    if (port) {
+		port->dev->stats.rx_errors++;
+		port->dev->stats.rx_length_errors++;
+	    }
+	    goto next;
+	}
+
+	skb = sw.rx_skbs[sw.cur_rx];
+	if (!skb) goto next;
+	skb_put(skb, len);
+
+	if (!port) {
+	    if (num == sw.master_port) {
+//		printk("port %02x %02x%02x\n",
+//		       skb->data[13], skb->data[14], skb->data[15]);
+//		int i;
+		num = ffs(*(skb->data + 13)) - 1;
+		*(skb->data + 13) = 0;
+		if (num >= ICPLUS_PORT_COUNT) {
+		    printk("invalid icplus port %x\n",
+			   (unsigned char)*(skb->data + 13));
+		    goto next;
+		}
+		port = sw.icplus_devs[num];
+
+//		printk("packet from port %d %d\n", num, len);
+//		for (i = 0; i < 20; ++i) {
+//		    printk("%02x ", (unsigned char)*(skb->data + i));
+//		}
+//		printk("\n");
+
+		if (skb->data[14] == 0xff && skb->data[15] == 0xff) {
+		    memmove(skb->data + 4, skb->data, 12);
+		    skb_pull(skb, 4);
+		}
+	    }
+	}
+	if (!port) {
+	    printk("admtek: no device\n");
+	    goto next;
+	}
+	if (port->master) port = port->master;
+	dev = port->dev;
+
+	if (skb) {
+	    sw.rx_skbs[sw.cur_rx] = NULL;
+	    if (netif_running(dev)) {
+		skb->dev = dev;
+		skb->protocol = eth_type_trans(skb, dev);
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+		// only place we need to flush cache
+		dma_cache_wback_inv((unsigned long)skb->data, len);
+
+		dev->last_rx = jiffies;
+		port->dev->stats.rx_packets++;
+		port->dev->stats.rx_bytes += len;
+		netif_receive_skb(skb);
+		++works;
+	    }
+	    else {
+		dev_kfree_skb_any(skb);
+	    }
+	}
+
+	next:
+	if (!sw.rx_skbs[sw.cur_rx]) {
+	    skb = netdev_alloc_skb(dev, RX_BUF_SIZE + 16);
+	    if (skb) skb_reserve(skb, 2);
+	    else {
+		printk("admtek: alloc rx skb failed\n");
+	    }
+	    sw.rx_skbs[sw.cur_rx] = skb;
+	}
+
+	if (sw.rx_skbs[sw.cur_rx]) {
+	    skb = sw.rx_skbs[sw.cur_rx];
+	    desc->buf2 = 0;
+	    desc->status = 0;
+	    desc->len = RX_BUF_SIZE;
+	    desc->buf1 = (desc->buf1 & DESC_RING_END) | DESC_OWN
+		| (((unsigned long)skb->data) & DESC_ADDR_MASK);
+	}
+	else {
+	    desc->buf2 = 0;
+	    desc->status = 0;
+	    desc->len = 0;
+	    desc->buf1 = (desc->buf1 & DESC_RING_END) | DESC_OWN;
+	}
+
+	++sw.cur_rx;
+	if (sw.cur_rx >= RX_DESC_COUNT) sw.cur_rx = 0;
+	if (works >= budget) break;
+    }
+    return works;
+}
+
+static void admtek_tx(void) {
+    struct admtek_tx_desc *desc;
+    struct admtek_port *port;
+
+    while (1) {
+	desc = sw.tx_descs + sw.dirty_tx;
+	if (sw.cur_tx == sw.dirty_tx) break;
+	if (desc->buf1 & DESC_OWN) break;
+
+//	printk("tx done %x\n", desc->ctrl);
+	port = netdev_priv(sw.tx_skbs[sw.dirty_tx]->dev);
+	port->dev->stats.tx_packets++;
+	port->dev->stats.tx_bytes += sw.tx_skbs[sw.dirty_tx]->len;
+
+	if (port->in_transmit >= sw.tx_desc_per_port) {
+	    if (netif_running(port->dev)) {
+		if (!timer_pending(&port->pause_timer)) {
+		    netif_wake_queue(port->dev);
+		}
+	    }
+	}
+	--port->in_transmit;
+
+	dev_kfree_skb(sw.tx_skbs[sw.dirty_tx]);
+	sw.tx_skbs[sw.dirty_tx] = NULL;
+
+	++sw.dirty_tx;
+	if (sw.dirty_tx >= sw.tx_desc_count) sw.dirty_tx = 0;
+    }
+}
+
+static int admtek_poll(struct napi_struct *napi, int budget)
+{
+    int work_done;
+
+    ADMTEK_REG(SW_Int_st_REG) = INT_MASK;
+
+    spin_lock(&sw.lock);
+
+    admtek_tx();
+
+    spin_unlock(&sw.lock);
+
+    work_done = admtek_rx(budget);
+
+    if (work_done >= budget)
+        return work_done;
+
+    if ((ADMTEK_REG(SW_Int_st_REG) & INT_MASK) != 0) {
+        // new event already pending, stay on poll list
+        return budget;
+    }
+
+    napi_complete(napi);
+    ADMTEK_REG(SW_Int_mask_REG) &= ~INT_MASK;
+
+    return work_done;
+}
+
+static irqreturn_t admtek_interrupt(int irq, void *dev_id)
+{
+    unsigned long status = ADMTEK_REG(SW_Int_st_REG);
+//    printk("irq: %08x\n", status);
+
+    if (status & INT_MASK) {
+        napi_schedule(&sw.napi);
+        ADMTEK_REG(SW_Int_mask_REG) |= INT_MASK;
+    }
+
+    if (status & PORT_STATUS_CHANGE_INT) {
+	unsigned new_status, i;
+
+        spin_lock(&sw.linklock);
+
+        new_status = ADMTEK_REG(PHY_st_REG);
+
+ 	for (i = 0; i < PORT_COUNT; ++i) {
+	    unsigned pm;
+	    struct net_device *dev;
+	    if (!sw.devs[i] || !ADMTEK_PORT(sw.devs[i])) continue;
+	    if (sw.devs[i]->master_count) continue;
+	    dev = sw.devs[i]->dev;
+	    if (!netif_running(dev)) continue;
+	    pm = 1 << sw.devs[i]->num;
+	    if ((new_status & pm) != (sw.link_status & pm)) {
+		if (new_status & pm) {
+		    printk("admtek: link up for %s\n", dev->name);
+		    netif_carrier_on(dev);
+ 		}
+ 		else {
+		    printk("admtek: link down for %s\n", dev->name);
+		    netif_carrier_off(dev);
+ 		}
+ 	    }
+ 	}
+
+	sw.link_status = new_status;
+
+        spin_unlock(&sw.linklock);
+
+        ADMTEK_REG(SW_Int_st_REG) = PORT_STATUS_CHANGE_INT;
+    }
+
+    return IRQ_RETVAL(1);
+}
+
+static int admtek_open(struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+//    printk("admtek_open: %s\n", dev->name);
+
+    if (!sw.open_admtek_devs) {
+	admtek_init_engine();
+	dev_open(sw.dum_dev);
+    }
+    ++sw.open_admtek_devs;
+
+    spin_lock_irq(&sw.linklock);
+
+//    admtek_set_mac(-1, port->num, dev->dev_addr);
+//    admtek_dump_macs();
+
+    if (!port->master_count) {
+	if ((ADMTEK_REG(PHY_st_REG) & (1 << port->num))) {
+	    printk("admtek: initial link up for %s\n", dev->name);
+	    netif_carrier_on(dev);
+	    sw.link_status |= (1 << port->num);
+	}
+	else {
+	    printk("admtek: initial link down for %s\n", dev->name);
+	    netif_carrier_off(dev);
+	    sw.link_status &= ~(1 << port->num);
+	}
+    }
+    else {
+	netif_carrier_on(dev);
+    }
+
+    spin_unlock_irq(&sw.linklock);
+
+    // enable port
+    ADMTEK_REG(Port_conf0_REG) &= ~(1 << port->num); 
+
+    netif_start_queue(dev);
+    return 0;
+}
+
+static int admtek_stop(struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+
+//    admtek_dump_macs();
+
+    del_timer_sync(&port->pause_timer);
+    netif_stop_queue(dev);
+
+    // disable port
+    ADMTEK_REG(Port_conf0_REG) |= (1 << port->num);
+
+    --sw.open_admtek_devs;
+    if (!sw.open_admtek_devs) {
+	dev_close(sw.dum_dev);
+	admtek_stop_engine();
+    }
+
+    return 0;
+}
+
+static void admtek_pause_timer(unsigned long data) {
+    struct net_device *dev = (struct net_device *)data;
+    struct admtek_port *port = netdev_priv(dev);
+    spin_lock(&sw.lock);
+
+    if ((ADMTEK_REG(Empty_cnt) & 0x1FF) < EMPTY_THRESH) {
+//	printk("%lu: continue pause queue: %s, %u\n",
+//	       jiffies, dev->name, port->in_transmit);
+	netif_stop_queue(dev);
+
+	port->pause_timer.expires = jiffies + 1;
+	add_timer(&port->pause_timer);
+    }
+    else {
+//	printk("%lu: resume queue: %s, %u\n",
+//	       jiffies, dev->name, port->in_transmit);
+	netif_wake_queue(dev);
+    }
+
+    spin_unlock(&sw.lock);
+}
+
+static int admtek_hard_start_xmit(struct sk_buff *skb,
+				  struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+    struct admtek_tx_desc *desc;
+    unsigned len;
+    int vlan = -1;
+//    printk("admtek_hard_start_xmit: %s\n", dev->name);
+
+    spin_lock(&sw.lock);
+
+    sw.tx_skbs[sw.cur_tx] = skb;
+
+    len = skb->len < ETH_ZLEN ? ETH_ZLEN : skb->len;
+    desc = sw.tx_descs + sw.cur_tx;
+
+    desc->ctrl = len << DESC_LEN_SHIFT;
+    if (port->master) vlan = port->master->num;
+    if (port->master_count) vlan = port->num;
+    if (vlan < 0) {
+	desc->ctrl |= 1 << (port->num + 8);
+    }
+    else {
+	desc->ctrl |= 1 << vlan;
+    }
+//    printk("xmit desc ctrl %08lx %s\n", desc->ctrl, dev->name);
+
+    desc->len = skb->len;
+    desc->buf2 = 0;
+    desc->buf1 = (desc->buf1 & DESC_RING_END) | 
+	((unsigned long)skb->data & DESC_ADDR_MASK) | DESC_OWN;
+
+    ADMTEK_REG(Send_trig_REG) = 1;
+
+    dev->trans_start = jiffies;
+
+    ++sw.cur_tx;
+    if (sw.cur_tx >= sw.tx_desc_count) sw.cur_tx = 0;
+
+    port->in_transmit++;
+    if (port->in_transmit >= sw.tx_desc_per_port) {
+//	printk("%lu: stop queue: %s, %u\n",
+//	       jiffies, dev->name, port->in_transmit);
+	netif_stop_queue(dev);
+	goto ret;
+    }
+
+    if ((ADMTEK_REG(Empty_cnt) & 0x1FF) < EMPTY_THRESH) {
+//	printk("%lu: pause queue: %s, %u\n",
+//	       jiffies, dev->name, port->in_transmit);
+	netif_stop_queue(dev);
+
+	port->pause_timer.expires = jiffies + 1;
+	add_timer(&port->pause_timer);
+	goto ret;
+    }
+ret:
+    spin_unlock(&sw.lock);
+    return 0;
+}
+
+static void admtek_get_drvinfo (struct net_device *dev,
+				struct ethtool_drvinfo *info) {
+    struct admtek_port *port = netdev_priv(dev);
+    strcpy(info->driver, "admtek");
+    strcpy(info->version, "1.0");
+    sprintf(info->bus_info, "00:00.0 admtek%d", port->num);
+}
+
+static int admtek_get_settings(struct net_device *dev,
+			       struct ethtool_cmd *cmd) {
+    struct admtek_port *port = netdev_priv(dev);
+    unsigned long reg;
+    spin_lock_irq(&sw.linklock);
+
+    // inspired from mii.c
+    cmd->supported =
+	(SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full |
+	 SUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full |
+	 SUPPORTED_Autoneg | SUPPORTED_TP | SUPPORTED_MII);
+    cmd->port = PORT_MII;
+    cmd->transceiver = XCVR_INTERNAL;
+    cmd->phy_address = 0;
+
+    cmd->advertising = ADVERTISED_TP | ADVERTISED_MII;
+    cmd->advertising |= ADVERTISED_10baseT_Half;
+    cmd->advertising |= ADVERTISED_10baseT_Full;
+    cmd->advertising |= ADVERTISED_100baseT_Half;
+    cmd->advertising |= ADVERTISED_100baseT_Full;
+
+    reg = ADMTEK_REG(PHY_cntl2_REG);
+    if ((reg & (1 << port->num))) {
+	cmd->advertising |= ADVERTISED_Autoneg;
+	cmd->autoneg = AUTONEG_ENABLE;
+    }
+    else cmd->autoneg = AUTONEG_DISABLE;
+
+    reg = ADMTEK_REG(PHY_st_REG);
+    if ((reg & ((1 << 8) << port->num))) cmd->speed = SPEED_100;
+    else cmd->speed = SPEED_10;
+    if ((reg & ((1 << 16) << port->num))) cmd->duplex = DUPLEX_FULL;
+    else cmd->duplex = DUPLEX_HALF;
+
+    spin_unlock_irq(&sw.linklock);
+    return 0;
+}
+
+static int admtek_set_settings(struct net_device *dev,
+			       struct ethtool_cmd *cmd) {
+    struct admtek_port *port = netdev_priv(dev);
+    spin_lock_irq(&sw.linklock);
+
+    // inspired from mii.c
+    if (cmd->speed != SPEED_10 && cmd->speed != SPEED_100)
+	return -EINVAL;
+    if (cmd->duplex != DUPLEX_HALF && cmd->duplex != DUPLEX_FULL)
+	return -EINVAL;
+    if (cmd->port != PORT_MII)
+	return -EINVAL;
+    if (cmd->transceiver != XCVR_INTERNAL)
+	return -EINVAL;
+    if (cmd->autoneg != AUTONEG_DISABLE && cmd->autoneg != AUTONEG_ENABLE)
+	return -EINVAL;
+
+    if (cmd->autoneg == AUTONEG_ENABLE) {
+	ADMTEK_REG(PHY_cntl2_REG) |= (1 << port->num);
+	ADMTEK_REG(PHY_cntl2_REG) |= ((1 << 5) << port->num);
+	ADMTEK_REG(PHY_cntl2_REG) |= ((1 << 10) << port->num);
+    } else {
+	ADMTEK_REG(PHY_cntl2_REG) &= ~(1 << port->num);
+
+	if (cmd->speed == SPEED_100) {
+	    ADMTEK_REG(PHY_cntl2_REG) |= ((1 << 5) << port->num);
+	}
+	else {
+	    ADMTEK_REG(PHY_cntl2_REG) &= ~((1 << 5) << port->num);
+	}
+
+	if (cmd->duplex == DUPLEX_FULL) {
+	    ADMTEK_REG(PHY_cntl2_REG) |= ((1 << 10) << port->num);
+	}
+	else {
+	    ADMTEK_REG(PHY_cntl2_REG) &= ~((1 << 10) << port->num);
+	}
+    }
+
+    spin_unlock_irq(&sw.linklock);
+    return 0;
+}
+
+static u32 admtek_get_link(struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+    int link = !!(sw.link_status & (1 << port->num));
+    if (!port->link && link) {
+	if (port->master) port->master->master_links++;
+    }
+    if (port->link && !link) {
+	if (port->master) port->master->master_links--;
+    }
+    port->link = link;
+    return port->link + port->master_links;
+}
+
+
+static struct ethtool_ops admtek_ethtool_ops = {
+    .get_drvinfo	= admtek_get_drvinfo,
+    .get_settings	= admtek_get_settings,
+    .set_settings	= admtek_set_settings,
+    .get_link		= admtek_get_link,
+};
+
+static int icplus_get_settings(struct net_device *dev,
+			       struct ethtool_cmd *cmd) {
+    struct admtek_port *port = netdev_priv(dev);
+    return mii_ethtool_gset(&port->mii_info, cmd);
+}
+
+static int icplus_set_settings(struct net_device *dev,
+				 struct ethtool_cmd *cmd) {
+    struct admtek_port *port = netdev_priv(dev);
+    return mii_ethtool_sset(&port->mii_info, cmd);
+}
+
+static u32 icplus_get_link(struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+    int link = mii_link_ok(&port->mii_info);
+    if (!port->link && link) {
+	if (port->master) port->master->master_links++;
+    }
+    if (port->link && !link) {
+	if (port->master) port->master->master_links--;
+    }
+    port->link = link;
+    return port->link + port->master_links;
+}
+ 
+static struct ethtool_ops icplus_ethtool_ops = {
+    .get_drvinfo  = admtek_get_drvinfo,
+    .get_settings = icplus_get_settings,
+    .set_settings = icplus_set_settings,
+    .get_link     = icplus_get_link,
+};
+
+
+
+static void admtek_tx_timeout(struct net_device *dev) {
+    unsigned i;
+    printk("admtek: tx timeout %s\n", dev->name);
+
+    admtek_dump();
+    spin_lock(&sw.lock);
+    admtek_init_engine();
+
+    // BUG: need to setup switch stuff aswell, but never have seen it recover
+    // from tx_timeout so its dead by now anyway
+    for (i = 0; i < PORT_COUNT; ++i) {
+	struct admtek_port *port = sw.devs[i];
+	if (!port || !ADMTEK_PORT(port) || !netif_running(port->dev)) continue;
+	ADMTEK_REG(Port_conf0_REG) &= ~(1 << port->num); 
+    }
+
+    spin_unlock(&sw.lock);
+    admtek_dump();
+}
+
+static int admtek_change_mtu(struct net_device *dev, int new_mtu) {
+    if (new_mtu < 68 || new_mtu > dev->l2mtu) return -EINVAL;
+    dev->mtu = new_mtu;
+    return 0;
+}
+
+static int admtek_set_mac_address(struct net_device *dev, void *p) {
+    struct sockaddr *addr = p;
+
+    if (!is_valid_ether_addr(addr->sa_data))
+	return -EADDRNOTAVAIL;
+    memcpy(dev->dev_addr, addr->sa_data, ETH_ALEN);
+    return 0;
+}
+
+static int admtek_get_type(struct admtek_port *port) {
+    if (port->num < 100) {
+	return SWITCH_ADMTEK;
+    }
+    return SWITCH_ICPLUS175C;
+}
+
+static int admtek_get_switch(struct admtek_port *port) {
+    if (port->num < 100) {
+	return 0;
+    }
+    return 1;
+}
+
+static void admtek_set_bandwidth_tx(struct admtek_port *port, int bw) {
+    if (port->num < 100) {
+	if (port->num < 4) {
+	    ADMTEK_REG(BW_cntl0_REG) &= ~(0x7 << (port->num * 8));
+	    ADMTEK_REG(BW_cntl0_REG) |= bw << (port->num * 8);
+	}
+	else {
+	    ADMTEK_REG(BW_cntl1_REG) &= ~(0x7);
+	    ADMTEK_REG(BW_cntl1_REG) |= bw;
+	}
+    }
+    else {
+	unsigned reg = (port->num - 100) / 2;
+	unsigned off = (port->num - 100) % 2 * 8 + 4;
+	unsigned val = icplus_read_reg(31, reg);
+	val &= ~(0x7 << off);
+	val |= bw << off;
+	icplus_write_reg(31, reg, val);
+    }
+}
+
+static void admtek_set_bandwidth_rx(struct admtek_port *port, int bw) {
+    if (port->num < 100) {
+	if (port->num < 4) {
+	    ADMTEK_REG(BW_cntl0_REG) &= ~(0x7 << (port->num * 8 + 4));
+	    ADMTEK_REG(BW_cntl0_REG) |= bw << (port->num * 8 + 4);
+	}
+	else {
+	    ADMTEK_REG(BW_cntl1_REG) &= ~(0x7 << 4);
+	    ADMTEK_REG(BW_cntl1_REG) |= bw << 4;
+	}
+    }
+    else {
+	unsigned reg = (port->num - 100) / 2;
+	unsigned off = (port->num - 100) % 2 * 8;
+	unsigned val = icplus_read_reg(31, reg);
+	val &= ~(0x7 << off);
+	val |= bw << off;
+	icplus_write_reg(31, reg, val);
+    }
+}
+
+static void admtek_set_vlan(struct admtek_port *port, int vlan, int enable) {
+    int num = port->num;
+    struct admtek_port *master = sw.admtek_devs[vlan];
+    int reg = vlan < 4 ? VLAN_G1_REG : VLAN_G2_REG;
+    int off = vlan % 4 * 8;
+
+//    printk("admtek set vlan %d %d %d\n", num, vlan, enable);
+    if (enable) {
+	ADMTEK_REG(reg) |= BIT(num) << off;
+
+	ADMTEK_REG(Port_conf1_REG) &= ~BIT(num);
+	ADMTEK_REG(Port_conf1_REG) &= ~BIT(num + 6);
+	ADMTEK_REG(Port_conf1_REG) |= BIT(num + 20);
+
+	netif_carrier_on(port->dev);
+
+	master->master_ports |= BIT(num);
+    }
+    else {
+	ADMTEK_REG(reg) &= ~(BIT(num) << off);
+
+	ADMTEK_REG(Port_conf1_REG) |= BIT(num);
+	ADMTEK_REG(Port_conf1_REG) |= BIT(num + 6);
+	ADMTEK_REG(Port_conf1_REG) &= ~BIT(num + 20);
+
+	master->master_ports &= ~BIT(num);
+    }
+}
+
+static void icplus_set_vlan(struct admtek_port *port, int vlan, int enable) {
+    int num = port->num - 100;
+    int ports = BIT(vlan);
+    int mask;
+    int i;
+    int val;
+    struct admtek_port *master = sw.icplus_devs[vlan];
+//    printk("%s master %s %d\n", port->dev->name, master->dev->name, enable);
+    for (i = 0; i < ICPLUS_PORT_COUNT; ++i) {
+	if (!sw.icplus_devs[i]) continue;
+	if (!sw.icplus_devs[i]->master) continue;
+	if (sw.icplus_devs[i]->master->num - 100 == vlan) {
+	    ports |= BIT(sw.icplus_devs[i]->num - 100);
+	}
+    }
+
+    if (enable) {
+	mask = ports | BIT(7);
+    }
+    else {
+	mask = (ports & ~BIT(num)) | BIT(7);
+    }
+
+    for (i = 0; i < 5; ++i) {
+	int reg = 19 + i / 2;
+	int off = i % 2 ? 0 : 8;
+	if (!(BIT(i) & ports)) continue;
+	val = icplus_read_reg(29, reg);
+	val &= ~(0xFF << off);
+	val |= mask << off;
+	icplus_write_reg(29, reg, val);
+    }
+
+    if (!enable) ports &= ~BIT(num);
+    master->master_ports = ports;
+    if (master->master_ports == BIT(vlan)) master->master_ports = 0;
+
+    val = icplus_read_reg(30, 16);
+    val &= ~BIT(num + 8);
+    val |= enable << (num + 8);
+    icplus_write_reg(30, 16, val);
+}
+
+static void admtek_special_set_vlan(struct admtek_port *port, int vlan,
+				    int enable) {
+    if (vlan < 100) {
+	admtek_set_vlan(port, vlan, enable);
+    }
+    else {
+	vlan -= 100;
+	icplus_set_vlan(port, vlan, enable);
+    }
+}
+
+struct admtek_port *admtek_find(unsigned ifindex) {
+    int i;
+    for (i = 0; i < PORT_COUNT; ++i) {
+	if (!sw.devs[i]) continue;
+	if (sw.devs[i]->dev->ifindex == ifindex) return sw.devs[i];
+    }
+    return NULL;
+}
+
+static void admtek_set_master(struct admtek_port *port, int m) {
+    struct admtek_port *master = admtek_find(m);
+    int vlan;
+
+    if (port->master) {
+	port->master->master_links -= port->link;
+	vlan = port->master->num;
+	--port->master->master_count;
+	if (!port->master->master_count) {
+	    admtek_special_set_vlan(port->master, vlan, 0);
+	}
+	admtek_special_set_vlan(port, vlan, 0);
+    }
+
+    port->master = master;
+
+    if (port->master) {
+	port->master->master_links += port->link;
+	vlan = port->master->num;
+	++port->master->master_count;
+	if (port->master->master_count == 1) {
+	    admtek_special_set_vlan(port->master, vlan, 1);
+	}
+	admtek_special_set_vlan(port, vlan, 1);
+    }
+
+//    icplus_dump_regs();
+//    admtek_dump();
+}
+
+#define ifr_ivalue  ifr_ifru.ifru_ivalue
+
+static int admtek_ioctl(struct net_device *dev, struct ifreq *rq, int cmd) {
+    struct admtek_port *port = netdev_priv(dev);
+
+    switch (cmd) {
+    case SIOCGTYPE:
+	rq->ifr_ivalue = admtek_get_type(port);
+	return 0;
+    case SIOCGSWITCH:
+	rq->ifr_ivalue = admtek_get_switch(port);
+	return 0;
+    case SIOCSTXBW:
+	admtek_set_bandwidth_tx(port, rq->ifr_ivalue);
+	return 0;
+    case SIOCSRXBW:
+	admtek_set_bandwidth_rx(port, rq->ifr_ivalue);
+	return 0;
+    case SIOCSMASTER:
+	admtek_set_master(port, rq->ifr_ivalue);
+	return 0;
+    }
+
+    if (!netif_running(dev))
+	return -EINVAL;
+
+    if (!port->mii_info.dev) return -ENOTSUPP;
+
+    return generic_mii_ioctl(&port->mii_info, if_mii(rq), cmd, NULL);
+}
+
+static struct net_device_ops admtek_dummy_netdev_ops = {
+};
+
+static void admtek_dum_setup(struct net_device *dev) {
+    dev->type = ARPHRD_VOID;
+    dev->mtu = 1500;
+    dev->tx_queue_len = 1000;
+    dev->flags = IFF_NOARP;
+    netif_napi_add(dev, &sw.napi, admtek_poll, 64);
+}
+
+static struct net_device *admtek_setup_dummy(void) {
+    struct net_device *dev = alloc_netdev(0, "admtek", admtek_dum_setup);
+    if (!dev) return NULL;
+
+    dev->netdev_ops = &admtek_dummy_netdev_ops;
+
+    if (register_netdev(dev) < 0) {
+	printk("admtek: register dummy failed\n");
+	kfree(dev);
+	return NULL;
+    }
+
+    return dev;
+}
+
+
+
+
+static int icplus_open(struct net_device *dev) {
+//    printk("icplus: open %s\n", dev->name);
+    if (!sw.open_icplus_devs) {
+	if (!sw.open_admtek_devs) {
+	    admtek_init_engine();
+	    dev_open(sw.dum_dev);
+	}
+	++sw.open_admtek_devs;
+
+	// enable port
+	ADMTEK_REG(Port_conf0_REG) &= ~(1 << sw.master_port); 
+    }
+    ++sw.open_icplus_devs;
+
+    netif_start_queue(dev);
+    return 0;
+}
+
+static int icplus_stop(struct net_device *dev) {
+//    printk("icplus: stop %s\n", dev->name);
+    netif_stop_queue(dev);
+
+    --sw.open_icplus_devs;
+    if (!sw.open_icplus_devs) {
+	// disable port
+	ADMTEK_REG(Port_conf0_REG) |= (1 << sw.master_port);
+
+	--sw.open_admtek_devs;
+	if (!sw.open_admtek_devs) {
+	    dev_close(sw.dum_dev);
+	    admtek_stop_engine();
+	}
+    }
+
+    return 0;
+}
+
+static int icplus_hard_start_xmit(struct sk_buff *skb,
+				  struct net_device *dev) {
+    struct admtek_port *port = netdev_priv(dev);
+    struct tx_head *head = &sw.tx_heads[sw.cur_tx];
+    struct admtek_tx_desc *desc;
+    unsigned len;
+
+//    printk("icplus: xmit %s %d %d\n", dev->name,
+//	   skb_headroom(skb), skb_tailroom(skb));
+
+    if (skb_padto(skb, ETH_ZLEN))
+	return 0;
+
+    spin_lock(&sw.lock);
+
+    memcpy(head->macs, skb->data, 12);
+    head->vlan0 = 0x81;
+    head->vlan1 = BIT(port->num - 100);
+    if (port->master_ports) {
+	head->vlan1 = port->master_ports;
+    }
+    head->vlan2 = 0x00;
+    head->vlan3 = port->num - 100;
+
+    desc = sw.tx_descs + sw.cur_tx;
+    sw.tx_skbs[sw.cur_tx] = skb;
+
+    len = (skb->len + 4) < ETH_ZLEN ? ETH_ZLEN : (skb->len + 4);
+    desc->ctrl = (len << DESC_LEN_SHIFT) | (1 << (sw.master_port + 8));
+    desc->len = 16;
+    desc->buf2 = (1 << 31) | (unsigned long)(skb->data + 12);
+    desc->buf1 = (desc->buf1 & DESC_RING_END) | (unsigned long)head | DESC_OWN;
+//    printk("tx desc %lx %lx %lx %lx %lx\n",
+//	   desc->buf1, desc->buf2, desc->len, desc->ctrl,
+//	   ADMTEK_REG(PHY_st_REG)
+//	);
+
+    ADMTEK_REG(Send_trig_REG) = 1;
+
+    dev->trans_start = jiffies;
+
+    ++sw.cur_tx;
+    if (sw.cur_tx >= sw.tx_desc_count) sw.cur_tx = 0;
+
+    port->in_transmit++;
+    if (port->in_transmit >= sw.tx_desc_per_port) {
+//	printk("%lu: stop queue: %s, %u\n",
+//	       jiffies, dev->name, port->in_transmit);
+	netif_stop_queue(dev);
+    }
+
+    spin_unlock(&sw.lock);
+    return 0;
+}
+
+static void icplus_write_phy(struct net_device *dev, int phy, int reg,
+			     int value) {
+    spin_lock(&sw.linklock);
+    icplus_write_reg(phy, reg, value);
+    spin_unlock(&sw.linklock);
+}
+
+static int icplus_read_phy(struct net_device *dev, int phy, int reg) {
+    int value;
+    spin_lock(&sw.linklock);
+    value = icplus_read_reg(phy, reg);
+    spin_unlock(&sw.linklock);
+    return value;
+}
+
+static const struct net_device_ops admtek_netdev_ops = {
+	.ndo_open		= admtek_open,
+	.ndo_stop		= admtek_stop,
+	.ndo_start_xmit		= admtek_hard_start_xmit,
+	.ndo_change_mtu		= admtek_change_mtu,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_tx_timeout		= admtek_tx_timeout,
+	.ndo_do_ioctl		= admtek_ioctl,
+	.ndo_set_mac_address	= admtek_set_mac_address,
+};
+
+static const struct net_device_ops icplus_netdev_ops = {
+	.ndo_open		= icplus_open,
+	.ndo_stop		= icplus_stop,
+	.ndo_start_xmit		= icplus_hard_start_xmit,
+	.ndo_change_mtu		= admtek_change_mtu,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_tx_timeout		= admtek_tx_timeout,
+	.ndo_do_ioctl		= admtek_ioctl,
+	.ndo_set_mac_address	= admtek_set_mac_address,
+};
+
+
+static int admtek_init_dev(struct net_device *dev, unsigned num,
+			   unsigned mac_idx) {
+    struct admtek_port *port = netdev_priv(dev);
+    int ret = 0;
+
+    memcpy(dev->dev_addr, mips_mac_address, 6);
+
+    if (dev->dev_addr[5] + mac_idx > 255) ++dev->dev_addr[4];
+    dev->dev_addr[5] += mac_idx;
+
+    dev->watchdog_timeo = HZ;
+    dev->irq = SW_IRQ;
+
+    if (num < 100) {
+	dev->netdev_ops = &admtek_netdev_ops;
+	dev->ethtool_ops = &admtek_ethtool_ops;
+	dev->l2mtu = 1518;
+	sw.admtek_devs[num] = port;
+    }
+    else {
+	dev->netdev_ops = &icplus_netdev_ops;
+	dev->ethtool_ops = &icplus_ethtool_ops;
+	dev->l2mtu = 1514;
+
+	port->mii_info.dev = dev;
+	port->mii_info.mdio_read = &icplus_read_phy;
+	port->mii_info.mdio_write = &icplus_write_phy;
+	port->mii_info.phy_id = num - 100;
+	port->mii_info.phy_id_mask = 0x1f;
+	port->mii_info.reg_num_mask = 0x1f;
+	sw.icplus_devs[num - 100] = port;
+    }
+
+    ret = register_netdev(dev);
+    if (ret) {
+	printk("admtek: register_netdev failed\n");
+	return ret;
+    }
+//    printk("admtek: %s -> %d\n", dev->name, num);
+
+    port->dev = dev;
+    port->num = num;
+
+    init_timer(&port->pause_timer);
+    port->pause_timer.data = (unsigned long)dev;
+    port->pause_timer.function = &admtek_pause_timer;
+
+    return ret;
+}
+
+static void admtek_cleanup_dev(struct admtek_port *port) {
+    if (port->dev) unregister_netdev(port->dev);
+    kfree(port->dev);
+}
+
+static void admtek_cleanup(void) {
+    unsigned i;
+    unsigned c;
+
+    ADMTEK_REG(SW_Int_mask_REG) |= SWITCH_INT_MASK; 
+
+    free_irq(SW_IRQ, &sw);
+
+    dev_close(sw.dum_dev);
+    unregister_netdev(sw.dum_dev);
+    kfree(sw.dum_dev);
+    for (i = 0; i < PORT_COUNT; ++i) {
+	if (sw.devs[i]) admtek_cleanup_dev(sw.devs[i]);
+    }
+    if (sw.tx_skbs) {
+	for (i = 0; i < sw.tx_desc_count; ++i) {
+	    if (sw.tx_skbs[i]) dev_kfree_skb(sw.tx_skbs[i]);
+	}
+	kfree(sw.tx_skbs);
+    }
+    if (sw.tx_heads) {
+	kfree(sw.tx_heads);
+    }
+    if (sw.tx_descs) {
+	c = sw.tx_desc_count;
+	pci_free_consistent(NULL, sizeof(struct admtek_rx_desc) * c,
+			    sw.tx_descs, sw.tx_descs_dma);
+    }
+    if (sw.rx_skbs) {
+	for (i = 0; i < RX_DESC_COUNT; ++i) {
+	    if (sw.rx_skbs[i]) dev_kfree_skb(sw.rx_skbs[i]);
+	}
+	kfree(sw.rx_skbs);
+    }
+    if (sw.rx_descs) {
+	c = RX_DESC_COUNT;
+	pci_free_consistent(NULL, sizeof(struct admtek_rx_desc) * c,
+			    sw.rx_descs, sw.rx_descs_dma);
+    }
+}
+
+static int __init admtek_probe(struct platform_device *pdev) {
+    int *port_map = (int *) pdev->dev.platform_data;
+    unsigned i;
+
+    printk("ADMTEK ethernet switch driver\n");
+
+    sw.tx_desc_per_port = 4;
+    sw.tx_desc_count = ((sw.tx_desc_per_port + 1) * PORT_COUNT);
+
+    if (request_irq(SW_IRQ, admtek_interrupt, IRQF_SHARED | IRQF_DISABLED,
+		    "ethernet switch", &sw)) {
+	printk("admtek: request irq failed\n");
+	goto err_out;
+    }
+
+    // alloc buffers
+    sw.rx_descs = pci_alloc_consistent(NULL, sizeof(struct admtek_rx_desc)
+				       * RX_DESC_COUNT, &sw.rx_descs_dma);
+    if (!sw.rx_descs) {
+	printk("admtek: alloc rx descriptors failed\n");
+	goto err_out;
+    }
+
+    sw.rx_skbs = kmalloc(sizeof(struct sk_buff *) * RX_DESC_COUNT, GFP_KERNEL);
+    if (!sw.rx_skbs) {
+	printk("admtek: alloc rx skb ptr buf failed\n");
+	goto err_out;
+    }
+    memset(sw.rx_skbs, 0, sizeof(struct sk_buff *) * RX_DESC_COUNT);
+
+    sw.tx_descs = pci_alloc_consistent(NULL, sizeof(struct admtek_tx_desc) *
+				       sw.tx_desc_count, &sw.tx_descs_dma);
+    if (!sw.tx_descs) {
+	printk("admtek: alloc tx descriptors failed\n");
+	goto err_out;
+    }
+
+    sw.tx_skbs = kmalloc(sizeof(struct sk_buff *) * sw.tx_desc_count,
+			 GFP_KERNEL);
+    if (!sw.tx_skbs) {
+	printk("admtek: alloc tx skb ptr buf failed\n");
+	goto err_out;
+    }
+    memset(sw.tx_skbs, 0, sizeof(struct sk_buff *) * sw.tx_desc_count);
+
+    sw.tx_heads = kmalloc(sizeof(struct tx_head) * sw.tx_desc_count,
+			  GFP_KERNEL | GFP_DMA);
+    if (!sw.tx_heads) {
+	printk("admtek: alloc tx head buf failed\n");
+	goto err_out;
+    }
+    memset(sw.tx_heads, 0, sizeof(struct tx_head) * sw.tx_desc_count);
+
+    spin_lock_init(&sw.lock);
+    spin_lock_init(&sw.linklock);
+
+    ADMTEK_REG(Port_conf1_REG) = 0x00000FFF;
+    ADMTEK_REG(VLAN_G1_REG) = 0;
+    ADMTEK_REG(VLAN_G2_REG) = 0;
+
+    sw.dum_dev = admtek_setup_dummy();
+    if (!sw.dum_dev) {
+	printk("admtek: dummy device setup failed\n");
+	goto err_out;
+    }
+
+    for (i = 0; i < RX_DESC_COUNT; ++i) {
+	sw.rx_skbs[i] = netdev_alloc_skb(sw.dum_dev, RX_BUF_SIZE + 16);
+	if (!sw.rx_skbs[i]) {
+	    printk("admtek: alloc rx skb failed\n");
+	    goto err_out;
+	}
+	skb_reserve(sw.rx_skbs[i], 2);
+    }
+
+    napi_enable(&sw.napi);
+    sw.master_port = port_map[0];
+    for (i = 0; i < PORT_COUNT; ++i) {
+	struct net_device *dev;
+	int p = port_map[i + 1];
+	if (p < 0) break;
+
+	dev = alloc_etherdev(sizeof(struct admtek_port));
+	if (dev == NULL) {
+	    printk("admtek: alloc_etherdev failed for port #%u\n", p);
+	    goto err_out;
+	}
+
+	if (admtek_init_dev(dev, p, i)) {
+	    printk("admtek: init failed for port #%u\n", p);
+	    goto err_out;
+	}
+	sw.devs[i] = netdev_priv(dev);
+    }
+
+    return 0;
+err_out:
+    admtek_cleanup();
+    return -ENODEV;
+}
+
+static int __exit admtek_remove(struct platform_device *pdev) {
+    admtek_cleanup();
+    return 0;
+}
+
+static struct platform_driver admtek_driver = {
+	.probe	= admtek_probe,
+	.remove = admtek_remove,
+	.driver	= {
+		.name	= "admtek",
+		.owner	= THIS_MODULE,
+	}
+};
+
+static int __init admtek_init(void) {
+	return platform_driver_register(&admtek_driver);
+}
+
+static void __exit admtek_exit(void) {
+	platform_driver_unregister(&admtek_driver);
+}
+
+module_init(admtek_init);
+module_exit(admtek_exit);
diff -puNrb linux-2.6.35/drivers/net/atl1c/atl1c_ethtool.c linux/drivers/net/atl1c/atl1c_ethtool.c
--- linux-2.6.35/drivers/net/atl1c/atl1c_ethtool.c	2011-04-26 16:28:16.391228756 +0300
+++ linux/drivers/net/atl1c/atl1c_ethtool.c	2011-05-02 10:08:26.541544932 +0300
@@ -30,87 +30,16 @@ static int atl1c_get_settings(struct net
 			      struct ethtool_cmd *ecmd)
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
-	struct atl1c_hw *hw = &adapter->hw;
-
-	ecmd->supported = (SUPPORTED_10baseT_Half  |
-			   SUPPORTED_10baseT_Full  |
-			   SUPPORTED_100baseT_Half |
-			   SUPPORTED_100baseT_Full |
-			   SUPPORTED_Autoneg       |
-			   SUPPORTED_TP);
-	if (hw->link_cap_flags & ATL1C_LINK_CAP_1000M)
-		ecmd->supported |= SUPPORTED_1000baseT_Full;
-
-	ecmd->advertising = ADVERTISED_TP;
-
-	ecmd->advertising |= hw->autoneg_advertised;
-
-	ecmd->port = PORT_TP;
-	ecmd->phy_address = 0;
-	ecmd->transceiver = XCVR_INTERNAL;
-
-	if (adapter->link_speed != SPEED_0) {
-		ecmd->speed = adapter->link_speed;
-		if (adapter->link_duplex == FULL_DUPLEX)
-			ecmd->duplex = DUPLEX_FULL;
-		else
-			ecmd->duplex = DUPLEX_HALF;
-	} else {
-		ecmd->speed = -1;
-		ecmd->duplex = -1;
-	}
-
-	ecmd->autoneg = AUTONEG_ENABLE;
-	return 0;
+	if (!(netdev->flags & IFF_UP)) return -EINVAL;
+	return mii_ethtool_gset(&adapter->mii, ecmd);
 }
 
 static int atl1c_set_settings(struct net_device *netdev,
 			      struct ethtool_cmd *ecmd)
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
-	struct atl1c_hw *hw = &adapter->hw;
-	u16  autoneg_advertised;
-
-	while (test_and_set_bit(__AT_RESETTING, &adapter->flags))
-		msleep(1);
-
-	if (ecmd->autoneg == AUTONEG_ENABLE) {
-		autoneg_advertised = ADVERTISED_Autoneg;
-	} else {
-		if (ecmd->speed == SPEED_1000) {
-			if (ecmd->duplex != DUPLEX_FULL) {
-				if (netif_msg_link(adapter))
-					dev_warn(&adapter->pdev->dev,
-						"1000M half is invalid\n");
-				clear_bit(__AT_RESETTING, &adapter->flags);
-				return -EINVAL;
-			}
-			autoneg_advertised = ADVERTISED_1000baseT_Full;
-		} else if (ecmd->speed == SPEED_100) {
-			if (ecmd->duplex == DUPLEX_FULL)
-				autoneg_advertised = ADVERTISED_100baseT_Full;
-			else
-				autoneg_advertised = ADVERTISED_100baseT_Half;
-		} else {
-			if (ecmd->duplex == DUPLEX_FULL)
-				autoneg_advertised = ADVERTISED_10baseT_Full;
-			else
-				autoneg_advertised = ADVERTISED_10baseT_Half;
-		}
-	}
-
-	if (hw->autoneg_advertised != autoneg_advertised) {
-		hw->autoneg_advertised = autoneg_advertised;
-		if (atl1c_restart_autoneg(hw) != 0) {
-			if (netif_msg_link(adapter))
-				dev_warn(&adapter->pdev->dev,
-					"ethtool speed/duplex setting failed\n");
-			clear_bit(__AT_RESETTING, &adapter->flags);
-			return -EINVAL;
-		}
-	}
-	clear_bit(__AT_RESETTING, &adapter->flags);
-	return 0;
+	if (!(netdev->flags & IFF_UP)) return -EINVAL;
+	return mii_ethtool_sset(&adapter->mii, ecmd);
 }
 
 static u32 atl1c_get_tx_csum(struct net_device *netdev)
diff -puNrb linux-2.6.35/drivers/net/atl1c/atl1c.h linux/drivers/net/atl1c/atl1c.h
--- linux-2.6.35/drivers/net/atl1c/atl1c.h	2011-04-26 16:28:16.391228756 +0300
+++ linux/drivers/net/atl1c/atl1c.h	2011-05-02 10:08:26.551545145 +0300
@@ -245,15 +245,15 @@ struct atl1c_tpd_ext_desc {
 #define RRS_PACKET_TYPE_802_3  	1
 #define RRS_PACKET_TYPE_ETH	0
 #define RRS_PACKET_IS_ETH(word) \
-	((((word) >> RRS_PACKET_TYPE_SHIFT) & RRS_PACKET_TYPE_MASK) == \
+    (((le32_to_cpu(word)) >> RRS_PACKET_TYPE_SHIFT) & RRS_PACKET_TYPE_MASK == \
 			RRS_PACKET_TYPE_ETH)
 #define RRS_RXD_IS_VALID(word) \
-	((((word) >> RRS_RXD_UPDATED_SHIFT) & RRS_RXD_UPDATED_MASK) == 1)
+    ((((le32_to_cpu(word)) >> RRS_RXD_UPDATED_SHIFT) & RRS_RXD_UPDATED_MASK) == 1)
 
 #define RRS_PACKET_PROT_IS_IPV4_ONLY(word) \
-	((((word) >> RRS_PROT_ID_SHIFT) & RRS_PROT_ID_MASK) == 1)
+    ((((le32_to_cpu(word)) >> RRS_PROT_ID_SHIFT) & RRS_PROT_ID_MASK) == 1)
 #define RRS_PACKET_PROT_IS_IPV6_ONLY(word) \
-	((((word) >> RRS_PROT_ID_SHIFT) & RRS_PROT_ID_MASK) == 6)
+    ((((le32_to_cpu(word)) >> RRS_PROT_ID_SHIFT) & RRS_PROT_ID_MASK) == 6)
 
 struct atl1c_recv_ret_status {
 	__le32  word0;
@@ -578,7 +578,6 @@ struct atl1c_adapter {
 
 	struct work_struct common_task;
 	struct timer_list watchdog_timer;
-	struct timer_list phy_config_timer;
 
 	/* All Descriptor memory */
 	struct atl1c_ring_header ring_header;
@@ -589,6 +588,7 @@ struct atl1c_adapter {
 	struct atl1c_smb smb;
 	int num_rx_queues;
 	u32 bd_number;     /* board number;*/
+	struct sk_buff_head rx_recycle;
 };
 
 #define AT_WRITE_REG(a, reg, value) ( \
diff -puNrb linux-2.6.35/drivers/net/atl1c/atl1c_hw.c linux/drivers/net/atl1c/atl1c_hw.c
--- linux-2.6.35/drivers/net/atl1c/atl1c_hw.c	2011-04-26 16:28:16.391228756 +0300
+++ linux/drivers/net/atl1c/atl1c_hw.c	2011-05-02 10:08:26.571591203 +0300
@@ -148,8 +148,14 @@ static int atl1c_get_permanent_address(s
 	/* maybe MAC-address is from BIOS */
 	AT_READ_REG(hw, REG_MAC_STA_ADDR, &addr[0]);
 	AT_READ_REG(hw, REG_MAC_STA_ADDR + 4, &addr[1]);
-	*(u32 *) &eth_addr[2] = swab32(addr[0]);
-	*(u16 *) &eth_addr[0] = swab16(*(u16 *)&addr[1]);
+
+	eth_addr[2] = addr[0] >> 24;
+	eth_addr[3] = addr[0] >> 16;
+	eth_addr[4] = addr[0] >> 8;
+	eth_addr[5] = addr[0];
+
+	eth_addr[0] = addr[1] >> 8;
+	eth_addr[1] = addr[1];
 
 	if (is_valid_ether_addr(eth_addr)) {
 		memcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);
diff -puNrb linux-2.6.35/drivers/net/atl1c/atl1c_hw.h linux/drivers/net/atl1c/atl1c_hw.h
--- linux-2.6.35/drivers/net/atl1c/atl1c_hw.h	2011-04-26 16:28:16.391228756 +0300
+++ linux/drivers/net/atl1c/atl1c_hw.h	2011-05-02 10:08:26.583103201 +0300
@@ -288,6 +288,8 @@ int atl1c_restart_autoneg(struct atl1c_h
 					      * comes from Analog SerDes */
 #define SERDES_LOCK_DETECT_EN       	0x2  /* 1: Enable SerDes Lock detect function */
 
+#define REG_LED_CONFIG            	0x142c
+
 /* MAC Control Register  */
 #define REG_MAC_CTRL         		0x1480
 #define MAC_CTRL_TX_EN			0x1
@@ -646,9 +648,6 @@ int atl1c_restart_autoneg(struct atl1c_h
 
 #define IMR_NORMAL_MASK		(\
 		ISR_MANUAL	|\
-		ISR_HW_RXF_OV	|\
-		ISR_RFD0_UR	|\
-		ISR_TXF_UR	|\
 		ISR_DMAR_TO_RST	|\
 		ISR_TXQ_TO_RST  |\
 		ISR_DMAW_TO_RST	|\
diff -puNrb linux-2.6.35/drivers/net/atl1c/atl1c_main.c linux/drivers/net/atl1c/atl1c_main.c
--- linux-2.6.35/drivers/net/atl1c/atl1c_main.c	2011-04-26 16:28:16.391228756 +0300
+++ linux/drivers/net/atl1c/atl1c_main.c	2011-05-02 10:08:26.613214871 +0300
@@ -19,6 +19,10 @@
  * Temple Place - Suite 330, Boston, MA  02111-1307, USA.
  */
 
+#ifdef powerpc
+#include <asm/rb_aux.h>
+#include <asm/machdep.h>
+#endif
 #include "atl1c.h"
 
 #define ATL1C_DRV_VERSION "1.0.0.2-NAPI"
@@ -58,6 +62,39 @@ MODULE_DESCRIPTION("Atheros 1000M Ethern
 MODULE_LICENSE("GPL");
 MODULE_VERSION(ATL1C_DRV_VERSION);
 
+/*
+static void atl1c_dump(struct atl1c_adapter *adapter) {
+    struct atl1c_hw *hw = &adapter->hw;
+    unsigned i;
+
+    printk("******** atl1c_dump:\n");
+    for (i = 0; i < 0x100; i += 16) {
+	unsigned v1, v2, v3, v4;
+	AT_READ_REG(hw, 0x1400 + i, &v1);
+	AT_READ_REG(hw, 0x1404 + i, &v2);
+	AT_READ_REG(hw, 0x1408 + i, &v3);
+	AT_READ_REG(hw, 0x140c + i, &v4);
+	printk("%04x: %08x %08x %08x %08x\n", 0x1400 + i, v1, v2, v3, v4);
+    }
+
+    printk("rx ring count=%d, size=%d, next_to_use=%d, next_to_clean=%d\n",
+	   adapter->rrd_ring[0].count,
+	   adapter->rrd_ring[0].size,
+	   adapter->rrd_ring[0].next_to_use,
+	   adapter->rrd_ring[0].next_to_clean);
+    for (i = 0; i < adapter->rrd_ring[0].count; ++i) {
+	struct atl1c_recv_ret_status *rrs;
+	rrs = ATL1C_RRD_DESC(&adapter->rrd_ring[0], i);
+	printk("%02x: w0=%08x rss=%08x vlan=%04x flag=%04x w3=%08x\n", i,
+	       le32_to_cpu(rrs->word0),
+	       le32_to_cpu(rrs->rss_hash),
+	       le16_to_cpu(rrs->vlan_tag),
+	       le16_to_cpu(rrs->flag),
+	       le32_to_cpu(rrs->word3));
+    }
+}
+*/
+
 static int atl1c_stop_mac(struct atl1c_hw *hw);
 static void atl1c_enable_rx_ctrl(struct atl1c_hw *hw);
 static void atl1c_enable_tx_ctrl(struct atl1c_hw *hw);
@@ -139,6 +176,24 @@ static void atl1c_reset_pcie(struct atl1
 }
 
 /*
+ * atl1c_wait_until_idle - wait up to AT_HW_MAX_IDLE_DELAY reads
+ * of the idle status register until the device is actually idle
+ */
+static u32 atl1c_wait_until_idle(struct atl1c_hw *hw)
+{
+	int timeout;
+	u32 data;
+
+	for (timeout = 0; timeout < AT_HW_MAX_IDLE_DELAY; timeout++) {
+		AT_READ_REG(hw, REG_IDLE_STATUS, &data);
+		if ((data & IDLE_STATUS_MASK) == 0)
+			return 0;
+		msleep(1);
+	}
+	return data;
+}
+
+/*
  * atl1c_irq_enable - Enable default interrupt generation settings
  * @adapter: board private structure
  */
@@ -173,39 +228,6 @@ static inline void atl1c_irq_reset(struc
 	atl1c_irq_enable(adapter);
 }
 
-/*
- * atl1c_wait_until_idle - wait up to AT_HW_MAX_IDLE_DELAY reads
- * of the idle status register until the device is actually idle
- */
-static u32 atl1c_wait_until_idle(struct atl1c_hw *hw)
-{
-	int timeout;
-	u32 data;
-
-	for (timeout = 0; timeout < AT_HW_MAX_IDLE_DELAY; timeout++) {
-		AT_READ_REG(hw, REG_IDLE_STATUS, &data);
-		if ((data & IDLE_STATUS_MASK) == 0)
-			return 0;
-		msleep(1);
-	}
-	return data;
-}
-
-/*
- * atl1c_phy_config - Timer Call-back
- * @data: pointer to netdev cast into an unsigned long
- */
-static void atl1c_phy_config(unsigned long data)
-{
-	struct atl1c_adapter *adapter = (struct atl1c_adapter *) data;
-	struct atl1c_hw *hw = &adapter->hw;
-	unsigned long flags;
-
-	spin_lock_irqsave(&adapter->mdio_lock, flags);
-	atl1c_restart_autoneg(hw);
-	spin_unlock_irqrestore(&adapter->mdio_lock, flags);
-}
-
 void atl1c_reinit_locked(struct atl1c_adapter *adapter)
 {
 	WARN_ON(in_interrupt());
@@ -299,6 +321,9 @@ static void atl1c_link_chg_event(struct 
 	schedule_work(&adapter->common_task);
 }
 
+static void atl1c_free_ring_resources(struct atl1c_adapter *adapter);
+static int atl1c_open(struct net_device *);
+
 static void atl1c_common_task(struct work_struct *work)
 {
 	struct atl1c_adapter *adapter;
@@ -308,10 +333,10 @@ static void atl1c_common_task(struct wor
 	netdev = adapter->netdev;
 
 	if (adapter->work_event & ATL1C_WORK_EVENT_RESET) {
-		netif_device_detach(netdev);
 		atl1c_down(adapter);
-		atl1c_up(adapter);
-		netif_device_attach(netdev);
+		atl1c_free_ring_resources(adapter);
+		atl1c_phy_disable(&adapter->hw);
+		atl1c_open(netdev);
 		return;
 	}
 
@@ -319,13 +344,6 @@ static void atl1c_common_task(struct wor
 		atl1c_check_link_status(adapter);
 }
 
-
-static void atl1c_del_timer(struct atl1c_adapter *adapter)
-{
-	del_timer_sync(&adapter->phy_config_timer);
-}
-
-
 /*
  * atl1c_tx_timeout - Respond to a Tx Hang
  * @netdev: network interface device structure
@@ -334,6 +352,7 @@ static void atl1c_tx_timeout(struct net_
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
 
+	printk("%s: tx timeout\n", netdev->name);
 	/* Do the reset outside of interrupt context */
 	adapter->work_event |= ATL1C_WORK_EVENT_RESET;
 	schedule_work(&adapter->common_task);
@@ -445,7 +464,7 @@ static int atl1c_set_mac_addr(struct net
 static void atl1c_set_rxbufsize(struct atl1c_adapter *adapter,
 				struct net_device *dev)
 {
-	int mtu = dev->mtu;
+	int mtu = dev->l2mtu;
 
 	adapter->rx_buffer_len = mtu > AT_RX_BUF_SIZE ?
 		roundup(mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN, 8) : AT_RX_BUF_SIZE;
@@ -457,24 +476,27 @@ static void atl1c_set_rxbufsize(struct a
  *
  * Returns 0 on success, negative on failure
  */
-static int atl1c_change_mtu(struct net_device *netdev, int new_mtu)
+static int atl1c_change_mtu(struct net_device *netdev, int new_mtu) {
+	if (new_mtu < 68 || new_mtu > netdev->l2mtu) return -EINVAL;
+	netdev->mtu = new_mtu;
+	return 0;
+}
+
+static int atl1c_change_l2mtu(struct net_device *netdev, int new_mtu)
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
-	int old_mtu   = netdev->mtu;
-	int max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;
+	int old_mtu   = netdev->l2mtu;
 
-	if ((max_frame < ETH_ZLEN + ETH_FCS_LEN) ||
-			(max_frame > MAX_JUMBO_FRAME_SIZE)) {
-		if (netif_msg_link(adapter))
-			dev_warn(&adapter->pdev->dev, "invalid MTU setting\n");
+	// limit l2mtu to safe value (jumbo - 100 should be ok)
+	if (new_mtu < 1500 || new_mtu > (MAX_JUMBO_FRAME_SIZE - 100))
 		return -EINVAL;
-	}
+
 	/* set MTU */
+	netdev->l2mtu = new_mtu;
+	adapter->hw.max_frame_size = new_mtu;
 	if (old_mtu != new_mtu && netif_running(netdev)) {
 		while (test_and_set_bit(__AT_RESETTING, &adapter->flags))
 			msleep(1);
-		netdev->mtu = new_mtu;
-		adapter->hw.max_frame_size = new_mtu;
 		atl1c_set_rxbufsize(adapter, netdev);
 		atl1c_down(adapter);
 		atl1c_up(adapter);
@@ -498,8 +520,11 @@ static int atl1c_mdio_read(struct net_de
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
 	u16 result;
+	unsigned long flags;
 
+	spin_lock_irqsave(&adapter->mdio_lock, flags);
 	atl1c_read_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, &result);
+	spin_unlock_irqrestore(&adapter->mdio_lock, flags);
 	return result;
 }
 
@@ -507,64 +532,11 @@ static void atl1c_mdio_write(struct net_
 			     int reg_num, int val)
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
-
-	atl1c_write_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, val);
-}
-
-/*
- * atl1c_mii_ioctl -
- * @netdev:
- * @ifreq:
- * @cmd:
- */
-static int atl1c_mii_ioctl(struct net_device *netdev,
-			   struct ifreq *ifr, int cmd)
-{
-	struct atl1c_adapter *adapter = netdev_priv(netdev);
-	struct pci_dev *pdev = adapter->pdev;
-	struct mii_ioctl_data *data = if_mii(ifr);
 	unsigned long flags;
-	int retval = 0;
-
-	if (!netif_running(netdev))
-		return -EINVAL;
 
 	spin_lock_irqsave(&adapter->mdio_lock, flags);
-	switch (cmd) {
-	case SIOCGMIIPHY:
-		data->phy_id = 0;
-		break;
-
-	case SIOCGMIIREG:
-		if (atl1c_read_phy_reg(&adapter->hw, data->reg_num & 0x1F,
-				    &data->val_out)) {
-			retval = -EIO;
-			goto out;
-		}
-		break;
-
-	case SIOCSMIIREG:
-		if (data->reg_num & ~(0x1F)) {
-			retval = -EFAULT;
-			goto out;
-		}
-
-		dev_dbg(&pdev->dev, "<atl1c_mii_ioctl> write %x %x",
-				data->reg_num, data->val_in);
-		if (atl1c_write_phy_reg(&adapter->hw,
-				     data->reg_num, data->val_in)) {
-			retval = -EIO;
-			goto out;
-		}
-		break;
-
-	default:
-		retval = -EOPNOTSUPP;
-		break;
-	}
-out:
+	atl1c_write_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, val);
 	spin_unlock_irqrestore(&adapter->mdio_lock, flags);
-	return retval;
 }
 
 /*
@@ -575,14 +547,9 @@ out:
  */
 static int atl1c_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)
 {
-	switch (cmd) {
-	case SIOCGMIIPHY:
-	case SIOCGMIIREG:
-	case SIOCSMIIREG:
-		return atl1c_mii_ioctl(netdev, ifr, cmd);
-	default:
-		return -EOPNOTSUPP;
-	}
+	struct atl1c_adapter *adapter = netdev_priv(netdev);
+	if (!netif_running(netdev)) return -EINVAL;
+	return generic_mii_ioctl(&adapter->mii, if_mii(ifr), cmd, NULL);
 }
 
 /*
@@ -662,8 +629,8 @@ static int __devinit atl1c_sw_init(struc
 	adapter->link_speed = SPEED_0;
 	adapter->link_duplex = FULL_DUPLEX;
 	adapter->num_rx_queues = AT_DEF_RECEIVE_QUEUE;
-	adapter->tpd_ring[0].count = 1024;
-	adapter->rfd_ring[0].count = 512;
+	adapter->tpd_ring[0].count = 256;
+	adapter->rfd_ring[0].count = 256;
 
 	hw->vendor_id = pdev->vendor;
 	hw->device_id = pdev->device;
@@ -680,7 +647,7 @@ static int __devinit atl1c_sw_init(struc
 	hw->intr_mask = IMR_NORMAL_MASK;
 	hw->phy_configured = false;
 	hw->preamble_len = 7;
-	hw->max_frame_size = adapter->netdev->mtu;
+	hw->max_frame_size = adapter->netdev->l2mtu;
 	if (adapter->num_rx_queues < 2) {
 		hw->rss_type = atl1c_rss_disable;
 		hw->rss_mode = atl1c_rss_mode_disable;
@@ -698,7 +665,7 @@ static int __devinit atl1c_sw_init(struc
 	hw->cmb_tpd = 4;
 	hw->cmb_tx_timer = 1;		/* 2 us  */
 	hw->rx_imt = 200;
-	hw->tx_imt = 1000;
+	hw->tx_imt = 10;
 
 	hw->tpd_burst = 5;
 	hw->rfd_burst = 8;
@@ -722,10 +689,11 @@ static int __devinit atl1c_sw_init(struc
 	return 0;
 }
 
-static inline void atl1c_clean_buffer(struct pci_dev *pdev,
+static inline void atl1c_clean_buffer(struct atl1c_adapter *adapter,
 				struct atl1c_buffer *buffer_info, int in_irq)
 {
 	u16 pci_driection;
+	struct sk_buff *skb = buffer_info->skb;
 	if (buffer_info->flags & ATL1C_BUFFER_FREE)
 		return;
 	if (buffer_info->dma) {
@@ -735,17 +703,20 @@ static inline void atl1c_clean_buffer(st
 			pci_driection = PCI_DMA_TODEVICE;
 
 		if (buffer_info->flags & ATL1C_PCIMAP_SINGLE)
-			pci_unmap_single(pdev, buffer_info->dma,
+			pci_unmap_single(adapter->pdev, buffer_info->dma,
 					buffer_info->length, pci_driection);
 		else if (buffer_info->flags & ATL1C_PCIMAP_PAGE)
-			pci_unmap_page(pdev, buffer_info->dma,
+			pci_unmap_page(adapter->pdev, buffer_info->dma,
 					buffer_info->length, pci_driection);
 	}
-	if (buffer_info->skb) {
-		if (in_irq)
-			dev_kfree_skb_irq(buffer_info->skb);
-		else
-			dev_kfree_skb(buffer_info->skb);
+	if (skb) {
+		if (skb_queue_len(&adapter->rx_recycle) < AT_MAX_RECEIVE_QUEUE
+		    && skb_recycle_check(skb, adapter->rx_buffer_len)) {
+			__skb_queue_head(&adapter->rx_recycle, skb);
+		}
+		else {
+			dev_kfree_skb_any(skb);
+		}
 	}
 	buffer_info->dma = 0;
 	buffer_info->skb = NULL;
@@ -760,13 +731,12 @@ static void atl1c_clean_tx_ring(struct a
 {
 	struct atl1c_tpd_ring *tpd_ring = &adapter->tpd_ring[type];
 	struct atl1c_buffer *buffer_info;
-	struct pci_dev *pdev = adapter->pdev;
 	u16 index, ring_count;
 
 	ring_count = tpd_ring->count;
 	for (index = 0; index < ring_count; index++) {
 		buffer_info = &tpd_ring->buffer_info[index];
-		atl1c_clean_buffer(pdev, buffer_info, 0);
+		atl1c_clean_buffer(adapter, buffer_info, 0);
 	}
 
 	/* Zero out Tx-buffers */
@@ -785,13 +755,12 @@ static void atl1c_clean_rx_ring(struct a
 	struct atl1c_rfd_ring *rfd_ring = adapter->rfd_ring;
 	struct atl1c_rrd_ring *rrd_ring = adapter->rrd_ring;
 	struct atl1c_buffer *buffer_info;
-	struct pci_dev *pdev = adapter->pdev;
 	int i, j;
 
 	for (i = 0; i < adapter->num_rx_queues; i++) {
 		for (j = 0; j < rfd_ring[i].count; j++) {
 			buffer_info = &rfd_ring[i].buffer_info[j];
-			atl1c_clean_buffer(pdev, buffer_info, 0);
+			atl1c_clean_buffer(adapter, buffer_info, 0);
 		}
 		/* zero out the descriptor ring */
 		memset(rfd_ring[i].desc, 0, rfd_ring[i].size);
@@ -1459,6 +1428,8 @@ static int atl1c_configure(struct atl1c_
 	atl1c_configure_rss(adapter);
 	atl1c_configure_dma(adapter);
 
+	AT_WRITE_REG(hw, REG_LED_CONFIG, 0xcf01cf31);
+
 	return 0;
 }
 
@@ -1501,7 +1472,9 @@ static struct net_device_stats *atl1c_ge
 	struct atl1c_hw_stats  *hw_stats = &adapter->hw_stats;
 	struct net_device_stats *net_stats = &adapter->net_stats;
 
+	if (netif_carrier_ok(netdev)) {
 	atl1c_update_hw_stats(adapter);
+	}
 	net_stats->rx_packets = hw_stats->rx_ok;
 	net_stats->tx_packets = hw_stats->tx_ok;
 	net_stats->rx_bytes   = hw_stats->rx_byte_cnt;
@@ -1545,7 +1518,6 @@ static bool atl1c_clean_tx_irq(struct at
 	struct atl1c_tpd_ring *tpd_ring = (struct atl1c_tpd_ring *)
 				&adapter->tpd_ring[type];
 	struct atl1c_buffer *buffer_info;
-	struct pci_dev *pdev = adapter->pdev;
 	u16 next_to_clean = atomic_read(&tpd_ring->next_to_clean);
 	u16 hw_next_to_clean;
 	u16 shift;
@@ -1557,20 +1529,19 @@ static bool atl1c_clean_tx_irq(struct at
 		shift = MB_NTPD_CONS_IDX_SHIFT;
 
 	AT_READ_REG(&adapter->hw, REG_MB_PRIO_CONS_IDX, &data);
-	hw_next_to_clean = (data >> shift) & MB_PRIO_PROD_IDX_MASK;
+	hw_next_to_clean = (data >> shift) & (tpd_ring->count - 1);
 
 	while (next_to_clean != hw_next_to_clean) {
 		buffer_info = &tpd_ring->buffer_info[next_to_clean];
-		atl1c_clean_buffer(pdev, buffer_info, 1);
+		atl1c_clean_buffer(adapter, buffer_info, 1);
 		if (++next_to_clean == tpd_ring->count)
 			next_to_clean = 0;
 		atomic_set(&tpd_ring->next_to_clean, next_to_clean);
-	}
 
-	if (netif_queue_stopped(adapter->netdev) &&
-			netif_carrier_ok(adapter->netdev)) {
+		if (netif_queue_stopped(adapter->netdev)) {
 		netif_wake_queue(adapter->netdev);
 	}
+	}
 
 	return true;
 }
@@ -1587,36 +1558,30 @@ static irqreturn_t atl1c_intr(int irq, v
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
 	struct pci_dev *pdev = adapter->pdev;
 	struct atl1c_hw *hw = &adapter->hw;
-	int max_ints = AT_MAX_INT_WORK;
-	int handled = IRQ_NONE;
 	u32 status;
 	u32 reg_data;
 
-	do {
 		AT_READ_REG(hw, REG_ISR, &reg_data);
 		status = reg_data & hw->intr_mask;
 
+/*
 		if (status == 0 || (status & ISR_DIS_INT) != 0) {
-			if (max_ints != AT_MAX_INT_WORK)
-				handled = IRQ_HANDLED;
-			break;
+		AT_WRITE_REG(&adapter->hw, REG_ISR, 0);
+		return IRQ_NONE;
 		}
+*/
+
 		/* link event */
 		if (status & ISR_GPHY)
 			atl1c_clear_phy_int(adapter);
-		/* Ack ISR */
-		AT_WRITE_REG(hw, REG_ISR, status | ISR_DIS_INT);
-		if (status & ISR_RX_PKT) {
+	if (status & (ISR_RX_PKT | ISR_TX_PKT)) {
 			if (likely(napi_schedule_prep(&adapter->napi))) {
-				hw->intr_mask &= ~ISR_RX_PKT;
+			hw->intr_mask &= ~(ISR_RX_PKT | ISR_TX_PKT);
 				AT_WRITE_REG(hw, REG_IMR, hw->intr_mask);
 				__napi_schedule(&adapter->napi);
 			}
 		}
-		if (status & ISR_TX_PKT)
-			atl1c_clean_tx_irq(adapter, atl1c_trans_normal);
 
-		handled = IRQ_HANDLED;
 		/* check if PCIE PHY Link down */
 		if (status & ISR_ERROR) {
 			if (netif_msg_hw(adapter))
@@ -1626,28 +1591,20 @@ static irqreturn_t atl1c_intr(int irq, v
 			/* reset MAC */
 			hw->intr_mask &= ~ISR_ERROR;
 			AT_WRITE_REG(hw, REG_IMR, hw->intr_mask);
+
 			adapter->work_event |= ATL1C_WORK_EVENT_RESET;
 			schedule_work(&adapter->common_task);
-			break;
 		}
 
-		if (status & ISR_OVER)
-			if (netif_msg_intr(adapter))
-				dev_warn(&pdev->dev,
-					"TX/RX overflow (status = 0x%x)\n",
-					status & ISR_OVER);
-
 		/* link event */
 		if (status & (ISR_GPHY | ISR_MANUAL)) {
 			adapter->net_stats.tx_carrier_errors++;
 			atl1c_link_chg_event(adapter);
-			break;
 		}
 
-	} while (--max_ints > 0);
 	/* re-enable Interrupt*/
-	AT_WRITE_REG(&adapter->hw, REG_ISR, 0);
-	return handled;
+	AT_WRITE_REG(&adapter->hw, REG_ISR, 0x7fffffff);
+	return IRQ_HANDLED;
 }
 
 static inline void atl1c_rx_checksum(struct atl1c_adapter *adapter,
@@ -1681,7 +1638,10 @@ static int atl1c_alloc_rx_buffer(struct 
 	while (next_info->flags & ATL1C_BUFFER_FREE) {
 		rfd_desc = ATL1C_RFD_DESC(rfd_ring, rfd_next_to_use);
 
-		skb = dev_alloc_skb(adapter->rx_buffer_len);
+		skb = __skb_dequeue(&adapter->rx_recycle);
+		if (!skb) {
+			skb = dev_alloc_skb(adapter->rx_buffer_len + 32);
+		}
 		if (unlikely(!skb)) {
 			if (netif_msg_rx_err(adapter))
 				dev_warn(&pdev->dev, "alloc rx buffer failed\n");
@@ -1729,7 +1689,7 @@ static void atl1c_clean_rrd(struct atl1c
 	/* the relationship between rrd and rfd is one map one */
 	for (i = 0; i < num; i++, rrs = ATL1C_RRD_DESC(rrd_ring,
 					rrd_ring->next_to_clean)) {
-		rrs->word3 &= ~RRS_RXD_UPDATED;
+		rrs->word3 &= cpu_to_le32(~RRS_RXD_UPDATED);
 		if (++rrd_ring->next_to_clean == rrd_ring->count)
 			rrd_ring->next_to_clean = 0;
 	}
@@ -1742,7 +1702,7 @@ static void atl1c_clean_rfd(struct atl1c
 	u16 rfd_index;
 	struct atl1c_buffer *buffer_info = rfd_ring->buffer_info;
 
-	rfd_index = (rrs->word0 >> RRS_RX_RFD_INDEX_SHIFT) &
+	rfd_index = (le32_to_cpu(rrs->word0) >> RRS_RX_RFD_INDEX_SHIFT) &
 			RRS_RX_RFD_INDEX_MASK;
 	for (i = 0; i < num; i++) {
 		buffer_info[rfd_index].skb = NULL;
@@ -1773,9 +1733,9 @@ static void atl1c_clean_rx_irq(struct at
 			break;
 		rrs = ATL1C_RRD_DESC(rrd_ring, rrd_ring->next_to_clean);
 		if (likely(RRS_RXD_IS_VALID(rrs->word3))) {
-			rfd_num = (rrs->word0 >> RRS_RX_RFD_CNT_SHIFT) &
-				RRS_RX_RFD_CNT_MASK;
-			if (unlikely(rfd_num != 1))
+			rfd_num = (le32_to_cpu(rrs->word0) >>
+				   RRS_RX_RFD_CNT_SHIFT) & RRS_RX_RFD_CNT_MASK;
+			if (unlikely(rfd_num) != 1)
 				/* TODO support mul rfd*/
 				if (netif_msg_rx_err(adapter))
 					dev_warn(&pdev->dev,
@@ -1786,20 +1746,22 @@ static void atl1c_clean_rx_irq(struct at
 		}
 rrs_checked:
 		atl1c_clean_rrd(rrd_ring, rrs, rfd_num);
-		if (rrs->word3 & (RRS_RX_ERR_SUM | RRS_802_3_LEN_ERR)) {
+		if (le32_to_cpu(rrs->word3) &
+		    (RRS_RX_ERR_SUM | RRS_802_3_LEN_ERR)) {
 			atl1c_clean_rfd(rfd_ring, rrs, rfd_num);
 				if (netif_msg_rx_err(adapter))
 					dev_warn(&pdev->dev,
 						"wrong packet! rrs word3 is %x\n",
-						rrs->word3);
+						 le32_to_cpu(rrs->word3));
 			continue;
 		}
 
-		length = le16_to_cpu((rrs->word3 >> RRS_PKT_SIZE_SHIFT) &
-				RRS_PKT_SIZE_MASK);
+		length = (le32_to_cpu(rrs->word3) >> RRS_PKT_SIZE_SHIFT) &
+			RRS_PKT_SIZE_MASK;
 		/* Good Receive */
 		if (likely(rfd_num == 1)) {
-			rfd_index = (rrs->word0 >> RRS_RX_RFD_INDEX_SHIFT) &
+			rfd_index = (le32_to_cpu(rrs->word0) >>
+				     RRS_RX_RFD_INDEX_SHIFT) &
 					RRS_RX_RFD_INDEX_MASK;
 			buffer_info = &rfd_ring->buffer_info[rfd_index];
 			pci_unmap_single(pdev, buffer_info->dma,
@@ -1816,7 +1778,8 @@ rrs_checked:
 		skb_put(skb, length - ETH_FCS_LEN);
 		skb->protocol = eth_type_trans(skb, netdev);
 		atl1c_rx_checksum(adapter, skb, rrs);
-		if (unlikely(adapter->vlgrp) && rrs->word3 & RRS_VLAN_INS) {
+		if (unlikely(adapter->vlgrp) &&
+		    le32_to_cpu(rrs->word3) & RRS_VLAN_INS) {
 			u16 vlan;
 
 			AT_TAG_TO_VLAN(rrs->vlan_tag, vlan);
@@ -1840,20 +1803,29 @@ static int atl1c_clean(struct napi_struc
 {
 	struct atl1c_adapter *adapter =
 			container_of(napi, struct atl1c_adapter, napi);
+	struct atl1c_hw *hw = &adapter->hw;
 	int work_done = 0;
+	u32 status;
 
-	/* Keep link state information with original netdev */
-	if (!netif_carrier_ok(adapter->netdev))
-		goto quit_polling;
+	atl1c_clean_tx_irq(adapter, atl1c_trans_normal);
 	/* just enable one RXQ */
 	atl1c_clean_rx_irq(adapter, 0, &work_done, budget);
 
-	if (work_done < budget) {
-quit_polling:
+	if (work_done >= budget) {
+		return work_done;
+	}
+
+	AT_READ_REG(hw, REG_ISR, &status);
+	if (status & (ISR_RX_PKT | ISR_TX_PKT)) {
+		if (netif_carrier_ok(adapter->netdev)) {
+			AT_WRITE_REG(&adapter->hw, REG_ISR, ISR_RX_PKT | ISR_TX_PKT);
+			return budget;
+		}
+	}
+
 		napi_complete(napi);
-		adapter->hw.intr_mask |= ISR_RX_PKT;
+	adapter->hw.intr_mask |= ISR_RX_PKT | ISR_TX_PKT;
 		AT_WRITE_REG(&adapter->hw, REG_IMR, adapter->hw.intr_mask);
-	}
 	return work_done;
 }
 
@@ -1974,7 +1946,8 @@ static int atl1c_tso_csum(struct atl1c_a
 							ip_hdr(skb)->saddr,
 							ip_hdr(skb)->daddr,
 							0, IPPROTO_TCP, 0);
-				(*tpd)->word1 |= 1 << TPD_IPV4_PACKET_SHIFT;
+				(*tpd)->word1 |=
+					cpu_to_le32(1 << TPD_IPV4_PACKET_SHIFT);
 			}
 		}
 
@@ -1998,17 +1971,19 @@ static int atl1c_tso_csum(struct atl1c_a
 						&ipv6_hdr(skb)->saddr,
 						&ipv6_hdr(skb)->daddr,
 						0, IPPROTO_TCP, 0);
-			etpd->word1 |= 1 << TPD_LSO_EN_SHIFT;
-			etpd->word1 |= 1 << TPD_LSO_VER_SHIFT;
+			etpd->word1 |= cpu_to_le32(1 << TPD_LSO_EN_SHIFT);
+			etpd->word1 |= cpu_to_le32(1 << TPD_LSO_VER_SHIFT);
 			etpd->pkt_len = cpu_to_le32(skb->len);
-			(*tpd)->word1 |= 1 << TPD_LSO_VER_SHIFT;
+			(*tpd)->word1 |= cpu_to_le32(1 << TPD_LSO_VER_SHIFT);
 		}
 
-		(*tpd)->word1 |= 1 << TPD_LSO_EN_SHIFT;
-		(*tpd)->word1 |= (skb_transport_offset(skb) & TPD_TCPHDR_OFFSET_MASK) <<
-				TPD_TCPHDR_OFFSET_SHIFT;
-		(*tpd)->word1 |= (skb_shinfo(skb)->gso_size & TPD_MSS_MASK) <<
-				TPD_MSS_SHIFT;
+		(*tpd)->word1 |= cpu_to_le32(1 << TPD_LSO_EN_SHIFT);
+		(*tpd)->word1 |= cpu_to_le32(
+			(skb_transport_offset(skb) & TPD_TCPHDR_OFFSET_MASK) <<
+			TPD_TCPHDR_OFFSET_SHIFT);
+		(*tpd)->word1 |= cpu_to_le32(
+			(skb_shinfo(skb)->gso_size & TPD_MSS_MASK) <<
+			TPD_MSS_SHIFT);
 		return 0;
 	}
 
@@ -2025,11 +2000,13 @@ check_sum:
 		} else {
 			css = cso + skb->csum_offset;
 
-			(*tpd)->word1 |= ((cso >> 1) & TPD_PLOADOFFSET_MASK) <<
-					TPD_PLOADOFFSET_SHIFT;
-			(*tpd)->word1 |= ((css >> 1) & TPD_CCSUM_OFFSET_MASK) <<
-					TPD_CCSUM_OFFSET_SHIFT;
-			(*tpd)->word1 |= 1 << TPD_CCSUM_EN_SHIFT;
+			(*tpd)->word1 |= cpu_to_le32(
+				((cso >> 1) & TPD_PLOADOFFSET_MASK) <<
+				TPD_PLOADOFFSET_SHIFT);
+			(*tpd)->word1 |= cpu_to_le32(
+				((css >> 1) & TPD_CCSUM_OFFSET_MASK) <<
+				TPD_CCSUM_OFFSET_SHIFT);
+			(*tpd)->word1 |= cpu_to_le32(1 << TPD_CCSUM_EN_SHIFT);
 		}
 	}
 	return 0;
@@ -2050,7 +2027,7 @@ static void atl1c_tx_map(struct atl1c_ad
 	int tso;
 
 	nr_frags = skb_shinfo(skb)->nr_frags;
-	tso = (tpd->word1 >> TPD_LSO_EN_SHIFT) & TPD_LSO_EN_MASK;
+	tso = (le32_to_cpu(tpd->word1) >> TPD_LSO_EN_SHIFT) & TPD_LSO_EN_MASK;
 	if (tso) {
 		/* TSO */
 		map_len = hdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);
@@ -2112,7 +2089,7 @@ static void atl1c_tx_map(struct atl1c_ad
 	}
 
 	/* The last tpd */
-	use_tpd->word1 |= 1 << TPD_EOP_SHIFT;
+	use_tpd->word1 |= cpu_to_le32(1 << TPD_EOP_SHIFT);
 	/* The last buffer info contain the skb address,
 	   so it will be free after unmap */
 	buffer_info->skb = skb;
@@ -2161,10 +2138,6 @@ static netdev_tx_t atl1c_xmit_frame(stru
 			dev_info(&adapter->pdev->dev, "tx locked\n");
 		return NETDEV_TX_LOCKED;
 	}
-	if (skb->mark == 0x01)
-		type = atl1c_trans_high;
-	else
-		type = atl1c_trans_normal;
 
 	if (atl1c_tpd_avail(adapter, type) < tpd_req) {
 		/* no enough descriptor, just stop queue */
@@ -2188,16 +2161,17 @@ static netdev_tx_t atl1c_xmit_frame(stru
 
 		vlan = cpu_to_le16(vlan);
 		AT_VLAN_TO_TAG(vlan, tag);
-		tpd->word1 |= 1 << TPD_INS_VTAG_SHIFT;
+		tpd->word1 |= cpu_to_le32(1 << TPD_INS_VTAG_SHIFT);
 		tpd->vlan_tag = tag;
 	}
 
 	if (skb_network_offset(skb) != ETH_HLEN)
-		tpd->word1 |= 1 << TPD_ETH_TYPE_SHIFT; /* Ethernet frame */
+		tpd->word1 |= cpu_to_le32(1 << TPD_ETH_TYPE_SHIFT); /* Ethernet frame */
 
 	atl1c_tx_map(adapter, skb, tpd, type);
 	atl1c_tx_queue(adapter, skb, tpd, type);
 
+	netdev->trans_start = jiffies;
 	spin_unlock_irqrestore(&adapter->tx_lock, flags);
 	return NETDEV_TX_OK;
 }
@@ -2255,6 +2229,7 @@ int atl1c_up(struct atl1c_adapter *adapt
 	int err;
 	int i;
 
+	skb_queue_head_init(&adapter->rx_recycle);
 	netif_carrier_off(netdev);
 	atl1c_init_ring_ptrs(adapter);
 	atl1c_set_multi(netdev);
@@ -2294,12 +2269,14 @@ void atl1c_down(struct atl1c_adapter *ad
 {
 	struct net_device *netdev = adapter->netdev;
 
-	atl1c_del_timer(adapter);
 	adapter->work_event = 0; /* clear all event */
 	/* signal that we're down so the interrupt handler does not
 	 * reschedule our watchdog timer */
 	set_bit(__AT_DOWN, &adapter->flags);
 	netif_carrier_off(netdev);
+	// XXX BLACK MAGIC: it seems that chip needs to tx out the queue before
+	// disabling otherwise after enabling back, interrupts may not happen
+	mdelay(500);
 	napi_disable(&adapter->napi);
 	atl1c_irq_disable(adapter);
 	atl1c_free_irq(adapter);
@@ -2313,6 +2290,7 @@ void atl1c_down(struct atl1c_adapter *ad
 	atl1c_clean_tx_ring(adapter, atl1c_trans_normal);
 	atl1c_clean_tx_ring(adapter, atl1c_trans_high);
 	atl1c_clean_rx_ring(adapter);
+	skb_queue_purge(&adapter->rx_recycle);
 }
 
 /*
@@ -2327,11 +2305,32 @@ void atl1c_down(struct atl1c_adapter *ad
  * handler is registered with the OS, the watchdog timer is started,
  * and the stack is notified that the interface is ready.
  */
+
+#ifdef CONFIG_RB1100
+static int bypass_disabled = 0;
+#endif
+
 static int atl1c_open(struct net_device *netdev)
 {
 	struct atl1c_adapter *adapter = netdev_priv(netdev);
 	int err;
 
+#ifdef CONFIG_RB1100
+//	printk("%s: open %x\n", netdev->name, adapter->pdev->bus->number);
+	if (machine_is(rb1100)) {
+		if (adapter->pdev->bus->number == 2 ||
+		    adapter->pdev->bus->number == 6) {
+			if (!bypass_disabled) {
+				change_latch(0x40, 0);
+			}
+			++bypass_disabled;
+		}
+	}
+#endif
+
+	atl1c_phy_reset(&adapter->hw);
+	atl1c_phy_init(&adapter->hw);
+
 	/* disallow open during test */
 	if (test_bit(__AT_TESTING, &adapter->flags))
 		return -EBUSY;
@@ -2379,6 +2378,21 @@ static int atl1c_close(struct net_device
 	WARN_ON(test_bit(__AT_RESETTING, &adapter->flags));
 	atl1c_down(adapter);
 	atl1c_free_ring_resources(adapter);
+	atl1c_phy_disable(&adapter->hw);
+
+#ifdef CONFIG_RB1100
+//	printk("%s: close %x\n", netdev->name, adapter->pdev->bus->number);
+	if (machine_is(rb1100)) {
+		if (adapter->pdev->bus->number == 2 ||
+		    adapter->pdev->bus->number == 6) {
+			--bypass_disabled;
+			if (!bypass_disabled) {
+				change_latch(0, 0x40);
+			}
+		}
+	}
+#endif
+
 	return 0;
 }
 
@@ -2539,6 +2553,7 @@ static const struct net_device_ops atl1c
 	.ndo_set_mac_address 	= atl1c_set_mac_addr,
 	.ndo_set_multicast_list = atl1c_set_multi,
 	.ndo_change_mtu		= atl1c_change_mtu,
+	.ndo_change_l2mtu	= atl1c_change_l2mtu,
 	.ndo_do_ioctl		= atl1c_ioctl,
 	.ndo_tx_timeout		= atl1c_tx_timeout,
 	.ndo_get_stats		= atl1c_get_stats,
@@ -2556,6 +2571,9 @@ static int atl1c_init_netdev(struct net_
 	netdev->irq  = pdev->irq;
 	netdev->netdev_ops = &atl1c_netdev_ops;
 	netdev->watchdog_timeo = AT_TX_WATCHDOG;
+
+	netdev->l2mtu = 1600;
+
 	atl1c_set_ethtool_ops(netdev);
 
 	/* TODO: add when ready */
@@ -2651,9 +2669,8 @@ static int __devinit atl1c_probe(struct 
 	adapter->mii.mdio_write = atl1c_mdio_write;
 	adapter->mii.phy_id_mask = 0x1f;
 	adapter->mii.reg_num_mask = MDIO_REG_ADDR_MASK;
+	adapter->mii.supports_gmii = 1;
 	netif_napi_add(netdev, &adapter->napi, atl1c_clean, 64);
-	setup_timer(&adapter->phy_config_timer, atl1c_phy_config,
-			(unsigned long)adapter);
 	/* setup the private structure */
 	err = atl1c_sw_init(adapter);
 	if (err) {
@@ -2664,7 +2681,7 @@ static int __devinit atl1c_probe(struct 
 			ATL1C_PCIE_PHY_RESET);
 
 	/* Init GPHY as early as possible due to power saving issue  */
-	atl1c_phy_reset(&adapter->hw);
+//	atl1c_phy_reset(&adapter->hw);
 
 	err = atl1c_reset_mac(&adapter->hw);
 	if (err) {
@@ -2675,11 +2692,13 @@ static int __devinit atl1c_probe(struct 
 	device_init_wakeup(&pdev->dev, 1);
 	/* reset the controller to
 	 * put the device in a known good starting state */
+/*
 	err = atl1c_phy_init(&adapter->hw);
 	if (err) {
 		err = -EIO;
 		goto err_reset;
 	}
+*/
 	if (atl1c_read_mac_addr(&adapter->hw) != 0) {
 		err = -EIO;
 		dev_err(&pdev->dev, "get mac address failed\n");
diff -puNrb linux-2.6.35/drivers/net/bonding/bonding.h linux/drivers/net/bonding/bonding.h
--- linux-2.6.35/drivers/net/bonding/bonding.h	2011-04-26 16:28:12.152789845 +0300
+++ linux/drivers/net/bonding/bonding.h	2011-05-02 10:08:26.623103660 +0300
@@ -15,6 +15,9 @@
 #ifndef _LINUX_BONDING_H
 #define _LINUX_BONDING_H
 
+#undef CONFIG_IPV6
+#undef CONFIG_IPV6_MODULE
+
 #include <linux/timer.h>
 #include <linux/proc_fs.h>
 #include <linux/if_bonding.h>
diff -puNrb linux-2.6.35/drivers/net/bonding/bond_main.c linux/drivers/net/bonding/bond_main.c
--- linux-2.6.35/drivers/net/bonding/bond_main.c	2011-04-26 16:28:12.162790000 +0300
+++ linux/drivers/net/bonding/bond_main.c	2011-05-02 10:08:26.652591795 +0300
@@ -89,7 +89,8 @@
 #define BOND_LINK_MON_INTERV	0
 #define BOND_LINK_ARP_INTERV	0
 
-static int max_bonds	= BOND_DEFAULT_MAX_BONDS;
+static char *devname = NULL;
+static int max_bonds	= 1;
 static int num_grat_arp = 1;
 static int num_unsol_na = 1;
 static int miimon	= BOND_LINK_MON_INTERV;
@@ -108,6 +109,8 @@ static char *arp_validate;
 static char *fail_over_mac;
 static struct bond_params bonding_defaults;
 
+module_param(devname, charp, 0);
+MODULE_PARM_DESC(devname, "Iface name");
 module_param(max_bonds, int, 0);
 MODULE_PARM_DESC(max_bonds, "Max number of bonded devices");
 module_param(num_grat_arp, int, 0644);
@@ -3004,12 +3007,16 @@ static void bond_ab_arp_probe(struct bon
 			bond->current_arp_slave->dev->name,
 			bond->curr_active_slave->dev->name);
 
+	bond_for_each_slave(bond, slave, i) {
+		if (IS_UP(slave->dev)) {
+			bond_arp_send_all(bond, slave);
+		}
+	}
 	if (bond->curr_active_slave) {
-		bond_arp_send_all(bond, bond->curr_active_slave);
+//		bond_arp_send_all(bond, bond->curr_active_slave);
 		read_unlock(&bond->curr_slave_lock);
 		return;
 	}
-
 	read_unlock(&bond->curr_slave_lock);
 
 	/* if we don't have a curr_active_slave, search for the next available
@@ -4248,6 +4255,10 @@ static int bond_xmit_roundrobin(struct s
 			res = bond_dev_queue_xmit(bond, skb, slave->dev);
 			break;
 		}
+		else {
+			/* need to incr rr_tx_counter for proper balancing */
+			bond->rr_tx_counter++;
+		}
 	}
 
 out:
@@ -5095,7 +5106,7 @@ static int __init bonding_init(void)
 		goto err_link;
 
 	for (i = 0; i < max_bonds; i++) {
-		res = bond_create(&init_net, NULL);
+		res = bond_create(&init_net, devname);
 		if (res)
 			goto err;
 	}
diff -puNrb linux-2.6.35/drivers/net/bonding/Makefile linux/drivers/net/bonding/Makefile
--- linux-2.6.35/drivers/net/bonding/Makefile	2011-04-26 16:28:12.162790000 +0300
+++ linux/drivers/net/bonding/Makefile	2011-05-02 10:08:26.703102788 +0300
@@ -6,6 +6,6 @@ obj-$(CONFIG_BONDING) += bonding.o
 
 bonding-objs := bond_main.o bond_3ad.o bond_alb.o bond_sysfs.o
 
-ipv6-$(subst m,y,$(CONFIG_IPV6)) += bond_ipv6.o
+#ipv6-$(subst m,y,$(CONFIG_IPV6)) += bond_ipv6.o
 bonding-objs += $(ipv6-y)
 
diff -puNrb linux-2.6.35/drivers/net/crether.c linux/drivers/net/crether.c
--- linux-2.6.35/drivers/net/crether.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/net/crether.c	2011-05-02 10:08:26.713103403 +0300
@@ -0,0 +1,814 @@
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+#include <asm/rb/cr.h>
+
+#define TX_RING_SIZE	128
+#define TX_QUEUE_LEN	120
+#define RX_RING_SIZE	128
+
+#define PACKET_BUF_LEN 1636
+
+
+#define DMA_BASE (CR_ETHER_BASE + 0x1000)
+
+#define CTR_REG(reg) \
+        ((*(volatile u32 *) KSEG1ADDR(CR_CNTRL_BASE + (reg))))
+#define MAC_REG(reg) \
+        ((*(volatile u32 *) KSEG1ADDR(CR_ETHER_BASE + (reg))))
+#define DMA_REG(reg) \
+        ((*(volatile u32 *) KSEG1ADDR(DMA_BASE + (reg))))
+
+
+#define MAC_CONTROL	    0x00
+#define MAC_ADDR_HIGH       0x04
+#define MAC_ADDR_LOW        0x08
+#define MAC_MULTI_HASH_HIGH 0x0C
+#define MAC_MULTI_HASH_LOW  0x10
+#define MAC_MII_ADDR        0x14
+#define MAC_MII_DATA        0x18
+#define MAC_FLOW_CONTROL    0x1C
+
+#define DMA_BUS_MODE       0x00
+#define DMA_TX_POLL_DEMAND 0x04
+#define DMA_RX_POLL_DEMAND 0x08
+#define DMA_RX_BASE_ADDR   0x0C
+#define DMA_TX_BASE_ADDR   0x10
+#define DMA_STATUS         0x14
+#define DMA_CONTROL        0x18
+#define DMA_INT_ENABLE     0x1C
+#define DMA_MISSED_COUNT   0x20
+#define DMA_TX_CURR_ADDR   0x50
+#define DMA_RX_CURR_ADDR   0x54
+
+// MAC_CONTROL
+#define MAC_FILTER_OFF         0x80000000 // Receive all incoming packets RW
+#define MAC_BIG_ENDIAN         0x40000000 // Big endian mode RW
+#define MAC_HEART_BEAT_OFF     0x10000000 // Heartbeat signal qual disable RW
+#define MAC_SELECT_SRL         0x08000000 // Select SRL port RW
+#define MAC_DISABLE_RX_OWN     0x00800000 // Disable receive own packets RW
+#define MAC_LOOPBACK_EXT       0x00400000 // External loopback RW
+#define MAC_LOOPBACK_INT       0x00200000 // Internal loopback
+#define MAC_FULL_DUPLEX        0x00100000 // Full duplex mode RW
+#define MAC_MCAST_FILTER_OFF   0x00080000 // Pass all multicast packets RW
+#define MAC_PROMISC_MODE_ON    0x00040000 // Receive all valid packets RW 1
+#define MAC_FILTER_INVERSE     0x00020000 // Inverse filtering RW
+#define MAC_BAD_FRAMES_ENABLE  0x00010000 // Pass bad frames RW
+#define MAC_PERFECT_FILTER_OFF 0x00008000 // Hash filtering only RW
+#define MAC_HASH_FILTER_ON     0x00002000 // perform hash filtering RW
+#define MAC_LATE_COLLISION_ON  0x00001000 // Enable late collision control RW
+#define MAC_BROADCAST_DISABLE  0x00000800 // Disable reception of bcast RW
+#define MAC_RETRY_DISABLE      0x00000400 // Disable retransmission RW
+#define MAC_PAD_STRIP_ENABLE   0x00000100 // Pad stripping enable RW
+#define MAC_DEFERRAL_ENABLE    0x00000020 // Deferral check enable RW
+#define MAC_TX_ENABLE          0x00000008 // Transmitter enable RW
+#define MAC_RX_ENABLE          0x00000004 // Receiver enable RW
+
+// MAC_MII_ADDR
+#define MII_DEV_MASK  0x0000F800 // MII device address
+#define MII_DEV_SHIFT         11
+#define MII_REG_MASK  0x000007C0 // MII register
+#define MII_REG_SHIFT          6
+#define MII_WRITE     0x00000002 // Write to register
+#define MII_READ               0 // Read from register
+#define MII_BUSY      0x00000001 // MII interface is busy
+
+// MAC_MII_DATA
+#define MII_DATA_MASK 0x0000FFFF // MII Data
+
+// MAC_FLOW_CONTROL
+#define MAC_PAUSE_TIME_MASK       0xFFFF0000  // PAUSE TIME field in ctrl frame
+#define MAC_PAUSE_TIME_SHIFT              15
+#define MAC_CONTROL_FRAME_ENABLE  0x00000004  // pass ctrl frames to host
+#define MAC_CONTROL_FRAME_DISABLE          0  // Don't pass ctrl frames to host
+#define MAC_FLOW_CONTROL_ENABLE   0x00000002  // Enable flow control
+#define MAC_FLOW_CONTROL_DISABLE           0  // Disable flow control
+#define MAC_SEND_PAUSE_FRAME      0x00000001  // send pause frame
+
+
+// DMA_BUS_MODE
+#define DMA_RX_ALIGN16           0x01000000 // rx to align on odd hw bndry
+#define DMA_BIG_ENDIAN_DES       0x00100000 // Big endian data buffer descr RW
+#define DMA_BURST_LENGTH32       0x00002000 // DMA_ burst length 32 RW
+#define DMA_BURST_LENGTH_16      0x00001000 // DMA_ burst length 16
+#define DMA_BURST_LENGTH_8       0x00000800 // DMA_ burst length 8
+#define DMA_BURST_LENGHT_4       0x00000400 // DMA_ burst length 4
+#define DMA_BURST_LENGTH_2       0x00000200 // DMA_ burst length 2
+#define DMA_BURST_LENGTH_1       0x00000100 // DMA_ burst length 1
+#define DMA_BURST_LENGTH_0       0x00000000 // DMA_ burst length 0
+#define DMA_BIG_ENDIAN_DATA      0x00000080 // Big endian data buffers RW
+#define DMA_DESCRIPTOR_SKIP_16   0x00000040 // number of dwords to skip RW
+#define DMA_DESCRIPTOR_SKIP_8    0x00000020 // between two unchained descr
+#define DMA_DESCRIPTOR_SKIP_4    0x00000010
+#define DMA_DESCRIPTOR_SKIP_2    0x00000008
+#define DMA_DESCRIPTOR_SKIP_1    0x00000004
+#define DMA_DESCRIPTOR_SKIP_0             0
+#define DMA_RECEIVE_PRIORITY_OFF 0x00000002 // equal rx and tx priorities RW
+#define DMA_RECEIVE_PRIORITY_ON           0 // Rx has prioryty over Tx 0
+#define DMA_RESET_ON             0x00000001 // Reset DMA engine RW
+
+// DMA_STATUS
+#define DMA_RX_ABORT         0x01000000 // receiver bus abort R 0
+#define DMA_TX_ABORT         0x00800000 // transmitter bus abort R 0
+
+// DMA_CONTROL
+#define DMA_STORE_AND_FORWARD 0x00000000 // Store and forward RW 0
+#define DMA_TX_THRESH_256     0x0000c000 // Non-SF threshold is 256 words
+#define DMA_TX_THRESH_128     0x00008000 // Non-SF threshold is 128 words
+#define DMA_TX_THRESH_64      0x00004000 // Non-SF threshold is 64 words
+#define DMA_TX_THRESH_32      0x00000000 // Non-SF threshold is 32 words
+#define DMA_TX_START          0x00002000 // Start/Stop transmission RW 0
+#define DMA_TX_SECOND_FRAME   0x00000004 // Operate on second frame RW 0
+#define DMA_RX_START          0x00000002 // Start/Stop reception RW 0
+
+// DMA_INT_ENABLE
+#define DMA_INT_NORMAL       0x00010000 // Normal interrupt summary RW 0
+#define DMA_INT_ABNORMAL     0x00008000 // Abnormal interrupt summary RW 0
+#define DMA_INT_EARLY_RX     0x00004000 // Early recv interrupt (Normal) RW 0
+#define DMA_INT_BUS_ERROR    0x00002000 // Fatal bus error (Abnormal) RW 0
+#define DMA_INT_EARLY_TX     0x00000400 // Early transmit interrupt RW 0
+#define DMA_INT_RX_STOPPED   0x00000100 // Recv process stopped (Abnormal) RW 0
+#define DMA_INT_RX_NO_BUFFER 0x00000080 // Recv buffer unavail (Abnormal) RW 0
+#define DMA_INT_RX_COMPLETED 0x00000040 // Completion of rcption (Normal) RW 0
+#define DMA_INT_TX_UNDERFLOW 0x00000020 // Trans underflow (Abnormal) RW 0
+#define DMA_INT_TX_JABBER    0x00000008 // Trans Jabber Timeout (Abnormal) RW 0
+#define DMA_INT_TX_NO_BUFFER 0x00000004 // Trans buffer unavailable (Normal) RW
+#define DMA_INT_TX_STOPPED   0x00000002 // Trans process stopped (Abnormal) RW0
+#define DMA_INT_TX_COMPLETED 0x00000001 // Trans completed (Normal) RW 0
+
+
+#define DMA_INT_ALL \
+      ( DMA_INT_NORMAL  \
+      | DMA_INT_ABNORMAL  \
+      | DMA_INT_EARLY_RX  \
+      | DMA_INT_BUS_ERROR \
+      | DMA_INT_EARLY_TX  \
+      | DMA_INT_RX_STOPPED \
+      | DMA_INT_RX_NO_BUFFER \
+      | DMA_INT_RX_COMPLETED \
+      | DMA_INT_TX_UNDERFLOW \
+      | DMA_INT_TX_JABBER \
+      | DMA_INT_TX_NO_BUFFER \
+      | DMA_INT_TX_STOPPED \
+      | DMA_INT_TX_COMPLETED)
+
+#define DMA_INT_INTERESTING \
+      ( DMA_INT_NORMAL  \
+      | DMA_INT_ABNORMAL  \
+      | DMA_INT_BUS_ERROR \
+      | DMA_INT_RX_COMPLETED \
+      | DMA_INT_TX_COMPLETED)
+
+#define DMA_INT_TX \
+      ( DMA_INT_TX_COMPLETED)
+
+#define DMA_INT_RX \
+      ( DMA_INT_RX_COMPLETED)
+
+
+
+// DMA Engine descriptor layout
+// status word of DMA descriptor
+#define DESC_OWN_BY_DMA       0x80000000 // Descriptor is owned by DMA engine
+#define DESC_FRAME_LEN_MASK   0x3FFF0000 // Receive descriptor frame length
+#define DESC_FRAME_LEN_SHIFT          16
+#define DESC_ERROR            0x00008000 // Error summary bit OR of following
+#define DESC_RX_TRUNCATED     0x00004000 // Rx - no more descs for recv frame
+#define DESC_RX_LENGTH_ERROR  0x00001000 // Rx - frame size != length field
+#define DESC_RX_RUNT          0x00000800 // Rx - runt frame
+#define DESC_RX_MULTICAST     0x00000400 // Rx - received frame is multicast
+#define DESC_RX_FIRST         0x00000200 // Rx - first descriptor of the frame
+#define DESC_RX_LAST          0x00000100 // Rx - last descriptor of the frame
+#define DESC_RX_LONG_FRAME    0x00000080 // Rx - frame is longer than 1518 b
+#define DESC_RX_LATE_COLL     0x00000040 // Rx - frame damaged by late collsion
+#define DESC_RX_FRAME_ETHER   0x00000020 // Rx - Frame type Ethernet 802.3
+#define DESC_RX_MII_ERROR     0x00000008 // Rx - error reported by MII iface
+#define DESC_RX_DRIBLING      0x00000004 // Rx - frame no multiple of 8 bits
+#define DESC_RX_CRC           0x00000002 // Rx - CRC error
+#define DESC_TX_TIMEOUT       0x00004000 // Tx - Transmit jabber timeout
+#define DESC_TX_LOST_CARRIER  0x00000800 // Tx - carrier lost during trans
+#define DESC_TX_NO_CARRIER    0x00000400 // Tx - no carrier from tranceiver
+#define DESC_TX_LATE_COLL     0x00000200 // Tx - trans aborted due to collision
+#define DESC_TX_EXC_COLLS     0x00000100 // Tx - trans aborted after 16 colls
+#define DESC_TX_HEARBEAT_FAIL 0x00000080 // Tx - heartbeat collision check fail
+#define DESC_TX_COLL_MASK     0x00000078 // Tx - Collision count
+#define DESC_TX_COLL_SHIFT             3
+#define DESC_TX_EXC_DEFERRAL  0x00000004 // Tx - excessive deferral
+#define DESC_TX_UNDERFLOW     0x00000002 // Tx - late data arrival from memory
+#define DESC_TX_DEFERRED      0x00000001 // Tx - frame transmision deferred
+
+// control word of DMA descriptor
+#define DESC_TX_INT_ENABLE    0x80000000 // Tx - interrupt on completion
+#define DESC_TX_LAST          0x40000000 // Tx - Last segment of the frame
+#define DESC_TX_FIRST         0x20000000 // Tx - First segment of the frame
+#define DESC_TX_DISABLE_CRC   0x04000000 // Tx - Add CRC disabled
+#define DESC_END_OF_RING      0x02000000 // End of descriptors ring
+#define DESC_CHAIN            0x01000000 // Second buffer address is chain
+#define DESC_TX_DISABLE_PAD   0x00800000 // disable padding
+#define DESC_SIZE_2_MASK      0x003FF800 // Buffer 2 size
+#define DESC_SIZE_2_SHIFT             11
+#define DESC_SIZE_1_MASK      0x000007FF // Buffer 1 size
+#define DESC_SIZE_1_SHIFT              0
+
+#define DMA_DESCR(base, off) ((base) + sizeof(struct dma_desc) * (off))
+
+
+extern unsigned char mips_mac_address[6];
+
+struct dma_desc {
+    u32 status;
+    u32 control;
+    u32 addr;
+    u32 next;
+};
+
+/*
+static void dump_regs(void) {
+    unsigned status = DMA_REG(DMA_STATUS);
+    printk("MAC_CONTROL      %08x  FLOWC %08x\n", MAC_REG(MAC_CONTROL), MAC_REG(MAC_FLOW_CONTROL));
+//    printk("MAC_ADDR_*       %08x/%08x  MH %08x/%08x\n",
+//	   MAC_REG(MAC_ADDR_HIGH), MAC_REG(MAC_ADDR_LOW),
+//	   MAC_REG(MAC_MULTI_HASH_HIGH), MAC_REG(MAC_MULTI_HASH_LOW));
+//    printk("MAC_MII_ADDR        %08x\n", MAC_REG(MAC_MII_ADDR));
+//    printk("MAC_MII_DATA        %08x\n", MAC_REG(MAC_MII_DATA));
+
+    printk("DMA  B/S %08x/%08x   C/I %08x/%08x   %x %x %x\n",
+	   DMA_REG(DMA_BUS_MODE), status, DMA_REG(DMA_CONTROL),
+	   DMA_REG(DMA_INT_ENABLE),
+	   (status >> 17) & 7, (status >> 20) & 7, (status >> 23) & 7);
+//    printk("DMA_MISSED_COUNT  %08x\n", DMA_REG(DMA_MISSED_COUNT));
+//    printk("DMA_*_POLL %08x/%08x\n",
+//	   DMA_REG(DMA_TX_POLL_DEMAND), DMA_REG(DMA_RX_POLL_DEMAND));
+    printk("DMA BASE %08x/%08x  CURR %08x/%08x\n",
+	   DMA_REG(DMA_TX_BASE_ADDR), DMA_REG(DMA_RX_BASE_ADDR),
+	   DMA_REG(DMA_TX_CURR_ADDR), DMA_REG(DMA_RX_CURR_ADDR));
+}
+
+static void dump_descr_regs(struct dma_desc *d) {
+    printk("DESCR: %08x %08x %08x %08x\n",
+	   d->status, d->control, d->addr, d->next);
+}
+*/
+
+struct crether_private {
+    volatile struct dma_desc *tx_ring;
+    volatile struct dma_desc *rx_ring;
+    dma_addr_t td_ring_dma;
+    dma_addr_t rd_ring_dma;
+
+    struct sk_buff *tx_skb[TX_RING_SIZE];
+    struct sk_buff *rx_skb[RX_RING_SIZE];
+    dma_addr_t rx_skb_dma[RX_RING_SIZE];
+
+    struct tasklet_struct *rx_tasklet;
+    struct tasklet_struct *tx_tasklet;
+
+    unsigned cur_rx;
+    unsigned dirty_rx;
+
+    unsigned cur_tx;
+    unsigned dirty_tx;
+
+    struct net_device *dev;
+    spinlock_t lock;
+
+    struct mii_if_info mii_if;
+};
+
+
+static int mdio_read(struct net_device *dev, int phy_id, int regnum)
+{
+    while (MAC_REG(MAC_MII_ADDR) & MII_BUSY) {}
+
+    MAC_REG(MAC_MII_ADDR) =
+	(phy_id << MII_DEV_SHIFT) | (regnum << MII_REG_SHIFT);
+
+    while (MAC_REG(MAC_MII_ADDR) & MII_BUSY) {}
+
+    return (MAC_REG(MAC_MII_DATA) & MII_DATA_MASK);
+}
+
+static void mdio_write(struct net_device *dev,
+		       int phy_id, int regnum, int value)
+{
+    while (MAC_REG(MAC_MII_ADDR) & MII_BUSY) {}
+
+    MAC_REG(MAC_MII_DATA) = value;
+    MAC_REG(MAC_MII_ADDR) =
+	(phy_id << MII_DEV_SHIFT) | (regnum << MII_REG_SHIFT) | MII_WRITE;
+
+    while (MAC_REG(MAC_MII_ADDR) & MII_BUSY) {}
+}
+
+
+static void crether_get_drvinfo (struct net_device *dev,
+				 struct ethtool_drvinfo *info)
+{
+    strcpy(info->driver, "crether");
+    strcpy(info->version, "1.0");
+    strcpy(info->bus_info, "00:00.0 crether");
+}
+
+static int crether_get_settings(struct net_device *dev,
+				struct ethtool_cmd *cmd)
+{
+    struct crether_private *np = netdev_priv(dev);
+
+    return mii_ethtool_gset(&np->mii_if, cmd);
+}
+
+static int crether_set_settings(struct net_device *dev,
+				struct ethtool_cmd *cmd)
+{
+    struct crether_private *np = netdev_priv(dev);
+    int rc;
+
+    spin_lock_irq(&np->lock);
+    rc = mii_ethtool_sset(&np->mii_if, cmd);
+    spin_unlock_irq(&np->lock);
+
+    return rc;
+}
+
+static int crether_nway_reset(struct net_device *dev)
+{
+    struct crether_private *np = netdev_priv(dev);
+
+    return mii_nway_restart(&np->mii_if);
+}
+
+static u32 crether_get_link(struct net_device *dev)
+{
+    struct crether_private *np = netdev_priv(dev);
+
+    return mii_link_ok(&np->mii_if);
+}
+
+static void crether_multicast_list(struct net_device *dev)
+{   
+    if ((dev->flags & IFF_PROMISC) ||
+	(dev->flags & IFF_ALLMULTI) ||
+	(netdev_mc_count(dev) > 0)) {
+	MAC_REG(MAC_CONTROL) |= MAC_PROMISC_MODE_ON;
+    }
+    else {
+	MAC_REG(MAC_CONTROL) &= ~MAC_PROMISC_MODE_ON;
+    }
+}
+
+
+static struct ethtool_ops crether_ethtool_ops = {
+    .get_drvinfo	= crether_get_drvinfo,
+    .get_settings	= crether_get_settings,
+    .set_settings	= crether_set_settings,
+    .nway_reset		= crether_nway_reset,
+    .get_link		= crether_get_link,
+
+    .get_sg		= ethtool_op_get_sg,
+    .set_sg		= ethtool_op_set_sg,
+    .get_tx_csum	= ethtool_op_get_tx_csum,
+    .set_tx_csum	= ethtool_op_set_tx_csum,
+};
+
+static int crether_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+    struct crether_private *lp = netdev_priv(dev);
+    int rc;
+
+//    if (!netif_running(dev))
+//	return -EINVAL;
+
+    spin_lock_irq(&lp->lock);
+    rc = generic_mii_ioctl(
+	&lp->mii_if, (struct mii_ioctl_data *) &rq->ifr_data, cmd, NULL);
+    spin_unlock_irq(&lp->lock);
+
+    return rc;
+}
+
+static int crether_init(struct net_device *dev)
+{
+    struct crether_private *lp = netdev_priv(dev);
+    int i;
+
+    //printk("***** crether_init\n");
+    // total reset of ethernet
+    CTR_REG(4) |= 3 << 10;
+    udelay(30);
+    CTR_REG(4) &= ~(3 << 10);
+//    dump_regs();
+
+    tasklet_disable(lp->rx_tasklet);
+    tasklet_disable(lp->tx_tasklet);
+
+    lp->cur_tx = 0;
+    lp->dirty_tx = 0;
+
+    for (i = 0; i < RX_RING_SIZE; i++) {
+	if (lp->rx_skb[i] == NULL) {
+	    struct sk_buff *skb = netdev_alloc_skb(dev, PACKET_BUF_LEN + 2);
+	    if (!skb) break;
+
+	    skb->dev = dev;
+	    skb_reserve(skb, 2);
+	    lp->rx_skb[i] = skb;
+	    lp->rx_skb_dma[i] = dma_map_single(
+		NULL, skb->data, PACKET_BUF_LEN, DMA_FROM_DEVICE);
+	}
+	lp->rx_ring[i].status = DESC_OWN_BY_DMA;
+	lp->rx_ring[i].control =
+	    DESC_CHAIN | (PACKET_BUF_LEN << DESC_SIZE_1_SHIFT);
+	lp->rx_ring[i].addr = lp->rx_skb_dma[i];
+	lp->rx_ring[i].next = DMA_DESCR(lp->rd_ring_dma, i + 1);
+    }
+    lp->rx_ring[i - 1].next = 0;
+    lp->rx_ring[i - 1].control = DESC_END_OF_RING;
+    lp->cur_rx = 0;
+    lp->dirty_rx = 0;
+
+    for (i = 0; i < TX_RING_SIZE; i++) {
+	lp->tx_ring[i].status = 0;
+	lp->tx_ring[i].control = DESC_CHAIN;
+	lp->tx_ring[i].addr = 0;
+	lp->tx_ring[i].next = DMA_DESCR(lp->td_ring_dma, i + 1);
+    }
+    lp->tx_ring[i - 1].next = 0;
+    lp->tx_ring[i - 1].control |= DESC_END_OF_RING;
+
+
+    MAC_REG(MAC_CONTROL) = MAC_FULL_DUPLEX;
+    DMA_REG(DMA_BUS_MODE) = DMA_BURST_LENGTH_2;
+
+    DMA_REG(DMA_STATUS) = DMA_INT_ALL;
+    DMA_REG(DMA_RX_BASE_ADDR) = lp->rd_ring_dma;
+    DMA_REG(DMA_TX_BASE_ADDR) = lp->td_ring_dma;
+    DMA_REG(DMA_CONTROL) = DMA_TX_THRESH_64;
+    DMA_REG(DMA_CONTROL) |= DMA_RX_START | DMA_TX_START;
+    MAC_REG(MAC_CONTROL) |= MAC_RX_ENABLE | MAC_TX_ENABLE;
+
+    DMA_REG(DMA_INT_ENABLE) = DMA_INT_INTERESTING;
+
+    tasklet_enable(lp->rx_tasklet);
+    tasklet_enable(lp->tx_tasklet);
+
+    netif_start_queue(dev);
+
+//    dump_regs();
+    //printk("***** crether_init out\n");
+
+    return 0; 
+}
+
+static int crether_restart(struct net_device *dev)
+{
+    disable_irq(CR_ETH_IRQ);
+
+    crether_init(dev);
+    crether_multicast_list(dev);
+
+    enable_irq(CR_ETH_IRQ);
+    return 0;
+}
+
+
+static int crether_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+    struct crether_private *lp = netdev_priv(dev);
+    unsigned long flags;
+    unsigned int entry;
+    volatile struct dma_desc *td;
+
+    if (skb_padto(skb, ETH_ZLEN))
+	return 0;
+
+    spin_lock_irqsave(&lp->lock, flags);
+
+//    printk("***** crether_xmit\n");
+    entry = lp->cur_tx % TX_RING_SIZE;
+    td = &lp->tx_ring[entry];
+
+    lp->tx_skb[entry] = skb;
+    td->status = 0;
+    td->control = DESC_CHAIN | DESC_TX_FIRST | DESC_TX_LAST |
+	DESC_TX_INT_ENABLE | (skb->len << DESC_SIZE_1_SHIFT);
+
+    if (entry == TX_RING_SIZE - 1) td->control |= DESC_END_OF_RING;
+
+    td->addr = dma_map_single(NULL, skb->data, skb->len, DMA_TO_DEVICE);
+    td->status = DESC_OWN_BY_DMA;
+
+    DMA_REG(DMA_TX_POLL_DEMAND) = 0;
+
+    ++lp->cur_tx;
+
+    if (lp->cur_tx == lp->dirty_tx + TX_QUEUE_LEN)
+	netif_stop_queue(dev);
+
+    dev->trans_start = jiffies;
+
+    spin_unlock_irqrestore(&lp->lock, flags);
+
+    return 0;
+}
+
+static irqreturn_t crether_interrupt(int irq, void *dev_id)
+{
+    struct net_device *dev = (struct net_device *) dev_id;
+    struct crether_private *lp = netdev_priv(dev);
+    unsigned status;
+    spin_lock(&lp->lock);
+
+    status = DMA_REG(DMA_STATUS);
+    DMA_REG(DMA_STATUS) = status & DMA_INT_ALL;
+
+//    printk("***** crether irq: %04x\n", status);
+//    dump_regs();
+    if (status & (DMA_INT_BUS_ERROR)) {
+	printk("crether:%s\n",
+	       (status & DMA_INT_BUS_ERROR) ? " BUS_ERROR" : "");
+	crether_restart(dev);
+	spin_unlock(&lp->lock);
+	return IRQ_HANDLED;
+    }
+
+    if (status & DMA_INT_RX_COMPLETED) {
+	tasklet_hi_schedule(lp->rx_tasklet);
+	DMA_REG(DMA_INT_ENABLE) &= ~(DMA_INT_RX);
+    }
+    if (status & DMA_INT_TX_COMPLETED) {
+	tasklet_hi_schedule(lp->tx_tasklet);
+	DMA_REG(DMA_INT_ENABLE) &= ~(DMA_INT_TX);
+    }
+
+    spin_unlock(&lp->lock);
+    return IRQ_HANDLED;
+}
+
+
+static void crether_rx_tasklet(unsigned long rx_data_dev)
+{
+    struct net_device *dev = (struct net_device *)rx_data_dev;	
+    struct crether_private* lp = netdev_priv(dev);
+    unsigned long flags;
+
+    int boguscnt = lp->dirty_rx + RX_RING_SIZE - lp->cur_rx;
+
+    spin_lock_irqsave(&lp->lock, flags);
+
+    // keep going while we have received into more descriptors
+    while (1) {
+	unsigned entry = lp->cur_rx % RX_RING_SIZE;
+	volatile struct dma_desc *rd = &lp->rx_ring[entry];
+	unsigned pktlen;
+	unsigned status;
+
+	if (rd->status & DESC_OWN_BY_DMA) break;
+	if (--boguscnt < 0) break;
+
+	status = rd->status;
+	if (status & DESC_ERROR && !(status & DESC_RX_LONG_FRAME)) {
+	    lp->dev->stats.rx_errors++;
+	    lp->dev->stats.rx_dropped++;
+
+	    if (status & DESC_RX_CRC) {
+		lp->dev->stats.rx_crc_errors++;
+	    }
+	    else if (status & DESC_RX_LENGTH_ERROR) {
+		lp->dev->stats.rx_length_errors++;
+	    }
+//	    else if (status & DESC_RX_LONG_FRAME) {
+//		lp->dev->stats.rx_length_errors++;
+//	    }
+	}
+	else {
+	    struct sk_buff *skb;
+
+	    pktlen = ((status >> 16) & 0x3FFF) - 4;
+
+	    skb = lp->rx_skb[entry];
+	    lp->rx_skb[entry] = NULL;
+	    dma_unmap_single(NULL, lp->rx_skb_dma[entry], pktlen,
+			     DMA_FROM_DEVICE);
+
+	    skb_put(skb, pktlen);
+	    skb->protocol = eth_type_trans(skb, dev);
+	    netif_rx(skb);
+
+	    dev->last_rx = jiffies;
+	    lp->dev->stats.rx_packets++;
+	    lp->dev->stats.rx_bytes += pktlen;
+	}
+	++lp->cur_rx;
+    }
+
+    // refill the rx ring buffers
+    for (; lp->cur_rx - lp->dirty_rx > 0; ++lp->dirty_rx) {
+	unsigned entry = lp->dirty_rx % RX_RING_SIZE;
+	volatile struct dma_desc *rd = &lp->rx_ring[entry];
+	struct sk_buff *skb;
+
+	if (lp->rx_skb[entry] == NULL) {
+	    skb = netdev_alloc_skb(dev, PACKET_BUF_LEN + 2);
+	    lp->rx_skb[entry] = skb;
+	    if (skb == NULL) break;
+
+	    skb->dev = dev;
+	    skb_reserve(skb, 2);
+	    lp->rx_skb_dma[entry] = dma_map_single(
+		NULL, skb->data, PACKET_BUF_LEN + 2,
+		DMA_FROM_DEVICE);
+	}
+	rd->addr = lp->rx_skb_dma[entry];
+	rd->status = DESC_OWN_BY_DMA;
+    }
+
+    DMA_REG(DMA_STATUS) &= ~(DMA_INT_RX_COMPLETED);
+    DMA_REG(DMA_INT_ENABLE) |= DMA_INT_RX;
+    DMA_REG(DMA_RX_POLL_DEMAND) = 0;
+    spin_unlock_irqrestore(&lp->lock, flags);
+}
+
+static void crether_tx_tasklet(unsigned long tx_data_dev)
+{
+    struct net_device *dev = (struct net_device *) tx_data_dev;
+    struct crether_private* lp = netdev_priv(dev);
+    u32 status;
+    unsigned long flags;
+
+    spin_lock_irqsave(&lp->lock, flags);
+
+    while (lp->dirty_tx != lp->cur_tx) {
+	unsigned entry = lp->dirty_tx % TX_RING_SIZE;
+
+	status = lp->tx_ring[entry].status;
+	if (status & DESC_OWN_BY_DMA) break;
+
+	if (!(status & DESC_ERROR)) {
+	    lp->dev->stats.tx_packets++;
+	    lp->dev->stats.tx_bytes += lp->tx_skb[entry]->len;
+	} else {
+	    lp->dev->stats.tx_errors++;
+	    lp->dev->stats.tx_dropped++;
+
+	    if (status & DESC_TX_UNDERFLOW) {
+		lp->dev->stats.tx_fifo_errors++;
+	    } else if (status & DESC_TX_EXC_DEFERRAL) {
+		lp->dev->stats.tx_carrier_errors++;
+	    } else if (status & DESC_TX_LOST_CARRIER) {
+		lp->dev->stats.tx_carrier_errors++;
+	    } else if (status & DESC_TX_NO_CARRIER) {
+		lp->dev->stats.tx_carrier_errors++;
+	    } else if (status & DESC_TX_EXC_COLLS) {
+		lp->dev->stats.collisions++;
+	    } else if (status & DESC_TX_LATE_COLL) {
+		lp->dev->stats.tx_window_errors++;
+	    } else if (status & DESC_TX_HEARBEAT_FAIL) {
+		lp->dev->stats.tx_heartbeat_errors++;
+	    }
+	}
+
+	dev_kfree_skb_any(lp->tx_skb[entry]);
+	lp->tx_skb[entry] = NULL;
+	++lp->dirty_tx;
+    }
+
+    if (lp->cur_tx - lp->dirty_tx < TX_QUEUE_LEN - 4)
+	netif_wake_queue(dev);
+
+    DMA_REG(DMA_STATUS) &= ~(DMA_INT_TX_COMPLETED);
+    DMA_REG(DMA_INT_ENABLE) |= DMA_INT_TX;
+    spin_unlock_irqrestore(&lp->lock, flags);
+}
+
+static void crether_tx_timeout(struct net_device *dev)
+{
+    struct crether_private *lp = netdev_priv(dev);
+    unsigned long flags;
+
+    spin_lock_irqsave(&lp->lock, flags);
+    crether_restart(dev);
+    spin_unlock_irqrestore(&lp->lock, flags);
+}
+
+static int crether_change_mtu(struct net_device *dev, int new_mtu) {
+    if (new_mtu < 68 || new_mtu > 1600) return -EINVAL;
+    dev->mtu = new_mtu;
+    return 0;
+}
+
+static int crether_open(struct net_device *dev)
+{
+    if (crether_init(dev)) {
+	printk("crether: could not init device\n");
+	return -EAGAIN;
+    }
+
+    if (request_irq(CR_ETH_IRQ, &crether_interrupt,
+		    IRQF_SHARED | IRQF_DISABLED, "crether", dev)) {
+	printk("crether: could not request IRQ %d\n", CR_ETH_IRQ);
+	return -EAGAIN;
+    }
+    return 0;
+}
+
+static int crether_close(struct net_device *dev)
+{
+    disable_irq(CR_ETH_IRQ);
+
+    MAC_REG(MAC_CONTROL) &= ~(MAC_RX_ENABLE | MAC_TX_ENABLE);
+    DMA_REG(DMA_CONTROL) &= ~(DMA_RX_START | DMA_TX_START);
+
+    free_irq(CR_ETH_IRQ, dev);
+
+    return 0;
+}
+
+static const struct net_device_ops crether_netdev_ops = {
+	.ndo_open		= crether_open,
+	.ndo_stop		= crether_close,
+	.ndo_start_xmit		= crether_xmit,
+	.ndo_set_multicast_list = &crether_multicast_list,
+	.ndo_tx_timeout		= crether_tx_timeout,
+	.ndo_change_mtu		= crether_change_mtu,
+	.ndo_do_ioctl		= crether_ioctl,
+	.ndo_validate_addr	= eth_validate_addr,
+};
+
+static int crether_probe(struct platform_device *pdev)
+{
+    struct net_device *dev;
+    struct crether_private *lp;
+    int i;
+
+    request_region(CR_ETHER_BASE, 0x2000, "crether");
+
+    dev = alloc_etherdev(sizeof(struct crether_private));
+
+    dev->base_addr = CR_ETHER_BASE;
+    dev->irq = CR_ETH_IRQ;
+    memcpy(dev->dev_addr, mips_mac_address, 6);
+
+    lp = netdev_priv(dev);
+    lp->dev = dev;
+
+    lp->tx_ring = dma_alloc_coherent(
+	&pdev->dev, DMA_DESCR(0, TX_RING_SIZE + RX_RING_SIZE),
+	&lp->td_ring_dma, GFP_KERNEL);
+    if (!lp->tx_ring) {
+	printk("crether: can't allocate descriptors\n");
+	return -ENOMEM;
+    }
+
+    lp->rx_ring = (void *) lp->tx_ring + DMA_DESCR(0, TX_RING_SIZE);
+    lp->rd_ring_dma = DMA_DESCR(lp->td_ring_dma, TX_RING_SIZE);
+
+    spin_lock_init(&lp->lock);
+
+    dev->netdev_ops = &crether_netdev_ops;
+    dev->ethtool_ops = &crether_ethtool_ops;
+    dev->watchdog_timeo = 6 * HZ;
+    dev->l2mtu = 1600;
+
+    lp->rx_tasklet = kmalloc(sizeof(struct tasklet_struct), GFP_KERNEL);
+    tasklet_init(lp->rx_tasklet, crether_rx_tasklet, (unsigned long)dev);
+    lp->tx_tasklet = kmalloc(sizeof(struct tasklet_struct), GFP_KERNEL);
+    tasklet_init(lp->tx_tasklet, crether_tx_tasklet, (unsigned long)dev);
+
+    lp->mii_if.dev = dev;
+    lp->mii_if.mdio_read = mdio_read;
+    lp->mii_if.mdio_write = mdio_write;
+    lp->mii_if.phy_id_mask = 0x1f;
+    lp->mii_if.reg_num_mask = 0x1f;
+    lp->mii_if.phy_id = 1;
+
+    register_netdev(dev);
+
+    printk("crether ethernet MAC address ");
+    for (i = 0; i < 5; i++)
+	printk("%2.2x:", dev->dev_addr[i]);
+    printk("%2.2x\n", dev->dev_addr[5]);
+
+    return 0;
+}
+
+static struct platform_driver crether_driver = {
+	.probe	= crether_probe,
+	.driver	= {
+		.name	= "cr-ether",
+		.owner	= THIS_MODULE,
+	}
+};
+
+int crether_init_module(void)
+{
+	return platform_driver_register(&crether_driver);
+}
+
+module_init(crether_init_module);
diff -puNrb linux-2.6.35/drivers/net/e1000/e1000_main.c linux/drivers/net/e1000/e1000_main.c
--- linux-2.6.35/drivers/net/e1000/e1000_main.c	2011-04-26 16:28:06.812477941 +0300
+++ linux/drivers/net/e1000/e1000_main.c	2011-05-02 10:08:26.743214565 +0300
@@ -2336,7 +2336,7 @@ static void e1000_watchdog(unsigned long
 			netif_carrier_on(netdev);
 			if (!test_bit(__E1000_DOWN, &adapter->flags))
 				mod_timer(&adapter->phy_info_timer,
-				          round_jiffies(jiffies + 2 * HZ));
+				          round_jiffies(jiffies + HZ));
 			adapter->smartspeed = 0;
 		}
 	} else {
@@ -2349,7 +2349,7 @@ static void e1000_watchdog(unsigned long
 
 			if (!test_bit(__E1000_DOWN, &adapter->flags))
 				mod_timer(&adapter->phy_info_timer,
-				          round_jiffies(jiffies + 2 * HZ));
+				          round_jiffies(jiffies + HZ));
 		}
 
 		e1000_smartspeed(adapter);
@@ -2408,7 +2408,7 @@ link_up:
 	/* Reset the timer */
 	if (!test_bit(__E1000_DOWN, &adapter->flags))
 		mod_timer(&adapter->watchdog_timer,
-		          round_jiffies(jiffies + 2 * HZ));
+		          round_jiffies(jiffies + HZ));
 }
 
 enum latency_range {
diff -puNrb linux-2.6.35/drivers/net/e1000e/82571.c linux/drivers/net/e1000e/82571.c
--- linux-2.6.35/drivers/net/e1000e/82571.c	2011-04-26 16:28:17.761229823 +0300
+++ linux/drivers/net/e1000e/82571.c	2011-05-02 10:08:26.763213480 +0300
@@ -936,12 +936,14 @@ static s32 e1000_reset_hw_82571(struct e
 	ew32(IMC, 0xffffffff);
 	icr = er32(ICR);
 
+	if (hw->mac.type == e1000_82571) {
 	/* Install any alternate MAC address into RAR0 */
 	ret_val = e1000_check_alt_mac_addr_generic(hw);
 	if (ret_val)
 		return ret_val;
 
 	e1000e_set_laa_state_82571(hw, true);
+	}
 
 	/* Reinitialize the 82571 serdes link state machine */
 	if (hw->phy.media_type == e1000_media_type_internal_serdes)
@@ -1618,6 +1620,7 @@ static s32 e1000_read_mac_addr_82571(str
 {
 	s32 ret_val = 0;
 
+	if (hw->mac.type == e1000_82571) {
 	/*
 	 * If there's an alternate MAC address place it in RAR0
 	 * so that it will override the Si installed default perm
@@ -1626,6 +1629,7 @@ static s32 e1000_read_mac_addr_82571(str
 	ret_val = e1000_check_alt_mac_addr_generic(hw);
 	if (ret_val)
 		goto out;
+	}
 
 	ret_val = e1000_read_mac_addr_generic(hw);
 
diff -puNrb linux-2.6.35/drivers/net/e1000e/defines.h linux/drivers/net/e1000e/defines.h
--- linux-2.6.35/drivers/net/e1000e/defines.h	2011-04-26 16:28:17.761229823 +0300
+++ linux/drivers/net/e1000e/defines.h	2011-05-02 10:08:26.773102523 +0300
@@ -620,6 +620,7 @@
 #define E1000_FLASH_UPDATES  2000
 
 /* NVM Word Offsets */
+#define NVM_COMPAT                 0x0003
 #define NVM_ID_LED_SETTINGS        0x0004
 #define NVM_INIT_CONTROL2_REG      0x000F
 #define NVM_INIT_CONTROL3_PORT_B   0x0014
@@ -642,6 +643,9 @@
 /* Mask bits for fields in Word 0x1a of the NVM */
 #define NVM_WORD1A_ASPM_MASK  0x000C
 
+/* Mask bits for fields in Word 0x03 of the EEPROM */
+#define NVM_COMPAT_LOM    0x0800
+
 /* For checksumming, the sum of all words in the NVM should equal 0xBABA. */
 #define NVM_SUM                    0xBABA
 
diff -puNrb linux-2.6.35/drivers/net/e1000e/lib.c linux/drivers/net/e1000e/lib.c
--- linux-2.6.35/drivers/net/e1000e/lib.c	2011-04-26 16:28:17.761229823 +0300
+++ linux/drivers/net/e1000e/lib.c	2011-05-02 10:08:26.793211143 +0300
@@ -183,6 +183,16 @@ s32 e1000_check_alt_mac_addr_generic(str
 	u16 offset, nvm_alt_mac_addr_offset, nvm_data;
 	u8 alt_mac_addr[ETH_ALEN];
 
+	ret_val = e1000_read_nvm(hw, NVM_COMPAT, 1, &nvm_data);
+	if (ret_val)
+		goto out;
+
+	/* Check for LOM (vs. NIC) or one of two valid mezzanine cards */
+	if (!((nvm_data & NVM_COMPAT_LOM) ||
+	      (hw->adapter->pdev->device == E1000_DEV_ID_82571EB_SERDES_DUAL) ||
+	      (hw->adapter->pdev->device == E1000_DEV_ID_82571EB_SERDES_QUAD)))
+		goto out;
+
 	ret_val = e1000_read_nvm(hw, NVM_ALT_MAC_ADDR_PTR, 1,
 	                         &nvm_alt_mac_addr_offset);
 	if (ret_val) {
diff -puNrb linux-2.6.35/drivers/net/e1000e/netdev.c linux/drivers/net/e1000e/netdev.c
--- linux-2.6.35/drivers/net/e1000e/netdev.c	2011-04-26 16:28:17.761229823 +0300
+++ linux/drivers/net/e1000e/netdev.c	2011-05-02 10:08:26.881590029 +0300
@@ -4148,7 +4148,7 @@ link_up:
 	/* Reset the timer */
 	if (!test_bit(__E1000_DOWN, &adapter->state))
 		mod_timer(&adapter->watchdog_timer,
-			  round_jiffies(jiffies + 2 * HZ));
+			  round_jiffies(jiffies + HZ));
 }
 
 #define E1000_TX_FLAGS_CSUM		0x00000001
diff -puNrb linux-2.6.35/drivers/net/e100.c linux/drivers/net/e100.c
--- linux-2.6.35/drivers/net/e100.c	2011-04-26 16:28:20.911915568 +0300
+++ linux/drivers/net/e100.c	2011-05-02 10:08:26.911586653 +0300
@@ -178,7 +178,7 @@
 #define DRV_DESCRIPTION		"Intel(R) PRO/100 Network Driver"
 #define DRV_COPYRIGHT		"Copyright(c) 1999-2006 Intel Corporation"
 
-#define E100_WATCHDOG_PERIOD	(2 * HZ)
+#define E100_WATCHDOG_PERIOD	(1 * HZ)
 #define E100_NAPI_WEIGHT	16
 
 #define FIRMWARE_D101M		"e100/d101m_ucode.bin"
diff -puNrb linux-2.6.35/drivers/net/gianfar_ethtool.c linux/drivers/net/gianfar_ethtool.c
--- linux-2.6.35/drivers/net/gianfar_ethtool.c	2011-04-26 16:28:20.901916346 +0300
+++ linux/drivers/net/gianfar_ethtool.c	2011-05-02 10:08:26.931599249 +0300
@@ -172,10 +172,13 @@ static int gfar_sset_count(struct net_de
 static void gfar_gdrvinfo(struct net_device *dev, struct
 	      ethtool_drvinfo *drvinfo)
 {
+	char busID[32];
+	sprintf(busID, "%u", ((struct gfar_private *)dev->priv)->einfo->phy_id);
+
 	strncpy(drvinfo->driver, DRV_NAME, GFAR_INFOSTR_LEN);
 	strncpy(drvinfo->version, gfar_driver_version, GFAR_INFOSTR_LEN);
 	strncpy(drvinfo->fw_version, "N/A", GFAR_INFOSTR_LEN);
-	strncpy(drvinfo->bus_info, "N/A", GFAR_INFOSTR_LEN);
+	strncpy(drvinfo->bus_info, busID, GFAR_INFOSTR_LEN);
 	drvinfo->regdump_len = 0;
 	drvinfo->eedump_len = 0;
 }
@@ -499,7 +502,7 @@ static int gfar_sringparam(struct net_de
 					priv->rx_queue[i]->rx_ring_size);
 
 		/* Now we take down the rings to rebuild them */
-		stop_gfar(dev);
+		stop_gfar(dev, 1);
 	}
 
 	/* Change the size */
@@ -511,7 +514,7 @@ static int gfar_sringparam(struct net_de
 
 	/* Rebuild the rings with the new size */
 	if (dev->flags & IFF_UP) {
-		err = startup_gfar(dev);
+		err = startup_gfar(dev, 1);
 		netif_tx_wake_all_queues(dev);
 	}
 	return err;
@@ -545,7 +548,7 @@ static int gfar_set_rx_csum(struct net_d
 					priv->rx_queue[i]->rx_ring_size);
 
 		/* Now we take down the rings to rebuild them */
-		stop_gfar(dev);
+		stop_gfar(dev, 1);
 	}
 
 	spin_lock_irqsave(&priv->bflock, flags);
@@ -553,7 +556,7 @@ static int gfar_set_rx_csum(struct net_d
 	spin_unlock_irqrestore(&priv->bflock, flags);
 
 	if (dev->flags & IFF_UP) {
-		err = startup_gfar(dev);
+		err = startup_gfar(dev, 1);
 		netif_tx_wake_all_queues(dev);
 	}
 	return err;
diff -puNrb linux-2.6.35/drivers/net/igb/igb_main.c linux/drivers/net/igb/igb_main.c
--- linux-2.6.35/drivers/net/igb/igb_main.c	2011-04-26 16:28:12.522789936 +0300
+++ linux/drivers/net/igb/igb_main.c	2011-05-02 10:08:26.953214022 +0300
@@ -3506,7 +3506,7 @@ static void igb_watchdog_task(struct wor
 	/* Reset the timer */
 	if (!test_bit(__IGB_DOWN, &adapter->state))
 		mod_timer(&adapter->watchdog_timer,
-			  round_jiffies(jiffies + 2 * HZ));
+			  round_jiffies(jiffies + HZ));
 }
 
 enum latency_range {
diff -puNrb linux-2.6.35/drivers/net/imq.c linux/drivers/net/imq.c
--- linux-2.6.35/drivers/net/imq.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/net/imq.c	2011-05-02 10:08:26.963103561 +0300
@@ -0,0 +1,733 @@
+/*
+ *             Pseudo-driver for the intermediate queue device.
+ *
+ *             This program is free software; you can redistribute it and/or
+ *             modify it under the terms of the GNU General Public License
+ *             as published by the Free Software Foundation; either version
+ *             2 of the License, or (at your option) any later version.
+ *
+ * Authors:    Patrick McHardy, <kaber@trash.net>
+ *
+ *            The first version was written by Martin Devera, <devik@cdi.cz>
+ *
+ * Credits:    Jan Rafaj <imq2t@cedric.vabo.cz>
+ *              - Update patch to 2.4.21
+ *             Sebastian Strollo <sstrollo@nortelnetworks.com>
+ *              - Fix "Dead-loop on netdevice imq"-issue
+ *             Marcel Sebek <sebek64@post.cz>
+ *              - Update to 2.6.2-rc1
+ *
+ *	       After some time of inactivity there is a group taking care
+ *	       of IMQ again: http://www.linuximq.net
+ *
+ *
+ *	       2004/06/30 - New version of IMQ patch to kernels <=2.6.7
+ *             including the following changes:
+ *
+ *	       - Correction of ipv6 support "+"s issue (Hasso Tepper)
+ *	       - Correction of imq_init_devs() issue that resulted in
+ *	       kernel OOPS unloading IMQ as module (Norbert Buchmuller)
+ *	       - Addition of functionality to choose number of IMQ devices
+ *	       during kernel config (Andre Correa)
+ *	       - Addition of functionality to choose how IMQ hooks on
+ *	       PRE and POSTROUTING (after or before NAT) (Andre Correa)
+ *	       - Cosmetic corrections (Norbert Buchmuller) (Andre Correa)
+ *
+ *
+ *             2005/12/16 - IMQ versions between 2.6.7 and 2.6.13 were
+ *             released with almost no problems. 2.6.14-x was released
+ *             with some important changes: nfcache was removed; After
+ *             some weeks of trouble we figured out that some IMQ fields
+ *             in skb were missing in skbuff.c - skb_clone and copy_skb_header.
+ *             These functions are correctly patched by this new patch version.
+ *
+ *             Thanks for all who helped to figure out all the problems with
+ *             2.6.14.x: Patrick McHardy, Rune Kock, VeNoMouS, Max CtRiX,
+ *             Kevin Shanahan, Richard Lucassen, Valery Dachev (hopefully
+ *             I didn't forget anybody). I apologize again for my lack of time.
+ *
+ *
+ *             2008/06/17 - 2.6.25 - Changed imq.c to use qdisc_run() instead 
+ *             of qdisc_restart() and moved qdisc_run() to tasklet to avoid
+ *             recursive locking. New initialization routines to fix 'rmmod' not
+ *             working anymore. Used code from ifb.c. (Jussi Kivilinna)
+ *
+ *             2008/08/06 - 2.6.26 - (JK)
+ *              - Replaced tasklet with 'netif_schedule()'.
+ *              - Cleaned up and added comments for imq_nf_queue().
+ *
+ *             2009/04/12
+ *              - Add skb_save_cb/skb_restore_cb helper functions for backuping
+ *                control buffer. This is needed because qdisc-layer on kernels
+ *                2.6.27 and newer overwrite control buffer. (Jussi Kivilinna)
+ *              - Add better locking for IMQ device. Hopefully this will solve
+ *                SMP issues. (Jussi Kivilinna)
+ *              - Port to 2.6.27
+ *              - Port to 2.6.28
+ *              - Port to 2.6.29 + fix rmmod not working
+ *
+ *             2009/04/20 - (Jussi Kivilinna)
+ *              - Use netdevice feature flags to avoid extra packet handling
+ *                by core networking layer and possibly increase performance.
+ *
+ *             2009/09/26 - (Jussi Kivilinna)
+ *              - Add imq_nf_reinject_lockless to fix deadlock with
+ *                imq_nf_queue/imq_nf_reinject.
+ *
+ *             2009/12/08 - (Jussi Kivilinna)
+ *              - Port to 2.6.32
+ *              - Add check for skb->nf_queue_entry==NULL in imq_dev_xmit()
+ *              - Also add better error checking for skb->nf_queue_entry usage
+ *
+ *             2010/02/25 - (Jussi Kivilinna)
+ *              - Port to 2.6.33
+ *
+ *	       Also, many thanks to pablo Sebastian Greco for making the initial
+ *	       patch and to those who helped the testing.
+ *
+ *             More info at: http://www.linuximq.net/ (Andre Correa)
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/moduleparam.h>
+#include <linux/list.h>
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/if_arp.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	#include <linux/netfilter_ipv6.h>
+#endif
+#include <linux/imq.h>
+#include <net/pkt_sched.h>
+#include <net/netfilter/nf_queue.h>
+
+static nf_hookfn imq_nf_hook;
+
+static struct nf_hook_ops imq_ingress_ipv4 = {
+	.hook		= imq_nf_hook,
+	.owner		= THIS_MODULE,
+	.pf		= PF_INET,
+	.hooknum	= NF_INET_PRE_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	.priority	= NF_IP_PRI_MANGLE + 1
+#else
+	.priority	= NF_IP_PRI_NAT_DST + 1
+#endif
+};
+
+static struct nf_hook_ops imq_egress_ipv4 = {
+	.hook		= imq_nf_hook,
+	.owner		= THIS_MODULE,
+	.pf		= PF_INET,
+	.hooknum	= NF_INET_POST_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
+	.priority	= NF_IP_PRI_LAST
+#else
+	.priority	= NF_IP_PRI_NAT_SRC - 1
+#endif
+};
+
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+static struct nf_hook_ops imq_ingress_ipv6 = {
+	.hook		= imq_nf_hook,
+	.owner		= THIS_MODULE,
+	.pf		= PF_INET6,
+	.hooknum	= NF_INET_PRE_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	.priority	= NF_IP6_PRI_MANGLE + 1
+#else
+	.priority	= NF_IP6_PRI_NAT_DST + 1
+#endif
+};
+
+static struct nf_hook_ops imq_egress_ipv6 = {
+	.hook		= imq_nf_hook,
+	.owner		= THIS_MODULE,
+	.pf		= PF_INET6,
+	.hooknum	= NF_INET_POST_ROUTING,
+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
+	.priority	= NF_IP6_PRI_LAST
+#else
+	.priority	= NF_IP6_PRI_NAT_SRC - 1
+#endif
+};
+#endif
+
+static unsigned int numdevs = 3;
+
+static DEFINE_SPINLOCK(imq_nf_queue_lock);
+
+static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
+
+
+static struct net_device_stats *imq_get_stats(struct net_device *dev)
+{
+	return &dev->stats;
+}
+
+/* called for packets kfree'd in qdiscs at places other than enqueue */
+static void imq_skb_destructor(struct sk_buff *skb)
+{
+	struct nf_queue_entry *entry = skb->nf_queue_entry;
+
+	skb->nf_queue_entry = NULL;
+
+	if (entry) {
+		nf_queue_entry_release_refs(entry);
+		kfree(entry);
+	}
+
+	skb_restore_cb(skb); /* kfree backup */
+}
+
+/* locking not needed when called from imq_nf_queue */
+static void imq_nf_reinject_lockless(struct nf_queue_entry *entry,
+				     unsigned int verdict)
+{
+	int status;
+
+	if (!entry->next_outfn) {
+		nf_reinject(entry, verdict);
+		return;
+	}
+
+	status = entry->next_outfn(entry, entry->next_queuenum);
+	if (status < 0) {
+		nf_queue_entry_release_refs(entry);
+		kfree_skb(entry->skb);
+		kfree(entry);
+	}
+}
+
+static void imq_nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
+{
+	int status;
+
+	if (!entry->next_outfn) {
+		spin_lock_bh(&imq_nf_queue_lock);
+		nf_reinject(entry, verdict);
+		spin_unlock_bh(&imq_nf_queue_lock);
+		return;
+	}
+
+	rcu_read_lock();
+	local_bh_disable();
+	status = entry->next_outfn(entry, entry->next_queuenum);
+	local_bh_enable();
+	if (status < 0) {
+		nf_queue_entry_release_refs(entry);
+		kfree_skb(entry->skb);
+		kfree(entry);
+	}
+
+	rcu_read_unlock();
+}
+
+static netdev_tx_t imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+//	printk("xmit: %s %p\n", dev->name, skb);
+	struct nf_queue_entry *entry = skb->nf_queue_entry;
+
+	skb->nf_queue_entry = NULL;
+	dev->trans_start = jiffies;
+
+	dev->stats.tx_bytes += skb->len;
+	dev->stats.tx_packets++;
+
+	if (entry == NULL) {
+		/* We don't know what is going on here.. packet is queued for
+		 * imq device, but (probably) not by us.
+		 *
+		 * If this packet was not send here by imq_nf_queue(), then
+		 * skb_save_cb() was not used and skb_free() should not show:
+		 *   WARNING: IMQ: kfree_skb: skb->cb_next:..
+		 * and/or
+		 *   WARNING: IMQ: kfree_skb: skb->nf_queue_entry...
+		 *
+		 * However if this message is shown, then IMQ is somehow broken
+		 * and you should report this to linuximq.net.
+		 */
+
+		/* imq_dev_xmit is black hole that eats all packets, report that
+		 * we eat this packet happily and increase dropped counters.
+		 */
+
+		dev->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+
+		return NETDEV_TX_OK;
+	}
+
+	skb_restore_cb(skb); /* restore skb->cb */
+
+	skb->imq_flags |= IMQ_F_ENQUEUE;
+	skb->destructor = NULL;
+
+	imq_nf_reinject(entry, NF_ACCEPT);
+
+	return NETDEV_TX_OK;
+}
+
+static netdev_tx_t imq_dev_xmit_to_next(struct sk_buff *skb,
+					struct net_device *dev)
+{
+	struct nf_queue_entry *entry = skb->nf_queue_entry;
+	struct net_device *imq2 = imq_devs_cache[2];
+	struct netdev_queue *txq;
+	struct Qdisc *q;
+
+//	printk("xmit to next: %s %p\n", dev->name, skb);
+	dev->trans_start = jiffies;
+
+	dev->stats.tx_bytes += skb->len;
+	dev->stats.tx_packets++;
+
+	if (entry == NULL) {
+		dev->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+		return NETDEV_TX_OK;
+	}
+
+	if (!(imq2->flags & IFF_UP) || (skb->imq_flags & IMQ_F_ENQUEUE)) {
+		skb_restore_cb(skb); /* restore skb->cb */
+		skb->destructor = NULL;
+		imq_nf_reinject(skb->nf_queue_entry, NF_ACCEPT);
+		return NETDEV_TX_OK;
+	}
+	imq2->last_rx = jiffies;
+
+	imq2->stats.rx_bytes += skb->len;
+	imq2->stats.rx_packets++;
+
+	txq = dev_pick_tx(imq2, skb);
+	q = rcu_dereference(txq->qdisc);
+
+	if (unlikely(!q->enqueue)) {
+		dev->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+		return NETDEV_TX_OK;
+	}
+
+	spin_lock_bh(qdisc_lock(q));
+
+//	users = atomic_read(&skb->users);
+//	skb_shared = skb_get(skb); /* increase reference count by one */
+	qdisc_enqueue_root(skb, q); /* might kfree_skb */
+
+//	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
+//		kfree_skb(skb_shared); /* decrease reference count by one */
+
+		spin_unlock_bh(qdisc_lock(q));
+
+		/* schedule qdisc dequeue */
+		__netif_schedule(q);
+
+	return NETDEV_TX_OK;
+}
+
+static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
+{
+	struct net_device *dev;
+	struct sk_buff *skb_orig, *skb, *skb_shared;
+	struct Qdisc *q;
+	struct netdev_queue *txq;
+	int users, index;
+	int retval = -EINVAL;
+
+	index = entry->skb->imq_flags & IMQ_F_IFMASK;
+	if (unlikely(index > numdevs - 1)) {
+		if (net_ratelimit())
+			printk(KERN_WARNING
+			       "IMQ: invalid device specified, highest is %u\n",
+			       numdevs - 1);
+		retval = -EINVAL;
+		goto out;
+	}
+
+	/* check for imq device by index from cache */
+	dev = imq_devs_cache[index];
+#if 0
+	if (unlikely(!dev)) {
+		char buf[8];
+
+		/* get device by name and cache result */
+		snprintf(buf, sizeof(buf), "imq%d", index);
+		dev = dev_get_by_name(&init_net, buf);
+		if (!dev) {
+			/* not found ?!*/
+			BUG();
+			retval = -ENODEV;
+			goto out;
+		}
+
+		imq_devs_cache[index] = dev;
+		dev_put(dev);
+	}
+#endif
+
+	if (unlikely(!(dev->flags & IFF_UP))) {
+		entry->skb->imq_flags = 0;
+		imq_nf_reinject_lockless(entry, NF_ACCEPT);
+		retval = 0;
+		goto out;
+	}
+	dev->last_rx = jiffies;
+
+	skb = entry->skb;
+	skb_orig = NULL;
+
+	/* skb has owner? => make clone */
+	if (unlikely(skb->destructor)) {
+		skb_orig = skb;
+		skb = skb_clone(skb, GFP_ATOMIC);
+		if (!skb) {
+			retval = -ENOMEM;
+			goto out;
+		}
+		entry->skb = skb;
+	}
+
+	skb->nf_queue_entry = entry;
+
+	dev->stats.rx_bytes += skb->len;
+	dev->stats.rx_packets++;
+
+	txq = dev_pick_tx(dev, skb);
+
+	q = rcu_dereference(txq->qdisc);
+	if (unlikely(!q->enqueue))
+		goto packet_not_eaten_by_imq_dev;
+
+	spin_lock_bh(qdisc_lock(q));
+
+	users = atomic_read(&skb->users);
+
+	skb_shared = skb_get(skb); /* increase reference count by one */
+	skb_save_cb(skb_shared); /* backup skb->cb, as qdisc layer will
+					overwrite it */
+	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
+
+	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
+		kfree_skb(skb_shared); /* decrease reference count by one */
+
+		skb->destructor = &imq_skb_destructor;
+
+		/* cloned? */
+		if (skb_orig)
+			kfree_skb(skb_orig); /* free original */
+
+		spin_unlock_bh(qdisc_lock(q));
+
+		/* schedule qdisc dequeue */
+		__netif_schedule(q);
+
+		retval = 0;
+		goto out;
+	} else {
+		skb_restore_cb(skb_shared); /* restore skb->cb */
+		skb->nf_queue_entry = NULL;
+		/* qdisc dropped packet and decreased skb reference count of
+		 * skb, so we don't really want to and try refree as that would
+		 * actually destroy the skb. */
+		spin_unlock_bh(qdisc_lock(q));
+		goto packet_not_eaten_by_imq_dev;
+	}
+
+packet_not_eaten_by_imq_dev:
+	/* cloned? restore original */
+	if (skb_orig) {
+		kfree_skb(skb);
+		entry->skb = skb_orig;
+	}
+	retval = -1;
+out:
+	return retval;
+}
+
+static struct nf_queue_handler nfqh = {
+	.name  = "imq",
+	.outfn = imq_nf_queue,
+};
+
+static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff *skb,
+				const struct net_device *indev,
+				const struct net_device *outdev,
+				int (*okfn)(struct sk_buff *))
+{
+	int index;
+	struct net_device *dev;
+
+	if (hook == NF_INET_PRE_ROUTING) {
+		skb->imq_flags = 0;
+		index = 0;
+		dev = imq_devs_cache[0];
+	}
+	else if (hook == NF_INET_POST_ROUTING) {
+		index = 1;
+		dev = imq_devs_cache[1];
+	}
+	else return NF_ACCEPT;
+
+	if (dev->flags & IFF_UP) {
+		skb->imq_flags &= IMQ_F_ENQUEUE;
+		skb->imq_flags |= index;
+		return NF_QUEUE;
+	}
+
+	// if imq0/1 is disabled and imq2 enabled and has not seen this packet,
+	// do not accept, but proceed to imq2
+	if (!(skb->imq_flags & IMQ_F_ENQUEUE) &&
+	    (imq_devs_cache[2]->flags & IFF_UP)) {
+		skb->imq_flags &= IMQ_F_ENQUEUE;
+		skb->imq_flags |= 2;
+		return NF_QUEUE;
+	}
+
+	return NF_ACCEPT;
+}
+
+static int imq_close(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+	return 0;
+}
+
+static int imq_open(struct net_device *dev)
+{
+	netif_start_queue(dev);
+	return 0;
+}
+
+static const struct net_device_ops imq_netdev_ops = {
+	.ndo_open		= imq_open,
+	.ndo_stop		= imq_close,
+	.ndo_start_xmit		= imq_dev_xmit_to_next,
+	.ndo_get_stats		= imq_get_stats,
+};
+
+static const struct net_device_ops imq2_netdev_ops = {
+	.ndo_open		= imq_open,
+	.ndo_stop		= imq_close,
+	.ndo_start_xmit		= imq_dev_xmit,
+	.ndo_get_stats		= imq_get_stats,
+};
+
+static void imq_setup(struct net_device *dev)
+{
+	static int xxx = 0;
+	if (xxx != 2) {
+		dev->netdev_ops		= &imq_netdev_ops;
+	}
+	else {
+		dev->netdev_ops		= &imq2_netdev_ops;
+	}
+	imq_devs_cache[xxx] = dev;
+	++xxx;
+
+	dev->type               = ARPHRD_VOID;
+	dev->mtu                = 16000;
+	dev->tx_queue_len       = 11000;
+	dev->flags              = IFF_NOARP;
+	dev->features           = NETIF_F_SG | NETIF_F_FRAGLIST |
+				  NETIF_F_GSO | NETIF_F_HW_CSUM |
+				  NETIF_F_HIGHDMA;
+	dev->priv_flags		&= ~IFF_XMIT_DST_RELEASE;
+}
+
+static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
+{
+	int ret = 0;
+
+	if (tb[IFLA_ADDRESS]) {
+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
+			ret = -EINVAL;
+			goto end;
+		}
+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
+			ret = -EADDRNOTAVAIL;
+			goto end;
+		}
+	}
+	return 0;
+end:
+	printk(KERN_WARNING "IMQ: imq_validate failed (%d)\n", ret);
+	return ret;
+}
+
+static struct rtnl_link_ops imq_link_ops __read_mostly = {
+	.kind		= "imq",
+	.priv_size	= 0,
+	.setup		= imq_setup,
+	.validate	= imq_validate,
+};
+
+static int __init imq_init_hooks(void)
+{
+	int err;
+
+	nf_register_queue_imq_handler(&nfqh);
+
+	err = nf_register_hook(&imq_ingress_ipv4);
+	if (err)
+		goto err1;
+
+	err = nf_register_hook(&imq_egress_ipv4);
+	if (err)
+		goto err2;
+
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	err = nf_register_hook(&imq_ingress_ipv6);
+	if (err)
+		goto err3;
+
+	err = nf_register_hook(&imq_egress_ipv6);
+	if (err)
+		goto err4;
+#endif
+
+	return 0;
+
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+err4:
+	nf_unregister_hook(&imq_ingress_ipv6);
+err3:
+	nf_unregister_hook(&imq_egress_ipv4);
+#endif
+err2:
+	nf_unregister_hook(&imq_ingress_ipv4);
+err1:
+	nf_unregister_queue_imq_handler();
+	return err;
+}
+
+static int __init imq_init_one(int index)
+{
+	struct net_device *dev;
+	int ret;
+
+	dev = alloc_netdev(0, "imq%d", imq_setup);
+	if (!dev)
+		return -ENOMEM;
+
+	ret = dev_alloc_name(dev, dev->name);
+	if (ret < 0)
+		goto fail;
+
+	dev->rtnl_link_ops = &imq_link_ops;
+	ret = register_netdevice(dev);
+	if (ret < 0)
+		goto fail;
+
+	return 0;
+fail:
+	free_netdev(dev);
+	return ret;
+}
+
+static int __init imq_init_devs(void)
+{
+	int err, i;
+
+	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
+		printk(KERN_ERR "IMQ: numdevs has to be betweed 1 and %u\n",
+		       IMQ_MAX_DEVS);
+		return -EINVAL;
+	}
+
+	rtnl_lock();
+	err = __rtnl_link_register(&imq_link_ops);
+
+	for (i = 0; i < numdevs && !err; i++)
+		err = imq_init_one(i);
+
+	if (err) {
+		__rtnl_link_unregister(&imq_link_ops);
+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+	}
+	rtnl_unlock();
+
+	return err;
+}
+
+static int __init imq_init_module(void)
+{
+	int err;
+
+#if defined(CONFIG_IMQ_NUM_DEVS)
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
+#endif
+
+	err = imq_init_devs();
+	if (err) {
+		printk(KERN_ERR "IMQ: Error trying imq_init_devs(net)\n");
+		return err;
+	}
+
+	err = imq_init_hooks();
+	if (err) {
+		printk(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
+		rtnl_link_unregister(&imq_link_ops);
+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+		return err;
+	}
+
+	printk(KERN_INFO "IMQ driver loaded successfully.\n");
+
+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	printk(KERN_INFO "\tHooking IMQ before NAT on PREROUTING.\n");
+#else
+	printk(KERN_INFO "\tHooking IMQ after NAT on PREROUTING.\n");
+#endif
+#if defined(CONFIG_IMQ_BEHAVIOR_AB) || defined(CONFIG_IMQ_BEHAVIOR_BB)
+	printk(KERN_INFO "\tHooking IMQ before NAT on POSTROUTING.\n");
+#else
+	printk(KERN_INFO "\tHooking IMQ after NAT on POSTROUTING.\n");
+#endif
+
+	return 0;
+}
+
+static void __exit imq_unhook(void)
+{
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	nf_unregister_hook(&imq_ingress_ipv6);
+	nf_unregister_hook(&imq_egress_ipv6);
+#endif
+	nf_unregister_hook(&imq_ingress_ipv4);
+	nf_unregister_hook(&imq_egress_ipv4);
+
+	nf_unregister_queue_imq_handler();
+}
+
+static void __exit imq_cleanup_devs(void)
+{
+	rtnl_link_unregister(&imq_link_ops);
+	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
+}
+
+static void __exit imq_exit_module(void)
+{
+	imq_unhook();
+	imq_cleanup_devs();
+	printk(KERN_INFO "IMQ driver unloaded successfully.\n");
+}
+
+module_init(imq_init_module);
+module_exit(imq_exit_module);
+
+module_param(numdevs, int, 0);
+MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will "
+			"be created)");
+MODULE_AUTHOR("http://www.linuximq.net");
+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See "
+			"http://www.linuximq.net/ for more information.");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS_RTNL_LINK("imq");
+
diff -puNrb linux-2.6.35/drivers/net/ixgbe/ixgbe_main.c linux/drivers/net/ixgbe/ixgbe_main.c
--- linux-2.6.35/drivers/net/ixgbe/ixgbe_main.c	2011-04-26 16:28:19.341607510 +0300
+++ linux/drivers/net/ixgbe/ixgbe_main.c	2011-05-02 10:08:26.983210566 +0300
@@ -4665,7 +4665,7 @@ static void ixgbe_sfp_task(struct work_s
 reschedule:
 	if (test_bit(__IXGBE_SFP_MODULE_NOT_FOUND, &adapter->state))
 		mod_timer(&adapter->sfp_timer,
-		          round_jiffies(jiffies + (2 * HZ)));
+		          round_jiffies(jiffies + HZ));
 }
 
 /**
@@ -5468,7 +5468,7 @@ static void ixgbe_watchdog(unsigned long
 
 watchdog_reschedule:
 	/* Reset the timer */
-	mod_timer(&adapter->watchdog_timer, round_jiffies(jiffies + 2 * HZ));
+	mod_timer(&adapter->watchdog_timer, round_jiffies(jiffies + HZ));
 
 watchdog_short_circuit:
 	schedule_work(&adapter->watchdog_task);
@@ -6654,7 +6654,7 @@ static int __devinit ixgbe_probe(struct 
 		 */
 		set_bit(__IXGBE_SFP_MODULE_NOT_FOUND, &adapter->state);
 		mod_timer(&adapter->sfp_timer,
-			  round_jiffies(jiffies + (2 * HZ)));
+			  round_jiffies(jiffies + HZ));
 		err = 0;
 	} else if (err == IXGBE_ERR_SFP_NOT_SUPPORTED) {
 		dev_err(&adapter->pdev->dev, "failed to initialize because "
diff -puNrb linux-2.6.35/drivers/net/Kconfig linux/drivers/net/Kconfig
--- linux-2.6.35/drivers/net/Kconfig	2011-04-26 16:28:20.851917737 +0300
+++ linux/drivers/net/Kconfig	2011-05-02 10:08:27.003225159 +0300
@@ -121,6 +121,129 @@ config EQUALIZER
 	  To compile this driver as a module, choose M here: the module
 	  will be called eql.  If unsure, say N.
 
+config IMQ
+       tristate "IMQ (intermediate queueing device) support"
+       depends on NETDEVICES && NETFILTER
+       ---help---
+         The IMQ device(s) is used as placeholder for QoS queueing disciplines.
+         Every packet entering/leaving the IP stack can be directed through
+         the IMQ device where it's enqueued/dequeued to the attached qdisc.
+         This allows you to treat network devices as classes and distribute
+         bandwidth among them. Iptables is used to specify through which IMQ
+         device, if any, packets travel.
+
+         More information at: http://www.linuximq.net/
+
+         To compile this driver as a module, choose M here: the module
+         will be called imq.  If unsure, say N.
+
+choice
+        prompt "IMQ behavior (PRE/POSTROUTING)"
+	depends on IMQ
+        default IMQ_BEHAVIOR_BA
+        help
+
+                This settings defines how IMQ behaves in respect to its
+                hooking in PREROUTING and POSTROUTING.
+
+                IMQ can work in any of the following ways:
+
+                    PREROUTING   |      POSTROUTING
+                -----------------|-------------------
+                #1  After NAT    |      After NAT
+                #2  After NAT    |      Before NAT
+                #3  Before NAT   |      After NAT
+                #4  Before NAT   |      Before NAT
+
+                The default behavior is to hook before NAT on PREROUTING
+                and after NAT on POSTROUTING (#3).
+
+                This settings are specially usefull when trying to use IMQ
+                to shape NATed clients.
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_AA
+        bool "IMQ AA"
+        help
+                This settings defines how IMQ behaves in respect to its
+                hooking in PREROUTING and POSTROUTING.
+
+                Choosing this option will make IMQ hook like this:
+
+                PREROUTING:   After NAT
+                POSTROUTING:  After NAT
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_AB
+        bool "IMQ AB"
+        help
+                This settings defines how IMQ behaves in respect to its
+                hooking in PREROUTING and POSTROUTING.
+
+                Choosing this option will make IMQ hook like this:
+
+                PREROUTING:   After NAT
+                POSTROUTING:  Before NAT
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_BA
+        bool "IMQ BA"
+        help
+                This settings defines how IMQ behaves in respect to its
+                hooking in PREROUTING and POSTROUTING.
+
+                Choosing this option will make IMQ hook like this:
+
+                PREROUTING:   Before NAT
+                POSTROUTING:  After NAT
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
+config IMQ_BEHAVIOR_BB
+        bool "IMQ BB"
+        help
+                This settings defines how IMQ behaves in respect to its
+                hooking in PREROUTING and POSTROUTING.
+
+                Choosing this option will make IMQ hook like this:
+
+                PREROUTING:   Before NAT
+                POSTROUTING:  Before NAT
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
+endchoice
+
+config IMQ_NUM_DEVS
+
+        int "Number of IMQ devices"
+	range 2 8
+	depends on IMQ
+        default "2"
+        help
+
+                This settings defines how many IMQ devices will be 
+		created.
+
+		The default value is 2.
+
+                More information can be found at: www.linuximq.net
+
+                If not sure leave the default settings alone.
+
 config TUN
 	tristate "Universal TUN/TAP device driver support"
 	select CRC32
@@ -1136,6 +1259,29 @@ config HP100
 	  To compile this driver as a module, choose M here. The module
 	  will be called hp100.
 
+config RBKORINA
+	tristate "RB500 Korina ethernet support"
+	depends on NET_ETHERNET && MIPS_MIKROTIK
+	help
+	  This is idt mips chip built-in ethernet port.
+
+	  To compile this driver as a module, choose M here and read
+	  <file:Documentation/networking/net-modules.txt>. The module
+	  will be called korina.
+
+config ADM5120_ETH
+	tristate "RB100 ADM5120 ethernet support"
+	depends on NET_ETHERNET && MIPS_MIKROTIK
+
+config CRETHER
+	tristate "RB CR ethernet support"
+	depends on NET_ETHERNET && MIPS_MIKROTIK
+
+config MT_VETH
+	bool "MetaROUTER Virtual Ethernet support"
+	depends on METAROUTER || MIPS_MIKROTIK
+	default y
+
 config NET_ISA
 	bool "Other ISA cards"
 	depends on ISA
diff -puNrb linux-2.6.35/drivers/net/Makefile linux/drivers/net/Makefile
--- linux-2.6.35/drivers/net/Makefile	2011-04-26 16:28:20.881915258 +0300
+++ linux/drivers/net/Makefile	2011-05-02 10:08:27.021585460 +0300
@@ -170,6 +170,7 @@ obj-$(CONFIG_XEN_NETDEV_FRONTEND) += xen
 
 obj-$(CONFIG_DUMMY) += dummy.o
 obj-$(CONFIG_IFB) += ifb.o
+obj-$(CONFIG_IMQ) += imq.o
 obj-$(CONFIG_MACVLAN) += macvlan.o
 obj-$(CONFIG_MACVTAP) += macvtap.o
 obj-$(CONFIG_DE600) += de600.o
@@ -249,6 +250,10 @@ obj-$(CONFIG_DM9000) += dm9000.o
 obj-$(CONFIG_PASEMI_MAC) += pasemi_mac_driver.o
 pasemi_mac_driver-objs := pasemi_mac.o pasemi_mac_ethtool.o
 obj-$(CONFIG_MLX4_CORE) += mlx4/
+obj-$(CONFIG_RBKORINA) += rbkorina.o
+obj-$(CONFIG_ADM5120_ETH) += admtek.o
+obj-$(CONFIG_CRETHER) += crether.o
+obj-$(CONFIG_MT_VETH) += mtveth.o
 obj-$(CONFIG_ENC28J60) += enc28j60.o
 obj-$(CONFIG_ETHOC) += ethoc.o
 obj-$(CONFIG_GRETH) += greth.o
diff -puNrb linux-2.6.35/drivers/net/mii.c linux/drivers/net/mii.c
--- linux-2.6.35/drivers/net/mii.c	2011-04-26 16:28:21.012477216 +0300
+++ linux/drivers/net/mii.c	2011-05-02 10:08:27.031545242 +0300
@@ -308,15 +308,20 @@ int mii_nway_restart (struct mii_if_info
  * netif_carrier_on() if current link status is Up or call
  * netif_carrier_off() if current link status is Down.
  */
-void mii_check_link (struct mii_if_info *mii)
+int mii_check_link (struct mii_if_info *mii)
 {
 	int cur_link = mii_link_ok(mii);
 	int prev_link = netif_carrier_ok(mii->dev);
 
-	if (cur_link && !prev_link)
+	if (cur_link && !prev_link) {
+		printk("%s: link up\n", mii->dev->name);
 		netif_carrier_on(mii->dev);
-	else if (prev_link && !cur_link)
+	}
+	else if (prev_link && !cur_link) {
+		printk("%s: link down\n", mii->dev->name);
 		netif_carrier_off(mii->dev);
+	}
+	return cur_link;
 }
 
 /**
diff -puNrb linux-2.6.35/drivers/net/mtveth.c linux/drivers/net/mtveth.c
--- linux-2.6.35/drivers/net/mtveth.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/net/mtveth.c	2011-05-02 10:08:27.041544692 +0300
@@ -0,0 +1,284 @@
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/interrupt.h>
+#include <asm/vm.h>
+
+#define MAX_IFACES	8
+
+#define TXBUF_COUNT	1024
+#define RXBUF_COUNT	128
+
+#define RXBUF_SIZE	1600
+
+extern int vm_create_queue(unsigned id, unsigned irq,
+			   unsigned tx, unsigned rx);
+extern int vm_release_queue(unsigned id);
+
+#define CMD_NEWIFACE	0
+#define CMD_DELIFACE	1
+
+struct ctrl_msg {
+	unsigned cmd;
+	unsigned short id;
+	unsigned char hwaddr[6];
+} __attribute__((packed));
+
+static volatile struct vdma_descr rx_descr[RXBUF_COUNT];
+static volatile struct vdma_descr tx_descr[TXBUF_COUNT];
+static struct sk_buff *rx_skbs[RXBUF_COUNT];
+static struct sk_buff *tx_skbs[TXBUF_COUNT];
+
+static unsigned last_tx;
+static atomic_t cur_tx;
+static unsigned cur_rx;
+static unsigned max_tx;
+
+static struct net_device *devs[MAX_IFACES];
+
+struct veth_private {
+	unsigned id;
+	atomic_t pending_tx;
+};
+
+static void ctrl_receiver(struct work_struct *work);
+
+static struct sk_buff_head ctrl_queue;
+static DECLARE_WORK(ctrl_work, ctrl_receiver);
+
+static int veth_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct veth_private *veth = netdev_priv(dev);
+	unsigned cur = atomic_read(&cur_tx) % TXBUF_COUNT;
+    
+	if (skb_padto(skb, ETH_ZLEN))
+		return NETDEV_TX_OK;
+
+	if (tx_descr[cur].size & DONE) {
+		dev->stats.tx_dropped++;
+		dev_kfree_skb_any(skb);
+		return NETDEV_TX_OK;
+	}
+
+	if (skb_headroom(skb) < 2) {
+		struct sk_buff *s = skb;
+		skb = skb_realloc_headroom(s, 2);
+		dev_kfree_skb_any(s);
+	} else {
+		skb = skb_unshare(skb, GFP_ATOMIC);
+	}
+	if (!skb) {
+		dev->stats.tx_dropped++;
+		return NETDEV_TX_OK;
+	}
+	*(u16 *) skb_push(skb, 2) = veth->id;
+
+	dev->stats.tx_packets++;
+	dev->stats.tx_bytes += skb->len;
+
+	tx_descr[cur].addr = (unsigned) skb->data;
+	tx_descr[cur].size = skb->len | DONE;
+
+	if (tx_skbs[cur]) {
+		/* should not happen */
+		dev->stats.tx_dropped++;
+		dev_kfree_skb_any(skb);
+		return NETDEV_TX_BUSY;
+	}
+
+	tx_skbs[cur] = skb;
+	atomic_add(1, &cur_tx);
+
+	if (atomic_add_return(1, &veth->pending_tx) >= max_tx) {
+		netif_stop_queue(dev);
+
+		/* in case we got rewaken right before stop */
+		if (atomic_read(&veth->pending_tx) < max_tx)
+			netif_wake_queue(dev);
+	}
+
+	return 0;
+}
+
+static irqreturn_t veth_interrupt(int irq, void *dev_id)
+{
+	unsigned cur;
+
+	while (last_tx != atomic_read(&cur_tx)) {
+		unsigned last = last_tx % TXBUF_COUNT;
+		struct net_device *dev;
+		struct veth_private *veth;
+
+		if (tx_descr[last].size & DONE)
+			break;
+
+		dev = tx_skbs[last]->dev;
+		veth = netdev_priv(dev);
+		dev_kfree_skb_irq(tx_skbs[last]);
+		tx_skbs[last] = NULL;
+
+		++last_tx;
+
+		if (atomic_sub_return(1, &veth->pending_tx) < max_tx)
+			netif_wake_queue(dev);
+	}
+
+	cur = cur_rx % RXBUF_COUNT;
+	while ((rx_descr[cur].size & DONE)) {
+		struct sk_buff *skb = rx_skbs[cur];
+		struct net_device *dev;
+		unsigned id;
+
+		skb_put(skb, rx_descr[cur].size & ~DONE);
+		if (skb->len < 2) {
+			dev_kfree_skb_irq(skb);
+			goto next;
+		}
+
+		id = *(u16 *) skb->data;
+		skb_pull(skb, 2);
+
+		if (id == 0) {
+			__skb_queue_tail(&ctrl_queue, skb);
+			schedule_work(&ctrl_work);
+			goto next;
+		}
+		if (id >= MAX_IFACES || !devs[id]) {
+			dev_kfree_skb_irq(skb);
+			goto next;
+		}
+		dev = devs[id];
+
+		skb->dev = dev;
+		skb->protocol = eth_type_trans(skb, dev);
+
+		dev->last_rx = jiffies;
+		++dev->stats.rx_packets;
+		dev->stats.rx_bytes += skb->len;
+
+		netif_rx(skb);
+
+	  next:
+		skb = dev_alloc_skb(RXBUF_SIZE);
+		rx_skbs[cur] = skb;
+		if (skb) {
+			rx_descr[cur].addr = (unsigned) skb->data;
+			rx_descr[cur].size = RXBUF_SIZE;
+		} else {
+			rx_descr[cur].size = 0;
+		}
+
+		++cur_rx;
+		cur = cur_rx % RXBUF_COUNT;
+	}
+
+	return IRQ_HANDLED;
+}
+
+static const struct net_device_ops veth_netdev_ops = {
+	.ndo_start_xmit		= veth_xmit,
+};
+
+static int veth_alloc_dev(unsigned id, const unsigned char *hwaddr)
+{
+	struct veth_private *veth;
+	struct net_device *dev;
+	int err;
+
+	//SET_NETDEV_DEV(dev, &pdev->dev);
+	//platform_set_drvdata(pdev, dev);
+
+	dev = alloc_etherdev(sizeof(struct veth_private));
+	if (!dev)
+		return -ENOMEM;
+
+	veth = netdev_priv(dev);
+	veth->id = id;
+	atomic_set(&veth->pending_tx, 1);
+	memcpy(dev->dev_addr, hwaddr, 6);
+	dev->netdev_ops = &veth_netdev_ops;
+
+	err = register_netdev(dev);
+	if (err < 0) {
+		printk("cannot register net device %u\n", err);
+		goto netdev_err;
+	}
+
+	devs[id] = dev;
+	return 0;
+
+  netdev_err:
+	free_netdev(dev);
+	return err;
+}
+
+static int recv_ctrl_msg(struct sk_buff *skb)
+{
+	struct ctrl_msg *msg = (struct ctrl_msg *) skb->data;
+
+	if (skb->len < sizeof(struct ctrl_msg))
+		return -EINVAL;
+
+	if (msg->cmd == CMD_NEWIFACE) {
+		if (msg->id >= MAX_IFACES || devs[msg->id])
+			return -EBUSY;
+
+		veth_alloc_dev(msg->id, msg->hwaddr);
+		return 0;
+	} else if (msg->cmd == CMD_DELIFACE) {
+		struct net_device *dev;
+
+		if (msg->id >= MAX_IFACES || !devs[msg->id])
+			return -EINVAL;
+		
+		dev = devs[msg->id];
+		devs[msg->id] = NULL;
+
+		unregister_netdev(dev);
+	}
+	return -EINVAL;
+}
+
+static void ctrl_receiver(struct work_struct *work)
+{
+	struct sk_buff *skb;
+
+	while ((skb = skb_dequeue(&ctrl_queue)))
+		recv_ctrl_msg(skb);
+}
+
+int veth_init(void)
+{
+	unsigned i;
+
+	if (vm_running() != 0)
+		return 0;
+
+	skb_queue_head_init(&ctrl_queue);
+
+	if (request_irq(get_virq_nr(3), veth_interrupt, IRQF_SHARED,
+			"veth", (void *) 1))
+		return -EBUSY;
+
+	for (i = 0; i < TXBUF_COUNT; ++i) {
+		tx_descr[i].addr = 0;
+		tx_descr[i].size = 0;
+		tx_descr[i].next = (unsigned) &tx_descr[i + 1];
+	}
+	for (i = 0; i < RXBUF_COUNT; ++i) {
+		rx_skbs[i] = dev_alloc_skb(RXBUF_SIZE);
+		rx_descr[i].addr = (unsigned) rx_skbs[i]->data;
+		rx_descr[i].size = RXBUF_SIZE;
+		rx_descr[i].next = (unsigned) &rx_descr[i + 1];
+	}
+	tx_descr[TXBUF_COUNT - 1].next = (unsigned) &tx_descr[0];
+	rx_descr[RXBUF_COUNT - 1].next = (unsigned) &rx_descr[0];
+	
+	vm_create_queue(3, 3,
+			(unsigned) &tx_descr[0], (unsigned) &rx_descr[0]);
+
+	max_tx = TXBUF_COUNT / MAX_IFACES;
+
+	return 0;
+}
+module_init(veth_init);
diff -puNrb linux-2.6.35/drivers/net/natsemi.c linux/drivers/net/natsemi.c
--- linux-2.6.35/drivers/net/natsemi.c	2011-04-26 16:28:20.881915258 +0300
+++ linux/drivers/net/natsemi.c	2011-05-02 10:08:27.061543334 +0300
@@ -99,9 +99,9 @@ static int full_duplex[MAX_UNITS];
    Making the Tx ring too large decreases the effectiveness of channel
    bonding and packet priority.
    There are no ill effects from too-large receive rings. */
-#define TX_RING_SIZE	16
-#define TX_QUEUE_LEN	10 /* Limit ring entries actually used, min 4. */
-#define RX_RING_SIZE	32
+#define TX_RING_SIZE	32
+#define TX_QUEUE_LEN	28 /* Limit ring entries actually used, min 4. */
+#define RX_RING_SIZE	64
 
 /* Operational parameters that usually are not changed. */
 /* Time in jiffies before concluding the transmitter is hung. */
@@ -591,6 +591,10 @@ struct netdev_private {
 	unsigned int iosize;
 	spinlock_t lock;
 	u32 msg_enable;
+
+	int long_cable;
+	int cable_magic_done;
+
 	/* EEPROM data */
 	int eeprom_size;
 };
@@ -1585,9 +1589,12 @@ static void do_cable_magic(struct net_de
 	if (dev->if_port != PORT_TP)
 		return;
 
-	if (np->srr >= SRR_DP83816_A5)
+	if (np->srr >= SRR_DP83816_A5 || np->long_cable)
 		return;
 
+	np->cable_magic_done = 1;
+	printk("natsemi: do cable magic\n");
+
 	/*
 	 * 100 MBit links with short cables can trip an issue with the chip.
 	 * The problem manifests as lots of CRC errors and/or flickering
@@ -1630,9 +1637,12 @@ static void undo_cable_magic(struct net_
 	if (dev->if_port != PORT_TP)
 		return;
 
-	if (np->srr >= SRR_DP83816_A5)
+	if (np->srr >= SRR_DP83816_A5 || !np->cable_magic_done)
 		return;
 
+	np->cable_magic_done = 0;
+	printk("natsemi: undo cable magic\n");
+
 	writew(1, ioaddr + PGSEL);
 	/* make sure the lock bit is clear */
 	data = readw(ioaddr + DSPCFG);
@@ -3091,6 +3101,19 @@ static int netdev_ioctl(struct net_devic
 						data->val_in);
 		}
 		return 0;
+	case 0x12345678: {
+		struct ethtool_value edata;
+		if (copy_from_user(&edata, rq->ifr_data, sizeof(edata)))
+			return -EFAULT;
+
+		spin_lock_irq(&np->lock);
+		undo_cable_magic(dev);
+		np->long_cable = edata.data;
+		do_cable_magic(dev);
+		spin_unlock_irq(&np->lock);
+
+		return 0;
+	}
 	default:
 		return -EOPNOTSUPP;
 	}
diff -puNrb linux-2.6.35/drivers/net/phy/phy.c linux/drivers/net/phy/phy.c
--- linux-2.6.35/drivers/net/phy/phy.c	2011-04-26 16:28:12.332789916 +0300
+++ linux/drivers/net/phy/phy.c	2011-05-02 10:08:27.071545258 +0300
@@ -428,7 +428,7 @@ void phy_start_machine(struct phy_device
 {
 	phydev->adjust_state = handler;
 
-	schedule_delayed_work(&phydev->state_queue, HZ);
+	schedule_delayed_work(&phydev->state_queue, 1);
 }
 
 /**
@@ -860,7 +860,6 @@ void phy_state_machine(struct work_struc
 				netif_carrier_on(phydev->attached_dev);
 			} else {
 				if (0 == phydev->link_timeout--) {
-					phy_force_reduction(phydev);
 					needs_aneg = 1;
 				}
 			}
diff -puNrb linux-2.6.35/drivers/net/ppp_generic.c linux/drivers/net/ppp_generic.c
--- linux-2.6.35/drivers/net/ppp_generic.c	2011-04-26 16:28:21.032477148 +0300
+++ linux/drivers/net/ppp_generic.c	2011-05-02 10:08:27.091544381 +0300
@@ -46,6 +46,7 @@
 #include <linux/stddef.h>
 #include <linux/device.h>
 #include <linux/mutex.h>
+#include <linux/etherdevice.h>
 #include <linux/slab.h>
 #include <net/slhc_vj.h>
 #include <asm/atomic.h>
@@ -65,12 +66,16 @@
 #define NP_AT	3		/* Appletalk protocol */
 #define NP_MPLS_UC 4		/* MPLS unicast */
 #define NP_MPLS_MC 5		/* MPLS multicast */
-#define NUM_NP	6		/* Number of NPs. */
+#define NP_BRIDGE 6
+#define NUM_NP	7		/* Number of NPs. */
 
 #define MPHDRLEN	6	/* multilink protocol header length */
 #define MPHDRLEN_SSN	4	/* ditto with short sequence numbers */
 #define MIN_FRAG_SIZE	64
 
+#define BCP_HDRLEN	2
+#define BCP_LAN_FCS	0x80
+
 /*
  * An instance of /dev/ppp can be associated with either a ppp
  * interface unit or a ppp channel.  In both cases, file->private_data
@@ -101,6 +106,7 @@ struct ppp_file {
  * It can have 0 or more ppp channels connected to it.
  */
 struct ppp {
+	unsigned	userid;		/* should be on top for traflog */
 	struct ppp_file	file;		/* stuff for read/write/poll 0 */
 	struct file	*owner;		/* file that owns this unit 48 */
 	struct list_head channels;	/* list of attached channels 4c */
@@ -229,8 +235,9 @@ struct ppp_net {
 #define E	0x40		/* this fragment ends a packet */
 
 /* Compare multilink sequence numbers (assumed to be 32 bits wide) */
-#define seq_before(a, b)	((s32)((a) - (b)) < 0)
-#define seq_after(a, b)		((s32)((a) - (b)) > 0)
+/* NOTE: use only 32k comparison window to cope with 16bit seq numbers */
+#define seq_before(a, b)	((s16)((a) - (b)) < 0)
+#define seq_after(a, b)		((s16)((a) - (b)) > 0)
 
 /* Prototypes. */
 static int ppp_unattached_ioctl(struct net *net, struct ppp_file *pf,
@@ -297,6 +304,8 @@ static inline int proto_to_npindex(int p
 		return NP_MPLS_UC;
 	case PPP_MPLS_MC:
 		return NP_MPLS_MC;
+	case PPP_BRIDGE:
+		return NP_BRIDGE;
 	}
 	return -EINVAL;
 }
@@ -309,6 +318,7 @@ static const int npindex_to_proto[NUM_NP
 	PPP_AT,
 	PPP_MPLS_UC,
 	PPP_MPLS_MC,
+	PPP_BRIDGE,
 };
 
 /* Translates an ethertype into an NP index */
@@ -340,6 +350,7 @@ static const int npindex_to_ethertype[NU
 	ETH_P_PPPTALK,
 	ETH_P_MPLS_UC,
 	ETH_P_MPLS_MC,
+	ETH_P_802_3
 };
 
 /*
@@ -354,6 +365,59 @@ static const int npindex_to_ethertype[NU
 #define ppp_unlock(ppp)		do { ppp_recv_unlock(ppp); \
 				     ppp_xmit_unlock(ppp); } while (0)
 
+static int bcp_encap(struct sk_buff **skb)
+{
+	unsigned char *pp;
+
+	if (skb_headroom(*skb) < PPP_HDRLEN + BCP_HDRLEN) {
+		struct sk_buff *ns;
+
+		ns = alloc_skb((*skb)->len + PPP_HDRLEN + BCP_HDRLEN,
+			       GFP_ATOMIC);
+		if (ns == 0)
+			return -EINVAL;
+		skb_reserve(ns, PPP_HDRLEN + BCP_HDRLEN);
+		skb_copy_bits(*skb, 0, skb_put(ns, (*skb)->len), (*skb)->len);
+		kfree_skb(*skb);
+		*skb = ns;
+	}
+
+	pp = skb_push(*skb, BCP_HDRLEN);
+	pp[0] = 0; /* flags */
+	pp[1] = 1; /* mactype */
+	return NP_BRIDGE;
+}
+
+static int
+bcp_decap(struct sk_buff *skb, struct net_device *dev)
+{
+	if (!pskb_may_pull(skb, BCP_HDRLEN + ETH_HLEN))
+		return -1;
+
+	if (skb->data[1] != 1)
+		return -1;
+
+	if (skb->data[0] & BCP_LAN_FCS) {
+		if (skb->len < 4)
+			return -1;
+		pskb_trim_rcsum(skb, skb->len - 4);
+	}
+	skb_pull_rcsum(skb, BCP_HDRLEN);
+
+	skb->protocol = eth_type_trans(skb, dev);
+
+	if (is_multicast_ether_addr(eth_hdr(skb)->h_dest)) {
+		if (is_broadcast_ether_addr(eth_hdr(skb)->h_dest))
+			skb->pkt_type = PACKET_BROADCAST;
+		else 
+			skb->pkt_type = PACKET_MULTICAST;
+	} else {
+		skb->pkt_type = PACKET_OTHERHOST;
+	}
+
+	return 0;
+}
+
 /*
  * /dev/ppp device routines.
  * The /dev/ppp device is used by pppd to control the ppp unit.
@@ -622,6 +686,19 @@ static long ppp_ioctl(struct file *file,
 			err = ppp_disconnect_channel(pch);
 			break;
 
+		case PPPIOCSMTU:
+			if (get_user(val, p))
+				break;
+			down_read(&pch->chan_sem);
+			chan = pch->chan;
+			err = -ENOTTY;
+			if (chan) {
+				err = 0;
+				if (!pch->chan->mtu || val < pch->chan->mtu)
+					pch->chan->mtu = val;
+			}
+			up_read(&pch->chan_sem);
+			break;
 		default:
 			down_read(&pch->chan_sem);
 			chan = pch->chan;
@@ -785,6 +862,12 @@ static long ppp_ioctl(struct file *file,
 		break;
 #endif /* CONFIG_PPP_MULTILINK */
 
+	case PPPIOCSUSER:
+		if (copy_from_user(&ppp->userid, (unsigned *) arg,
+				   sizeof(ppp->userid))) break;
+		err = 0;
+		break;
+
 	default:
 		err = -ENOTTY;
 	}
@@ -946,7 +1029,13 @@ ppp_start_xmit(struct sk_buff *skb, stru
 	int npi, proto;
 	unsigned char *pp;
 
+	if (skb_network_header(skb) > skb->data)
+		npi = bcp_encap(&skb);
+	else {
 	npi = ethertype_to_npindex(ntohs(skb->protocol));
+		if (npi < 0) npi = bcp_encap(&skb);
+	}
+
 	if (npi < 0)
 		goto outf;
 
@@ -980,7 +1069,8 @@ ppp_start_xmit(struct sk_buff *skb, stru
 
  outf:
 	kfree_skb(skb);
-	++dev->stats.tx_dropped;
+	if (ppp->dev)
+		++ppp->dev->stats.tx_dropped;
 	return NETDEV_TX_OK;
 }
 
@@ -1458,6 +1548,9 @@ static int ppp_mp_explode(struct ppp *pp
 			continue;
 		}
 
+		/* do not fragment into too many small packets */
+		flen = min(max(flen, 34), len);
+
 		mtu = pch->chan->mtu - hdrlen;
 		if (mtu < 4)
 			mtu = 4;
@@ -1666,8 +1759,11 @@ ppp_receive_nonmp_frame(struct ppp *ppp,
 	 * that come in as well as compressed frames.
 	 */
 	if (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN) &&
-	    (ppp->rstate & (SC_DC_FERROR | SC_DC_ERROR)) == 0)
-		skb = ppp_decompress_frame(ppp, skb);
+	    (ppp->rstate & (SC_DC_FERROR)) == 0) {
+		ns = ppp_decompress_frame(ppp, skb);
+		if (!ns) goto err;
+		skb = ns;
+	}
 
 	if (ppp->flags & SC_MUST_COMP && ppp->rstate & SC_DC_FERROR)
 		goto err;
@@ -1781,8 +1877,13 @@ ppp_receive_nonmp_frame(struct ppp *ppp,
 			/* chop off protocol */
 			skb_pull_rcsum(skb, 2);
 			skb->dev = ppp->dev;
+			if (npi == NP_BRIDGE) {
+				if (bcp_decap(skb, ppp->dev) != 0)
+					goto err;
+			} else {
 			skb->protocol = htons(npindex_to_ethertype[npi]);
 			skb_reset_mac_header(skb);
+			}
 			netif_rx(skb);
 		}
 	}
@@ -1826,12 +1927,14 @@ ppp_decompress_frame(struct ppp *ppp, st
 		/* the decompressor still expects the A/C bytes in the hdr */
 		len = ppp->rcomp->decompress(ppp->rc_state, skb->data - 2,
 				skb->len + 2, ns->data, obuff_size);
-		if (len < 0) {
+		if (len <= 0) {
 			/* Pass the compressed frame to pppd as an
 			   error indication. */
 			if (len == DECOMP_FATALERROR)
 				ppp->rstate |= SC_DC_FERROR;
 			kfree_skb(ns);
+			if (len == 0 || (ppp->rstate & SC_DC_ERROR))
+				return NULL;
 			goto err;
 		}
 
@@ -2242,6 +2345,12 @@ ppp_output_wakeup(struct ppp_channel *ch
 	ppp_channel_push(pch);
 }
 
+struct net_device *ppp_get_device(struct ppp_channel *chan) {
+	struct channel *ch = chan->ppp;
+	if (ch && ch->ppp) return ch->ppp->dev;
+	return NULL;
+}
+
 /*
  * Compression control.
  */
@@ -2925,6 +3034,7 @@ EXPORT_SYMBOL(ppp_input_error);
 EXPORT_SYMBOL(ppp_output_wakeup);
 EXPORT_SYMBOL(ppp_register_compressor);
 EXPORT_SYMBOL(ppp_unregister_compressor);
+EXPORT_SYMBOL(ppp_get_device);
 MODULE_LICENSE("GPL");
 MODULE_ALIAS_CHARDEV(PPP_MAJOR, 0);
 MODULE_ALIAS("devname:ppp");
diff -puNrb linux-2.6.35/drivers/net/ppp_mppe.c linux/drivers/net/ppp_mppe.c
--- linux-2.6.35/drivers/net/ppp_mppe.c	2011-04-26 16:28:20.861920796 +0300
+++ linux/drivers/net/ppp_mppe.c	2011-05-02 10:08:27.111544860 +0300
@@ -64,6 +64,13 @@ MODULE_LICENSE("Dual BSD/GPL");
 MODULE_ALIAS("ppp-compress-" __stringify(CI_MPPE));
 MODULE_VERSION("1.0.2");
 
+static inline int is_ip_packet(unsigned char *obuf) {
+	unsigned proto = ntohs(*(unsigned short *) obuf);
+
+	return proto == 0x0021 || proto == 0x002d || proto == 0x002f
+	    || proto == 0x0031 || proto == 0x0057;
+}
+
 static unsigned int
 setup_sg(struct scatterlist *sg, const void *address, unsigned int length)
 {
@@ -187,6 +194,10 @@ static void mppe_rekey(struct ppp_mppe_s
 	crypto_blkcipher_setkey(state->arc4, state->session_key, state->keylen);
 }
 
+static void mppe_reset_key(struct ppp_mppe_state * state) {
+	crypto_blkcipher_setkey(state->arc4, state->session_key, state->keylen);
+}
+
 /*
  * Allocate space for a (de)compressor.
  */
@@ -407,14 +418,16 @@ mppe_compress(void *arg, unsigned char *
 	obuf[1] = state->ccount & 0xff;
 
 	if (!state->stateful ||	/* stateless mode     */
-	    ((state->ccount & 0xff) == 0xff) ||	/* "flag" packet      */
-	    (state->bits & MPPE_BIT_FLUSHED)) {	/* CCP Reset-Request  */
+	    ((state->ccount & 0xff) == 0xff)) {	/* "flag" packet      */
 		/* We must rekey */
 		if (state->debug && state->stateful)
 			printk(KERN_DEBUG "mppe_compress[%d]: rekeying\n",
 			       state->unit);
 		mppe_rekey(state, 0);
 		state->bits |= MPPE_BIT_FLUSHED;
+	} else if (state->bits & MPPE_BIT_FLUSHED) {
+		/* CCP Reset-Request  */
+		mppe_reset_key(state);
 	}
 	obuf[0] |= state->bits;
 	state->bits &= ~MPPE_BIT_FLUSHED;	/* reset for next xmit */
@@ -510,6 +523,13 @@ mppe_decompress(void *arg, unsigned char
 		printk(KERN_DEBUG "mppe_decompress[%d]: ccount %d\n",
 		       state->unit, ccount);
 
+	if (((ccount - state->ccount - 1) & (MPPE_CCOUNT_SPACE - 1)) > 0x800) {
+		printk(KERN_DEBUG "mppe_decompress: "
+		       "packet out of order seq %d, expected %d\n",
+		       ccount, (state->ccount + 1) % MPPE_CCOUNT_SPACE);
+		return 0;
+	}
+
 	/* sanity checks -- terminate with extreme prejudice */
 	if (!(MPPE_BITS(ibuf) & MPPE_BIT_ENCRYPTED)) {
 		printk(KERN_DEBUG
@@ -524,12 +544,7 @@ mppe_decompress(void *arg, unsigned char
 		state->sanity_errors += 100;
 		sanity = 1;
 	}
-	if (state->stateful && ((ccount & 0xff) == 0xff) && !flushed) {
-		printk(KERN_DEBUG "mppe_decompress[%d]: FLUSHED bit not set on "
-		       "flag packet!\n", state->unit);
-		state->sanity_errors += 100;
-		sanity = 1;
-	}
+	if (state->stateful && ((ccount & 0xff) == 0xff)) flushed = 1;
 
 	if (sanity) {
 		if (state->sanity_errors < SANITY_MAX)
@@ -594,8 +609,12 @@ mppe_decompress(void *arg, unsigned char
 				 */
 			}
 		}
-		if (flushed)
+		if (flushed) {
+		    if ((ccount & 0xff) == 0xff)
 			mppe_rekey(state, 0);
+		    else
+			mppe_reset_key(state);
+		}
 	}
 
 	/*
@@ -609,37 +628,25 @@ mppe_decompress(void *arg, unsigned char
 	isize -= PPP_HDRLEN + MPPE_OVHD;	/* -6 */
 	/* net osize: isize-4 */
 
-	/*
-	 * Decrypt the first byte in order to check if it is
-	 * a compressed or uncompressed protocol field.
-	 */
+	/* And finally, decrypt the rest of the packet. */
 	sg_init_table(sg_in, 1);
 	sg_init_table(sg_out, 1);
-	setup_sg(sg_in, ibuf, 1);
-	setup_sg(sg_out, obuf, 1);
-	if (crypto_blkcipher_decrypt(&desc, sg_out, sg_in, 1) != 0) {
+	setup_sg(sg_in, ibuf, isize);
+	setup_sg(sg_out, obuf, osize);
+
+	if (crypto_blkcipher_decrypt(&desc, sg_out, sg_in, isize) != 0) {
 		printk(KERN_DEBUG "crypto_cypher_decrypt failed\n");
 		return DECOMP_ERROR;
 	}
 
-	/*
-	 * Do PFC decompression.
-	 * This would be nicer if we were given the actual sk_buff
-	 * instead of a char *.
-	 */
-	if ((obuf[0] & 0x01) != 0) {
-		obuf[1] = obuf[0];
-		obuf[0] = 0;
-		obuf++;
-		osize++;
+	if (!is_ip_packet(obuf)) {
+		if (!state->stateful) {
+			printk(KERN_DEBUG
+			       "MPPE not an ip packet (proto=0x%x)\n",
+			       ntohs(*(unsigned short *) obuf));
+			return DECOMP_FATALERROR;
 	}
-
-	/* And finally, decrypt the rest of the packet. */
-	setup_sg(sg_in, ibuf + 1, isize - 1);
-	setup_sg(sg_out, obuf + 1, osize - 1);
-	if (crypto_blkcipher_decrypt(&desc, sg_out, sg_in, isize - 1)) {
-		printk(KERN_DEBUG "crypto_cypher_decrypt failed\n");
-		return DECOMP_ERROR;
+		if (!flushed) return DECOMP_ERROR;
 	}
 
 	state->stats.unc_bytes += osize;
diff -puNrb linux-2.6.35/drivers/net/pppoe.c linux/drivers/net/pppoe.c
--- linux-2.6.35/drivers/net/pppoe.c	2011-04-26 16:28:20.962476952 +0300
+++ linux/drivers/net/pppoe.c	2011-05-02 10:08:27.131588909 +0300
@@ -77,6 +77,7 @@
 #include <linux/file.h>
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
+#include <linux/jhash.h>
 
 #include <linux/nsproxy.h>
 #include <net/net_namespace.h>
@@ -84,8 +85,9 @@
 #include <net/sock.h>
 
 #include <asm/uaccess.h>
+#include <asm/unaligned.h>
 
-#define PPPOE_HASH_BITS 4
+#define PPPOE_HASH_BITS 12
 #define PPPOE_HASH_SIZE (1 << PPPOE_HASH_BITS)
 #define PPPOE_HASH_MASK	(PPPOE_HASH_SIZE - 1)
 
@@ -140,23 +142,11 @@ static inline int cmp_addr(struct pppoe_
 	return a->sid == sid && !memcmp(a->remote, addr, ETH_ALEN);
 }
 
-#if 8 % PPPOE_HASH_BITS
-#error 8 must be a multiple of PPPOE_HASH_BITS
-#endif
-
 static int hash_item(__be16 sid, unsigned char *addr)
 {
-	unsigned char hash = 0;
-	unsigned int i;
-
-	for (i = 0; i < ETH_ALEN; i++)
-		hash ^= addr[i];
-	for (i = 0; i < sizeof(sid_t) * 8; i += 8)
-		hash ^= (__force __u32)sid >> i;
-	for (i = 8; (i >>= 1) >= PPPOE_HASH_BITS;)
-		hash ^= hash >> i;
-
-	return hash & PPPOE_HASH_MASK;
+	return jhash_3words(
+		sid, get_unaligned((u32 *) addr),
+		get_unaligned((u16 *) addr + 2), 0) % PPPOE_HASH_SIZE;
 }
 
 /**********************************************************************
@@ -922,6 +912,9 @@ static int __pppoe_xmit(struct sock *sk,
 	if (!dev)
 		goto abort;
 
+	nf_bridge_put(skb->nf_bridge);
+	skb->nf_bridge = NULL;
+
 	/* Copy the data if there is no space for the header or if it's
 	 * read-only.
 	 */
diff -puNrb linux-2.6.35/drivers/net/r8169.c linux/drivers/net/r8169.c
--- linux-2.6.35/drivers/net/r8169.c	2011-04-26 16:28:20.932489033 +0300
+++ linux/drivers/net/r8169.c	2011-05-02 10:08:27.151586177 +0300
@@ -69,7 +69,7 @@ static const int multicast_filter_limit 
 
 #define R8169_REGS_SIZE		256
 #define R8169_NAPI_WEIGHT	64
-#define NUM_TX_DESC	64	/* Number of Tx descriptor registers */
+#define NUM_TX_DESC	256	/* Number of Tx descriptor registers */
 #define NUM_RX_DESC	256	/* Number of Rx descriptor registers */
 #define RX_BUF_SIZE	1536	/* Rx Buffer size */
 #define R8169_TX_RING_BYTES	(NUM_TX_DESC * sizeof(struct TxDesc))
@@ -3027,6 +3027,7 @@ rtl8169_init_one(struct pci_dev *pdev, c
 
 	SET_NETDEV_DEV(dev, &pdev->dev);
 	dev->netdev_ops = &rtl8169_netdev_ops;
+	dev->l2mtu = 16383;
 	tp = netdev_priv(dev);
 	tp->dev = dev;
 	tp->pci_dev = pdev;
@@ -3943,33 +3944,10 @@ static void rtl_hw_start_8101(struct net
 
 static int rtl8169_change_mtu(struct net_device *dev, int new_mtu)
 {
-	struct rtl8169_private *tp = netdev_priv(dev);
-	int ret = 0;
-
-	if (new_mtu < ETH_ZLEN || new_mtu > SafeMtu)
+	if (new_mtu < ETH_ZLEN || new_mtu > dev->l2mtu)
 		return -EINVAL;
-
 	dev->mtu = new_mtu;
-
-	if (!netif_running(dev))
-		goto out;
-
-	rtl8169_down(dev);
-
-	rtl8169_set_rxbufsize(tp, dev->mtu);
-
-	ret = rtl8169_init_ring(dev);
-	if (ret < 0)
-		goto out;
-
-	napi_enable(&tp->napi);
-
-	rtl_hw_start(dev);
-
-	rtl8169_request_timer(dev);
-
-out:
-	return ret;
+	return 0;
 }
 
 static inline void rtl8169_make_unusable_by_asic(struct RxDesc *desc)
diff -puNrb linux-2.6.35/drivers/net/rbkorina.c linux/drivers/net/rbkorina.c
--- linux-2.6.35/drivers/net/rbkorina.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/net/rbkorina.c	2011-05-02 10:08:27.161544703 +0300
@@ -0,0 +1,885 @@
+/*
+        Copyright 2003 Integrated Device Technology, Inc.
+        Copyright 2002 MontaVista Software Inc.
+                stevel@mvista.com or source@mvista.com
+*/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/ctype.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/proc_fs.h>
+#include <linux/in.h>
+#include <linux/slab.h> 
+#include <linux/string.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/errno.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <asm/unaligned.h>
+
+#define KORINA_DMA_RX_IRQ 40
+#define KORINA_DMA_TX_IRQ 41
+#define KORINA_UNDERFLOW_IRQ 114
+
+#define TX_RING_SIZE	128
+#define TX_QUEUE_LEN	120
+#define RX_RING_SIZE	128
+
+#define PKT_BUF_SZ	1636
+
+
+#define KORINA_BASE 0x18060000
+#define DMA_BASE 0x18040000
+
+#define DMA_REG(channel, reg) \
+        ((*(volatile u32 *) KSEG1ADDR(DMA_BASE + (channel) * 20 + (reg))))
+
+#define KORINA_REG(reg) \
+        ((*(volatile u32 *) KSEG1ADDR(KORINA_BASE + (reg))))
+
+#define DMA_RX_CHANNEL 0
+#define DMA_TX_CHANNEL 1
+
+#define DMA_CONTROLL    0x00
+#define DMA_STATUS      0x04
+#define DMA_STATUS_MASK 0x08
+#define DMA_DESCR_PTR   0x0c
+#define DMA_NEXT_DESCR  0x10
+
+#define DMAC_RUN        0x01
+#define DMAC_DONE       0x02
+#define DMAC_ABORT      0x10
+
+#define DMAS_FINISHED	0x01
+#define DMAS_DONE	0x02
+#define DMAS_ERROR	0x08
+#define DMAS_HALT       0x10
+
+#define DMASM_FINISHED	0x01
+#define DMASM_DONE	0x02
+#define DMASM_CHAIN	0x04
+#define DMASM_ERROR	0x08
+#define DMASM_HALT	0x10
+
+#define KORINA_CONTROL		0x0000
+#define KORINA_FIFO_TX_THRE	0x0004
+#define KORINA_ADDR_RECOGN	0x0008
+#define KORINA_CLOCK		0x0028
+#define KORINA_ADDR_LO		0x0100
+#define KORINA_ADDR_HI		0x0104
+#define KORINA_CONFIG1		0x0200
+#define KORINA_CONFIG2		0x0204
+#define KORINA_BTB_IPACK_GAP	0x0208
+#define KORINA_NBTB_IPACK_GAP	0x020c
+#define KORINA_MAX_FRAME	0x0214
+#define KORINA_MII_CONFIG	0x0220
+#define KORINA_MII_COMMAND	0x0224
+#define KORINA_MII_ADDR		0x0228
+#define KORINA_MII_WRITE_DATA	0x022c
+#define KORINA_MII_READ_DATA	0x0230
+#define KORINA_MII_IND		0x0234
+
+#define ETHINTFC_ENABLE		0x01
+#define ETHINTFC_RESETTING	0x04
+#define ETHINTFC_UNDERFLOW	0x20
+
+#define ETHARC_PROMISC		0x01
+#define ETHARC_ALL_MULTICAST	0x02
+#define ETHARC_BROADCAST	0x08
+
+#define ETHMAC1_RX_ENABLE 0x01
+
+#define ETHMAC2_FULL_DUPLEX	0x01
+#define ETHMAC2_CRC_ENABLE	0x10
+#define ETHMAC2_PAD_ENABLE	0x20
+
+#define MIIMCFG_RESET		0x8000
+
+#define MIIMCMD_READ		0x01
+
+#define MIIMIND_BUSY		0x01
+#define MIIMIND_NOT_VALID	0x04
+
+#define MII_CLOCK 1250000
+
+#define DMAD_COUNT		0x0003ffff
+#define DMAD_INT_ON_FINISHED	0x08000000
+#define DMAD_INT_ON_DONE	0x10000000
+#define DMAD_DONE		0x40000000
+#define DMAD_FINISHED		0x80000000
+
+#define DMA_DESCR(base, off) ((base) + sizeof(struct dma_desc) * (off))
+
+#define DEVCS_RX_OK		0x00000004
+#define DEVCS_RX_OVERFLOW	0x00000100
+#define DEVCS_RX_CRC_ERR	0x00000200
+#define DEVCS_RX_CODE_VIOLATION 0x00000400
+#define DEVCS_RX_LEN_ERROR	0x00001000
+#define DEVCS_RX_BAD_LENGTH	0x00002000
+
+#define DEVCS_TX_FIRST_DESC		0x00000001
+#define DEVCS_TX_LAST_DESC		0x00000002
+#define DEVCS_TX_OK			0x00000040
+#define DEVCS_TX_UNDERFLOW		0x00000200
+#define DEVCS_TX_OVERSIZED		0x00000400
+#define DEVCS_TX_EXCESSIVE_DEFERAL	0x00000800
+#define DEVCS_TX_EXCESSIVE_COLLISIONS	0x00001000
+#define DEVCS_TX_LATE_COLLISION		0x00002000
+
+
+extern unsigned long mips_hpt_frequency;
+extern unsigned char mips_mac_address[6];
+
+struct dma_desc {
+        u32 control;
+        u32 addr;
+        u32 devcs;
+        u32 link;
+};
+
+struct korina_private {
+	volatile struct dma_desc *tx_ring;
+	volatile struct dma_desc *rx_ring;
+	dma_addr_t td_ring_dma;
+	dma_addr_t rd_ring_dma;
+
+	struct sk_buff *tx_skb[TX_RING_SIZE];
+	struct sk_buff *rx_skb[RX_RING_SIZE];
+	dma_addr_t rx_skb_dma[RX_RING_SIZE];
+
+	unsigned cur_rx;
+	unsigned dirty_rx;
+
+	unsigned cur_tx;
+	unsigned dirty_tx;
+	
+	spinlock_t lock;
+
+	struct net_device *dev;
+	struct mii_if_info mii_if;
+	struct napi_struct napi;
+};
+
+static void korina_dump(struct net_device *dev) {
+    struct korina_private *np = netdev_priv(dev);
+    int i;
+
+
+    printk("TX %d(%d) %d(%d)\n",
+	   np->cur_tx, np->cur_tx % TX_RING_SIZE,
+	   np->dirty_tx, np->dirty_tx % TX_RING_SIZE);
+    printk("DMA_CONTROLL %08x\n", DMA_REG(DMA_TX_CHANNEL, DMA_CONTROLL));
+    printk("DMA_STATUS   %08x\n", DMA_REG(DMA_TX_CHANNEL, DMA_STATUS));
+    printk("DMA_MASK     %08x\n", DMA_REG(DMA_TX_CHANNEL, DMA_STATUS_MASK));
+    printk("DMA_DESCR    %08x\n", DMA_REG(DMA_TX_CHANNEL, DMA_DESCR_PTR));
+    printk("DMA_NEXT     %08x\n", DMA_REG(DMA_TX_CHANNEL, DMA_NEXT_DESCR));
+    for (i = 0; i < TX_RING_SIZE; ++i) {
+	printk("%03d: %08x %08x %08x %08x\n", i,
+	       np->tx_ring[i].control,
+	       np->tx_ring[i].addr,
+	       np->tx_ring[i].devcs,
+	       np->tx_ring[i].link
+	    );
+    }
+    printk("RX %d(%d) %d(%d)\n",
+	   np->cur_rx, np->cur_rx % RX_RING_SIZE,
+	   np->dirty_rx, np->dirty_rx % RX_RING_SIZE);
+    printk("DMA_CONTROLL %08x\n", DMA_REG(DMA_RX_CHANNEL, DMA_CONTROLL));
+    printk("DMA_STATUS   %08x\n", DMA_REG(DMA_RX_CHANNEL, DMA_STATUS));
+    printk("DMA_MASK     %08x\n", DMA_REG(DMA_RX_CHANNEL, DMA_STATUS_MASK));
+    printk("DMA_DESCR    %08x\n", DMA_REG(DMA_RX_CHANNEL, DMA_DESCR_PTR));
+    printk("DMA_NEXT     %08x\n", DMA_REG(DMA_RX_CHANNEL, DMA_NEXT_DESCR));
+    for (i = 0; i < RX_RING_SIZE; ++i) {
+	printk("%03d: %08x %08x %08x %08x\n", i,
+	       np->rx_ring[i].control,
+	       np->rx_ring[i].addr,
+	       np->rx_ring[i].devcs,
+	       np->rx_ring[i].link
+	    );
+    }
+}
+
+static inline void dma_abort(struct net_device *dev, int channel)
+{
+        if (DMA_REG(channel, DMA_CONTROLL) & DMAC_RUN) {
+                DMA_REG(channel, DMA_CONTROLL) = DMAC_ABORT;
+                while (!(DMA_REG(channel, DMA_STATUS) & DMAS_HALT)) {
+			dev->trans_start = jiffies;
+                }
+                DMA_REG(channel, DMA_STATUS) = 0;
+        }
+        DMA_REG(channel, DMA_DESCR_PTR) = 0;
+        DMA_REG(channel, DMA_NEXT_DESCR) = 0;
+}
+
+static int mdio_read(struct net_device *dev, int phy_id, int regnum)
+{
+	int value;
+
+	KORINA_REG(KORINA_MII_ADDR) = (phy_id << 8) | regnum;
+	KORINA_REG(KORINA_MII_COMMAND) = MIIMCMD_READ;
+
+	while (KORINA_REG(KORINA_MII_IND) & MIIMIND_BUSY);
+
+	if (KORINA_REG(KORINA_MII_IND) & MIIMIND_NOT_VALID) return 0;
+
+	value = KORINA_REG(KORINA_MII_READ_DATA);
+	KORINA_REG(KORINA_MII_COMMAND) = 0;
+
+	return value;
+}
+
+static void mdio_write(struct net_device *dev,
+		       int phy_id, int regnum, int value)
+{
+	KORINA_REG(KORINA_MII_ADDR) = (phy_id << 8) | regnum;
+	KORINA_REG(KORINA_MII_WRITE_DATA) = value;
+
+	while(KORINA_REG(KORINA_MII_IND) & MIIMIND_BUSY);
+}
+
+
+static void korina_get_drvinfo (struct net_device *dev,
+				struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, "korina");
+	strcpy(info->version, "1.0");
+	strcpy(info->bus_info, "00:00.0 korina");
+}
+
+static int korina_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct korina_private *np = netdev_priv(dev);
+
+	return mii_ethtool_gset(&np->mii_if, cmd);
+}
+
+static int korina_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct korina_private *np = netdev_priv(dev);
+	int rc;
+
+	spin_lock_irq(&np->lock);
+	rc = mii_ethtool_sset(&np->mii_if, cmd);
+	spin_unlock_irq(&np->lock);
+
+	return rc;
+}
+
+static int korina_nway_reset(struct net_device *dev)
+{
+	struct korina_private *np = netdev_priv(dev);
+
+	return mii_nway_restart(&np->mii_if);
+}
+
+static u32 korina_get_link(struct net_device *dev)
+{
+	struct korina_private *np = netdev_priv(dev);
+
+	return mii_link_ok(&np->mii_if);
+}
+
+static void korina_multicast_list(struct net_device *dev)
+{   
+	unsigned recognise = ETHARC_BROADCAST;
+
+	if (dev->flags & IFF_PROMISC)
+		recognise |= ETHARC_PROMISC;
+	if ((dev->flags & IFF_ALLMULTI) || (netdev_mc_count(dev) > 0))
+		recognise |= ETHARC_ALL_MULTICAST;
+
+	KORINA_REG(KORINA_ADDR_RECOGN) = recognise;
+}
+
+
+static struct ethtool_ops korina_ethtool_ops = {
+	.get_drvinfo		= korina_get_drvinfo,
+	.get_settings		= korina_get_settings,
+	.set_settings		= korina_set_settings,
+	.nway_reset		= korina_nway_reset,
+	.get_link		= korina_get_link,
+
+	.get_sg			= ethtool_op_get_sg,
+	.set_sg			= ethtool_op_set_sg,
+	.get_tx_csum		= ethtool_op_get_tx_csum,
+	.set_tx_csum		= ethtool_op_set_tx_csum,
+};
+
+static int korina_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	struct korina_private *lp = netdev_priv(dev);
+	int rc;
+
+#if 0
+	if (!netif_running(dev))
+		return -EINVAL;
+#endif
+
+	spin_lock_irq(&lp->lock);
+	rc = generic_mii_ioctl(
+		&lp->mii_if, (struct mii_ioctl_data *) &rq->ifr_data, cmd, NULL);
+	spin_unlock_irq(&lp->lock);
+
+	return rc;
+}
+
+static inline void korina_start_rx(struct korina_private *lp, dma_addr_t rd)
+{
+        DMA_REG(DMA_RX_CHANNEL, DMA_NEXT_DESCR) = 0;
+        DMA_REG(DMA_RX_CHANNEL, DMA_DESCR_PTR) = 0;
+        DMA_REG(DMA_RX_CHANNEL, DMA_DESCR_PTR) = rd;
+}
+
+static int korina_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+ 	struct korina_private *lp = netdev_priv(dev);
+	unsigned int entry = lp->cur_tx % TX_RING_SIZE;
+	unsigned int prev_entry = (lp->cur_tx - 1) % TX_RING_SIZE;
+ 	volatile struct dma_desc *td;
+
+	if (skb_padto(skb, ETH_ZLEN))
+		return 0;
+    
+	spin_lock(&lp->lock);
+
+	lp->tx_skb[entry] = skb;
+	td = &lp->tx_ring[entry];
+	td->link = 0;
+	td->addr = dma_map_single(NULL, skb->data, skb->len, DMA_TO_DEVICE);
+	td->devcs = DEVCS_TX_FIRST_DESC | DEVCS_TX_LAST_DESC;
+	td->control = skb->len | DMAD_INT_ON_FINISHED;
+
+	lp->tx_ring[prev_entry].link = DMA_DESCR(lp->td_ring_dma, entry);
+
+	if (DMA_REG(DMA_TX_CHANNEL, DMA_NEXT_DESCR) == 0) {
+		DMA_REG(DMA_TX_CHANNEL, DMA_NEXT_DESCR) =
+			DMA_DESCR(lp->td_ring_dma, entry);
+	}
+
+	++lp->cur_tx;
+	if (lp->cur_tx == lp->dirty_tx + TX_QUEUE_LEN) {
+//		printk("stop queue\n");
+//		korina_dump(dev);
+		netif_stop_queue(dev);
+	}
+
+	dev->trans_start = jiffies;
+
+     	spin_unlock(&lp->lock);
+
+    	return 0;
+}
+
+static int korina_rx(struct net_device *dev, int budget);
+static void korina_tx(struct net_device *dev);
+
+static int korina_poll(struct napi_struct *napi, int budget)
+{
+	struct korina_private *lp = container_of(napi, struct korina_private,
+						 napi);
+	unsigned long flags;
+	int work_done;
+
+	DMA_REG(DMA_TX_CHANNEL, DMA_STATUS) = ~(DMASM_FINISHED | DMASM_ERROR);
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS) = ~(DMASM_DONE | DMASM_ERROR);
+
+	spin_lock(&lp->lock);
+	korina_tx(lp->dev);
+   	spin_unlock(&lp->lock);
+
+	work_done = korina_rx(lp->dev, budget);
+
+	if (work_done >= budget)
+	    return work_done;
+
+	if (DMA_REG(DMA_TX_CHANNEL, DMA_STATUS)
+	    & (DMASM_FINISHED | DMASM_ERROR))
+	    return budget;
+	if (DMA_REG(DMA_RX_CHANNEL, DMA_STATUS)
+	    & (DMASM_DONE | DMASM_HALT | DMASM_ERROR))
+	    return budget;
+
+	napi_complete(napi);
+
+	local_irq_save(flags);
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS_MASK) &=
+	    ~(DMASM_DONE | DMASM_HALT | DMASM_ERROR);
+	DMA_REG(DMA_TX_CHANNEL, DMA_STATUS_MASK) &=
+	    ~(DMASM_FINISHED | DMASM_ERROR);
+	local_irq_restore(flags);
+
+	return work_done;
+}
+
+static irqreturn_t korina_dma_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *) dev_id;
+	struct korina_private *lp = netdev_priv(dev);
+
+	spin_lock(&lp->lock);
+
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS_MASK) |=
+		DMASM_DONE | DMASM_HALT | DMASM_ERROR;
+	DMA_REG(DMA_TX_CHANNEL, DMA_STATUS_MASK) |=
+		DMASM_FINISHED | DMASM_ERROR;
+
+	napi_schedule(&lp->napi);
+
+	spin_unlock(&lp->lock);
+
+	return IRQ_HANDLED;
+}
+
+
+static int korina_rx(struct net_device *dev, int budget)
+{
+	struct korina_private* lp = netdev_priv(dev);
+	int boguscnt = lp->dirty_rx + RX_RING_SIZE - lp->cur_rx;
+	int cnt = 0;
+
+	/* keep going while we have received into more descriptors */
+	while (budget--) {
+		unsigned entry = lp->cur_rx % RX_RING_SIZE;
+		volatile struct dma_desc *rd = &lp->rx_ring[entry];
+		unsigned pktlen;
+		unsigned devcs;
+
+		if (!(rd->control & DMAD_DONE)) break;
+		if (--boguscnt < 0) break;
+
+	     	devcs = rd->devcs;
+	     	pktlen = devcs >> 16;
+
+	     	if (pktlen != PKT_BUF_SZ - (rd->control & DMAD_COUNT)) {
+			/*
+			 * Due to a bug in korina processor, the packet length
+			 * given by devcs field and count field sometimes differ.
+			 * If that is the case, report Error.
+			 */
+			lp->dev->stats.rx_errors++;
+			lp->dev->stats.rx_dropped++;
+	      	} else if (pktlen < 64 || pktlen > PKT_BUF_SZ) {
+			lp->dev->stats.rx_errors++;
+			lp->dev->stats.rx_dropped++;
+	    	} else if (devcs & DEVCS_RX_OK) {
+			struct sk_buff *skb = lp->rx_skb[entry];
+			lp->rx_skb[entry] = NULL;
+			dma_unmap_single(NULL, lp->rx_skb_dma[entry], pktlen,
+					 DMA_FROM_DEVICE);
+
+			skb_put(skb, pktlen - 4);
+			skb->protocol = eth_type_trans(skb, dev);
+			netif_receive_skb(skb);
+
+			dev->last_rx = jiffies;
+			lp->dev->stats.rx_packets++;
+			lp->dev->stats.rx_bytes += skb->len;
+		} else {
+		 	/* This should only happen if we enable 
+			   accepting broken packets */
+			lp->dev->stats.rx_errors++;
+			lp->dev->stats.rx_dropped++;
+
+			if (devcs & DEVCS_RX_CRC_ERR) {
+		        	lp->dev->stats.rx_crc_errors++;
+		     	} else if (devcs & (DEVCS_RX_BAD_LENGTH
+					    | DEVCS_RX_LEN_ERROR)) {
+		          	lp->dev->stats.rx_length_errors++;
+		      	} else if (devcs & DEVCS_RX_OVERFLOW) {
+				/*
+				 * The overflow errors are handled through
+				 * an interrupt handler.
+				 */
+				lp->dev->stats.rx_over_errors++;
+		     	}
+			else if (devcs & DEVCS_RX_CODE_VIOLATION) {
+				lp->dev->stats.rx_frame_errors++;
+			}
+		}
+		++lp->cur_rx;
+		++cnt;
+	}
+
+	/* refill the rx ring buffers */
+	for (; lp->cur_rx - lp->dirty_rx > 0; ++lp->dirty_rx) {
+		unsigned entry = lp->dirty_rx % RX_RING_SIZE;
+		volatile struct dma_desc *rd = &lp->rx_ring[entry];
+		struct sk_buff *skb;
+
+		if (lp->rx_skb[entry] == NULL) {
+			skb = dev_alloc_skb(PKT_BUF_SZ + 2);
+			lp->rx_skb[entry] = skb;
+			if (skb == NULL) break;
+
+			skb->dev = dev;
+			skb_reserve(skb, 2);
+			lp->rx_skb_dma[entry] = dma_map_single(
+				NULL, skb->data, PKT_BUF_SZ + 2, DMA_FROM_DEVICE);
+		}
+		lp->rx_ring[(lp->dirty_rx - 1) % RX_RING_SIZE].link =
+			DMA_DESCR(lp->rd_ring_dma, entry);
+		rd->control = PKT_BUF_SZ | DMAD_INT_ON_DONE;
+		rd->addr = lp->rx_skb_dma[entry];
+		rd->devcs = 0;
+		rd->link = 0;
+	}
+	lp->rx_ring[(lp->dirty_rx - 1) % RX_RING_SIZE].link = 0;
+
+	if (DMA_REG(DMA_RX_CHANNEL, DMA_STATUS) & DMAS_HALT) {
+		int pos = DMA_REG(DMA_RX_CHANNEL, DMA_DESCR_PTR) -
+		    lp->rd_ring_dma;
+		DMA_REG(DMA_RX_CHANNEL, DMA_STATUS) = ~DMAS_HALT;
+
+		pos /= sizeof(struct dma_desc);
+		++pos;
+		pos %= RX_RING_SIZE;
+		korina_start_rx(lp, DMA_DESCR(lp->rd_ring_dma, pos));
+	}
+
+	return cnt;
+}
+
+static void korina_tx(struct net_device *dev)
+{
+	struct korina_private* lp = netdev_priv(dev);
+	u32 devcs;
+	int stopped = netif_queue_stopped(dev);
+
+	while (lp->dirty_tx != lp->cur_tx) {
+		unsigned entry = lp->dirty_tx % TX_RING_SIZE;
+		unsigned xentry;
+
+		if (!(lp->tx_ring[entry].control & DMAD_FINISHED)) {
+			if (!stopped) break;
+			// XXX: occasionally dma engine somehow skips one or two descriptors. this check works around this, so that we do not have to go tx timeout path
+			xentry = (lp->dirty_tx + 40) % TX_RING_SIZE;
+			if (!(lp->tx_ring[xentry].control & DMAD_FINISHED)) {
+				break;
+			}
+//			printk("pass on\n");
+		}
+
+		++lp->dirty_tx;
+		if (!lp->tx_skb[entry]) continue;
+
+		devcs = lp->tx_ring[entry].devcs;
+
+	    	if (devcs & DEVCS_TX_OK) {
+			lp->dev->stats.tx_packets++;
+			lp->dev->stats.tx_bytes += lp->tx_skb[entry]->len;
+	    	} else {
+			lp->dev->stats.tx_errors++;
+			lp->dev->stats.tx_dropped++;
+			
+			if (devcs & DEVCS_TX_UNDERFLOW) {
+				lp->dev->stats.tx_fifo_errors++;
+			} else if (devcs & DEVCS_TX_OVERSIZED) {
+				lp->dev->stats.tx_aborted_errors++;
+			} else if (devcs & DEVCS_TX_EXCESSIVE_DEFERAL) {
+				lp->dev->stats.tx_carrier_errors++;
+			} else if (devcs & DEVCS_TX_EXCESSIVE_COLLISIONS) {
+				lp->dev->stats.collisions++;
+			} else if (devcs & DEVCS_TX_LATE_COLLISION) {
+				lp->dev->stats.tx_window_errors++;
+			}
+    		}
+
+		dev_kfree_skb(lp->tx_skb[entry]);
+		lp->tx_skb[entry] = NULL;
+	}
+
+	if (lp->cur_tx - lp->dirty_tx < TX_QUEUE_LEN - (TX_QUEUE_LEN / 4)) {
+		if (stopped) {
+//			printk("wake queue\n");
+			netif_wake_queue(dev);
+		}
+	}
+}
+
+static int korina_hw_open(struct net_device *dev) {
+	struct korina_private *lp = netdev_priv(dev);
+	int i;
+
+	dma_abort(dev, DMA_TX_CHANNEL);
+	dma_abort(dev, DMA_RX_CHANNEL);
+
+	/* reset ethernet logic */ 
+	KORINA_REG(KORINA_CONTROL) = 0;
+	while (KORINA_REG(KORINA_CONTROL) & ETHINTFC_RESETTING) {
+		dev->trans_start = jiffies;
+	}
+	KORINA_REG(KORINA_CONTROL) = ETHINTFC_ENABLE;
+	KORINA_REG(KORINA_MAX_FRAME) = PKT_BUF_SZ;
+
+	lp->cur_tx = 0;
+	lp->dirty_tx = 0;
+	
+  	for (i = 0; i < RX_RING_SIZE; i++) {
+		if (lp->rx_skb[i] == NULL) {
+			struct sk_buff *skb = dev_alloc_skb(PKT_BUF_SZ + 2);
+			if (!skb) break;
+
+			skb->dev = dev;
+			skb_reserve(skb, 2);
+			lp->rx_skb[i] = skb;
+			lp->rx_skb_dma[i] = dma_map_single(
+				NULL, skb->data, PKT_BUF_SZ + 2,
+				DMA_FROM_DEVICE);
+		}
+		lp->rx_ring[i].control = DMAD_INT_ON_DONE | PKT_BUF_SZ;
+		lp->rx_ring[i].devcs = 0;
+                lp->rx_ring[i].addr = lp->rx_skb_dma[i];
+		lp->rx_ring[i].link = DMA_DESCR(lp->rd_ring_dma, i + 1);
+
+  	}
+	lp->rx_ring[i - 1].link = 0;
+	lp->dirty_rx = i - RX_RING_SIZE;
+
+	lp->cur_rx = 0;
+	lp->dirty_rx = 0;
+
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS) = 0;
+
+	korina_start_rx(lp, lp->rd_ring_dma);
+
+	DMA_REG(DMA_TX_CHANNEL, DMA_STATUS_MASK) =
+		~(DMASM_FINISHED | DMASM_ERROR);
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS_MASK) =
+		~(DMASM_DONE | DMASM_HALT | DMASM_ERROR);
+
+	/* accept only broadcasts and unicasts */
+	KORINA_REG(KORINA_ADDR_RECOGN) = ETHARC_BROADCAST;
+
+	for (i = 0; i < 4; ++i) {
+		KORINA_REG(KORINA_ADDR_LO + i * 8) =
+			swab32(get_unaligned((u32 *) &dev->dev_addr[2]));
+		KORINA_REG(KORINA_ADDR_HI + i * 8) =
+			swab16(get_unaligned((u16 *) &dev->dev_addr[0]));
+	}
+
+	KORINA_REG(KORINA_CONFIG2) = ETHMAC2_PAD_ENABLE | ETHMAC2_CRC_ENABLE
+		| ETHMAC2_FULL_DUPLEX;
+	/* back to back inter packet gap */ 
+	KORINA_REG(KORINA_BTB_IPACK_GAP) = 21;
+	/* non back to back inter packet gap */ 
+	KORINA_REG(KORINA_NBTB_IPACK_GAP) = 18;
+	KORINA_REG(KORINA_MII_CONFIG) = MIIMCFG_RESET;
+	mb();
+	udelay(1000);
+	KORINA_REG(KORINA_MII_CONFIG) = 0;
+	KORINA_REG(KORINA_CLOCK) = (mips_hpt_frequency / MII_CLOCK + 1) & ~1;
+	/* don't transmit until fifo contains 48 bytes */
+	KORINA_REG(KORINA_FIFO_TX_THRE) = 48;
+	KORINA_REG(KORINA_CONFIG1) = ETHMAC1_RX_ENABLE;
+
+	korina_multicast_list(dev);
+	return 0;
+}
+
+static int korina_open(struct net_device *dev)
+{
+	korina_hw_open(dev);
+
+	netif_start_queue(dev);
+
+	enable_irq(KORINA_DMA_RX_IRQ);
+	enable_irq(KORINA_DMA_TX_IRQ);
+	enable_irq(KORINA_UNDERFLOW_IRQ);
+	return 0;
+}
+
+static int korina_hw_close(struct net_device *dev) {
+	struct korina_private *lp = netdev_priv(dev);
+	int i;
+
+	DMA_REG(DMA_TX_CHANNEL, DMA_STATUS_MASK) |=
+		DMASM_FINISHED | DMASM_ERROR;
+	DMA_REG(DMA_RX_CHANNEL, DMA_STATUS_MASK) |=
+		DMASM_DONE | DMASM_HALT | DMASM_ERROR;
+
+	for (i = 0; i < TX_RING_SIZE; ++i) {
+		if (lp->tx_skb[i]) {
+			dev_kfree_skb_any(lp->tx_skb[i]);
+			lp->tx_skb[i] = NULL;
+		}
+	}
+
+	return 0;
+}
+
+static int korina_close(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+
+	disable_irq(KORINA_DMA_RX_IRQ);
+	disable_irq(KORINA_DMA_TX_IRQ);
+	disable_irq(KORINA_UNDERFLOW_IRQ);
+
+	korina_hw_close(dev);
+	return 0;
+}
+
+static irqreturn_t korina_und_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *) dev_id;
+	struct korina_private *lp = netdev_priv(dev);
+
+	printk("korina: tx underflow, resetting\n");
+
+	spin_lock(&lp->lock);
+
+	KORINA_REG(KORINA_CONTROL) &= ~ETHINTFC_UNDERFLOW;
+	korina_hw_close(dev);
+	korina_hw_open(dev);
+
+	spin_unlock(&lp->lock);
+
+	return IRQ_HANDLED;
+}
+
+
+static void korina_tx_timeout(struct net_device *dev)
+{
+	struct korina_private *lp = netdev_priv(dev);
+	unsigned long flags;
+
+	printk("korina: tx timeout\n");
+	korina_dump(dev);
+	spin_lock_irqsave(&lp->lock, flags);
+
+	korina_hw_close(dev);
+	korina_hw_open(dev);
+	netif_start_queue(dev);
+
+	spin_unlock_irqrestore(&lp->lock, flags);
+}
+
+static int korina_change_mtu(struct net_device *dev, int new_mtu) {
+    if (new_mtu < 68 || new_mtu > 1600) return -EINVAL;
+    dev->mtu = new_mtu;
+    return 0;
+}
+
+static const struct net_device_ops korina_netdev_ops = {
+	.ndo_open		= korina_open,
+	.ndo_stop		= korina_close,
+	.ndo_start_xmit		= korina_xmit,
+	.ndo_set_multicast_list = &korina_multicast_list,
+	.ndo_tx_timeout		= korina_tx_timeout,
+	.ndo_change_mtu		= korina_change_mtu,
+	.ndo_validate_addr	= eth_validate_addr,
+	.ndo_do_ioctl		= korina_ioctl,
+};
+
+static int korina_probe(struct platform_device *pdev)
+{
+	struct net_device *dev;
+	struct korina_private *lp;
+	int i;
+
+	request_region(KORINA_BASE, 0x24c, "korina");
+	
+	dev = alloc_etherdev(sizeof(struct korina_private));
+
+	dev->base_addr = KORINA_BASE;
+	dev->irq = KORINA_DMA_RX_IRQ;
+	memcpy(dev->dev_addr, mips_mac_address, 6);
+
+	lp = netdev_priv(dev);
+	lp->dev = dev;
+
+	lp->tx_ring = dma_alloc_coherent(
+		NULL, DMA_DESCR(0, TX_RING_SIZE + RX_RING_SIZE),
+		&lp->td_ring_dma, GFP_KERNEL);
+	if (!lp->tx_ring) {
+		printk("korina: can't allocate descriptors\n");
+		return -ENOMEM;
+	}
+
+	lp->rx_ring = (void *) lp->tx_ring + DMA_DESCR(0, TX_RING_SIZE);
+	lp->rd_ring_dma = DMA_DESCR(lp->td_ring_dma, TX_RING_SIZE);
+
+	spin_lock_init(&lp->lock);
+
+	dev->netdev_ops = &korina_netdev_ops;
+	dev->watchdog_timeo = HZ;
+	netif_napi_add(dev, &lp->napi, korina_poll, 64);
+	napi_enable(&lp->napi);
+
+	dev->l2mtu = 1600;
+
+	SET_ETHTOOL_OPS(dev, &korina_ethtool_ops);
+	lp->mii_if.dev = dev;
+	lp->mii_if.mdio_read = mdio_read;
+	lp->mii_if.mdio_write = mdio_write;
+	lp->mii_if.phy_id_mask = 0x1f;
+	lp->mii_if.reg_num_mask = 0x1f;
+	lp->mii_if.phy_id = 1;
+
+	if (request_irq(KORINA_DMA_RX_IRQ, &korina_dma_interrupt,
+			IRQF_SHARED | IRQF_DISABLED,
+			"korina rx", dev)) {
+		printk("korina: could not request IRQ %d\n", KORINA_DMA_RX_IRQ);
+		goto err;
+	}
+	if (request_irq(KORINA_DMA_TX_IRQ, &korina_dma_interrupt,
+			IRQF_SHARED | IRQF_DISABLED,
+			"korina tx", dev)) {
+		printk("korina: could not request IRQ %d\n", KORINA_DMA_TX_IRQ);
+		goto free_rx_irq;
+	}
+	
+	if (request_irq(KORINA_UNDERFLOW_IRQ, &korina_und_interrupt,
+			IRQF_SHARED | IRQF_DISABLED,
+			"korina underflow", dev)) {
+		printk("korina: could not request IRQ %d\n",
+		       KORINA_UNDERFLOW_IRQ);
+		goto free_both_irq;
+	}
+	disable_irq(KORINA_DMA_RX_IRQ);
+	disable_irq(KORINA_DMA_TX_IRQ);
+	disable_irq(KORINA_UNDERFLOW_IRQ);
+
+	platform_set_drvdata(pdev, dev);
+	register_netdev(dev);
+
+        printk("korina ethernet MAC address ");
+	for (i = 0; i < 5; i++)
+		printk("%2.2x:", dev->dev_addr[i]);
+	printk("%2.2x\n", dev->dev_addr[5]);
+    
+	return 0;
+free_both_irq:
+	free_irq(KORINA_DMA_TX_IRQ, dev);
+free_rx_irq:
+	free_irq(KORINA_DMA_RX_IRQ, dev);
+err:
+	return -EAGAIN;
+}
+
+static struct platform_driver korina_driver = {
+	.probe	= korina_probe,
+	.driver	= {
+		.name = "korina",
+		.owner = THIS_MODULE,
+	},
+};
+
+static int korina_init_module(void)
+{
+	return platform_driver_register(&korina_driver);
+}
+
+module_init(korina_init_module)
diff -puNrb linux-2.6.35/drivers/net/ucc_geth.c linux/drivers/net/ucc_geth.c
--- linux-2.6.35/drivers/net/ucc_geth.c	2011-04-26 16:28:20.871916144 +0300
+++ linux/drivers/net/ucc_geth.c	2011-05-02 10:08:27.181592350 +0300
@@ -77,7 +77,7 @@ static struct ucc_geth_info ugeth_primar
 	.uf_info = {
 		    .bd_mem_part = MEM_PART_SYSTEM,
 		    .rtsm = UCC_FAST_SEND_IDLES_BETWEEN_FRAMES,
-		    .max_rx_buf_length = 1536,
+		    .max_rx_buf_length = 1664,
 		    /* adjusted at startup if max-speed 1000 */
 		    .urfs = UCC_GETH_URFS_INIT,
 		    .urfet = UCC_GETH_URFET_INIT,
@@ -109,15 +109,15 @@ static struct ucc_geth_info ugeth_primar
 	.excessDefer = 1,
 	.maxRetransmission = 0xf,
 	.collisionWindow = 0x37,
-	.receiveFlowControl = 1,
-	.transmitFlowControl = 1,
+	.receiveFlowControl = 0,
+	.transmitFlowControl = 0,
 	.maxGroupAddrInHash = 4,
 	.maxIndAddrInHash = 4,
 	.prel = 7,
-	.maxFrameLength = 1518,
+	.maxFrameLength = 1650,
 	.minFrameLength = 64,
-	.maxD1Length = 1520,
-	.maxD2Length = 1520,
+	.maxD1Length = 1648,
+	.maxD2Length = 1648,
 	.vlantype = 0x8100,
 	.ecamptr = ((uint32_t) NULL),
 	.eventRegMask = UCCE_OTHER,
@@ -2016,7 +2016,7 @@ static void ucc_geth_set_multi(struct ne
 		    (struct ucc_geth_82xx_address_filtering_pram __iomem *) ugeth->
 		    p_rx_glbl_pram->addressfiltering;
 
-		if (dev->flags & IFF_ALLMULTI) {
+		if (1 /*dev->flags & IFF_ALLMULTI */) {
 			/* Catch all multicast addresses, so set the
 			 * filter to all 1's.
 			 */
@@ -2043,6 +2043,39 @@ static void ucc_geth_set_multi(struct ne
 	}
 }
 
+static void ucc_geth_fast_stop(struct ucc_geth_private *ugeth) {
+	struct ucc_geth *ug_regs = ugeth->ug_regs;
+
+	ugeth_disable(ugeth, COMM_DIR_RX_AND_TX);
+
+	out_be32(&ug_regs->maccfg1,
+		 in_be32(&ug_regs->maccfg1) &
+		 ~(MACCFG1_ENABLE_RX | MACCFG1_ENABLE_TX));
+}
+
+static void ucc_geth_fast_start(struct ucc_geth_private *ugeth) {
+	struct ucc_geth *ug_regs = ugeth->ug_regs;
+
+	ugeth_enable(ugeth, COMM_DIR_RX_AND_TX);
+
+	out_be32(&ug_regs->maccfg1,
+		 in_be32(&ug_regs->maccfg1) |
+		 MACCFG1_ENABLE_RX | MACCFG1_ENABLE_TX);
+}
+
+static void ucc_geth_fast_restart(struct ucc_geth_private *ugeth) {
+    ucc_geth_fast_stop(ugeth);
+    ucc_geth_fast_start(ugeth);
+}
+
+static void ucc_geth_tx_check(struct ucc_geth_private *ugeth) {
+	if (ugeth->last_tx && jiffies - ugeth->last_tx > HZ) {
+		ugeth->last_tx = 0;
+		printk("%s: tx is stuck, restart\n", ugeth->ndev->name);
+		ucc_geth_fast_restart(ugeth);
+	}
+}
+
 static void ucc_geth_stop(struct ucc_geth_private *ugeth)
 {
 	struct ucc_geth __iomem *ug_regs = ugeth->ug_regs;
@@ -3119,6 +3152,9 @@ static int ucc_geth_start_xmit(struct sk
 	u8 txQ = 0;
 	unsigned long flags;
 
+	if (skb_padto(skb, ETH_ZLEN))
+		return 0;
+
 	ugeth_vdbg("%s: IN", __func__);
 
 	spin_lock_irqsave(&ugeth->lock, flags);
@@ -3147,6 +3183,10 @@ static int ucc_geth_start_xmit(struct sk
 
 	/* set bd status and length */
 	out_be32((u32 __iomem *)bd, bd_status);
+	out_be16(&((struct ucc_fast *)ugeth->ug_regs)->utodr, 0xffff);
+
+	if (!ugeth->last_tx) ugeth->last_tx = jiffies;
+	else ucc_geth_tx_check(ugeth);
 
 	/* Move to next BD in the ring */
 	if (!(bd_status & T_W))
@@ -3238,10 +3278,10 @@ static int ucc_geth_rx(struct ucc_geth_p
 		}
 
 		skb = get_new_skb(ugeth, bd);
+
 		if (!skb) {
 			if (netif_msg_rx_err(ugeth))
 				ugeth_warn("%s: No Rx Data Buffer", __func__);
-			dev->stats.rx_dropped++;
 			break;
 		}
 
@@ -3274,6 +3314,8 @@ static int ucc_geth_tx(struct net_device
 	bd = ugeth->confBd[txQ];
 	bd_status = in_be32((u32 __iomem *)bd);
 
+	ucc_geth_tx_check(ugeth);
+
 	/* Normal processing. */
 	while ((bd_status & T_R) == 0) {
 		struct sk_buff *skb;
@@ -3282,19 +3324,23 @@ static int ucc_geth_tx(struct net_device
 		/* Handle the transmitted buffer and release */
 		/* the BD to be used with the current frame  */
 
+		ugeth->last_tx = 0;
+
 		skb = ugeth->tx_skbuff[txQ][ugeth->skb_dirtytx[txQ]];
 		if (!skb)
 			break;
 
 		dev->stats.tx_packets++;
 
+		if (skb) {
 		if (skb_queue_len(&ugeth->rx_recycle) < RX_BD_RING_LEN &&
 			     skb_recycle_check(skb,
 				    ugeth->ug_info->uf_info.max_rx_buf_length +
 				    UCC_GETH_RX_DATA_BUF_ALIGNMENT))
 			__skb_queue_head(&ugeth->rx_recycle, skb);
 		else
-			dev_kfree_skb(skb);
+			dev_kfree_skb_any(skb);
+		}
 
 		ugeth->tx_skbuff[txQ][ugeth->skb_dirtytx[txQ]] = NULL;
 		ugeth->skb_dirtytx[txQ] =
@@ -3316,12 +3362,20 @@ static int ucc_geth_tx(struct net_device
 	return 0;
 }
 
+#define UCCE_TXRX	(UCC_GETH_UCCE_RXF0 | \
+			 UCC_GETH_UCCE_TXB0 | \
+			 UCC_GETH_UCCE_BSY | \
+			 UCCE_OTHER)
+
 static int ucc_geth_poll(struct napi_struct *napi, int budget)
 {
 	struct ucc_geth_private *ugeth = container_of(napi, struct ucc_geth_private, napi);
 	struct ucc_geth_info *ug_info;
+	struct ucc_fast_private *uccf = ugeth->uccf;
 	int howmany, i;
 
+	out_be32(uccf->p_ucce, UCCE_TXRX);
+
 	ug_info = ugeth->ug_info;
 
 	/* Tx event processing */
@@ -3334,10 +3388,14 @@ static int ucc_geth_poll(struct napi_str
 	for (i = 0; i < ug_info->numQueuesRx; i++)
 		howmany += ucc_geth_rx(ugeth, i, budget - howmany);
 
-	if (howmany < budget) {
+	if (howmany >= budget)
+		return howmany;
+
+	if (in_be32(uccf->p_ucce) & UCCE_TXRX)
+		return budget;
+
 		napi_complete(napi);
-		setbits32(ugeth->uccf->p_uccm, UCCE_RX_EVENTS | UCCE_TX_EVENTS);
-	}
+	out_be32(uccf->p_uccm, in_be32(uccf->p_uccm) | UCCE_TXRX);
 
 	return howmany;
 }
@@ -3356,6 +3414,14 @@ static irqreturn_t ucc_geth_irq_handler(
 	uccf = ugeth->uccf;
 	ug_info = ugeth->ug_info;
 
+#if 1
+	ucce = in_be32(uccf->p_ucce) & in_be32(uccf->p_uccm);
+	if (!ucce)
+		return IRQ_NONE;
+
+	out_be32(uccf->p_uccm, in_be32(uccf->p_uccm) & ~UCCE_TXRX);
+	napi_schedule(&ugeth->napi);
+#else
 	/* read and clear events */
 	ucce = (u32) in_be32(uccf->p_ucce);
 	uccm = (u32) in_be32(uccf->p_uccm);
@@ -3379,6 +3445,7 @@ static irqreturn_t ucc_geth_irq_handler(
 			dev->stats.tx_errors++;
 	}
 
+#endif
 	return IRQ_HANDLED;
 }
 
@@ -3704,13 +3771,21 @@ static phy_interface_t to_phy_interface(
 	return PHY_INTERFACE_MODE_MII;
 }
 
+static int ucc_geth_change_mtu(struct net_device *dev, int new_mtu) {
+    if (new_mtu < 68 || new_mtu > 1632) {
+	return -EINVAL;
+    }
+    dev->mtu = new_mtu;
+    return 0;
+}
+
 static const struct net_device_ops ucc_geth_netdev_ops = {
 	.ndo_open		= ucc_geth_open,
 	.ndo_stop		= ucc_geth_close,
 	.ndo_start_xmit		= ucc_geth_start_xmit,
 	.ndo_validate_addr	= eth_validate_addr,
 	.ndo_set_mac_address	= ucc_geth_set_mac_addr,
-	.ndo_change_mtu		= eth_change_mtu,
+	.ndo_change_mtu		= ucc_geth_change_mtu,
 	.ndo_set_multicast_list	= ucc_geth_set_multi,
 	.ndo_tx_timeout		= ucc_geth_timeout,
 #ifdef CONFIG_NET_POLL_CONTROLLER
@@ -3915,6 +3990,8 @@ static int ucc_geth_probe(struct of_devi
 	netif_napi_add(dev, &ugeth->napi, ucc_geth_poll, 64);
 	dev->mtu = 1500;
 
+	dev->l2mtu = 1632;
+
 	ugeth->msg_enable = netif_msg_init(debug.msg_enable, UGETH_MSG_DEFAULT);
 	ugeth->phy_interface = phy_interface;
 	ugeth->max_speed = max_speed;
@@ -3927,6 +4004,7 @@ static int ucc_geth_probe(struct of_devi
 		free_netdev(dev);
 		return err;
 	}
+	netif_carrier_off(dev);
 
 	mac_addr = of_get_mac_address(np);
 	if (mac_addr)
diff -puNrb linux-2.6.35/drivers/net/ucc_geth_ethtool.c linux/drivers/net/ucc_geth_ethtool.c
--- linux-2.6.35/drivers/net/ucc_geth_ethtool.c	2011-04-26 16:28:21.032477148 +0300
+++ linux/drivers/net/ucc_geth_ethtool.c	2011-05-02 10:08:27.201586288 +0300
@@ -350,10 +350,13 @@ static void
 uec_get_drvinfo(struct net_device *netdev,
                        struct ethtool_drvinfo *drvinfo)
 {
+	struct ucc_geth_private *ugeth = netdev_priv(netdev);
+
 	strncpy(drvinfo->driver, DRV_NAME, 32);
 	strncpy(drvinfo->version, DRV_VERSION, 32);
 	strncpy(drvinfo->fw_version, "N/A", 32);
-	strncpy(drvinfo->bus_info, "QUICC ENGINE", 32);
+	sprintf(drvinfo->bus_info, "ucc.%d",
+		ugeth->ug_info->uf_info.ucc_num);
 	drvinfo->eedump_len = 0;
 	drvinfo->regdump_len = uec_get_regs_len(netdev);
 }
diff -puNrb linux-2.6.35/drivers/net/ucc_geth.h linux/drivers/net/ucc_geth.h
--- linux-2.6.35/drivers/net/ucc_geth.h	2011-04-26 16:28:20.871916144 +0300
+++ linux/drivers/net/ucc_geth.h	2011-05-02 10:08:27.211589717 +0300
@@ -875,8 +875,8 @@ struct ucc_geth_hardware_statistics {
 #define UCC_GETH_SIZE_OF_BD                     QE_SIZEOF_BD
 
 /* Driver definitions */
-#define TX_BD_RING_LEN                          0x10
-#define RX_BD_RING_LEN                          0x10
+#define TX_BD_RING_LEN                          0x80
+#define RX_BD_RING_LEN                          0x80
 
 #define TX_RING_MOD_MASK(size)                  (size-1)
 #define RX_RING_MOD_MASK(size)                  (size-1)
@@ -1223,6 +1223,7 @@ struct ucc_geth_private {
 	int oldspeed;
 	int oldduplex;
 	int oldlink;
+	unsigned long last_tx;
 	int wol_en;
 
 	struct device_node *node;
diff -puNrb linux-2.6.35/drivers/net/usb/hso.c linux/drivers/net/usb/hso.c
--- linux-2.6.35/drivers/net/usb/hso.c	2011-04-26 16:28:16.191229519 +0300
+++ linux/drivers/net/usb/hso.c	2011-05-02 10:08:27.241589437 +0300
@@ -395,7 +395,7 @@ static void dbg_dump(int line_count, con
 
 /* module parameters */
 static int debug;
-static int tty_major;
+static int tty_major = 234;
 static int disable_net;
 
 /* driver info */
@@ -435,20 +435,20 @@ static const s32 icon321_port_spec[] = {
 
 /* list of devices we support */
 static const struct usb_device_id hso_ids[] = {
-	{default_port_device(0x0af0, 0x6711)},
-	{default_port_device(0x0af0, 0x6731)},
-	{default_port_device(0x0af0, 0x6751)},
-	{default_port_device(0x0af0, 0x6771)},
+//	{default_port_device(0x0af0, 0x6711)},
+//	{default_port_device(0x0af0, 0x6731)},
+//	{default_port_device(0x0af0, 0x6751)},
+//	{default_port_device(0x0af0, 0x6771)},
 	{default_port_device(0x0af0, 0x6791)},
-	{default_port_device(0x0af0, 0x6811)},
-	{default_port_device(0x0af0, 0x6911)},
+//	{default_port_device(0x0af0, 0x6811)},
+//	{default_port_device(0x0af0, 0x6911)},
 	{default_port_device(0x0af0, 0x6951)},
 	{default_port_device(0x0af0, 0x6971)},
-	{default_port_device(0x0af0, 0x7011)},
-	{default_port_device(0x0af0, 0x7031)},
-	{default_port_device(0x0af0, 0x7051)},
-	{default_port_device(0x0af0, 0x7071)},
-	{default_port_device(0x0af0, 0x7111)},
+//	{default_port_device(0x0af0, 0x7011)},
+//	{default_port_device(0x0af0, 0x7031)},
+//	{default_port_device(0x0af0, 0x7051)},
+//	{default_port_device(0x0af0, 0x7071)},
+//	{default_port_device(0x0af0, 0x7111)},
 	{default_port_device(0x0af0, 0x7211)},
 	{default_port_device(0x0af0, 0x7251)},
 	{default_port_device(0x0af0, 0x7271)},
diff -puNrb linux-2.6.35/drivers/net/via-rhine.c linux/drivers/net/via-rhine.c
--- linux-2.6.35/drivers/net/via-rhine.c	2011-04-26 16:28:20.962476952 +0300
+++ linux/drivers/net/via-rhine.c	2011-05-02 10:08:27.261592575 +0300
@@ -54,6 +54,9 @@ static int rx_copybreak;
    power state D3 so PXE booting fails. bootparam(7): via-rhine.avoid_D3=1 */
 static int avoid_D3;
 
+/* Work-around for systems, where link should be on immediately after enable */
+static int disable_sleep_mode;
+
 /*
  * In case you are looking for 'options[]' or 'full_duplex[]', they
  * are gone. Use ethtool(8) instead.
@@ -71,9 +74,9 @@ static const int multicast_filter_limit 
    Making the Tx ring too large decreases the effectiveness of channel
    bonding and packet priority.
    There are no ill effects from too-large receive rings. */
-#define TX_RING_SIZE	16
-#define TX_QUEUE_LEN	10	/* Limit ring entries actually used. */
-#define RX_RING_SIZE	64
+#define TX_RING_SIZE	128
+#define TX_QUEUE_LEN	120	/* Limit ring entries actually used. */
+#define RX_RING_SIZE	128
 
 /* Operational parameters that usually are not changed. */
 
@@ -101,6 +104,7 @@ static const int multicast_filter_limit 
 #include <linux/ethtool.h>
 #include <linux/crc32.h>
 #include <linux/bitops.h>
+#include <linux/rtnetlink.h>
 #include <linux/workqueue.h>
 #include <asm/processor.h>	/* Processor type for cache alignment. */
 #include <asm/io.h>
@@ -120,6 +124,10 @@ static const char version[] __devinitcon
 #else
 #endif
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#undef USE_MMIO
+#endif
+
 MODULE_AUTHOR("Donald Becker <becker@scyld.com>");
 MODULE_DESCRIPTION("VIA Rhine PCI Fast Ethernet driver");
 MODULE_LICENSE("GPL");
@@ -128,10 +136,12 @@ module_param(max_interrupt_work, int, 0)
 module_param(debug, int, 0);
 module_param(rx_copybreak, int, 0);
 module_param(avoid_D3, bool, 0);
+module_param(disable_sleep_mode, bool, 0);
 MODULE_PARM_DESC(max_interrupt_work, "VIA Rhine maximum events handled per interrupt");
 MODULE_PARM_DESC(debug, "VIA Rhine debug level (0-7)");
 MODULE_PARM_DESC(rx_copybreak, "VIA Rhine copy breakpoint for copy-only-tiny-frames");
 MODULE_PARM_DESC(avoid_D3, "Avoid power state D3 (work-around for broken BIOSes)");
+MODULE_PARM_DESC(disable_sleep_mode, "Completely disable VIA Rhine D3");
 
 /*
 		Theory of Operation
@@ -405,6 +415,16 @@ struct rhine_private {
 	void __iomem *base;
 };
 
+static int rhine_change_mtu(struct net_device *dev, int new_mtu) {
+	struct rhine_private *rp = netdev_priv(dev);
+
+	if (new_mtu < 68 || new_mtu > 1600) return -EINVAL;
+	if ((rp->quirks & rqRhineI) && new_mtu > 1500) return -EINVAL;
+
+	dev->mtu = new_mtu;
+	return 0;
+}
+
 static int  mdio_read(struct net_device *dev, int phy_id, int location);
 static void mdio_write(struct net_device *dev, int phy_id, int location, int value);
 static int  rhine_open(struct net_device *dev);
@@ -588,18 +608,48 @@ static int rhine_napipoll(struct napi_st
 	struct net_device *dev = rp->dev;
 	void __iomem *ioaddr = rp->base;
 	int work_done;
+	u32 intr_status;
+
+	intr_status = get_intr_status(dev);
+
+	/* Acknowledge all of the current interrupt sources ASAP. */
+	if (intr_status & IntrTxDescRace)
+		iowrite8(0x08, ioaddr + IntrStatus2);
+	iowrite16(intr_status & 0xffff, ioaddr + IntrStatus);
+
+	if (intr_status & IntrTxErrSummary) {
+		/* Avoid scavenging before Tx engine turned off */
+		RHINE_WAIT_FOR(!(ioread8(ioaddr+ChipCmd) & CmdTxOn));
+		if (debug > 2 && ioread8(ioaddr+ChipCmd) & CmdTxOn)
+			printk(KERN_WARNING "%s: "
+			       "rhine_interrupt() Tx engine"
+			       "still on.\n", dev->name);
+	}
+	rhine_tx(dev);
+	
+	/* Abnormal error summary/uncommon events handlers. */
+	if (intr_status & (IntrPCIErr | IntrLinkChange |
+			   IntrStatsMax | IntrTxError | IntrTxAborted |
+			   IntrTxUnderrun | IntrTxDescRace))
+		rhine_error(dev, intr_status);
+
 
 	work_done = rhine_rx(dev, budget);
 
-	if (work_done < budget) {
+	if (work_done >= budget)
+		return work_done;
+	if (get_intr_status(dev) & 0xffff)
+		return budget;
+
 		napi_complete(napi);
 
+	/* Enable interrupts by setting the interrupt mask. */
 		iowrite16(IntrRxDone | IntrRxErr | IntrRxEmpty| IntrRxOverflow |
 			  IntrRxDropped | IntrRxNoBuf | IntrTxAborted |
 			  IntrTxDone | IntrTxError | IntrTxUnderrun |
 			  IntrPCIErr | IntrStatsMax | IntrLinkChange,
 			  ioaddr + IntrEnable);
-	}
+	
 	return work_done;
 }
 
@@ -614,8 +664,10 @@ static void __devinit rhine_hw_init(stru
 	if (rp->quirks & rqRhineI)
 		msleep(5);
 
+#if !defined CONFIG_MIPS_MIKROTIK && !defined CONFIG_RB_PPC
 	/* Reload EEPROM controlled bytes cleared by soft reset */
 	rhine_reload_eeprom(pioaddr, dev);
+#endif
 }
 
 static const struct net_device_ops rhine_netdev_ops = {
@@ -624,7 +676,7 @@ static const struct net_device_ops rhine
 	.ndo_start_xmit		 = rhine_start_tx,
 	.ndo_get_stats		 = rhine_get_stats,
 	.ndo_set_multicast_list	 = rhine_set_rx_mode,
-	.ndo_change_mtu		 = eth_change_mtu,
+	.ndo_change_mtu		 = rhine_change_mtu,
 	.ndo_validate_addr	 = eth_validate_addr,
 	.ndo_set_mac_address 	 = eth_mac_addr,
 	.ndo_do_ioctl		 = netdev_ioctl,
@@ -687,6 +739,7 @@ static int __devinit rhine_init_one(stru
 	rc = pci_enable_device(pdev);
 	if (rc)
 		goto err_out;
+        pci_set_power_state(pdev, PCI_D0);
 
 	/* this should always be supported */
 	rc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));
@@ -792,6 +845,8 @@ static int __devinit rhine_init_one(stru
 
 	netif_napi_add(dev, &rp->napi, rhine_napipoll, 64);
 
+	dev->l2mtu = 1600;
+
 	if (rp->quirks & rqRhineI)
 		dev->features |= NETIF_F_SG|NETIF_F_HW_CSUM;
 
@@ -837,6 +892,14 @@ static int __devinit rhine_init_one(stru
 		printk(KERN_INFO "%s: No D3 power state at shutdown.\n",
 		       dev->name);
 
+	if (!disable_sleep_mode) {
+		/* shut down until somebody really needs it */
+		rtnl_lock();
+		iowrite8(0x80, ioaddr + 0xa1);
+		pci_set_power_state(pdev, PCI_D3hot);
+		rtnl_unlock();
+	}
+
 	return 0;
 
 err_out_unmap:
@@ -910,7 +973,7 @@ static void alloc_rbufs(struct net_devic
 
 	rp->dirty_rx = rp->cur_rx = 0;
 
-	rp->rx_buf_sz = (dev->mtu <= 1500 ? PKT_BUF_SZ : dev->mtu + 32);
+	rp->rx_buf_sz = 1600 + 32;
 	rp->rx_head_desc = &rp->rx_ring[0];
 	next = rp->rx_ring_dma;
 
@@ -1118,6 +1181,8 @@ static int mdio_read(struct net_device *
 	void __iomem *ioaddr = rp->base;
 	int result;
 
+	if (rp->pdev->current_state != PCI_D0) return 0;
+
 	rhine_disable_linkmon(ioaddr, rp->quirks);
 
 	/* rhine_disable_linkmon already cleared MIICmd */
@@ -1136,6 +1201,8 @@ static void mdio_write(struct net_device
 	struct rhine_private *rp = netdev_priv(dev);
 	void __iomem *ioaddr = rp->base;
 
+	if (rp->pdev->current_state != PCI_D0) return;
+
 	rhine_disable_linkmon(ioaddr, rp->quirks);
 
 	/* rhine_disable_linkmon already cleared MIICmd */
@@ -1154,6 +1221,11 @@ static int rhine_open(struct net_device 
 	void __iomem *ioaddr = rp->base;
 	int rc;
 
+	rc = pci_enable_device(rp->pdev);
+	if (rc)
+		return rc;
+        pci_set_power_state(rp->pdev, PCI_D0);
+
 	rc = request_irq(rp->pdev->irq, rhine_interrupt, IRQF_SHARED, dev->name,
 			dev);
 	if (rc)
@@ -1310,64 +1382,13 @@ static irqreturn_t rhine_interrupt(int i
 	struct net_device *dev = dev_instance;
 	struct rhine_private *rp = netdev_priv(dev);
 	void __iomem *ioaddr = rp->base;
-	u32 intr_status;
-	int boguscnt = max_interrupt_work;
-	int handled = 0;
-
-	while ((intr_status = get_intr_status(dev))) {
-		handled = 1;
-
-		/* Acknowledge all of the current interrupt sources ASAP. */
-		if (intr_status & IntrTxDescRace)
-			iowrite8(0x08, ioaddr + IntrStatus2);
-		iowrite16(intr_status & 0xffff, ioaddr + IntrStatus);
-		IOSYNC;
-
-		if (debug > 4)
-			printk(KERN_DEBUG "%s: Interrupt, status %8.8x.\n",
-			       dev->name, intr_status);
-
-		if (intr_status & (IntrRxDone | IntrRxErr | IntrRxDropped |
-				   IntrRxWakeUp | IntrRxEmpty | IntrRxNoBuf)) {
-			iowrite16(IntrTxAborted |
-				  IntrTxDone | IntrTxError | IntrTxUnderrun |
-				  IntrPCIErr | IntrStatsMax | IntrLinkChange,
-				  ioaddr + IntrEnable);
 
+	if (get_intr_status(dev)) {
+		iowrite16(0, ioaddr + IntrEnable);
 			napi_schedule(&rp->napi);
+		return IRQ_HANDLED;
 		}
-
-		if (intr_status & (IntrTxErrSummary | IntrTxDone)) {
-			if (intr_status & IntrTxErrSummary) {
-				/* Avoid scavenging before Tx engine turned off */
-				RHINE_WAIT_FOR(!(ioread8(ioaddr+ChipCmd) & CmdTxOn));
-				if (debug > 2 &&
-				    ioread8(ioaddr+ChipCmd) & CmdTxOn)
-					printk(KERN_WARNING "%s: "
-					       "rhine_interrupt() Tx engine "
-					       "still on.\n", dev->name);
-			}
-			rhine_tx(dev);
-		}
-
-		/* Abnormal error summary/uncommon events handlers. */
-		if (intr_status & (IntrPCIErr | IntrLinkChange |
-				   IntrStatsMax | IntrTxError | IntrTxAborted |
-				   IntrTxUnderrun | IntrTxDescRace))
-			rhine_error(dev, intr_status);
-
-		if (--boguscnt < 0) {
-			printk(KERN_WARNING "%s: Too much work at interrupt, "
-			       "status=%#8.8x.\n",
-			       dev->name, intr_status);
-			break;
-		}
-	}
-
-	if (debug > 3)
-		printk(KERN_DEBUG "%s: exiting interrupt, status=%8.8x.\n",
-		       dev->name, ioread16(ioaddr + IntrStatus));
-	return IRQ_RETVAL(handled);
+	return IRQ_NONE;
 }
 
 /* This routine is logically part of the interrupt handler, but isolated
@@ -1427,7 +1448,7 @@ static void rhine_tx(struct net_device *
 					 rp->tx_skbuff[entry]->len,
 					 PCI_DMA_TODEVICE);
 		}
-		dev_kfree_skb_irq(rp->tx_skbuff[entry]);
+		dev_kfree_skb(rp->tx_skbuff[entry]);
 		rp->tx_skbuff[entry] = NULL;
 		entry = (++rp->dirty_tx) % TX_RING_SIZE;
 	}
@@ -1529,7 +1550,7 @@ static int rhine_rx(struct net_device *d
 				skb_put(skb, pkt_len);
 				pci_unmap_single(rp->pdev,
 						 rp->rx_skbuff_dma[entry],
-						 rp->rx_buf_sz,
+						 pkt_len,
 						 PCI_DMA_FROMDEVICE);
 			}
 			skb->protocol = eth_type_trans(skb, dev);
@@ -1867,6 +1888,11 @@ static int rhine_close(struct net_device
 	free_tbufs(dev);
 	free_ring(dev);
 
+	if (!disable_sleep_mode) {
+		iowrite8(0x80, ioaddr + 0xa1);
+		pci_set_power_state(rp->pdev, PCI_D3hot);
+	}
+
 	return 0;
 }
 
diff -puNrb linux-2.6.35/drivers/net/via-velocity.c linux/drivers/net/via-velocity.c
--- linux-2.6.35/drivers/net/via-velocity.c	2011-04-26 16:28:21.002477418 +0300
+++ linux/drivers/net/via-velocity.c	2011-05-02 10:08:27.281590481 +0300
@@ -1365,7 +1365,7 @@ static void velocity_init_registers(stru
 		/*
 		 *	Init CAM filter
 		 */
-		velocity_init_cam_filter(vptr);
+//		velocity_init_cam_filter(vptr);
 
 		/*
 		 *	Set packet filter: Receive directed and broadcast address
@@ -2116,7 +2116,7 @@ static int velocity_rx_srv(struct veloci
 		/*
 		 *	Don't drop CE or RL error frame although RXOK is off
 		 */
-		if (rd->rdesc0.RSR & (RSR_RXOK | RSR_CE | RSR_RL)) {
+		if (rd->rdesc0.RSR & (RSR_RXOK | RSR_CE | RSR_RL | RSR_VIDM)) {
 			if (velocity_receive_frame(vptr, rd_curr) < 0)
 				stats->rx_dropped++;
 		} else {
diff -puNrb linux-2.6.35/drivers/net/wan/c101.c linux/drivers/net/wan/c101.c
--- linux-2.6.35/drivers/net/wan/c101.c	2011-04-26 16:28:17.541229002 +0300
+++ linux/drivers/net/wan/c101.c	2011-05-02 10:08:27.301591298 +0300
@@ -379,7 +379,7 @@ static int __init c101_run(unsigned long
 	hdlc->xmit = sca_xmit;
 	card->settings.clock_type = CLOCK_EXT;
 
-	result = register_hdlc_device(dev);
+	result = register_hdlc_device(dev, "hdlc%d");
 	if (result) {
 		printk(KERN_WARNING "c101: unable to register hdlc device\n");
 		c101_destroy_card(card);
diff -puNrb linux-2.6.35/drivers/net/wan/dscc4.c linux/drivers/net/wan/dscc4.c
--- linux-2.6.35/drivers/net/wan/dscc4.c	2011-04-26 16:28:17.541229002 +0300
+++ linux/drivers/net/wan/dscc4.c	2011-05-02 10:08:27.311592723 +0300
@@ -695,7 +695,7 @@ static void dscc4_free1(struct pci_dev *
 	root = ppriv->root;
 
 	for (i = 0; i < dev_per_card; i++)
-		unregister_hdlc_device(dscc4_to_dev(root + i));
+		unregister_hdlc_device(dscc4_to_dev(root + i), "hdlc%d");
 
 	pci_set_drvdata(pdev, NULL);
 
diff -puNrb linux-2.6.35/drivers/net/wan/farsync.c linux/drivers/net/wan/farsync.c
--- linux-2.6.35/drivers/net/wan/farsync.c	2011-04-26 16:28:17.511229178 +0300
+++ linux/drivers/net/wan/farsync.c	2011-05-02 10:08:27.331591492 +0300
@@ -2524,7 +2524,7 @@ fst_add_one(struct pci_dev *pdev, const 
         spin_lock_init ( &card->card_lock );
 
         for ( i = 0 ; i < card->nports ; i++ ) {
-		struct net_device *dev = alloc_hdlcdev(&card->ports[i]);
+		struct net_device *dev = alloc_hdlcdev(&card->ports[i], "fars%d");
 		hdlc_device *hdlc;
 		if (!dev) {
 			while (i--)
diff -puNrb linux-2.6.35/drivers/net/wan/farsync.h linux/drivers/net/wan/farsync.h
--- linux-2.6.35/drivers/net/wan/farsync.h	2011-04-26 16:28:17.521228576 +0300
+++ linux/drivers/net/wan/farsync.h	2011-05-02 10:08:27.361589400 +0300
@@ -3,7 +3,7 @@
  *
  *      Actually sync driver for X.21, V.35 and V.24 on FarSync T-series cards
  *
- *      Copyright (C) 2001 FarSite Communications Ltd.
+ *      Copyright (C) 2001-2004 FarSite Communications Ltd.
  *      www.farsite.co.uk
  *
  *      This program is free software; you can redistribute it and/or
@@ -21,27 +21,10 @@
  *      this file may not be changed arbitrarily.
  */
 
-/*      What's in a name
- *
- *      The project name for this driver is Oscar. The driver is intended to be
- *      used with the FarSite T-Series cards (T2P & T4P) running in the high
- *      speed frame shifter mode. This is sometimes referred to as X.21 mode
- *      which is a complete misnomer as the card continues to support V.24 and
- *      V.35 as well as X.21.
- *
- *      A short common prefix is useful for routines within the driver to avoid
- *      conflict with other similar drivers and I chosen to use "fst_" for this
- *      purpose (FarSite T-series).
- *
- *      Finally the device driver needs a short network interface name. Since
- *      "hdlc" is already in use I've chosen the even less informative "sync"
- *      for the present.
- */
 #define FST_NAME                "fst"           /* In debug/info etc */
 #define FST_NDEV_NAME           "sync"          /* For net interface */
 #define FST_DEV_NAME            "farsync"       /* For misc interfaces */
 
-
 /*      User version number
  *
  *      This version number is incremented with each official release of the
@@ -50,16 +33,26 @@
  *      have individual versions (or IDs) that move much faster than the
  *      the release version as individual updates are tracked.
  */
-#define FST_USER_VERSION        "1.04"
+#define FST_USER_VERSION        "1.06"
+#define FST_PATCH_LEVEL         "04"
+#define FST_PLATFORM            "ia32"
+#define FST_ADDITIONAL          ""
 
+#define FST_INCLUDES_CHAR
 
 /*      Ioctl call command values
  */
-#define FSTWRITE        (SIOCDEVPRIVATE+10)
-#define FSTCPURESET     (SIOCDEVPRIVATE+11)
-#define FSTCPURELEASE   (SIOCDEVPRIVATE+12)
-#define FSTGETCONF      (SIOCDEVPRIVATE+13)
-#define FSTSETCONF      (SIOCDEVPRIVATE+14)
+#define FSTWRITE        (SIOCDEVPRIVATE+4)
+#define FSTCPURESET     (SIOCDEVPRIVATE+5)
+#define FSTCPURELEASE   (SIOCDEVPRIVATE+6)
+#define FSTGETCONF      (SIOCDEVPRIVATE+7)
+#define FSTSETCONF      (SIOCDEVPRIVATE+8)
+#define FSTSNOTIFY      (SIOCDEVPRIVATE+9)
+#define FSTGSTATE       (SIOCDEVPRIVATE+10)
+#define FSTSYSREQ       (SIOCDEVPRIVATE+11)
+#define FSTGETSHELL     (SIOCDEVPRIVATE+12)
+#define FSTSETMON       (SIOCDEVPRIVATE+13)
+#define FSTSETPORT      (SIOCDEVPRIVATE+14)
 
 
 /*      FSTWRITE
@@ -107,6 +100,7 @@ struct fstioc_info {
         unsigned char  proto;           /* Line protocol */
         unsigned char  internalClock;   /* 1 => internal clock, 0 => external */
         unsigned int   lineSpeed;       /* Speed in bps */
+        unsigned int   estLineSpeed;    /* Estimated speed in bps */
         unsigned int   v24IpSts;        /* V.24 control input status */
         unsigned int   v24OpSts;        /* V.24 control output status */
         unsigned short clockStatus;     /* lsb: 0=> present, 1=> absent */
@@ -115,6 +109,8 @@ struct fstioc_info {
         unsigned short debug;           /* Debug flags */
         unsigned char  transparentMode; /* Not used always 0 */
         unsigned char  invertClock;     /* Invert clock feature for syncing */
+        unsigned char  asyncAbility ;   /* The ability to do async */
+        unsigned char  synthAbility;    /* The ability to syth a clock */
         unsigned char  startingSlot;    /* Time slot to use for start of tx */
         unsigned char  clockSource;     /* External or internal */
         unsigned char  framing;         /* E1, T1 or J1 */
@@ -138,8 +134,113 @@ struct fstioc_info {
         unsigned short lossOfSignal;
         unsigned short receiveRemoteAlarm;
         unsigned short alarmIndicationSignal;
+        unsigned short _reserved[64];
+        unsigned char  ignoreCarrier;  /* If set transmit regardless of carrier state */
+        unsigned char  numTxBuffers;   /* No of tx buffers in card window */
+        unsigned char  numRxBuffers;   /* No of rx buffers in card window */
+        unsigned int   txBufferSize;   /* Size of tx buffers in card window */
+        unsigned int   rxBufferSize;   /* Size of rx buffers in card window */
+        unsigned char  terminalType;  /* Additional hdsl */
+        unsigned char  annexType;
+        unsigned char  encap;
+        unsigned char  testMode;
+        unsigned char  backoff;
+        unsigned char  bLineProbingEnable;
+        unsigned char  snrth;
+        unsigned char  lpath;
+        unsigned short vpi;
+        unsigned short vci;
+        unsigned char  activationStatus;
+        unsigned char  noCommonModeStatus;
+        unsigned char  transceiverStatus1;
+        unsigned char  transceiverStatus2;
+        unsigned char  lineLoss;
+        char           signalQuality;
+        unsigned char  nearEndBlockErrorCount;
+        char           signalToNoiseRatio;
+        unsigned char  erroredSecondCount;
+        unsigned char  severelyErroredSecondCount;
+        unsigned char  lossOfSyncWordSecondCount;
+        unsigned char  unavailableSecondCount;
+        char           frequencyDeviation;
+        char           negotiatedPowerBackOff;
+        unsigned char  negotiatedPSD;
+        unsigned char  negotiatedBChannels;
+        unsigned char  negotiatedZBits;
+        unsigned short negotiatedSyncWord;
+        unsigned char  negotiatedStuffBits;
+        unsigned char  chipVersion;
+        unsigned char  firmwareVersion;
+        unsigned char  romVersion;
+        unsigned short atmTxCellCount;
+        unsigned short atmRxCellCount;
+        unsigned short atmHecErrorCount;
+        unsigned int   atmCellsDropped;
+        unsigned char  transmitMSBFirst;
+        unsigned char  receiveMSBFirst;
+        unsigned char xpldVersion;
+        unsigned char  farEndCountryCode[2]; 
+        unsigned char  farEndProviderCode[4];
+        unsigned char  farEndVendorInfo[2];
 };
 
+/*      FSTGSTATE
+ *
+ *      Used to query why a state change message has been issued by the driver
+ *      It could be because there was a change in line states or that the txq
+ *      has reached an empty state
+ */
+struct fstioc_status {
+  int carrier_state;
+  int txq_length;
+};
+
+/*      FSTSYSREQ
+ *
+ *      Used to provide a simple transparent command/repsonse interface between
+ *      an application and the firmware running on the card
+ */
+struct fstioc_req {
+  unsigned short msg_type;
+  unsigned short msg_len;
+  unsigned short ret_code;
+  unsigned short i_reg_idx;
+  unsigned short value;
+  unsigned char u_msg[16];
+  unsigned char u_msg_reserved[16];
+  unsigned char u_reserved[4];
+};
+
+
+#define MSG_FIFO_EEPROM_RD 0x769b
+#define MSG_FIFO_EEPROM_WR 0xcd4a
+#define RSP_FIFO_SUCCESS   0x0000
+#define RSP_FIFO_FAILURE   0x0001
+
+
+/*      FSTSETMON
+ *
+ *      Used to provide a simple monitoring data 
+ */
+#define FSTIOC_MON_VERSION 0
+#define FST_MON_RX         0
+#define FST_MON_TX         1
+
+struct fstioc_mon {
+  unsigned char version;
+  unsigned char tx_rx_ind;
+  unsigned int  sequence;
+  unsigned long timestamp;
+  unsigned int  length;
+};
+
+/*      FSTSETPORT
+ *
+ *      Used to provide a DSL port control
+ */
+#define FST_DSL_PORT_NORMAL         0
+#define FST_DSL_PORT_ACTIVE         1
+
 /* "valid" bitmask */
 #define FSTVAL_NONE     0x00000000      /* Nothing valid (firmware not running).
                                          * Slight misnomer. In fact nports,
@@ -161,8 +262,11 @@ struct fstioc_info {
 #define FSTVAL_MODE     0x00000400      /* cardMode */
 #define FSTVAL_PHASE    0x00000800      /* Clock phase */
 #define FSTVAL_TE1      0x00001000      /* T1E1 Configuration */
+#define FSTVAL_BUFFERS  0x00002000      /* Tx and Rx buffer settings */
+#define FSTVAL_DSL_S1   0x00004000      /* DSL-S1 Configuration */
+#define FSTVAL_T4E      0x00008000      /* T4E Mk II Configuration */
 #define FSTVAL_DEBUG    0x80000000      /* debug */
-#define FSTVAL_ALL      0x00001FFF      /* Note: does not include DEBUG flag */
+#define FSTVAL_ALL      0x0000FFFF      /* Note: does not include DEBUG flag */
 
 /* "type" */
 #define FST_TYPE_NONE   0               /* Probably should never happen */
@@ -172,6 +276,8 @@ struct fstioc_info {
 #define FST_TYPE_T2U    4               /* T2U X21 2 port card */
 #define FST_TYPE_T4U    5               /* T4U X21 4 port card */
 #define FST_TYPE_TE1    6               /* T1E1 X21 1 port card */
+#define FST_TYPE_DSL_S1 7               /* DSL-S1 card */
+#define FST_TYPE_T4E    8               /* T4E Mk II */
 
 /* "family" */
 #define FST_FAMILY_TXP  0               /* T2P or T4P */
@@ -194,9 +300,12 @@ struct fstioc_info {
 #define X21             2
 #define V35             3
 #define X21D            4
-#define T1              5
-#define E1              6
-#define J1              7
+#define NOCABLE         5
+#define RS530_449       6
+#define T1              7
+#define E1              8
+#define J1              9
+#define SHDSL           10
 
 /* "proto" */
 #define FST_RAW         4               /* Two way raw packets */
@@ -227,6 +336,14 @@ struct fstioc_info {
 #define CARD_MODE_IDENTIFY      0x0001
 
 /* 
+ * TxRx Start Parameters
+ */
+#define START_TX 1
+#define START_RX 2
+#define START_TX_AND_RX (START_TX | START_RX)
+#define START_DEFAULT START_TX_AND_RX
+
+/* 
  * Constants for T1/E1 configuration
  */
 
@@ -318,6 +435,42 @@ struct fstioc_info {
 #define BUFFER_96_BIT        2
 #define BUFFER_NONE          3
 
+/*
+ * DSL Equipment types
+ */
+#define EQUIP_TYPE_REMOTE    0
+#define EQUIP_TYPE_CENTRAL   1
+
+/*
+ * DSL Operating modes
+ */
+#define ANNEX_A              1    /* US */
+#define ANNEX_B              0    /* EU */
+
+/*
+ * DSL ATM Encapsulation methods
+ */
+#define ENCAP_PPP            0
+#define ENCAP_MPOA           1
+#define MPOA_HEADER_LEN      8
+
+/*
+ * DSL Test Modes
+ */
+#define TEST_MODE_NONE                        0
+#define TEST_MODE_DEFAULT TEST_MODE_NONE
+
+#define TEST_MODE_ALTERNATING_SINGLE_PULSE    1
+#define TEST_MODE_ANALOG_TRANSPARENT_LOOP     4
+#define TEST_MODE_ANALOG_NON_TRANSPARENT_LOOP 8
+#define TEST_MODE_TRANSMIT_SC_SR              9
+#define TEST_MODE_TRANSMIT_TC_PAM_SCRONE      10
+#define TEST_MODE_LINE_DRIVER_NO_SIGNAL       11
+#define TEST_MODE_AGC_TO_LINE_DRIVER_LOOP     12
+
+#define TEST_MODE_LOOP_TDM_TO_LINE            16
+#define TEST_MODE_LOOP_PAYLOAD_TO_LINE        17
+
 /*      Debug support
  *
  *      These should only be enabled for development kernels, production code
@@ -342,8 +495,9 @@ extern int fst_debug_mask;              
 #define DBG_TX          0x0040          /* Packet transmission */
 #define DBG_RX          0x0080          /* Packet reception */
 #define DBG_CMD         0x0100          /* Port command issuing */
-
-#define DBG_ASS         0xFFFF          /* Assert like statements. Code that
+#define DBG_ATM         0x0200          /* ATM processing */
+#define DBG_TTY         0x0400          /* PPPd processing */
+#define DBG_ASS         0x0001          /* Assert like statements. Code that
                                          * should never be reached, if you see
                                          * one of these then I've been an ass
                                          */
diff -puNrb linux-2.6.35/drivers/net/wan/hdlc.c linux/drivers/net/wan/hdlc.c
--- linux-2.6.35/drivers/net/wan/hdlc.c	2011-04-26 16:28:17.541229002 +0300
+++ linux/drivers/net/wan/hdlc.c	2011-05-02 10:08:27.371544565 +0300
@@ -251,10 +251,10 @@ static void hdlc_setup(struct net_device
 	spin_lock_init(&hdlc->state_lock);
 }
 
-struct net_device *alloc_hdlcdev(void *priv)
+struct net_device *alloc_hdlcdev(void *priv, const char *dnt)
 {
 	struct net_device *dev;
-	dev = alloc_netdev(sizeof(struct hdlc_device), "hdlc%d", hdlc_setup);
+	dev = alloc_netdev(sizeof(struct hdlc_device), dnt, hdlc_setup);
 	if (dev)
 		dev_to_hdlc(dev)->priv = priv;
 	return dev;
diff -puNrb linux-2.6.35/drivers/net/wan/hdlc_fr.c linux/drivers/net/wan/hdlc_fr.c
--- linux-2.6.35/drivers/net/wan/hdlc_fr.c	2011-04-26 16:28:17.511229178 +0300
+++ linux/drivers/net/wan/hdlc_fr.c	2011-05-02 10:08:27.391585781 +0300
@@ -1070,7 +1070,18 @@ static int fr_add_pvc(struct net_device 
 	hdlc_device *hdlc = dev_to_hdlc(frad);
 	pvc_device *pvc;
 	struct net_device *dev;
-	int result, used;
+	int used;
+	char dname[16];
+
+	/* use high word of dlci as device name hint */
+	sprintf(dname, type == ARPHRD_ETHER ? "pvceth%d" : "pvc%d", dlci >> 16);
+	dlci &= 0xffff;
+
+	dev = dev_get_by_name(&init_net, dname);
+	if (dev != NULL) {
+		dev_put(dev);
+		return -EEXIST;
+	}
 
 	if ((pvc = add_pvc(frad, dlci)) == NULL) {
 		printk(KERN_WARNING "%s: Memory squeeze on fr_add_pvc()\n",
@@ -1084,9 +1095,9 @@ static int fr_add_pvc(struct net_device 
 	used = pvc_is_used(pvc);
 
 	if (type == ARPHRD_ETHER)
-		dev = alloc_netdev(0, "pvceth%d", ether_setup);
+		dev = alloc_netdev(0, dname, ether_setup);
 	else
-		dev = alloc_netdev(0, "pvc%d", pvc_setup);
+		dev = alloc_netdev(0, dname, pvc_setup);
 
 	if (!dev) {
 		printk(KERN_WARNING "%s: Memory squeeze on fr_pvc()\n",
@@ -1106,12 +1117,7 @@ static int fr_add_pvc(struct net_device 
 	dev->tx_queue_len = 0;
 	dev->ml_priv = pvc;
 
-	result = dev_alloc_name(dev, dev->name);
-	if (result < 0) {
-		free_netdev(dev);
-		delete_unused_pvcs(hdlc);
-		return result;
-	}
+	strcpy(dev->name, dname);
 
 	if (register_netdevice(dev) != 0) {
 		free_netdev(dev);
@@ -1270,8 +1276,10 @@ static int fr_ioctl(struct net_device *d
 				   sizeof(fr_proto_pvc)))
 			return -EFAULT;
 
+#if 0
 		if (pvc.dlci <= 0 || pvc.dlci >= 1024)
 			return -EINVAL;	/* Only 10 bits, DLCI 0 reserved */
+#endif
 
 		if (ifr->ifr_settings.type == IF_PROTO_FR_ADD_ETH_PVC ||
 		    ifr->ifr_settings.type == IF_PROTO_FR_DEL_ETH_PVC)
diff -puNrb linux-2.6.35/drivers/net/wan/lmc/lmc_main.c linux/drivers/net/wan/lmc/lmc_main.c
--- linux-2.6.35/drivers/net/wan/lmc/lmc_main.c	2011-04-26 16:28:17.321229128 +0300
+++ linux/drivers/net/wan/lmc/lmc_main.c	2011-05-02 10:08:27.401544789 +0300
@@ -850,7 +850,7 @@ static int __devinit lmc_init_one(struct
 		goto err_kzalloc;
 	}
 
-	dev = alloc_hdlcdev(sc);
+	dev = alloc_hdlcdev(sc, "lmc%d");
 	if (!dev) {
 		printk(KERN_ERR "lmc:alloc_netdev for device failed\n");
 		goto err_hdlcdev;
diff -puNrb linux-2.6.35/drivers/net/wan/n2.c linux/drivers/net/wan/n2.c
--- linux-2.6.35/drivers/net/wan/n2.c	2011-04-26 16:28:17.541229002 +0300
+++ linux/drivers/net/wan/n2.c	2011-05-02 10:08:27.421588417 +0300
@@ -473,7 +473,7 @@ static int __init n2_run(unsigned long i
 		port->settings.clock_type = CLOCK_EXT;
 		port->card = card;
 
-		if (register_hdlc_device(dev)) {
+		if (register_hdlc_device(dev, "hdlc%d")) {
 			printk(KERN_WARNING "n2: unable to register hdlc "
 			       "device\n");
 			port->card = NULL;
diff -puNrb linux-2.6.35/drivers/oprofile/cpu_buffer.c linux/drivers/oprofile/cpu_buffer.c
--- linux-2.6.35/drivers/oprofile/cpu_buffer.c	2011-04-26 16:27:49.692478030 +0300
+++ linux/drivers/oprofile/cpu_buffer.c	2011-05-02 10:08:27.431609972 +0300
@@ -324,7 +324,7 @@ void oprofile_add_sample(struct pt_regs 
 
 	if (likely(regs)) {
 		is_kernel = !user_mode(regs);
-		pc = profile_pc(regs);
+		pc = instruction_pointer(regs);
 	} else {
 		is_kernel = 0;    /* This value will not be used */
 		pc = ESCAPE_CODE; /* as this causes an early return. */
diff -puNrb linux-2.6.35/drivers/oprofile/hrtimer.c linux/drivers/oprofile/hrtimer.c
--- linux-2.6.35/drivers/oprofile/hrtimer.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/oprofile/hrtimer.c	2011-05-02 10:08:27.441586089 +0300
@@ -0,0 +1,58 @@
+#include <asm/irq_regs.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/hrtimer.h>
+#include <linux/module.h>
+#include <linux/oprofile.h>
+
+static int polling;
+module_param(polling, int, 0);
+
+static DEFINE_PER_CPU(struct hrtimer, op_hrtimer);
+
+static enum hrtimer_restart hrtimer_oprofile_timer(struct hrtimer *t)
+{
+	oprofile_add_sample(get_irq_regs(), 0);
+
+	hrtimer_forward_now(t, ns_to_ktime(5000000));
+
+	return HRTIMER_RESTART;
+}
+
+static void hrtimer_oprofile_start_one(void *d)
+{
+	struct hrtimer *ht = &__get_cpu_var(op_hrtimer);
+
+	hrtimer_init(ht, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+	ht->function = hrtimer_oprofile_timer;
+
+	hrtimer_start(ht, ns_to_ktime(5000000), HRTIMER_MODE_REL_PINNED);
+}
+
+static int hrtimer_oprofile_start(void)
+{
+	on_each_cpu(hrtimer_oprofile_start_one, NULL, 1);
+	return 0;
+}
+
+static void hrtimer_oprofile_stop(void)
+{
+	int cpu;
+
+	for_each_online_cpu(cpu)
+		hrtimer_cancel(&per_cpu(op_hrtimer, cpu));
+}
+
+int __init hrtimer_oprofile_init(struct oprofile_operations *ops)
+{
+	if (!polling) 
+		return -ENODEV;
+
+	ops->create_files = NULL;
+	ops->setup = NULL;
+	ops->shutdown = NULL;
+	ops->start = hrtimer_oprofile_start;
+	ops->stop = hrtimer_oprofile_stop;
+	ops->cpu_type = "timer";
+	return 0;
+}
diff -puNrb linux-2.6.35/drivers/pci/probe.c linux/drivers/pci/probe.c
--- linux-2.6.35/drivers/pci/probe.c	2011-04-26 16:27:43.292167561 +0300
+++ linux/drivers/pci/probe.c	2011-05-02 10:08:27.451544717 +0300
@@ -1355,11 +1355,19 @@ unsigned int __devinit pci_scan_child_bu
 {
 	unsigned int devfn, pass, max = bus->secondary;
 	struct pci_dev *dev;
+	unsigned int devfn_limit = 0x100;
 
 	dev_dbg(&bus->dev, "scanning bus\n");
 
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#ifdef CONFIG_MIPS_MIKROTIK
+	/* PCI fix for RB532 */
+	if (bus->number == 0) devfn_limit = 22 * 8;
+#endif
+#endif
+
 	/* Go find them, Rover! */
-	for (devfn = 0; devfn < 0x100; devfn += 8)
+	for (devfn = 0; devfn < devfn_limit; devfn += 8)
 		pci_scan_slot(bus, devfn);
 
 	/* Reserve buses for SR-IOV capability. */
diff -puNrb linux-2.6.35/drivers/pci/setup-bus.c linux/drivers/pci/setup-bus.c
--- linux-2.6.35/drivers/pci/setup-bus.c	2011-04-26 16:27:43.302168985 +0300
+++ linux/drivers/pci/setup-bus.c	2011-05-02 10:08:27.471585834 +0300
@@ -442,7 +442,9 @@ static void pbus_size_io(struct pci_bus 
 		old_size = 0;
 /* To be fixed in 2.5: we should have sort of HAVE_ISA
    flag in the struct pci_bus. */
-#if defined(CONFIG_ISA) || defined(CONFIG_EISA)
+/* NOTE: all io resources get aligned to 1024 with maximum size 256,
+   so we should increase IO space 4 times even on RB500/RB100/RB800 */
+#if defined(CONFIG_ISA) || defined(CONFIG_EISA) || defined(CONFIG_MIPS_MIKROTIK) || defined(CONFIG_RB_PCI)
 	size = (size & 0xff) + ((size & ~0xffUL) << 2);
 #endif
 	size = ALIGN(size + size1, 4096);
diff -puNrb linux-2.6.35/drivers/pcmcia/yenta_socket.c linux/drivers/pcmcia/yenta_socket.c
--- linux-2.6.35/drivers/pcmcia/yenta_socket.c	2011-04-26 16:27:45.842509099 +0300
+++ linux/drivers/pcmcia/yenta_socket.c	2011-05-02 10:08:27.481544801 +0300
@@ -710,7 +710,8 @@ static int yenta_allocate_res(struct yen
 
 	region.start = config_readl(socket, addr_start) & mask;
 	region.end = config_readl(socket, addr_end) | ~mask;
-	if (region.start && region.end > region.start && !override_bios) {
+	if (region.start && region.end > region.start
+		 && (region.end - region.start) >= 0x3fffff && !override_bios) {
 		pcibios_bus_to_resource(dev, res, &region);
 		if (pci_claim_resource(dev, PCI_BRIDGE_RESOURCES + nr) == 0)
 			return 0;
diff -puNrb linux-2.6.35/drivers/serial/8250.c linux/drivers/serial/8250.c
--- linux-2.6.35/drivers/serial/8250.c	2011-04-26 16:27:22.572169229 +0300
+++ linux/drivers/serial/8250.c	2011-05-02 10:08:27.501588417 +0300
@@ -43,6 +43,11 @@
 #include <asm/io.h>
 #include <asm/irq.h>
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+#endif
+
 #include "8250.h"
 
 #ifdef CONFIG_SPARC
@@ -2850,8 +2855,10 @@ static struct console serial8250_console
 	.data		= &serial8250_reg,
 };
 
+extern int uart_disabled;
 static int __init serial8250_console_init(void)
 {
+	if (uart_disabled) return 0;	
 	if (nr_uarts > UART_NR)
 		nr_uarts = UART_NR;
 
@@ -3200,6 +3207,10 @@ static int __init serial8250_init(void)
 	if (nr_uarts > UART_NR)
 		nr_uarts = UART_NR;
 
+#ifdef CONFIG_MIPS_MIKROTIK
+	if (mips_machgroup == MACH_GROUP_MT_RB100) return -1;
+#endif
+
 	printk(KERN_INFO "Serial: 8250/16550 driver, "
 		"%d ports, IRQ sharing %sabled\n", nr_uarts,
 		share_irqs ? "en" : "dis");
diff -puNrb linux-2.6.35/drivers/serial/adm5120_uart.c linux/drivers/serial/adm5120_uart.c
--- linux-2.6.35/drivers/serial/adm5120_uart.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/serial/adm5120_uart.c	2011-05-02 10:08:27.511544724 +0300
@@ -0,0 +1,531 @@
+/*
+ *	Serial driver for ADM5120 SoC
+ *
+ *	Derived from drivers/serial/uart00.c
+ *	Copyright 2001 Altera Corporation
+ *
+ *	Some pieces are derived from the ADMtek 2.4 serial driver.
+ *	Copyright (C) ADMtek Incorporated, 2003
+ *		daniell@admtek.com.tw
+ *	Which again was derived from drivers/char/serial.c
+ *	Copyright (C) Linus Torvalds et al.
+ *
+ *	Copyright Jeroen Vreeken (pe1rxq@amsat.org), 2005
+ */
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/ioport.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/console.h>
+#include <linux/platform_device.h>
+#include <asm/bootinfo.h>
+#include <asm/rb/boards.h>
+
+#define ADM5120_UART_BASE0		0x12600000
+#define ADM5120_UART_BASE1		0x12800000
+#define ADM5120_UART_SIZE		0x20
+
+#define ADM5120_UART_IRQ0		9
+#define ADM5120_UART_IRQ1		10
+
+#define ADM5120_UART_REG(base, reg) \
+	(*(volatile u32 *)KSEG1ADDR((base)+(reg)))
+
+#define ADM5120_UART_DATA		0x00
+#define ADM5120_UART_RS			0x04
+#define ADM5120_UART_LCR_H		0x08
+#define ADM5120_UART_LCR_M		0x0c
+#define ADM5120_UART_LCR_L		0x10
+#define ADM5120_UART_CR			0x14
+#define ADM5120_UART_FR			0x18
+#define ADM5120_UART_IR			0x1c
+
+#define ADM5120_UART_FE			0x01
+#define ADM5120_UART_PE			0x02
+#define ADM5120_UART_BE			0x04
+#define ADM5120_UART_OE			0x08
+#define ADM5120_UART_ERR		0x0f
+#define ADM5120_UART_FIFO_EN		0x10
+#define ADM5120_UART_EN			0x01
+#define ADM5120_UART_TIE		0x20
+#define ADM5120_UART_RIE		0x50
+#define ADM5120_UART_IE			0x78
+#define ADM5120_UART_CTS		0x01
+#define ADM5120_UART_DSR		0x02
+#define ADM5120_UART_DCD		0x04
+#define ADM5120_UART_TXFF		0x20
+#define ADM5120_UART_TXFE		0x80
+#define ADM5120_UART_RXFE		0x10
+#define ADM5120_UART_BRK		0x01
+#define ADM5120_UART_PEN		0x02
+#define ADM5120_UART_EPS		0x04
+#define ADM5120_UART_STP2		0x08
+#define ADM5120_UART_W5			0x00
+#define ADM5120_UART_W6			0x20
+#define ADM5120_UART_W7			0x40
+#define ADM5120_UART_W8			0x60
+#define ADM5120_UART_MIS		0x01
+#define ADM5120_UART_RIS		0x02
+#define ADM5120_UART_TIS		0x04
+#define ADM5120_UART_RTIS		0x08
+
+static void adm5120ser_stop_tx(struct uart_port *port)
+{
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_CR) &= ~ADM5120_UART_TIE;
+}
+
+static void adm5120ser_irq_rx(struct uart_port *port)
+{
+	struct tty_struct *tty = port->state->port.tty;
+	unsigned int status, ch, rds, flg, ignored = 0;
+
+	status = ADM5120_UART_REG(port->iobase, ADM5120_UART_FR);
+	while (!(status & ADM5120_UART_RXFE)) {
+		/* 
+		 * We need to read rds before reading the 
+		 * character from the fifo
+		 */
+		rds = ADM5120_UART_REG(port->iobase, ADM5120_UART_RS);
+		ch = ADM5120_UART_REG(port->iobase, ADM5120_UART_DATA);
+		port->icount.rx++;
+
+		flg = TTY_NORMAL;
+
+		/*
+		 * Note that the error handling code is
+		 * out of the main execution path
+		 */
+		if (rds & ADM5120_UART_ERR)
+			goto handle_error;
+		if (uart_handle_sysrq_char(port, ch))
+			goto ignore_char;
+
+	error_return:
+		tty_insert_flip_char(tty, ch, flg);
+
+	ignore_char:
+		status = ADM5120_UART_REG(port->iobase, ADM5120_UART_FR);
+	}
+ out:
+	tty_flip_buffer_push(tty);
+	return;
+
+ handle_error:
+ 	ADM5120_UART_REG(port->iobase, ADM5120_UART_RS) = 0xff;
+	if (rds & ADM5120_UART_BE) {
+		port->icount.brk++;
+		if (uart_handle_break(port))
+			goto ignore_char;
+	} else if (rds & ADM5120_UART_PE)
+		port->icount.parity++;
+	else if (rds & ADM5120_UART_FE)
+		port->icount.frame++;
+	if (rds & ADM5120_UART_OE)
+		port->icount.overrun++;
+
+	if (rds & port->ignore_status_mask) {
+		if (++ignored > 100)
+			goto out;
+		goto ignore_char;
+	}
+	rds &= port->read_status_mask;
+
+	if (rds & ADM5120_UART_BE)
+		flg = TTY_BREAK;
+	else if (rds & ADM5120_UART_PE)
+		flg = TTY_PARITY;
+	else if (rds & ADM5120_UART_FE)
+		flg = TTY_FRAME;
+
+	if (rds & ADM5120_UART_OE) {
+		/*
+		 * CHECK: does overrun affect the current character?
+		 * ASSUMPTION: it does not.
+		 */
+		tty_insert_flip_char(tty, ch, flg);
+		ch = 0;
+		flg = TTY_OVERRUN;
+	}
+#ifdef CONFIG_MAGIC_SYSRQ
+	port->sysrq = 0;
+#endif
+	goto error_return;
+}
+
+static void adm5120ser_irq_tx(struct uart_port *port)
+{
+	struct circ_buf *xmit = &port->state->xmit;
+	int count;
+
+	if (port->x_char) {
+		ADM5120_UART_REG(port->iobase, ADM5120_UART_DATA) =
+		    port->x_char;
+		port->icount.tx++;
+		port->x_char = 0;
+		return;
+	}
+	if (uart_circ_empty(xmit) || uart_tx_stopped(port)) {
+		adm5120ser_stop_tx(port);
+		return;
+	}
+
+	count = port->fifosize >> 1;
+	do {
+		ADM5120_UART_REG(port->iobase, ADM5120_UART_DATA) =
+		    xmit->buf[xmit->tail];
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+		port->icount.tx++;
+		if (uart_circ_empty(xmit))
+			break;
+	} while (--count > 0);
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(port);
+
+	if (uart_circ_empty(xmit))
+		adm5120ser_stop_tx(port);
+}
+
+static void adm5120ser_irq_modem(struct uart_port *port)
+{
+	unsigned int status;
+
+	status = ADM5120_UART_REG(port->iobase, ADM5120_UART_FR);
+
+	if (status & ADM5120_UART_DCD)
+		uart_handle_dcd_change(port, status & ADM5120_UART_DCD);
+
+	if (status & ADM5120_UART_DSR)
+		port->icount.dsr++;
+
+	if (status & ADM5120_UART_CTS)
+		uart_handle_cts_change(port, status & ADM5120_UART_CTS);
+
+	wake_up_interruptible(&port->state->port.delta_msr_wait);
+}
+
+static irqreturn_t adm5120ser_irq(int irq, void *dev_id)
+{
+	struct uart_port *port = dev_id;
+	unsigned long ir = ADM5120_UART_REG(port->iobase, ADM5120_UART_IR);
+
+	if (ir & (ADM5120_UART_RIS | ADM5120_UART_RTIS))
+		adm5120ser_irq_rx(port);
+	if (ir & ADM5120_UART_TIS)
+		adm5120ser_irq_tx(port);
+	if (ir & ADM5120_UART_MIS) {
+		adm5120ser_irq_modem(port);
+		ADM5120_UART_REG(port->iobase, ADM5120_UART_IR) = 0xff;
+	}
+
+	return IRQ_HANDLED;
+}
+
+static unsigned int adm5120ser_tx_empty(struct uart_port *port)
+{
+	unsigned int fr = ADM5120_UART_REG(port->iobase, ADM5120_UART_FR);
+	return (fr & ADM5120_UART_TXFE) ? TIOCSER_TEMT : 0;
+}
+
+static void adm5120ser_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+}
+
+static unsigned int adm5120ser_get_mctrl(struct uart_port *port)
+{
+	unsigned int result = 0;
+	unsigned int fr = ADM5120_UART_REG(port->iobase, ADM5120_UART_FR);
+
+	if (fr & ADM5120_UART_CTS)
+		result |= TIOCM_CTS;
+	if (fr & ADM5120_UART_DSR)
+		result |= TIOCM_DSR;
+	if (fr & ADM5120_UART_DCD)
+		result |= TIOCM_CAR;
+	return result;
+}
+
+static void adm5120ser_start_tx(struct uart_port *port)
+{
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_CR) |= ADM5120_UART_TIE;
+}
+
+static void adm5120ser_stop_rx(struct uart_port *port)
+{
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_CR) &= ~ADM5120_UART_RIE;
+}
+
+static void adm5120ser_enable_ms(struct uart_port *port)
+{
+}
+
+static void adm5120ser_break_ctl(struct uart_port *port, int break_state)
+{
+	unsigned long flags;
+	unsigned long lcrh;
+
+	spin_lock_irqsave(&port->lock, flags);
+	lcrh = ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_H);
+	if (break_state == -1)
+		lcrh |= ADM5120_UART_BRK;
+	else
+		lcrh &= ~ADM5120_UART_BRK;
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_H) = lcrh;
+	spin_unlock_irqrestore(&port->lock, flags);
+}
+
+static int adm5120ser_startup(struct uart_port *port)
+{
+	int ret;
+
+	ret = request_irq(port->irq, adm5120ser_irq, 0, "ADM5120 UART", port);
+	if (ret) {
+		printk(KERN_ERR "Couldn't get irq %d\n", port->irq);
+		return ret;
+	}
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_H) |=
+	    ADM5120_UART_FIFO_EN;
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_CR) |=
+	    ADM5120_UART_EN | ADM5120_UART_IE;
+	return 0;
+}
+
+static void adm5120ser_shutdown(struct uart_port *port)
+{
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_CR) &= ~ADM5120_UART_IE;
+	free_irq(port->irq, port);
+}
+
+static void adm5120ser_set_termios(struct uart_port *port,
+    struct ktermios *termios, struct ktermios *old)
+{
+	unsigned int baud, quot, lcrh;
+	unsigned long flags;
+
+	termios->c_cflag |= CREAD;
+
+	baud = uart_get_baud_rate(port, termios, old, 0, port->uartclk/16);
+	quot = uart_get_divisor(port, baud) - 1;
+
+	lcrh = ADM5120_UART_FIFO_EN;
+	switch (termios->c_cflag & CSIZE) {
+		case CS5:
+			lcrh |= ADM5120_UART_W5;
+			break;
+		case CS6:
+			lcrh |= ADM5120_UART_W6;
+			break;
+		case CS7:
+			lcrh |= ADM5120_UART_W7;
+			break;
+		default:
+			lcrh |= ADM5120_UART_W8;
+			break;
+	}
+	if (termios->c_cflag & CSTOPB)
+		lcrh |= ADM5120_UART_STP2;
+	if (termios->c_cflag & PARENB) {
+		lcrh |= ADM5120_UART_PEN;
+		if (!(termios->c_cflag & PARODD))
+			lcrh |= ADM5120_UART_EPS;
+	}
+
+	spin_lock_irqsave(&port->lock, flags);
+
+	/*
+	 * Update the per-port timeout.
+	 */
+	uart_update_timeout(port, termios->c_cflag, baud);
+
+	port->read_status_mask = ADM5120_UART_OE;
+	if (termios->c_iflag & INPCK)
+		port->read_status_mask |= ADM5120_UART_FE | ADM5120_UART_PE;
+	if (termios->c_iflag & (BRKINT | PARMRK))
+		port->read_status_mask |= ADM5120_UART_BE;
+
+	/*
+	 * Characters to ignore
+	 */
+	port->ignore_status_mask = 0;
+	if (termios->c_iflag & IGNPAR)
+		port->ignore_status_mask |= ADM5120_UART_FE | ADM5120_UART_PE;
+	if (termios->c_iflag & IGNBRK) {
+		port->ignore_status_mask |= ADM5120_UART_BE;
+		/*
+		 * If we're ignoring parity and break indicators,
+		 * ignore overruns to (for real raw support).
+		 */
+		if (termios->c_iflag & IGNPAR)
+			port->ignore_status_mask |= ADM5120_UART_OE;
+	}
+
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_M) = (quot >> 8) & 0xf;
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_L) = quot & 0xff;
+
+	/* NOTE: should be written after UART_LCR_M & UART_LCR_L */
+	ADM5120_UART_REG(port->iobase, ADM5120_UART_LCR_H) = lcrh;
+
+	spin_unlock_irqrestore(&port->lock, flags);
+}
+
+static const char *adm5120ser_type(struct uart_port *port)
+{
+	return port->type == PORT_ADM5120 ? "ADM5120" : NULL;
+}
+
+static void adm5120ser_config_port(struct uart_port *port, int flags)
+{
+	if (flags & UART_CONFIG_TYPE)
+		port->type = PORT_ADM5120;
+}
+
+static void adm5120ser_release_port(struct uart_port *port)
+{
+	release_mem_region(port->iobase, ADM5120_UART_SIZE);
+}
+
+static int adm5120ser_request_port(struct uart_port *port)
+{
+	return request_mem_region(port->iobase, ADM5120_UART_SIZE,
+	    "adm5120-uart") != NULL ? 0 : -EBUSY; 
+}
+
+static struct uart_ops adm5120ser_ops = {
+	.tx_empty =	adm5120ser_tx_empty,
+	.set_mctrl =	adm5120ser_set_mctrl,
+	.get_mctrl =	adm5120ser_get_mctrl,
+	.stop_tx =	adm5120ser_stop_tx,
+	.start_tx =	adm5120ser_start_tx,
+	.stop_rx =	adm5120ser_stop_rx,
+	.enable_ms =	adm5120ser_enable_ms,
+	.break_ctl =	adm5120ser_break_ctl,
+	.startup =	adm5120ser_startup,
+	.shutdown =	adm5120ser_shutdown,
+	.set_termios =	adm5120ser_set_termios,
+	.type =		adm5120ser_type,
+	.config_port =	adm5120ser_config_port,
+	.release_port =	adm5120ser_release_port,
+	.request_port =	adm5120ser_request_port,
+};
+
+static void adm5120console_put(const char c)
+{
+	while ((ADM5120_UART_REG(ADM5120_UART_BASE0, ADM5120_UART_FR) &
+	     ADM5120_UART_TXFF) != 0);
+	ADM5120_UART_REG(ADM5120_UART_BASE0, ADM5120_UART_DATA) = c;
+}
+
+static void adm5120console_write(struct console *con, const char *s,
+    unsigned int count)
+{
+	while (count--) {
+		if (*s == '\n')
+			adm5120console_put('\r');
+		adm5120console_put(*s);
+		s++;
+	}
+}
+
+static struct uart_port adm5120ser_ports[] = {
+	{
+		.iobase =	ADM5120_UART_BASE0,
+		.irq =		ADM5120_UART_IRQ0,
+		.uartclk =	62500000,
+		.fifosize =	16,
+		.ops =		&adm5120ser_ops,
+		.line =		0,
+		.flags =	ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST,
+	},
+};
+
+static int adm5120console_setup(struct console *con, char *options)
+{
+	struct uart_port *port;
+	int baud = 115200;
+	int bits = 8;
+	int parity = 'n';
+	int flow = 'n';
+	int ret = 0;
+
+	port = &adm5120ser_ports[0];
+
+	if (options) {
+		uart_parse_options(options, &baud, &parity, &bits, &flow);
+		ret = uart_set_options(port, con, baud, parity, bits, flow);
+	}
+
+	/* Enable port */
+	ADM5120_UART_REG(ADM5120_UART_BASE0, ADM5120_UART_CR) = ADM5120_UART_EN;
+
+	return ret;
+}
+
+static struct uart_driver adm5120ser_reg;
+
+static struct console adm5120_serconsole = {
+	.name =		"ttyS",
+	.write =	adm5120console_write,
+	.device =	uart_console_device,
+	.setup =	adm5120console_setup,
+	.flags =	CON_PRINTBUFFER,
+	.index =	0,
+	.data =		&adm5120ser_reg,
+};
+
+static int __init adm5120console_init(void)
+{
+	if (mips_machgroup == MACH_GROUP_MT_RB100)
+		register_console(&adm5120_serconsole);
+	return 0;
+}
+
+console_initcall(adm5120console_init);
+
+
+static struct uart_driver adm5120ser_reg = {
+	.owner	=	THIS_MODULE,
+	.driver_name =	"adm5120",
+	.dev_name =	"ttyS",
+	.major =	TTY_MAJOR,
+	.minor =	64,
+	.nr =		1,
+	.cons =		&adm5120_serconsole,
+};
+
+static int adm5120ser_probe(struct platform_device *pdev)
+{
+	uart_add_one_port(&adm5120ser_reg, &adm5120ser_ports[0]);
+	platform_set_drvdata(pdev, &adm5120ser_ports[0]);
+	return 0;
+}
+
+static struct platform_driver adm5120ser_driver = {
+	.probe	= adm5120ser_probe,
+	.driver	= {
+		.name	= "rb100-uart",
+		.owner	= THIS_MODULE,
+	},
+};
+
+static int __init adm5120ser_init(void)
+{
+	int ret;
+
+	printk("RB100 UART\n");
+
+	if (mips_machgroup != MACH_GROUP_MT_RB100) return 0;
+
+	ret = uart_register_driver(&adm5120ser_reg);
+	if (ret == 0) {
+		ret = platform_driver_register(&adm5120ser_driver);
+		if (ret) uart_unregister_driver(&adm5120ser_reg);
+	}
+	return ret;
+}
+
+module_init(adm5120ser_init);
diff -puNrb linux-2.6.35/drivers/serial/Kconfig linux/drivers/serial/Kconfig
--- linux-2.6.35/drivers/serial/Kconfig	2011-04-26 16:27:22.582169195 +0300
+++ linux/drivers/serial/Kconfig	2011-05-02 10:08:27.531587269 +0300
@@ -277,6 +277,15 @@ config SERIAL_8250_RM9K
 
 comment "Non-8250 serial port support"
 
+config SERIAL_ADM5120
+	bool "ADM5120 serial port support"
+	depends on MIPS_MIKROTIK
+	select SERIAL_CORE
+	select SERIAL_CORE_CONSOLE
+	help
+	  Driver for the on chip UARTs on the ADM5120
+
+
 config SERIAL_AMBA_PL010
 	tristate "ARM AMBA PL010 serial port support"
 	depends on ARM_AMBA && (BROKEN || !ARCH_VERSATILE)
diff -puNrb linux-2.6.35/drivers/serial/Makefile linux/drivers/serial/Makefile
--- linux-2.6.35/drivers/serial/Makefile	2011-04-26 16:27:22.582169195 +0300
+++ linux/drivers/serial/Makefile	2011-05-02 10:08:27.541544671 +0300
@@ -28,6 +28,7 @@ obj-$(CONFIG_SERIAL_8250_BOCA) += 8250_b
 obj-$(CONFIG_SERIAL_8250_EXAR_ST16C554) += 8250_exar_st16c554.o
 obj-$(CONFIG_SERIAL_8250_HUB6) += 8250_hub6.o
 obj-$(CONFIG_SERIAL_8250_MCA) += 8250_mca.o
+obj-$(CONFIG_SERIAL_ADM5120) += adm5120_uart.o
 obj-$(CONFIG_SERIAL_AMBA_PL010) += amba-pl010.o
 obj-$(CONFIG_SERIAL_AMBA_PL011) += amba-pl011.o
 obj-$(CONFIG_SERIAL_CLPS711X) += clps711x.o
diff -puNrb linux-2.6.35/drivers/serial/serial_core.c linux/drivers/serial/serial_core.c
--- linux-2.6.35/drivers/serial/serial_core.c	2011-04-26 16:27:22.602167347 +0300
+++ linux/drivers/serial/serial_core.c	2011-05-02 10:08:27.551544895 +0300
@@ -364,7 +364,7 @@ uart_get_baud_rate(struct uart_port *por
 		 */
 		if (baud == 0) {
 			hung_up = 1;
-			baud = 9600;
+			baud = 115200;
 		}
 
 		if (baud >= min && baud <= max)
@@ -2165,6 +2165,14 @@ uart_report_port(struct uart_driver *drv
 	       address, port->irq, uart_type(port));
 }
 
+int uart_disabled = 0;
+EXPORT_SYMBOL(uart_disabled);
+static int __init disable_uart(char *s) {
+    uart_disabled = 1;
+    return 1;
+}
+__setup("uart-disabled", disable_uart);
+
 static void
 uart_configure_port(struct uart_driver *drv, struct uart_state *state,
 		    struct uart_port *port)
@@ -2214,8 +2222,9 @@ uart_configure_port(struct uart_driver *
 		 * successfully registered yet, try to re-register it.
 		 * It may be that the port was not available.
 		 */
-		if (port->cons && !(port->cons->flags & CON_ENABLED))
-			register_console(port->cons);
+		if (port->cons && !(port->cons->flags & CON_ENABLED)) {
+			if (!uart_disabled) register_console(port->cons);
+		}
 
 		/*
 		 * Power down all ports by default, except the
diff -puNrb linux-2.6.35/drivers/spi/Kconfig linux/drivers/spi/Kconfig
--- linux-2.6.35/drivers/spi/Kconfig	2011-04-26 16:27:33.872869330 +0300
+++ linux/drivers/spi/Kconfig	2011-05-02 10:08:27.571587316 +0300
@@ -243,6 +243,14 @@ config SPI_PXA2XX
 	  The driver can be configured to use any SSP port and additional
 	  documentation can be found a Documentation/spi/pxa2xx.
 
+config SPI_RB400
+	bool "RB400 SPI master"
+	depends on SPI_MASTER && MIPS_MIKROTIK
+
+config SPI_RB_PPC
+	bool "RB powerpc SPI master"
+	depends on SPI_MASTER && RB1100
+
 config SPI_S3C24XX
 	tristate "Samsung S3C24XX series SPI"
 	depends on ARCH_S3C2410 && EXPERIMENTAL
diff -puNrb linux-2.6.35/drivers/spi/Makefile linux/drivers/spi/Makefile
--- linux-2.6.35/drivers/spi/Makefile	2011-04-26 16:27:33.882798957 +0300
+++ linux/drivers/spi/Makefile	2011-05-02 10:08:27.581591719 +0300
@@ -41,6 +41,8 @@ obj-$(CONFIG_SPI_S3C24XX)		+= spi_s3c24x
 obj-$(CONFIG_SPI_S3C64XX)		+= spi_s3c64xx.o
 obj-$(CONFIG_SPI_TXX9)			+= spi_txx9.o
 obj-$(CONFIG_SPI_XILINX)		+= xilinx_spi.o
+obj-$(CONFIG_SPI_RB400)			+= spi_rb400.o
+obj-$(CONFIG_SPI_RB_PPC)		+= spi_rb_ppc.o
 obj-$(CONFIG_SPI_XILINX_OF)		+= xilinx_spi_of.o
 obj-$(CONFIG_SPI_XILINX_PLTFM)		+= xilinx_spi_pltfm.o
 obj-$(CONFIG_SPI_SH_SCI)		+= spi_sh_sci.o
diff -puNrb linux-2.6.35/drivers/spi/spi_rb400.c linux/drivers/spi/spi_rb400.c
--- linux-2.6.35/drivers/spi/spi_rb400.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/spi/spi_rb400.c	2011-05-02 10:08:27.601590905 +0300
@@ -0,0 +1,492 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/sched.h>
+#include <linux/hardirq.h>
+#include <linux/platform_device.h>
+#include <asm/rb/rb400.h>
+
+#include <linux/spi/spi.h>
+
+#define RB400_DEBUG 0
+#define REG_PLL_CONFIG	0x18050000
+
+#if RB400_DEBUG
+#define CLK_HALF_DELAY() ndelay(20000)
+#else
+#define CLK_HALF_DELAY() while(0) {}
+#endif
+
+#define SPI_BASE	0x1F000000
+#define   SPI_FUNC	  0x000000
+#define     SBIT_FUNC_GPIO	0x00000001
+#define   SPI_CTRL	  0x000004
+#define	    SPI_CTRL_FASTEST	0x40
+#define     SPI_FLASH_HZ	33333334
+#define     SPI_CPLD_HZ		33333334
+#define   SPI_IO_CTRL	  0x000008
+#define     SBIT_DO2_SHIFT	18
+#define     SBIT_DO2		(1u << SBIT_DO2_SHIFT)
+#define     SBIT_CS_ALL		0x00070000
+#define     SBIT_CS_2		0x00040000
+#define     SBIT_CS_1		0x00020000
+#define     SBIT_CS_0		0x00010000
+#define     SBIT_CLK		0x00000100
+#define     SBIT_DO_SHIFT	0
+#define     SBIT_DO		(1u << SBIT_DO_SHIFT)
+#define   SPI_RDATA	  0x00000C
+
+#define SPI_REG(x)	(*(volatile unsigned *)((unsigned) spi_base + (x)))
+
+extern unsigned mips_hpt_frequency;
+static void __iomem *spi_base;
+
+struct rb400_spi {
+	unsigned		spi_ctrl_flash;
+	unsigned		spi_ctrl_fread;
+
+	unsigned long		cur_jiffies;
+	long			req_till_schedule;
+
+	spinlock_t		lock;
+	struct list_head	queue;
+	int			busy:1;
+	int			cs_wait;
+};
+static unsigned spi_clk_low = SBIT_CS_ALL;
+static unsigned spi_hclk_delay = 0;
+static const unsigned spi_cs_map[] = {
+	SBIT_CS_ALL ^ SBIT_CS_0,
+	SBIT_CS_ALL ^ SBIT_CS_0 ^ SBIT_CS_2,
+	SBIT_CS_ALL ^ SBIT_CS_1,
+	SBIT_CS_ALL ^ SBIT_CS_2,
+	SBIT_CS_ALL
+};
+
+static void inline do_spi_init(struct spi_device *spi) {
+	unsigned hz = spi->max_speed_hz;
+	if (hz == 0 || hz >= 10000000) {
+		spi_hclk_delay = 0;
+	}
+	else {
+		spi_hclk_delay = 500000000 / hz - 50;
+	}
+#if RB400_DEBUG
+	if (spi_hclk_delay < 20000) spi_hclk_delay = 20000;
+#endif
+	if (unlikely(spi->mode & SPI_CS_HIGH)) {
+		spi_clk_low = SBIT_CS_ALL;
+	}
+	else {
+		spi_clk_low = spi_cs_map[spi->chip_select];
+		SPI_REG(SPI_IO_CTRL) = spi_clk_low;
+#if RB400_DEBUG
+		printk("do_spi_init CS %x\n",
+		       (spi_clk_low ^ SBIT_CS_ALL) >> 16);
+#endif
+	}
+}
+static void inline do_spi_finish(void) {
+	if (unlikely(spi_hclk_delay)) ndelay(spi_hclk_delay);
+	SPI_REG(SPI_IO_CTRL) = (SBIT_CS_ALL | (SPI_REG(SPI_IO_CTRL) & 1));
+#if RB400_DEBUG
+	printk("do_spi_finish (CS %x)\n", SBIT_CS_ALL >> 16);
+#endif
+}
+
+static void inline do_spi_clk(int bit) {
+	unsigned bval = spi_clk_low | (bit & 1);
+	CLK_HALF_DELAY();
+	SPI_REG(SPI_IO_CTRL) = bval;
+	CLK_HALF_DELAY();
+	SPI_REG(SPI_IO_CTRL) = bval | SBIT_CLK;
+}
+
+static void do_spi_byte(uint8_t byte) {
+	do_spi_clk(byte >> 7);
+	do_spi_clk(byte >> 6);
+	do_spi_clk(byte >> 5);
+	do_spi_clk(byte >> 4);
+	do_spi_clk(byte >> 3);
+	do_spi_clk(byte >> 2);
+	do_spi_clk(byte >> 1);
+	do_spi_clk(byte);
+#if RB400_DEBUG
+	printk("spi_byte sent 0x%x got 0x%x\n",
+	       (unsigned)byte,
+	       SPI_REG(SPI_RDATA));
+#endif
+}
+
+static void inline do_spi_clk_delay(int bit) {
+	unsigned bval = spi_clk_low | (bit & 1);
+	ndelay(spi_hclk_delay);
+	SPI_REG(SPI_IO_CTRL) = bval;
+	ndelay(spi_hclk_delay);
+	SPI_REG(SPI_IO_CTRL) = bval | SBIT_CLK;
+}
+
+static void do_spi_byte_delay(uint8_t byte) {
+	do_spi_clk_delay(byte >> 7);
+	do_spi_clk_delay(byte >> 6);
+	do_spi_clk_delay(byte >> 5);
+	do_spi_clk_delay(byte >> 4);
+	do_spi_clk_delay(byte >> 3);
+	do_spi_clk_delay(byte >> 2);
+	do_spi_clk_delay(byte >> 1);
+	do_spi_clk_delay(byte);
+#if RB400_DEBUG
+	printk("spi_byte_delay sent 0x%x got 0x%x\n",
+	       (unsigned)byte,
+	       SPI_REG(SPI_RDATA));
+#endif
+}
+
+static void inline do_spi_clk_fast(int bit1, int bit2) {
+	unsigned bval = (spi_clk_low |
+			 ((bit1 << SBIT_DO_SHIFT) & SBIT_DO) |
+			 ((bit2 << SBIT_DO2_SHIFT) & SBIT_DO2));
+	CLK_HALF_DELAY();
+	SPI_REG(SPI_IO_CTRL) = bval;
+	CLK_HALF_DELAY();
+	SPI_REG(SPI_IO_CTRL) = bval | SBIT_CLK;
+}
+
+static void do_spi_byte_fast(uint8_t byte) {
+	do_spi_clk_fast(byte >> 7, byte >> 6);
+	do_spi_clk_fast(byte >> 5, byte >> 4);
+	do_spi_clk_fast(byte >> 3, byte >> 2);
+	do_spi_clk_fast(byte >> 1, byte >> 0);
+#if RB400_DEBUG
+	printk("spi_byte_fast sent 0x%x got 0x%x\n",
+	       (unsigned)byte,
+	       SPI_REG(SPI_RDATA));
+#endif
+}
+
+static int rb400_spi_txrx(struct spi_transfer *t)
+{
+	const unsigned char *rxv_ptr = NULL;
+	const unsigned char *tx_ptr = t->tx_buf;
+	unsigned char *rx_ptr = t->rx_buf;
+	unsigned i;
+
+#if RB400_DEBUG
+	printk("spi_txrx len %u tx %u rx %u\n",
+	       t->len,
+	       (t->tx_buf ? 1 : 0),
+	       (t->rx_buf ? 1 : 0));
+#endif
+	if (t->verify) {
+		rxv_ptr = tx_ptr;
+		tx_ptr = NULL;
+	}
+
+	for (i = 0; i < t->len; ++i) {
+		unsigned char sdata = tx_ptr ? tx_ptr[i] : 0;
+		if (t->fast_write)
+			do_spi_byte_fast(sdata);
+		else if (unlikely(spi_hclk_delay))
+			do_spi_byte_delay(sdata);
+		else
+			do_spi_byte(sdata);
+		if (rx_ptr) {
+			rx_ptr[i] = SPI_REG(SPI_RDATA) & 0xff;
+		}
+		else if (rxv_ptr) {
+			if (rxv_ptr[i] != (unsigned char)SPI_REG(SPI_RDATA)) {
+				return i;
+			}
+		}
+	}
+	return i;
+}
+
+static int rb400_spi_read_fast(struct rb400_spi *rbspi,
+			       struct spi_message *m) {
+	struct spi_transfer *t;
+	const unsigned char *tx_ptr;
+	unsigned addr;
+
+	/* check for exactly two transfers */
+	if (list_empty(&m->transfers) ||
+	    list_is_last(m->transfers.next, &m->transfers) ||
+	    !list_is_last(m->transfers.next->next, &m->transfers)) {
+		return -1;
+	}
+
+	/* first transfer contains command and address  */
+	t = list_entry(m->transfers.next,
+		       struct spi_transfer, transfer_list);
+	if (t->len != 5 || t->tx_buf == NULL) {
+		return -1;
+	}
+	tx_ptr = t->tx_buf;
+	if (tx_ptr[0] != SPI_CMD_READ_FAST) {
+		return -1;
+	}
+	addr = tx_ptr[1];
+	addr = tx_ptr[2] | (addr << 8);
+	addr = tx_ptr[3] | (addr << 8);
+	addr += (unsigned) spi_base;
+
+	m->actual_length += t->len;
+
+	/* second transfer contains data itself */
+	t = list_entry(m->transfers.next->next,
+		       struct spi_transfer, transfer_list);
+
+	if (t->tx_buf && !t->verify) {
+		return -1;
+	}
+
+	SPI_REG(SPI_FUNC) = SBIT_FUNC_GPIO;
+	SPI_REG(SPI_CTRL) = rbspi->spi_ctrl_fread;
+	SPI_REG(SPI_FUNC) = 0;
+
+	if (t->rx_buf) {
+		memcpy(t->rx_buf, (const void *)addr, t->len);
+	}
+	else if (t->tx_buf) {
+		unsigned char buf[t->len];
+		memcpy(buf, (const void *)addr, t->len);
+		if (memcmp(t->tx_buf, buf, t->len) != 0) {
+			m->status = -EMSGSIZE;
+		}
+	}
+	m->actual_length += t->len;
+
+	if (rbspi->spi_ctrl_flash != rbspi->spi_ctrl_fread) {
+		SPI_REG(SPI_FUNC) = SBIT_FUNC_GPIO;
+		SPI_REG(SPI_CTRL) = rbspi->spi_ctrl_flash;
+		SPI_REG(SPI_FUNC) = 0;
+	}
+	
+	return 0;
+}
+
+static int rb400_spi_msg(struct rb400_spi *rbspi,
+			 struct spi_message *m) {
+	struct spi_transfer *t = NULL;
+
+	m->status = 0;
+	if (list_empty(&m->transfers))
+		return -1;
+	if (m->fast_read) {
+		if (rb400_spi_read_fast(rbspi, m) == 0)
+			return -1;
+	}
+
+	SPI_REG(SPI_FUNC) = SBIT_FUNC_GPIO;
+	SPI_REG(SPI_CTRL) = SPI_CTRL_FASTEST;
+	do_spi_init(m->spi);
+
+	list_for_each_entry (t, &m->transfers, transfer_list) {
+		int len = rb400_spi_txrx(t);
+		if (len != t->len) {
+			m->status = -EMSGSIZE;
+			break;
+		}
+		m->actual_length += len;
+
+		if (t->cs_change) {
+			if (list_is_last(&t->transfer_list, &m->transfers)) {
+				/* wait for continuation */
+				return m->spi->chip_select;
+			}
+			do_spi_finish();
+			ndelay(100);
+		}
+	}
+
+	do_spi_finish();
+	SPI_REG(SPI_CTRL) = rbspi->spi_ctrl_flash;
+	SPI_REG(SPI_FUNC) = 0;
+	return -1;
+}
+
+static void rb400_spi_process_queue_locked(struct rb400_spi *rbspi,
+					   unsigned long *flags) {
+	int cs = rbspi->cs_wait;
+	rbspi->busy = 1;
+	while (!list_empty(&rbspi->queue)) {
+		struct spi_message *m;
+		list_for_each_entry(m, &rbspi->queue, queue) {
+			if (cs < 0 || cs == m->spi->chip_select) break;
+		}
+		if (&m->queue == &rbspi->queue) break;
+
+		list_del_init(&m->queue);
+		spin_unlock_irqrestore(&rbspi->lock, *flags);
+
+		cs = rb400_spi_msg(rbspi, m);
+		rbspi->req_till_schedule -= m->actual_length;
+		m->complete(m->context);
+
+		spin_lock_irqsave(&rbspi->lock, *flags);
+	}
+	rbspi->cs_wait = cs;
+	rbspi->busy = 0;
+	if (cs >= 0) {
+		// TODO: add timer to unlock cs after 1s inactivity
+	}
+}
+
+static int rb400_spi_transfer(struct spi_device *spi,
+			      struct spi_message *m) {
+	struct rb400_spi *rbspi = spi_master_get_devdata(spi->master);
+	unsigned long flags;
+
+	m->actual_length = 0;
+	m->status = -EINPROGRESS;
+
+	spin_lock_irqsave(&rbspi->lock, flags);
+	if (m->spi->chip_select == 2 && rbspi->cs_wait == -1) {
+		if (rbspi->cur_jiffies != jiffies) {
+			rbspi->cur_jiffies = jiffies;
+			rbspi->req_till_schedule = 3000;
+		}
+		else if (rbspi->req_till_schedule < 0 && !in_interrupt()) {
+			rbspi->req_till_schedule = (1 << 30);
+			spin_unlock_irqrestore(&rbspi->lock, flags);
+			schedule();
+			spin_lock_irqsave(&rbspi->lock, flags);
+		}
+	}
+	list_add_tail(&m->queue, &rbspi->queue);
+	if (rbspi->busy ||
+	    (rbspi->cs_wait >= 0 && rbspi->cs_wait != m->spi->chip_select)) {
+		/* job will be done later */
+		spin_unlock_irqrestore(&rbspi->lock, flags);
+		return 0;
+	}
+
+	/* process job in current context */
+	rb400_spi_process_queue_locked(rbspi, &flags);
+	spin_unlock_irqrestore(&rbspi->lock, flags);
+
+	return 0;
+}
+
+static int rb400_spi_setup(struct spi_device *spi)
+{
+	struct rb400_spi *rbspi = spi_master_get_devdata(spi->master);
+	unsigned long flags;
+
+	if (spi->mode & ~(SPI_CS_HIGH)) {
+		printk("RB400 SPI: mode %x not supported\n",
+		       (unsigned)spi->mode);
+		return -EINVAL;
+	}
+	if (spi->bits_per_word != 8 && spi->bits_per_word != 0) {
+		printk("RB400 SPI: bits_per_word %u not supported\n",
+		       (unsigned)spi->bits_per_word);
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&rbspi->lock, flags);
+	if (rbspi->cs_wait == spi->chip_select && !rbspi->busy) {
+		rbspi->cs_wait = -1;
+		rb400_spi_process_queue_locked(rbspi, &flags);
+	}
+	spin_unlock_irqrestore(&rbspi->lock, flags);
+	return 0;
+}
+
+static unsigned get_spi_ctrl(unsigned hz_max, const char *name) {
+	void __iomem *pll_config = ioremap(REG_PLL_CONFIG, PAGE_SIZE);
+	unsigned ahb_div = ((rb400_readl((unsigned) pll_config) >> 20) & 0x7)
+	    + 1;
+	unsigned ahb_clock = (mips_hpt_frequency  + ahb_div - 1) / ahb_div;
+	unsigned div = (ahb_clock - 1) / (2 * hz_max);
+	if (div == 0) {
+		// CPU has a bug at (div == 0) - first bit read is random
+		++div;
+	}
+	if (name) {
+		unsigned ahb_khz = (ahb_clock + 500) / 1000;
+		unsigned div_real = 2 * (div + 1);
+		printk(KERN_INFO "%s SPI clock %u kHz (AHB %u kHz / %u)\n",
+		       name,
+		       ahb_khz / div_real,
+		       ahb_khz, div_real);
+	}
+	iounmap(pll_config);
+	return SPI_CTRL_FASTEST + div;
+}
+
+static void rb400_spi_add_devices(struct spi_master *master, const void *data) {
+	struct spi_board_info **info;
+	for (info = (struct spi_board_info **)data; *info != NULL; ++info) {
+		(void) spi_new_device(master, *info);
+	}
+}
+
+static int rb400_spi_probe(struct platform_device *pdev)
+{
+	struct spi_master *master;
+	struct rb400_spi *rbspi;
+	int err = 0;
+
+	master = spi_alloc_master(&pdev->dev, sizeof(*rbspi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+	master->bus_num = 0;
+	master->num_chipselect = 4;
+	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;
+	master->setup    = rb400_spi_setup;
+	master->transfer = rb400_spi_transfer;
+
+	rbspi = spi_master_get_devdata(master);
+	memset(rbspi, 0, sizeof(*rbspi));
+	rbspi->spi_ctrl_flash = get_spi_ctrl(SPI_FLASH_HZ, "FLASH");
+	rbspi->spi_ctrl_fread = get_spi_ctrl(SPI_CPLD_HZ, "CPLD");
+	rbspi->cs_wait = -1;
+
+	spin_lock_init(&rbspi->lock);
+	INIT_LIST_HEAD(&rbspi->queue);
+
+	err = spi_register_master(master);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to register SPI master\n");
+		goto err_register;
+	}
+	rb400_spi_add_devices(master, pdev->dev.platform_data);
+	return 0;
+
+err_register:
+	spi_master_put(master);;
+err_nomem:
+	return err;
+}
+
+static struct platform_driver rb400_spi_drv = {
+	.probe		= rb400_spi_probe,
+        .driver		= {
+		.name	= "rb400-spi",
+		.owner	= THIS_MODULE,
+        },
+};
+
+static int __init rb400_spi_init(void)
+{
+	spi_base = ioremap(SPI_BASE, 0x01000000);
+	if (!spi_base)
+		return -ENOMEM;
+
+        return platform_driver_register(&rb400_spi_drv);
+}
+
+static void __exit rb400_spi_exit(void)
+{
+        platform_driver_unregister(&rb400_spi_drv);
+	iounmap(spi_base);
+}
+
+module_init(rb400_spi_init);
+module_exit(rb400_spi_exit);
diff -puNrb linux-2.6.35/drivers/spi/spi_rb_ppc.c linux/drivers/spi/spi_rb_ppc.c
--- linux-2.6.35/drivers/spi/spi_rb_ppc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/spi/spi_rb_ppc.c	2011-05-02 10:08:27.611544702 +0300
@@ -0,0 +1,321 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/of.h>
+#include <asm/rb_aux.h>
+#include <asm/io.h>
+
+#include <linux/spi/spi.h>
+
+#define RB_PPC_DEBUG 0
+#define USE_SPINLOCK 0
+
+#if USE_SPINLOCK
+#define INIT_LOCK(lock)			spin_lock_init(lock);
+/* WARNING: disabling of interrupts makes watchdog to reboot RB on big tasks */
+#define LOCK_AND_SAVE(lock,flags)	spin_lock_irqsave(lock,flags)
+#define UNLOCK_AND_RESTORE(lock,flags)	spin_unlock_irqrestore(lock,flags)
+#else
+#define INIT_LOCK(lock)			do {} while (0)
+#define LOCK_AND_SAVE(lock,flags)	do {} while (0)
+#define UNLOCK_AND_RESTORE(lock,flags)	do {} while (0)
+#endif
+
+
+struct rb_ppc_spi {
+#if USE_SPINLOCK
+	spinlock_t		lock;
+#endif
+	struct list_head	queue;
+	union {
+		void *		baddr;
+	};
+	void (*set_cs)(struct spi_device *spi, int on);
+	int (*txrx)(struct rb_ppc_spi *rbspi, struct spi_transfer *t);
+	int			cs_wait;
+	int			busy:1;
+};
+
+static void set_cs(struct spi_device *spi, int on) {
+	int bit = (int) spi->controller_data;
+	if (spi->mode & SPI_CS_HIGH) on = !on;
+	if (on) {
+		change_latch(bit, 0);
+	}
+	else {
+		change_latch(0, bit);
+	}
+}
+
+static uint8_t get_spi_byte(struct rb_ppc_spi *rbspi) {
+	return in_8(rbspi->baddr);
+}
+
+static void do_spi_byte(struct rb_ppc_spi *rbspi, uint8_t byte) {
+	out_8(rbspi->baddr, byte);
+#if RB_PPC_DEBUG
+	printk("spi_byte sent 0x%x got 0x%x\n",
+	       (unsigned)byte,
+	       (unsigned)get_spi_byte(rbspi));
+#endif
+}
+
+static int rb_ppc_spi_txrx(struct rb_ppc_spi *rbspi, struct spi_transfer *t)
+{
+	const unsigned char *rxv_ptr = NULL;
+	const unsigned char *tx_ptr = t->tx_buf;
+	unsigned char *rx_ptr = t->rx_buf;
+	unsigned i;
+
+#if RB_PPC_DEBUG
+	printk("spi_txrx len %u tx %u rx %u\n",
+	       t->len,
+	       (t->tx_buf ? 1 : 0),
+	       (t->rx_buf ? 1 : 0));
+#endif
+	if (t->verify) {
+		rxv_ptr = tx_ptr;
+		tx_ptr = NULL;
+	}
+
+	for (i = 0; i < t->len; ++i) {
+		unsigned char sdata = tx_ptr ? tx_ptr[i] : 0;
+		do_spi_byte(rbspi, sdata);
+		if (rx_ptr) {
+			rx_ptr[i] = get_spi_byte(rbspi);
+		}
+		else if (rxv_ptr) {
+			if (rxv_ptr[i] != get_spi_byte(rbspi)) {
+				return i;
+			}
+		}
+	}
+	return i;
+}
+
+static void mpc8544_spi_init(struct rb_ppc_spi *rbspi)
+{
+	rbspi->set_cs = &set_cs;
+	rbspi->txrx = &rb_ppc_spi_txrx;
+}
+
+static int rb_ppc_spi_msg(struct rb_ppc_spi *rbspi,
+			 struct spi_message *m) {
+	struct spi_transfer *t = NULL;
+
+	m->status = 0;
+	if (list_empty(&m->transfers))
+		return -1;
+
+	(rbspi->set_cs)(m->spi, 0);
+
+	list_for_each_entry (t, &m->transfers, transfer_list) {
+		int len = (rbspi->txrx)(rbspi, t);
+		if (len != t->len) {
+			m->status = -EMSGSIZE;
+			break;
+		}
+		m->actual_length += len;
+
+		if (t->cs_change) {
+			if (list_is_last(&t->transfer_list, &m->transfers)) {
+				/* wait for continuation */
+#if RB_PPC_DEBUG
+				printk("cs %d cont\n", m->spi->chip_select);
+#endif
+				return m->spi->chip_select;
+			}
+			(rbspi->set_cs)(m->spi, 1);
+			ndelay(100);
+			(rbspi->set_cs)(m->spi, 0);	// TODO: optimize
+		}
+	}
+
+	(rbspi->set_cs)(m->spi, 1);
+	return -1;
+}
+
+static void rb_ppc_spi_process_queue_locked(struct rb_ppc_spi *rbspi,
+					   unsigned long *flags) {
+	int cs = rbspi->cs_wait;
+	rbspi->busy = 1;
+	while (!list_empty(&rbspi->queue)) {
+		struct spi_message *m;
+		list_for_each_entry(m, &rbspi->queue, queue) {
+			if (cs < 0 || cs == m->spi->chip_select) break;
+		}
+		if (&m->queue == &rbspi->queue) break;
+
+		list_del_init(&m->queue);
+		UNLOCK_AND_RESTORE(&rbspi->lock, *flags);
+
+		cs = rb_ppc_spi_msg(rbspi, m);
+		m->complete(m->context);
+
+		LOCK_AND_SAVE(&rbspi->lock, *flags);
+	}
+	rbspi->cs_wait = cs;
+	rbspi->busy = 0;
+	if (cs >= 0) {
+		// TODO: add timer to unlock cs after 1s inactivity
+	}
+}
+
+static int rb_ppc_spi_transfer(struct spi_device *spi,
+			      struct spi_message *m) {
+	struct rb_ppc_spi *rbspi = spi_master_get_devdata(spi->master);
+	unsigned long flags;
+
+	m->actual_length = 0;
+	m->status = -EINPROGRESS;
+
+	LOCK_AND_SAVE(&rbspi->lock, flags);
+	list_add_tail(&m->queue, &rbspi->queue);
+	if (rbspi->busy ||
+	    (rbspi->cs_wait >= 0 && rbspi->cs_wait != m->spi->chip_select)) {
+		/* job will be done later */
+		UNLOCK_AND_RESTORE(&rbspi->lock, flags);
+		return 0;
+	}
+
+	/* process job in current context */
+	rb_ppc_spi_process_queue_locked(rbspi, &flags);
+	UNLOCK_AND_RESTORE(&rbspi->lock, flags);
+	return 0;
+}
+
+static int rb_ppc_spi_setup(struct spi_device *spi)
+{
+	struct rb_ppc_spi *rbspi = spi_master_get_devdata(spi->master);
+	unsigned long flags;
+
+	if ((spi->mode & ~SPI_CS_HIGH) != 3) {
+		printk("RB_PPC SPI: mode %x not supported\n",
+		       (unsigned)spi->mode);
+		return -EINVAL;
+	}
+	if (spi->bits_per_word != 8 && spi->bits_per_word != 0) {
+		printk("RB_PPC SPI: bits_per_word %u not supported\n",
+		       (unsigned)spi->bits_per_word);
+		return -EINVAL;
+	}
+
+	LOCK_AND_SAVE(&rbspi->lock, flags);
+	(rbspi->set_cs)(spi, 1);
+	if (rbspi->cs_wait == spi->chip_select && !rbspi->busy) {
+		rbspi->cs_wait = -1;
+		rb_ppc_spi_process_queue_locked(rbspi, &flags);
+	}
+	UNLOCK_AND_RESTORE(&rbspi->lock, flags);
+	return 0;
+}
+
+static int rb_ppc_spi_probe(struct of_device *pdev,
+			    const struct of_device_id *match)
+{
+	struct spi_master *master;
+	struct rb_ppc_spi *rbspi;
+	struct resource res;
+	struct spi_board_info spi_microsd = {
+		.modalias = "mmc_spi",
+		.max_speed_hz = 10 * 1000 * 1000,
+		.bus_num = 0,
+		.chip_select = 0,
+		.mode = SPI_MODE_3,
+	};
+	const unsigned *ss;
+	int sslen = 0;
+	int i;
+	int err = 0;
+
+
+	printk("RB_PPC SPI\n");
+
+	if (of_address_to_resource(pdev->dev.of_node, 0, &res)) {
+		dev_err(&pdev->dev, "no reg property for SPI master\n");
+		err = -ENODEV;
+		goto err_nomem;
+	}
+	ss = of_get_property(pdev->dev.of_node, "slave_select", &sslen);
+	sslen /= 4;
+	if (sslen < 2) {
+		dev_err(&pdev->dev,
+			"missing slave_select property for SPI master\n");
+		err = -ENODEV;
+		goto err_nomem;
+	}
+	master = spi_alloc_master(&pdev->dev, sizeof(*rbspi));
+	if (master == NULL) {
+		dev_err(&pdev->dev, "No memory for spi_master\n");
+		err = -ENOMEM;
+		goto err_nomem;
+	}
+	master->bus_num = 0;
+	master->num_chipselect = sslen - 1;
+	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;
+	master->setup    = rb_ppc_spi_setup;
+	master->transfer = rb_ppc_spi_transfer;
+
+	rbspi = spi_master_get_devdata(master);
+	memset(rbspi, 0, sizeof(*rbspi));
+	rbspi->cs_wait = -1;
+	rbspi->baddr = ioremap_nocache(res.start, res.end - res.start + 1);
+
+	INIT_LOCK(&rbspi->lock);
+	INIT_LIST_HEAD(&rbspi->queue);
+
+	if (ss[0] == 0x600) {
+	}
+	else {
+		mpc8544_spi_init(rbspi);
+	}
+
+	err = spi_register_master(master);
+	if (err) {
+		dev_err(&pdev->dev, "Failed to register SPI master\n");
+		goto err_register;
+	}
+	for (i = 1; i < sslen; ++i) {
+		spi_microsd.chip_select = i - 1;
+		spi_microsd.controller_data = (void *)(1 << ss[i]);
+		spi_new_device(master, &spi_microsd);
+	}
+	return 0;
+
+err_register:
+	spi_master_put(master);
+err_nomem:
+	return err;
+}
+
+static struct of_device_id rb_ppc_spi_ids[] = {
+	{ .name = "spi" },
+	{}
+};
+
+static struct of_platform_driver rb_ppc_spi_driver = {
+	.driver	= {
+		.name = "rbppc-spi",
+		.owner = THIS_MODULE,
+		.of_match_table = rb_ppc_spi_ids,
+	},
+	.probe	= rb_ppc_spi_probe,
+};
+
+static int __init rb_ppc_spi_init(void)
+{
+	of_register_platform_driver(&rb_ppc_spi_driver);
+	return 0;
+}
+
+static void __exit rb_ppc_spi_exit(void)
+{
+	of_unregister_platform_driver(&rb_ppc_spi_driver);
+}
+
+module_init(rb_ppc_spi_init);
+module_exit(rb_ppc_spi_exit);
diff -puNrb linux-2.6.35/drivers/usb/core/message.c linux/drivers/usb/core/message.c
--- linux-2.6.35/drivers/usb/core/message.c	2011-04-26 16:28:23.022169653 +0300
+++ linux/drivers/usb/core/message.c	2011-05-02 10:08:27.621544801 +0300
@@ -1510,6 +1510,10 @@ static int usb_if_uevent(struct device *
 		   alt->desc.bInterfaceProtocol))
 		return -ENOMEM;
 
+	if (add_uevent_var(env, "IFNUM=%d",
+		   alt->desc.bInterfaceNumber))
+		return -ENOMEM;
+
 	if (add_uevent_var(env,
 		   "MODALIAS=usb:"
 		   "v%04Xp%04Xd%04Xdc%02Xdsc%02Xdp%02Xic%02Xisc%02Xip%02X",
diff -puNrb linux-2.6.35/drivers/usb/core/quirks.c linux/drivers/usb/core/quirks.c
--- linux-2.6.35/drivers/usb/core/quirks.c	2011-04-26 16:28:23.022169653 +0300
+++ linux/drivers/usb/core/quirks.c	2011-05-02 10:08:27.641587502 +0300
@@ -45,6 +45,10 @@ static const struct usb_device_id usb_qu
 	{ USB_DEVICE(0x04b4, 0x0526), .driver_info =
 			USB_QUIRK_CONFIG_INTF_STRINGS },
 
+	/* Koncept FC686 barcode reader(v36a) */
+	{ USB_DEVICE(0x04b4, 0x0100), .driver_info =
+			USB_QUIRK_CONFIG_INTF_STRINGS },
+
 	/* Roland SC-8820 */
 	{ USB_DEVICE(0x0582, 0x0007), .driver_info = USB_QUIRK_RESET_RESUME },
 
diff -puNrb linux-2.6.35/drivers/usb/host/ehci-hcd.c linux/drivers/usb/host/ehci-hcd.c
--- linux-2.6.35/drivers/usb/host/ehci-hcd.c	2011-04-26 16:28:25.432477693 +0300
+++ linux/drivers/usb/host/ehci-hcd.c	2011-05-02 10:08:27.651544798 +0300
@@ -1128,6 +1128,11 @@ MODULE_LICENSE ("GPL");
 #define	PS3_SYSTEM_BUS_DRIVER	ps3_ehci_driver
 #endif
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#include "ehci-rb400.c"
+#define PLATFORM_DRIVER		ehci_rb400_driver
+#endif
+
 #ifdef CONFIG_USB_EHCI_HCD_PPC_OF
 #include "ehci-ppc-of.c"
 #define OF_PLATFORM_DRIVER	ehci_hcd_ppc_of_driver
diff -puNrb linux-2.6.35/drivers/usb/host/ehci-q.c linux/drivers/usb/host/ehci-q.c
--- linux-2.6.35/drivers/usb/host/ehci-q.c	2011-04-26 16:28:25.452477501 +0300
+++ linux/drivers/usb/host/ehci-q.c	2011-05-02 10:08:27.661544630 +0300
@@ -42,6 +42,10 @@
 
 /* fill a qtd, returning how much of the buffer we were able to queue up */
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#include <asm/rb/boards.h>
+#endif
+
 static int
 qtd_fill(struct ehci_hcd *ehci, struct ehci_qtd *qtd, dma_addr_t buf,
 		  size_t len, int token, int maxpacket)
@@ -1194,6 +1198,17 @@ static void end_unlink_async (struct ehc
 		ehci->reclaim = NULL;
 		start_unlink_async (ehci, next);
 	}
+
+#ifdef CONFIG_MIPS_MIKROTIK
+	/* Fix for Synopsys HC bug: When software uses the Doorbell mechanism
+	 * to remove queue heads, the HC still has references to the removed
+	 * queue head even after indicating an IAA.
+	 * NOTE: helps AR7100 as well
+	 */
+	if (mips_machgroup == MACH_GROUP_MT_RB400) {
+		writel((u32)ehci->async->qh_dma, &ehci->regs->async_next);
+	}
+#endif
 }
 
 /* makes sure the async qh will become idle */
diff -puNrb linux-2.6.35/drivers/usb/host/ehci-rb400.c linux/drivers/usb/host/ehci-rb400.c
--- linux-2.6.35/drivers/usb/host/ehci-rb400.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/usb/host/ehci-rb400.c	2011-05-02 10:08:27.681587731 +0300
@@ -0,0 +1,178 @@
+#include <linux/platform_device.h>
+#include <asm/rb/boards.h>
+#include <asm/rb/rb400.h>
+
+#define AR724x_RESET			0x1806001c
+
+#define AR724x_RST_USBSUS_OVRIDE	(1 << 3)
+#define AR724x_RST_USB_HOST		(1 << 5)
+#define AR724x_RST_USB_PHY		(1 << 4)
+
+static void modreg(unsigned addr, unsigned set, unsigned clear) {
+	rb400_writel((rb400_readl(addr) & ~clear) | set, addr);
+}
+
+static int is700(void) {
+	return mips_machgroup == MACH_GROUP_MT_RB700;
+}
+
+static int usb_ehci_rb400_reset(struct usb_hcd *hcd)
+{
+	struct ehci_hcd *ehci = hcd_to_ehci(hcd);
+	unsigned offset = is700() ? 0x100 : 0;
+	int retval;
+
+	ehci->caps = hcd->regs + offset;
+	ehci->regs = hcd->regs + offset 
+		+ HC_LENGTH(ehci_readl(ehci, &ehci->caps->hc_capbase));
+	ehci->hcs_params = ehci_readl(ehci, &ehci->caps->hcs_params);
+
+	if (!is700()) {
+		retval = ehci_halt(ehci);
+		if (retval)
+			return retval;
+	}
+	
+	retval = ehci_init(hcd);
+	if (retval)
+		return retval;
+	
+	if (is700()) {
+		hcd->has_tt = 1;
+	}
+
+	ehci->sbrn = 0x20;
+	return ehci_reset(ehci);
+}
+
+static int usb_ehci_rb400_probe(const struct hc_driver *driver, 
+				struct platform_device *pdev)
+{
+	struct usb_hcd *hcd;
+	struct resource *res;
+	int irq;
+	int retval = -ENOMEM;
+
+	if (is700() && is_ar7240()) {
+		return -ENODEV;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no IRQ\n");
+		return -ENODEV;
+	}
+	irq = res->start;
+
+	hcd = usb_create_hcd(driver, &pdev->dev, "rb400_usb");
+	if (!hcd)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no mem region\n");
+		goto err1;
+	}
+
+	hcd->rsrc_start = res->start;
+	hcd->rsrc_len = res->end - res->start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len,
+				driver->description)) {
+		dev_err(&pdev->dev, "memory already in use\n");
+		retval = -EBUSY;
+		goto err1;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		dev_err(&pdev->dev, "ioremap failed");
+		retval = -EFAULT;
+		goto err2;
+	}
+
+	if (is700()) {
+		unsigned ptr;
+		struct ehci_hcd *ehci = hcd_to_ehci(hcd);
+		ehci->caps = hcd->regs + 0x100;
+		ehci->regs = hcd->regs + 0x140;
+
+		ptr = (unsigned) ioremap_nocache(AR724x_RESET, 4);
+
+		modreg(ptr, AR724x_RST_USBSUS_OVRIDE, 0);
+		mdelay(10);
+
+		modreg(ptr, AR724x_RST_USBSUS_OVRIDE, AR724x_RST_USB_HOST);
+		mdelay(10);
+		
+		modreg(ptr, AR724x_RST_USBSUS_OVRIDE, AR724x_RST_USB_PHY);
+		mdelay(10);
+
+		iounmap((void *) ptr);
+
+	}
+
+	retval = usb_add_hcd(hcd, irq, IRQF_SHARED);
+	if (retval != 0)
+		goto err3;
+	return 0;
+
+  err3:
+	iounmap(hcd->regs);
+  err2:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+  err1:
+	usb_put_hcd(hcd);
+	return retval;
+}
+
+
+void usb_ehci_rb400_remove(struct usb_hcd *hcd, struct platform_device *dev)
+{
+	usb_remove_hcd(hcd);
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+static const struct hc_driver ehci_rb400_hc_driver = {
+	.description		= hcd_name,
+	.product_desc		= "RB400 EHCI",
+	.hcd_priv_size		= sizeof(struct ehci_hcd),
+	.irq			= ehci_irq,
+	.flags			= HCD_MEMORY | HCD_USB2,
+	.reset			= usb_ehci_rb400_reset,
+	.start			= ehci_run,
+	.stop			= ehci_stop,
+	.shutdown		= ehci_shutdown,	    
+	.urb_enqueue		= ehci_urb_enqueue,
+	.urb_dequeue		= ehci_urb_dequeue,
+	.endpoint_disable	= ehci_endpoint_disable,
+	.get_frame_number	= ehci_get_frame,
+	.hub_status_data	= ehci_hub_status_data,
+	.hub_control		= ehci_hub_control,
+};
+
+static int ehci_rb400_drv_probe(struct platform_device *pdev)
+{
+	if (usb_disabled())
+		return -ENODEV;
+
+	return usb_ehci_rb400_probe(&ehci_rb400_hc_driver, pdev);
+}
+
+static int ehci_rb400_drv_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_ehci_rb400_remove(hcd, pdev);
+	return 0;
+}
+
+static struct platform_driver ehci_rb400_driver = {
+	.probe	=  ehci_rb400_drv_probe,
+	.remove	=  ehci_rb400_drv_remove,
+	.driver	= {
+		.name = "rb400-ehci"
+	},
+};
diff -puNrb linux-2.6.35/drivers/usb/host/ohci-hcd.c linux/drivers/usb/host/ohci-hcd.c
--- linux-2.6.35/drivers/usb/host/ohci-hcd.c	2011-04-26 16:28:25.452477501 +0300
+++ linux/drivers/usb/host/ohci-hcd.c	2011-05-02 10:08:27.691544800 +0300
@@ -1080,6 +1080,11 @@ MODULE_LICENSE ("GPL");
 #define PS3_SYSTEM_BUS_DRIVER	ps3_ohci_driver
 #endif
 
+#ifdef CONFIG_MIPS_MIKROTIK
+#include "ohci-rb400.c"
+#define PLATFORM_DRIVER		ohci_hcd_rb400_driver
+#endif
+
 #ifdef CONFIG_USB_OHCI_HCD_SSB
 #include "ohci-ssb.c"
 #define SSB_OHCI_DRIVER		ssb_ohci_driver
diff -puNrb linux-2.6.35/drivers/usb/host/ohci-rb400.c linux/drivers/usb/host/ohci-rb400.c
--- linux-2.6.35/drivers/usb/host/ohci-rb400.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/drivers/usb/host/ohci-rb400.c	2011-05-02 10:08:27.701589780 +0300
@@ -0,0 +1,133 @@
+#include <linux/platform_device.h>
+#include <asm/rb/boards.h>
+#include <asm/rb/rb400.h>
+
+static int usb_hcd_rb400_probe(const struct hc_driver *driver,
+			       struct platform_device *pdev)
+{
+	struct resource *res;
+	struct usb_hcd *hcd;
+	int irq;
+	int retval;
+
+	if (mips_machgroup == MACH_GROUP_MT_RB700 && !is_ar7240()) {
+		return -ENODEV;
+	}
+	
+	res = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no IRQ\n");
+		return -ENODEV;
+	}
+	irq = res->start;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no mem region\n");
+		return -ENODEV;
+	}
+
+	hcd = usb_create_hcd(driver, &pdev->dev, "rb400_usb");
+	if (!hcd)
+		return -ENOMEM;
+
+	hcd->rsrc_start = res->start;
+	hcd->rsrc_len = res->end - res->start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len,
+				driver->description)) {
+		dev_err(&pdev->dev, "memory already in use\n");
+		retval = -EBUSY;
+		goto err1;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		dev_err(&pdev->dev, "ioremap failed");
+		retval = -EFAULT;
+		goto err2;
+	}
+
+	ohci_hcd_init(hcd_to_ohci(hcd));
+
+	retval = usb_add_hcd(hcd, irq, IRQF_SHARED);
+	if (retval == 0)
+		return 0;
+
+	iounmap(hcd->regs);
+ err2:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+ err1:
+	usb_put_hcd(hcd);
+	return retval;
+}
+
+
+void usb_hcd_rb400_remove(struct usb_hcd *hcd, struct platform_device *dev)
+{
+	usb_remove_hcd(hcd);
+	iounmap(hcd->regs);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+	usb_put_hcd(hcd);
+}
+
+
+static int ohci_rb400_start(struct usb_hcd *hcd)
+{
+	struct ohci_hcd	*ohci = hcd_to_ohci(hcd);
+	int ret;
+
+	ret = ohci_init(ohci);
+	if (ret < 0)
+		return ret;
+
+	ret = ohci_run(ohci);
+	if (ret < 0) {
+		ohci_stop (hcd);
+		return ret;
+	}
+	return 0;
+}
+
+static const struct hc_driver ohci_rb400_hc_driver = {
+	.description        = hcd_name,
+	.product_desc       = "RB400 OHCI",
+	.hcd_priv_size      = sizeof(struct ohci_hcd),
+	.irq                = ohci_irq,
+	.flags              = HCD_USB11 | HCD_MEMORY,
+	.start              = ohci_rb400_start,
+	.stop               = ohci_stop,
+	.shutdown	    = ohci_shutdown,
+	.urb_enqueue        = ohci_urb_enqueue,
+	.urb_dequeue        = ohci_urb_dequeue,
+	.endpoint_disable   = ohci_endpoint_disable,
+	.get_frame_number   = ohci_get_frame,
+	.hub_status_data    = ohci_hub_status_data,
+	.hub_control        = ohci_hub_control,
+	.start_port_reset   = ohci_start_port_reset,
+};
+
+static int ohci_hcd_rb400_drv_probe(struct platform_device *pdev)
+{
+	if (usb_disabled())
+		return -ENODEV;
+
+	return usb_hcd_rb400_probe(&ohci_rb400_hc_driver, pdev);
+}
+
+static int ohci_hcd_rb400_drv_remove(struct platform_device *pdev)
+{
+	struct usb_hcd *hcd = platform_get_drvdata(pdev);
+
+	usb_hcd_rb400_remove(hcd, pdev);
+	return 0;
+}
+
+static struct platform_driver ohci_hcd_rb400_driver = {
+	.probe		= ohci_hcd_rb400_drv_probe,
+	.remove		= ohci_hcd_rb400_drv_remove,
+	.driver		= {
+		.name	= "rb400-ohci",
+		.owner	= THIS_MODULE,
+	},
+};
diff -puNrb linux-2.6.35/drivers/usb/serial/option.c linux/drivers/usb/serial/option.c
--- linux-2.6.35/drivers/usb/serial/option.c	2011-04-26 16:28:22.702477640 +0300
+++ linux/drivers/usb/serial/option.c	2011-05-02 10:08:27.721584260 +0300
@@ -386,6 +386,11 @@ static const struct option_blacklist_inf
 };
 
 static const struct usb_device_id option_ids[] = {
+        // cdma sprint modemi
+	{ USB_DEVICE(0x16d8, 0x6002) },
+	{ USB_DEVICE(0x16d8, 0x6008) },
+	{ USB_DEVICE_AND_INTERFACE_INFO(0x16d8, 0x6803, 0xff, 0xff, 0xff) },
+
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_COLT) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_RICOLA) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_RICOLA_LIGHT) },
@@ -410,7 +415,17 @@ static const struct usb_device_id option
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_ETNA_MODEM_GT) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_ETNA_MODEM_EX) },
 	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_ETNA_KOI_MODEM) },
-	{ USB_DEVICE(OPTION_VENDOR_ID, OPTION_PRODUCT_GTM380_MODEM) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6711) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6731) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6751) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6771) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6811) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x6911) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x7011) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x7031) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x7051) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x7071) },
+	{ USB_DEVICE(OPTION_VENDOR_ID, 0x7111) },
 	{ USB_DEVICE(QUANTA_VENDOR_ID, QUANTA_PRODUCT_Q101) },
 	{ USB_DEVICE(QUANTA_VENDOR_ID, QUANTA_PRODUCT_Q111) },
 	{ USB_DEVICE(QUANTA_VENDOR_ID, QUANTA_PRODUCT_GLX) },
diff -puNrb linux-2.6.35/drivers/usb/serial/qcserial.c linux/drivers/usb/serial/qcserial.c
--- linux-2.6.35/drivers/usb/serial/qcserial.c	2011-04-26 16:28:22.712505373 +0300
+++ linux/drivers/usb/serial/qcserial.c	2011-05-02 10:08:27.731605673 +0300
@@ -82,6 +82,9 @@ static const struct usb_device_id id_tab
 	{USB_DEVICE(0x16d8, 0x8002)},	/* CMDTech Gobi 2000 Modem device (VU922) */
 	{USB_DEVICE(0x05c6, 0x9204)},	/* Gobi 2000 QDL device */
 	{USB_DEVICE(0x05c6, 0x9205)},	/* Gobi 2000 Modem device */
+
+	{USB_DEVICE(0x0af0, 0x8109)},
+	{USB_DEVICE(0x0af0, 0x8110)},
 	{ }				/* Terminating entry */
 };
 MODULE_DEVICE_TABLE(usb, id_table);
@@ -150,7 +153,8 @@ static int qcprobe(struct usb_serial *se
 	case 3:
 	case 4:
 		/* Composite mode */
-		if (ifnum == 2) {
+                // interface 1 provides access to QCDM port [Mikrotik]
+		if (ifnum == 1 || ifnum == 2) {
 			dbg("Modem port found");
 			retval = usb_set_interface(serial->dev, ifnum, 0);
 			if (retval < 0) {
diff -puNrb linux-2.6.35/drivers/usb/serial/usb-serial.c linux/drivers/usb/serial/usb-serial.c
--- linux-2.6.35/drivers/usb/serial/usb-serial.c	2011-04-26 16:28:22.702477640 +0300
+++ linux/drivers/usb/serial/usb-serial.c	2011-05-02 10:08:27.751592019 +0300
@@ -913,6 +913,7 @@ int usb_serial_probe(struct usb_interfac
 		buffer_size = serial->type->bulk_in_size;
 		if (!buffer_size)
 			buffer_size = le16_to_cpu(endpoint->wMaxPacketSize);
+		if (type->max_buf_size) buffer_size = type->max_buf_size;
 		port->bulk_in_size = buffer_size;
 		port->bulk_in_endpointAddress = endpoint->bEndpointAddress;
 		port->bulk_in_buffer = kmalloc(buffer_size, GFP_KERNEL);
diff -puNrb linux-2.6.35/drivers/usb/serial/usb_wwan.c linux/drivers/usb/serial/usb_wwan.c
--- linux-2.6.35/drivers/usb/serial/usb_wwan.c	2011-04-26 16:28:22.702477640 +0300
+++ linux/drivers/usb/serial/usb_wwan.c	2011-05-02 10:08:27.761590572 +0300
@@ -1,17 +1,17 @@
 /*
   USB Driver layer for GSM modems
 
-  Copyright (C) 2005  Matthias Urlichs <smurf@smurf.noris.de>
+  Copyright (C) 2005  Matthias Urlichs <smurf@...>
 
   This driver is free software; you can redistribute it and/or modify
   it under the terms of Version 2 of the GNU General Public License as
   published by the Free Software Foundation.
 
-  Portions copied from the Keyspan driver by Hugh Blemings <hugh@blemings.org>
+  Portions copied from the Keyspan driver by Hugh Blemings <hugh@...>
 
   History: see the git log.
 
-  Work sponsored by: Sigos GmbH, Germany <info@sigos.de>
+  Work sponsored by: Sigos GmbH, Germany <info@...>
 
   This driver exists because the "normal" serial driver doesn't work too well
   with GSM modems. Issues:
@@ -20,19 +20,19 @@
 */
 
 #define DRIVER_VERSION "v0.7.2"
-#define DRIVER_AUTHOR "Matthias Urlichs <smurf@smurf.noris.de>"
+#define DRIVER_AUTHOR "Matthias Urlichs <smurf@...>"
 #define DRIVER_DESC "USB Driver for GSM modems"
 
 #include <linux/kernel.h>
 #include <linux/jiffies.h>
 #include <linux/errno.h>
-#include <linux/slab.h>
 #include <linux/tty.h>
 #include <linux/tty_flip.h>
 #include <linux/module.h>
 #include <linux/bitops.h>
 #include <linux/usb.h>
 #include <linux/usb/serial.h>
+#include <linux/slab.h>
 #include "usb-wwan.h"
 
 static int debug;
diff -puNrb linux-2.6.35/drivers/usb/storage/initializers.c linux/drivers/usb/storage/initializers.c
--- linux-2.6.35/drivers/usb/storage/initializers.c	2011-04-26 16:28:24.441857500 +0300
+++ linux/drivers/usb/storage/initializers.c	2011-05-02 10:08:27.771545216 +0300
@@ -102,5 +102,5 @@ int usb_stor_huawei_e220_init(struct us_
 				      USB_TYPE_STANDARD | USB_RECIP_DEVICE,
 				      0x01, 0x0, NULL, 0x0, 1000);
 	US_DEBUGP("Huawei mode set result is %d\n", result);
-	return 0;
+	return -1;
 }
diff -puNrb linux-2.6.35/drivers/usb/storage/scsiglue.c linux/drivers/usb/storage/scsiglue.c
--- linux-2.6.35/drivers/usb/storage/scsiglue.c	2011-04-26 16:28:24.451860298 +0300
+++ linux/drivers/usb/storage/scsiglue.c	2011-05-02 10:08:27.791585215 +0300
@@ -449,6 +449,9 @@ static int proc_info (struct Scsi_Host *
 	SPRINTF("     Protocol: %s\n", us->protocol_name);
 	SPRINTF("    Transport: %s\n", us->transport_name);
 
+	SPRINTF("     VendorID: %04x\n", us->pusb_dev->descriptor.idVendor);
+	SPRINTF("     ProductID: %04x\n", us->pusb_dev->descriptor.idProduct);
+
 	/* show the device flags */
 	if (pos < buffer + length) {
 		pos += sprintf(pos, "       Quirks:");
diff -puNrb linux-2.6.35/drivers/watchdog/booke_wdt.c linux/drivers/watchdog/booke_wdt.c
--- linux-2.6.35/drivers/watchdog/booke_wdt.c	2011-04-26 16:27:39.311605007 +0300
+++ linux/drivers/watchdog/booke_wdt.c	2011-05-02 10:08:27.801591610 +0300
@@ -34,7 +34,7 @@
  */
 
 #ifdef	CONFIG_FSL_BOOKE
-#define WDT_PERIOD_DEFAULT 38	/* Ex. wdt_period=28 bus=333Mhz,reset=~40sec */
+#define WDT_PERIOD_DEFAULT 35	/* hand picked value by tial and error */
 #else
 #define WDT_PERIOD_DEFAULT 3	/* Refer to the PPC40x and PPC4xx manuals */
 #endif				/* for timing information */
@@ -109,14 +109,43 @@ static void __booke_wdt_enable(void *dat
 	__booke_wdt_ping(NULL);
 	val = mfspr(SPRN_TCR);
 	val &= ~WDTP_MASK;
+#ifdef CONFIG_4xx
+	val |= (TCR_WIE|TCR_WRC(WRC_SYSTEM)|WDTP(booke_wdt_period));
+#else
 	val |= (TCR_WIE|TCR_WRC(WRC_CHIP)|WDTP(booke_wdt_period));
+#endif
 
 	mtspr(SPRN_TCR, val);
 }
 
+static void booke_wdt_timer_ping(unsigned long arg);
+static DEFINE_TIMER(wdt_timer, booke_wdt_timer_ping, 0, 0);
+
+static unsigned persistent = 0;
+
+static void booke_wdt_timer_ping(unsigned long arg)
+{
+	if (persistent) {
+	    booke_wdt_ping();
+	    mod_timer(&wdt_timer, jiffies + 5 * HZ);
+	}
+}
+
 static ssize_t booke_wdt_write(struct file *file, const char __user *buf,
 				size_t count, loff_t *ppos)
 {
+	if (count)
+	{
+		size_t i;
+		persistent = 0;
+		for (i = 0; i < count; ++i) {
+			char c;
+			if (get_user(c, buf + i))
+				return -EFAULT;
+			if (c == 'V')
+				persistent = 1;
+		}
+	}
 	booke_wdt_ping();
 	return count;
 }
@@ -193,12 +222,19 @@ static int booke_wdt_open(struct inode *
 	return nonseekable_open(inode, file);
 }
 
+static int booke_wdt_release(struct inode *inode, struct file *file)
+{
+	if (persistent) booke_wdt_timer_ping(0);
+	return 0;
+}
+
 static const struct file_operations booke_wdt_fops = {
 	.owner = THIS_MODULE,
 	.llseek = no_llseek,
 	.write = booke_wdt_write,
 	.unlocked_ioctl = booke_wdt_ioctl,
 	.open = booke_wdt_open,
+	.release = booke_wdt_release,
 };
 
 static struct miscdevice booke_wdt_miscdev = {
diff -puNrb linux-2.6.35/drivers/watchdog/mpc8xxx_wdt.c linux/drivers/watchdog/mpc8xxx_wdt.c
--- linux-2.6.35/drivers/watchdog/mpc8xxx_wdt.c	2011-04-26 16:27:39.322535712 +0300
+++ linux/drivers/watchdog/mpc8xxx_wdt.c	2011-05-02 10:08:27.811231681 +0300
@@ -29,6 +29,15 @@
 #include <linux/uaccess.h>
 #include <sysdev/fsl_soc.h>
 
+#define RESET_CAUSE_IOCTL _IO('R', 1)
+
+#define RESET_COLD	0
+#define RESET_WARM	1
+#define RESET_WATCHDOG	2
+
+static unsigned __iomem *rsr = NULL;
+#define RSR_WDT_RESET 0x8
+
 struct mpc8xxx_wdt {
 	__be32 res0;
 	__be32 swcrr; /* System watchdog control register */
@@ -100,17 +109,48 @@ static void mpc8xxx_wdt_pr_warn(const ch
 		reset ? "reset" : "machine check exception");
 }
 
+static int expect_close;
+
+static void mpc8xxx_start_dog(void)
+{
+	u32 tmp = SWCRR_SWEN;
+	/* Good, fire up the show */
+	if (prescale)
+		tmp |= SWCRR_SWPR;
+	if (reset)
+		tmp |= SWCRR_SWRI;
+
+	tmp |= timeout << 16;
+
+	out_be32(&wd_base->swcrr, tmp);
+}
+
+static int expect_close;
+
 static ssize_t mpc8xxx_wdt_write(struct file *file, const char __user *buf,
 				 size_t count, loff_t *ppos)
 {
 	if (count)
+	{
+		size_t i;
+
+		expect_close = 0;
+		for (i = 0; i < count; ++i) {
+			char c;
+			if (get_user(c, buf + i))
+				return -EFAULT;
+			if (c == 'V')
+				expect_close = 1;
+			if (c == 'S')
+				mpc8xxx_start_dog();
+		}
 		mpc8xxx_wdt_keepalive();
+	}
 	return count;
 }
 
 static int mpc8xxx_wdt_open(struct inode *inode, struct file *file)
 {
-	u32 tmp = SWCRR_SWEN;
 	if (test_and_set_bit(0, &wdt_is_open))
 		return -EBUSY;
 
@@ -118,15 +158,7 @@ static int mpc8xxx_wdt_open(struct inode
 	if (nowayout)
 		__module_get(THIS_MODULE);
 
-	/* Good, fire up the show */
-	if (prescale)
-		tmp |= SWCRR_SWPR;
-	if (reset)
-		tmp |= SWCRR_SWRI;
-
-	tmp |= timeout << 16;
-
-	out_be32(&wd_base->swcrr, tmp);
+	__module_get(THIS_MODULE); // for easier merge
 
 	del_timer_sync(&wdt_timer);
 
@@ -135,14 +167,23 @@ static int mpc8xxx_wdt_open(struct inode
 
 static int mpc8xxx_wdt_release(struct inode *inode, struct file *file)
 {
-	if (!nowayout)
+	if (!nowayout || expect_close)
 		mpc8xxx_wdt_timer_ping(0);
 	else
 		mpc8xxx_wdt_pr_warn("watchdog closed");
 	clear_bit(0, &wdt_is_open);
+	expect_close = 0;
 	return 0;
 }
 
+static void clean_rsr(void)
+{
+    if (rsr) {
+	iounmap(rsr);
+	rsr = NULL;
+    }
+}
+
 static long mpc8xxx_wdt_ioctl(struct file *file, unsigned int cmd,
 							unsigned long arg)
 {
@@ -155,6 +196,14 @@ static long mpc8xxx_wdt_ioctl(struct fil
 	};
 
 	switch (cmd) {
+	case RESET_CAUSE_IOCTL:
+	    if (rsr && (in_be32(rsr) & RSR_WDT_RESET)) {
+		out_be32(rsr, in_be32(rsr) | RSR_WDT_RESET);
+		return RESET_WATCHDOG;
+	    }
+	    else {
+		return RESET_COLD;
+	    }
 	case WDIOC_GETSUPPORT:
 		return copy_to_user(argp, &ident, sizeof(ident)) ? -EFAULT : 0;
 	case WDIOC_GETSTATUS:
@@ -194,6 +243,19 @@ static int __devinit mpc8xxx_wdt_probe(s
 	u32 freq = fsl_get_sys_freq();
 	bool enabled;
 
+	{	    
+	    /* get reset status register */
+	    struct device_node *soc = of_find_node_by_type(NULL, "soc");
+	    if (soc) {	    
+		unsigned int size;
+		static phys_addr_t immrbase = -1;
+		const void *prop = of_get_property(soc, "reg", &size);
+		immrbase = of_translate_address(soc, prop);
+		rsr = (unsigned *) ioremap_nocache(immrbase + 0x910, 0x4);
+		of_node_put(soc);
+	    }
+	}
+
 	if (!freq || freq == -1)
 		return -EINVAL;
 
@@ -214,6 +276,8 @@ static int __devinit mpc8xxx_wdt_probe(s
 	else
 		timeout_sec = timeout / freq;
 
+	timeout_sec = 1;
+
 #ifdef MODULE
 	ret = mpc8xxx_wdt_init_late();
 	if (ret)
@@ -234,6 +298,7 @@ static int __devinit mpc8xxx_wdt_probe(s
 	return 0;
 err_unmap:
 	iounmap(wd_base);
+	clean_rsr();
 	wd_base = NULL;
 	return ret;
 }
@@ -245,6 +310,7 @@ static int __devexit mpc8xxx_wdt_remove(
 	misc_deregister(&mpc8xxx_wdt_miscdev);
 	iounmap(wd_base);
 
+	clean_rsr();
 	return 0;
 }
 
diff -puNrb linux-2.6.35/firmware/Makefile linux/firmware/Makefile
--- linux-2.6.35/firmware/Makefile	2011-04-26 16:26:42.822195460 +0300
+++ linux/firmware/Makefile	2011-05-02 10:08:27.821545889 +0300
@@ -139,7 +139,7 @@ fw-shipped-$(CONFIG_USB_VICAM) += vicam/
 fw-shipped-$(CONFIG_VIDEO_CPIA2) += cpia2/stv0672_vp4.bin
 fw-shipped-$(CONFIG_YAM) += yam/1200.bin yam/9600.bin
 
-fw-shipped-all := $(fw-shipped-y) $(fw-shipped-m) $(fw-shipped-)
+fw-shipped-all := $(fw-shipped-y) $(fw-shipped-m)
 
 # Directories which we _might_ need to create, so we have a rule for them.
 firmware-dirs := $(sort $(patsubst %,$(objtree)/$(obj)/%/,$(dir $(fw-external-y) $(fw-shipped-all))))
diff -puNrb linux-2.6.35/fs/Kconfig linux/fs/Kconfig
--- linux-2.6.35/fs/Kconfig	2011-04-26 16:26:31.371241228 +0300
+++ linux/fs/Kconfig	2011-05-02 10:08:27.851262161 +0300
@@ -189,6 +189,8 @@ source "fs/romfs/Kconfig"
 source "fs/sysv/Kconfig"
 source "fs/ufs/Kconfig"
 source "fs/exofs/Kconfig"
+source "fs/yaffs/Kconfig"
+source "fs/metafs/Kconfig"
 
 endif # MISC_FILESYSTEMS
 
diff -puNrb linux-2.6.35/fs/Makefile linux/fs/Makefile
--- linux-2.6.35/fs/Makefile	2011-04-26 16:26:31.381231766 +0300
+++ linux/fs/Makefile	2011-05-02 10:08:27.861588603 +0300
@@ -63,6 +63,7 @@ obj-$(CONFIG_PROFILING)		+= dcookies.o
 obj-$(CONFIG_DLM)		+= dlm/
  
 # Do not add any filesystems before this line
+obj-$(CONFIG_META_FS)		+= metafs/
 obj-$(CONFIG_FSCACHE)		+= fscache/
 obj-$(CONFIG_REISERFS_FS)	+= reiserfs/
 obj-$(CONFIG_EXT3_FS)		+= ext3/ # Before ext2 so root fs can be ext3
@@ -101,6 +102,7 @@ obj-$(CONFIG_EFS_FS)		+= efs/
 obj-$(CONFIG_JFFS2_FS)		+= jffs2/
 obj-$(CONFIG_LOGFS)		+= logfs/
 obj-$(CONFIG_UBIFS_FS)		+= ubifs/
+obj-$(CONFIG_YAFFS_FS)		+= yaffs/
 obj-$(CONFIG_AFFS_FS)		+= affs/
 obj-$(CONFIG_ROMFS_FS)		+= romfs/
 obj-$(CONFIG_QNX4FS_FS)		+= qnx4/
diff -puNrb linux-2.6.35/fs/metafs/inode.c linux/fs/metafs/inode.c
--- linux-2.6.35/fs/metafs/inode.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/metafs/inode.c	2011-05-02 10:08:27.881591084 +0300
@@ -0,0 +1,903 @@
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/statfs.h>
+#include <linux/pagemap.h>
+#include <linux/namei.h>
+#include <linux/slab.h>
+#include <asm/vm.h>
+
+#define CMD_GETINODE		0
+#define CMD_RELEASE_INODE	1
+#define CMD_LOOKUP		2
+#define CMD_READPAGE		3
+#define CMD_READLINK		4
+#define CMD_READDIR		5
+#define CMD_WRITEPAGE		6
+#define CMD_CREATE		7
+#define CMD_UNLINK		8
+#define CMD_SYMLINK		9
+#define CMD_RENAME		10
+#define CMD_SETINODE		11
+#define CMD_STATFS		12
+#define CMD_HLINK		13
+#define CMD_FSYNC		14
+
+struct hptime {
+	unsigned sec;
+	unsigned nsec;
+};
+
+struct getinode_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+} __attribute__((packed));
+
+struct inode_rep {
+	int status;
+	unsigned long long ino;
+	unsigned long long size;
+	unsigned mode;
+	unsigned nlink;
+	unsigned uid;
+	unsigned gid;
+	unsigned rdev;
+	struct hptime atime;
+	struct hptime mtime;
+	struct hptime ctime;
+	unsigned long blksize;
+	unsigned long long blocks;
+} __attribute__((packed));
+
+struct setinode_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+	unsigned long long size;
+	unsigned mode;
+	unsigned uid;
+	unsigned gid;
+	unsigned rdev;
+} __attribute__((packed));
+
+struct lookup_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long parent_ino;
+	char name[0];
+} __attribute__((packed));
+
+struct create_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long parent_ino;
+	unsigned mode;
+	unsigned dev;
+	char name[0];
+} __attribute__((packed));
+
+struct unlink_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long parent_ino;
+	char name[0];
+} __attribute__((packed));
+
+struct symlink_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long parent_ino;
+	unsigned namelen;
+	char names[0];
+} __attribute__((packed));
+
+struct hlink_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long parent_ino;
+	unsigned long long ino;
+	char name[0];
+} __attribute__((packed));
+
+struct rename_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long old_parent_ino;
+	unsigned long long new_parent_ino;
+	unsigned old_namelen;
+	char names[0];
+} __attribute__((packed));
+
+struct readpage_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+	unsigned long long offset;
+	unsigned size;
+} __attribute__((packed));
+
+struct writepage_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+	unsigned long long offset;
+	unsigned size;
+} __attribute__((packed));
+
+struct fsync_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+} __attribute__((packed));
+
+struct readlink_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+} __attribute__((packed));
+
+struct readlink_rep {
+	int status;
+	char target[0];
+} __attribute__((packed));
+
+struct readdir_req {
+	unsigned short id;
+	unsigned short cmd;
+	unsigned long long ino;
+	unsigned long long offset;
+	unsigned size;
+} __attribute__((packed));
+
+struct dirnode {
+	unsigned long long ino;
+	unsigned long long offset;
+	unsigned char type;
+	unsigned short len;
+	char name[0];
+} __attribute__((packed));
+
+struct readdir_rep {
+	int status;
+	unsigned long long offset;
+	struct dirnode entries[0];
+} __attribute__((packed));
+
+struct statfs_req {
+	unsigned short id;
+	unsigned short cmd;
+} __attribute__((packed));
+
+struct statfs_rep {
+	int status;
+	unsigned blocks;
+	unsigned bfree;
+} __attribute__((packed));
+
+#define BUF_COUNT	16
+
+extern int vm_create_queue(unsigned id, unsigned irq,
+			   unsigned tx, unsigned rx);
+extern int vm_release_queue(unsigned id);
+
+static volatile struct vdma_descr rx_descr[BUF_COUNT];
+static volatile struct vdma_descr tx_descr[BUF_COUNT];
+
+#define MFS_ID(sb) ((unsigned) sb->s_fs_info)
+
+
+static void mfs_update_inode(struct inode *i, struct inode_rep *rep);
+static struct inode *mfs_new_inode(struct super_block *sb,
+				   struct inode_rep *rep);
+
+static void start_new_request(unsigned *tx_idx, unsigned tx_slots,
+			      unsigned *rx_idx, unsigned rx_slots)
+{
+	static DEFINE_MUTEX(mfs_lock);
+	static unsigned cur_tx;
+	static unsigned cur_rx;
+
+	mutex_lock(&mfs_lock);
+
+	*tx_idx = cur_tx;
+	cur_tx += tx_slots;
+
+	*rx_idx = cur_rx;
+	cur_rx += rx_slots;
+
+	mutex_unlock(&mfs_lock);
+}
+
+static void prepare_receive(unsigned idx, void *resp, unsigned rp_size)
+{
+	idx = idx & (BUF_COUNT - 1);
+
+	rx_descr[idx].addr = (unsigned) resp;
+	rx_descr[idx].size = rp_size;
+}
+
+static void post_request(unsigned idx, const void *req, unsigned rq_size)
+{
+	idx = idx & (BUF_COUNT - 1);
+
+	while (tx_descr[idx].size & DONE) {
+		hc_yield();
+	}
+
+	tx_descr[idx].addr = (unsigned) req;
+	tx_descr[idx].size = rq_size | DONE;
+}
+
+static unsigned wait_for_reply(unsigned idx)
+{
+	idx = idx & (BUF_COUNT - 1);
+
+	while (!(rx_descr[idx].size & DONE)) {
+		hc_yield();
+	}
+	return rx_descr[idx].size & ~(PAGE_MASK<<1);
+}
+
+static unsigned send_request(const void *req, unsigned rq_size,
+			     void *resp, unsigned rp_size)
+{
+	unsigned tx;
+	unsigned rx;
+
+	start_new_request(&tx, 1, &rx, 1);
+	prepare_receive(rx, resp, rp_size);
+	post_request(tx, req, rq_size);
+	return wait_for_reply(rx);
+}
+
+static struct kmem_cache *mfs_inode_cachep;
+
+static struct inode *mfs_alloc_inode(struct super_block *sb)
+{
+	return kmem_cache_alloc(mfs_inode_cachep, GFP_KERNEL);
+}
+
+static void mfs_destroy_inode(struct inode *inode)
+{
+	kmem_cache_free(mfs_inode_cachep, inode);
+}
+
+static struct dentry *mfs_lookup(struct inode *dir,
+				 struct dentry *dentry, struct nameidata *nd)
+{
+	unsigned size = sizeof(struct lookup_req) + dentry->d_name.len;
+	unsigned char buf[size];
+	struct lookup_req *req = (struct lookup_req *) buf;
+	struct inode_rep rep;
+	struct inode *inode = NULL;
+	struct dentry *res = NULL;
+	unsigned ret;
+
+	req->id = MFS_ID(dir->i_sb);
+	req->cmd = CMD_LOOKUP;
+	req->parent_ino = dir->i_ino;
+	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
+
+	rep.status = -EINVAL;
+	ret = send_request(req, size, &rep, sizeof(rep));
+	if (ret == sizeof(rep) && rep.status == 0)
+		inode = mfs_new_inode(dir->i_sb, &rep);
+	d_add(dentry, inode);
+	return res;
+}
+
+static int mfs_create_file(struct inode *dir, struct dentry *dentry,
+			   int mode, dev_t dev)
+{
+	unsigned size = sizeof(struct create_req) + dentry->d_name.len;
+	unsigned char buf[size];
+	struct create_req *req = (struct create_req *) buf;
+	struct inode_rep rep;
+	struct inode *inode = NULL;
+	unsigned ret;
+
+	req->id = MFS_ID(dir->i_sb);
+	req->cmd = CMD_CREATE;
+	req->parent_ino = dir->i_ino;
+	req->mode = mode;
+	req->dev = (unsigned) dev;
+	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
+
+	rep.status = -EINVAL;
+	ret = send_request(req, size, &rep, sizeof(rep));
+	if (ret < sizeof(rep))
+		return rep.status;
+
+	inode = mfs_new_inode(dir->i_sb, &rep);
+	d_instantiate(dentry, inode);
+	return 0;
+}
+
+static int mfs_create(struct inode *dir, struct dentry *dentry, int mode,
+		      struct nameidata *nd)
+{
+	return mfs_create_file(dir, dentry, mode, MKDEV(0, 0));
+}
+
+static int mfs_unlink(struct inode *dir, struct dentry *dentry)
+{
+	unsigned size = sizeof(struct unlink_req) + dentry->d_name.len;
+	unsigned char buf[size];
+	struct unlink_req *req = (struct unlink_req *) buf;
+	int err = -EINVAL;
+    
+	req->id = MFS_ID(dir->i_sb);
+	req->cmd = CMD_UNLINK;
+	req->parent_ino = dir->i_ino;
+	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
+
+	send_request(req, size, &err, sizeof(err));
+	return err;
+}
+
+static int mfs_symlink(struct inode *dir, struct dentry *dentry,
+		       const char *target)
+{
+	unsigned tlen = strlen(target);
+	unsigned size = sizeof(struct symlink_req) + dentry->d_name.len + tlen;
+	unsigned char buf[size];
+	struct symlink_req *req = (struct symlink_req *) buf;
+	struct inode_rep rep;
+	struct inode *inode = NULL;
+	unsigned ret;
+    
+	req->id = MFS_ID(dir->i_sb);
+	req->cmd = CMD_SYMLINK;
+	req->parent_ino = dir->i_ino;
+	req->namelen = dentry->d_name.len;
+	memcpy(req->names, dentry->d_name.name, dentry->d_name.len);
+	memcpy(req->names + req->namelen, target, tlen);
+
+	rep.status = -EINVAL;
+	ret = send_request(req, size, &rep, sizeof(rep));
+	if (ret < sizeof(rep))
+		return rep.status;
+
+	inode = mfs_new_inode(dir->i_sb, &rep);
+	d_instantiate(dentry, inode);
+	return 0;
+}
+
+static int mfs_link(struct dentry *old_dentry, struct inode *dir,
+		    struct dentry *dentry)
+{
+	unsigned size = sizeof(struct hlink_req) + dentry->d_name.len;
+	unsigned char buf[size];
+	struct hlink_req *req = (struct hlink_req *) buf;
+	struct inode_rep rep;
+	unsigned ret;
+    
+	req->id = MFS_ID(dir->i_sb);
+	req->cmd = CMD_HLINK;
+	req->parent_ino = dir->i_ino;
+	req->ino = old_dentry->d_inode->i_ino;
+	memcpy(req->name, dentry->d_name.name, dentry->d_name.len);
+
+	rep.status = -EINVAL;
+	ret = send_request(req, size, &rep, sizeof(rep));
+	if (ret < sizeof(rep))
+		return rep.status;
+
+	mfs_update_inode(old_dentry->d_inode, &rep);
+
+	atomic_inc(&old_dentry->d_inode->i_count);
+	d_instantiate(dentry, old_dentry->d_inode);
+	return 0;
+}
+
+static int mfs_mkdir(struct inode *dir, struct dentry *dentry, int mode)
+{
+	return mfs_create_file(dir, dentry, mode | S_IFDIR, MKDEV(0, 0));
+}
+
+static int mfs_rmdir(struct inode *dir, struct dentry *dentry)
+{
+	return mfs_unlink(dir, dentry);
+}
+
+static int mfs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		     dev_t rdev) {
+	return mfs_create_file(dir, dentry, mode, rdev);
+}
+
+static int mfs_rename(struct inode *old_dir, struct dentry *old_dentry,
+		      struct inode *new_dir, struct dentry *new_dentry)
+{
+	unsigned size = sizeof(struct rename_req) +
+	    old_dentry->d_name.len + new_dentry->d_name.len;
+	unsigned char buf[size];
+	struct rename_req *req = (struct rename_req *) buf;
+	int err = -EINVAL;
+    
+	req->id = MFS_ID(old_dir->i_sb);
+	req->cmd = CMD_RENAME;
+	req->old_parent_ino = old_dir->i_ino;
+	req->new_parent_ino = new_dir->i_ino;
+	req->old_namelen = old_dentry->d_name.len;
+	memcpy(req->names, old_dentry->d_name.name, old_dentry->d_name.len);
+	memcpy(req->names + req->old_namelen,
+	       new_dentry->d_name.name, new_dentry->d_name.len);
+
+	send_request(req, size, &err, sizeof(err));
+	return err;
+}
+
+static int mfs_readdir(struct file *file, void *dirent, filldir_t filldir)
+{
+	struct readdir_req req;
+	struct readdir_rep *rep;
+	struct dirnode *dn;
+	unsigned len;
+	int res = -EINVAL;
+
+	rep = kmalloc(PAGE_SIZE, GFP_KERNEL);
+	if (!rep)
+		return -ENOMEM;
+
+	req.id = MFS_ID(file->f_dentry->d_inode->i_sb);
+	req.cmd = CMD_READDIR;
+	req.ino = file->f_dentry->d_inode->i_ino;
+	req.offset = file->f_pos;
+	req.size = PAGE_SIZE;
+
+	len = send_request(&req, sizeof(req), rep, PAGE_SIZE);
+	if (len <= sizeof(*rep)) {
+		if (len >= sizeof(int))
+			res = rep->status;
+		goto eod;
+	}
+	
+	dn = rep->entries;
+	res = 0;
+	while ((char *) dn + sizeof(struct dirnode) < (char *) rep + len) {
+		if ((char *) dn + dn->len > (char *) rep + len)
+			break;
+		if (filldir(dirent, dn->name, dn->len - sizeof(struct dirnode),
+			    dn->offset, dn->ino, dn->type) < 0)
+			break;
+		++res;
+		dn = (struct dirnode *) ((unsigned char *) dn + dn->len);
+	}
+	file->f_pos = rep->offset;
+
+  eod:
+	kfree(rep);
+	return res;
+}
+
+static int mfs_readpage(struct file *file, struct page *page)
+{
+	struct readpage_req req;
+	void *buf;
+	int res = -EIO;
+	unsigned len;
+	unsigned tx;
+	unsigned rx;
+
+	buf = kmap(page);
+	if (!buf)
+		goto err_out;
+
+	req.id = MFS_ID(file->f_dentry->d_inode->i_sb);
+	req.cmd = CMD_READPAGE;
+	req.ino = file->f_dentry->d_inode->i_ino;
+	req.offset = page_offset(page);
+	req.size = PAGE_SIZE;
+
+	start_new_request(&tx, 1, &rx, 2);
+	prepare_receive(rx, &res, sizeof(res));
+	prepare_receive(rx + 1, buf, PAGE_SIZE);
+	post_request(tx, &req, sizeof(req));
+
+	if (wait_for_reply(rx) < sizeof(res)) {
+		res = -EINVAL;
+		goto err_out;
+	}
+	if (res) {
+		memset(buf, 0, PAGE_SIZE);
+		SetPageError(page);
+		goto err_buf;
+	}
+	len = wait_for_reply(rx + 1);
+
+	memset(buf + len, 0, PAGE_SIZE - len);
+	SetPageUptodate(page);
+
+  err_buf:
+	kunmap(page);
+	flush_dcache_page(page);
+  err_out:
+	unlock_page(page);
+	return res;
+}
+
+static int mfs_write_begin(struct file *file, struct address_space *mapping,
+			   loff_t pos, unsigned len, unsigned flags,
+			   struct page **pagep, void **fsdata)
+{
+	pgoff_t index = pos >> PAGE_CACHE_SHIFT;
+
+	*pagep = grab_cache_page_write_begin(mapping, index, flags);
+	if (!*pagep)
+		return -ENOMEM;
+
+	// FIXME: do prereading
+
+	return 0;
+}
+
+static int mfs_write_end(struct file *file, struct address_space *mapping,
+			 loff_t pos, unsigned blen, unsigned copied,
+			 struct page *page, void *fsdata)
+{
+	struct inode *i = file->f_dentry->d_inode;
+	struct writepage_req req;
+	void *buf;
+	int len = -EFAULT;
+	unsigned tx;
+	unsigned rx;
+	unsigned size;
+
+	flush_dcache_page(page);
+
+	buf = kmap(page);
+	if (!buf)
+		return -EINVAL;
+
+	req.id = MFS_ID(i->i_sb);
+	req.cmd = CMD_WRITEPAGE;
+	req.ino = file->f_dentry->d_inode->i_ino;
+	req.offset = pos;
+	req.size = blen;
+
+	start_new_request(&tx, 2, &rx, 1);
+	prepare_receive(rx, &len, sizeof(len));
+	post_request(tx, &req, sizeof(req));
+	post_request(tx + 1, buf + (pos & (PAGE_CACHE_SIZE - 1)), blen);
+	wait_for_reply(rx);
+
+	if (len >= 0) {
+		if (len != blen) {
+			SetPageError(page);
+			ClearPageUptodate(page);
+		} else {
+			SetPageUptodate(page);
+		}
+
+		size = req.offset + len;
+		if (size > i_size_read(i)) i_size_write(i, size);
+	}
+
+	kunmap(page);
+	unlock_page(page);
+	page_cache_release(page);
+	return len;
+}
+
+static int mfs_fsync(struct file *file, int datasync)
+{
+	struct fsync_req req;
+	int err = -EINVAL;
+
+	req.id = MFS_ID(file->f_mapping->host->i_sb);
+	req.cmd = CMD_FSYNC;
+	req.ino = file->f_mapping->host->i_ino;
+
+	send_request(&req, sizeof(req), &err, sizeof(err));
+	return err;
+}
+
+static void *mfs_follow_link(struct dentry *dentry, struct nameidata *nd)
+{
+	struct readlink_req req;
+	struct readlink_rep *rep;
+	int len;
+
+	rep = kmalloc(256, GFP_KERNEL);
+	if (!rep)
+		return ERR_PTR(-ENOMEM);
+
+	req.id = MFS_ID(dentry->d_inode->i_sb);
+	req.cmd = CMD_READLINK;
+	req.ino = dentry->d_inode->i_ino;
+	
+	rep->status = -EINVAL;
+	len = send_request(&req, sizeof(req), rep, 255);
+	if (len < sizeof(*rep) + 1) {
+		kfree(rep);
+		return ERR_PTR(rep->status);
+	}
+
+	*((char *) rep + len) = 0;
+	nd_set_link(nd, rep->target);
+	return NULL;
+}
+
+static void mfs_put_link(struct dentry *direntry,
+			 struct nameidata *nd, void *cookie)
+{
+	char *p = nd_get_link(nd);
+
+	if (!IS_ERR(p))
+		kfree(p - sizeof(struct readlink_rep));
+}
+
+static int mfs_setattr(struct dentry *dentry, struct iattr *attr)
+{
+	struct setinode_req req;
+	struct inode_rep rep;
+	struct inode *i = dentry->d_inode;
+	unsigned ia = attr->ia_valid;
+	unsigned len;
+
+	req.id = MFS_ID(i->i_sb);
+	req.cmd = CMD_SETINODE;
+	req.ino = i->i_ino;
+	req.mode = ia & ATTR_MODE ? attr->ia_mode : i->i_mode;
+	req.uid = ia & ATTR_UID ? attr->ia_uid : i->i_uid;
+	req.gid = ia & ATTR_GID ? attr->ia_gid : i->i_gid;
+	req.size = ia & ATTR_SIZE ? attr->ia_size : i->i_size;
+
+	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
+	if (len < sizeof(rep))
+		return -EINVAL;
+	    
+	if (rep.status)
+		return rep.status;
+
+	mfs_update_inode(i, &rep);
+	return 0;
+}
+
+static const struct file_operations mfs_dir_fops = {
+	.read		= generic_read_dir,
+	.readdir	= mfs_readdir,
+};
+
+static const struct inode_operations mfs_dir_ops = {
+	.lookup		= mfs_lookup,
+	.create		= mfs_create,
+	.link		= mfs_link,
+	.unlink		= mfs_unlink,
+	.symlink	= mfs_symlink,
+	.mkdir		= mfs_mkdir,
+	.rmdir		= mfs_rmdir,
+	.mknod		= mfs_mknod,
+	.rename		= mfs_rename,
+	.setattr	= mfs_setattr,
+};
+
+static const struct inode_operations mfs_file_ops = {
+	.setattr	= mfs_setattr,
+};
+
+static const struct file_operations mfs_fops = {
+	.llseek		= generic_file_llseek,
+	.read		= do_sync_read,
+	.write		= do_sync_write,
+	.aio_read	= generic_file_aio_read,
+	.aio_write	= generic_file_aio_write,
+	.mmap		= generic_file_readonly_mmap,
+	.splice_read	= generic_file_splice_read,
+	.fsync		= mfs_fsync,
+};
+
+static const struct address_space_operations mfs_aops = {
+	.readpage	= mfs_readpage,
+	.write_begin	= mfs_write_begin,
+	.write_end	= mfs_write_end,
+};
+
+static const struct inode_operations mfs_link_ops = {
+	.readlink	= generic_readlink,
+	.follow_link	= mfs_follow_link,
+	.put_link	= mfs_put_link,
+	.setattr	= mfs_setattr,
+};
+
+static void mfs_update_inode(struct inode *i, struct inode_rep *rep)
+{
+	i->i_ino = rep->ino;
+	i->i_mode = rep->mode;
+	i->i_nlink = rep->nlink;
+	i->i_uid = rep->uid;
+	i->i_gid = rep->gid;
+	i->i_size = rep->size;
+	i->i_atime.tv_sec = rep->atime.sec;
+	i->i_atime.tv_nsec = rep->atime.nsec;
+	i->i_mtime.tv_sec = rep->mtime.sec;
+	i->i_mtime.tv_nsec = rep->mtime.nsec;
+	i->i_ctime.tv_sec = rep->ctime.sec;
+	i->i_ctime.tv_nsec = rep->ctime.nsec;
+	i->i_blkbits = ffs(rep->blksize);
+	i->i_blocks = rep->blocks;
+
+	if (i->i_sb->s_flags & MS_RDONLY)
+		i->i_mode &= ~0222;
+}
+
+static struct inode *mfs_new_inode(struct super_block *sb,
+				   struct inode_rep *rep)
+{
+	struct inode *i = new_inode(sb);
+	if (!i) return NULL;
+
+	mfs_update_inode(i, rep);
+
+	if (S_ISREG(rep->mode)) {
+		i->i_op = &mfs_file_ops;
+		i->i_fop = &mfs_fops;
+		i->i_data.a_ops = &mfs_aops;
+	} else if (S_ISDIR(rep->mode)) {
+		i->i_op = &mfs_dir_ops;
+		i->i_fop = &mfs_dir_fops;
+	} else if (S_ISLNK(rep->mode)) {
+		i->i_op = &mfs_link_ops;
+	} else {
+		init_special_inode(i, rep->mode, (dev_t) rep->rdev);
+	}
+
+	insert_inode_hash(i);
+	return i;
+}
+
+static struct inode *mfs_getinode(struct super_block *sb,
+				  unsigned long long ino)
+{
+	struct getinode_req req;
+	struct inode_rep rep;
+	unsigned len;
+
+	req.id = MFS_ID(sb);
+	req.cmd = CMD_GETINODE;
+	req.ino = ino;
+	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
+
+	if (len < sizeof(rep) || rep.status)
+		return NULL;
+
+	return mfs_new_inode(sb, &rep);
+}
+
+static void mfs_put_super(struct super_block *sb)
+{
+}
+
+static int mfs_statfs(struct dentry *dentry, struct kstatfs *buf)
+{
+	struct statfs_req req;
+	struct statfs_rep rep;
+	struct super_block *sb = dentry->d_sb;
+	unsigned len;
+
+	req.id = MFS_ID(sb);
+	req.cmd = CMD_STATFS;
+	rep.status = -EINVAL;
+	len = send_request(&req, sizeof(req), &rep, sizeof(rep));
+
+	if (len < sizeof(rep) || rep.status)
+		return rep.status;
+
+	buf->f_type = sb->s_magic;
+	buf->f_bsize = 512;
+	buf->f_blocks = rep.blocks;
+	buf->f_bfree = rep.bfree;
+	buf->f_bavail = rep.bfree;
+	buf->f_namelen = 255;
+
+	return 0;
+}
+
+static const struct super_operations mfs_ops = {
+	.alloc_inode	= mfs_alloc_inode,
+	.destroy_inode	= mfs_destroy_inode,
+	.put_super	= mfs_put_super,
+	.statfs		= mfs_statfs,
+};
+
+static int mfs_fill_super(struct super_block *sb, void *data, int silent)
+{
+	struct inode *root;
+	unsigned id;
+
+	if (*(char *) data == '/') ++data;
+	id = simple_strtoul((char *) data, NULL, 10);
+
+	sb->s_magic = 0xdeadbeef;
+	sb->s_op = &mfs_ops;
+	if (id == 0)
+		sb->s_flags |= MS_RDONLY;
+	sb->s_fs_info = (void *) id;
+
+	root = mfs_getinode(sb, 0);
+	if (!root)	    
+		goto out;
+
+	sb->s_root = d_alloc_root(root);
+	if (!sb->s_root)
+		goto outiput;
+
+	return 0;
+
+  outiput:
+	iput(root);
+  out:
+	return -EINVAL;
+}
+
+static int mfs_get_sb(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data, struct vfsmount *mnt)
+{
+	return get_sb_nodev(fs_type, flags,
+			    (void *) dev_name, mfs_fill_super, mnt);
+}
+
+static struct file_system_type mfs_fs_type = {
+	.owner		= THIS_MODULE,
+	.name		= "metafs",
+	.get_sb		= mfs_get_sb,
+	.kill_sb	= kill_block_super,
+	.fs_flags	= FS_REQUIRES_DEV,
+};
+
+static void init_once(void *foo)
+{
+	struct inode * inode = (struct inode *) foo;
+
+	inode_init_once(inode);
+}
+
+static int __init init_mfs_fs(void)
+{
+	unsigned i;
+	int err;
+
+	if (vm_running() != 0)
+		return 0;
+
+	printk("MFS init\n");
+	mfs_inode_cachep = kmem_cache_create("metafs_inode_cache",
+					     sizeof(struct inode),
+					     0, (SLAB_RECLAIM_ACCOUNT|
+						 SLAB_MEM_SPREAD),
+					     init_once);
+	if (!mfs_inode_cachep)
+		return -ENOMEM;
+
+	for (i = 0; i < BUF_COUNT; ++i) {
+		tx_descr[i].addr = 0;
+		tx_descr[i].size = 0;
+		tx_descr[i].next = (unsigned) &tx_descr[i + 1];
+
+		rx_descr[i].addr = 0;
+		rx_descr[i].size = DONE;
+		rx_descr[i].next = (unsigned) &rx_descr[i + 1];
+	}
+	tx_descr[BUF_COUNT - 1].next = (unsigned) &tx_descr[0];
+	rx_descr[BUF_COUNT - 1].next = (unsigned) &rx_descr[0];
+	
+	vm_create_queue(2, -1u,
+			(unsigned) &tx_descr[0], (unsigned) &rx_descr[0]);
+
+        err = register_filesystem(&mfs_fs_type);
+	if (err != 0) {
+		kmem_cache_destroy(mfs_inode_cachep);
+		return err;
+	}
+
+	return 0;
+}
+
+static void __exit exit_mfs_fs(void)
+{
+	unregister_filesystem(&mfs_fs_type);
+	kmem_cache_destroy(mfs_inode_cachep);
+}
+
+module_init(init_mfs_fs);
+module_exit(exit_mfs_fs);
diff -puNrb linux-2.6.35/fs/metafs/Kconfig linux/fs/metafs/Kconfig
--- linux-2.6.35/fs/metafs/Kconfig	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/metafs/Kconfig	2011-05-02 10:08:27.891544982 +0300
@@ -0,0 +1,3 @@
+config META_FS
+	depends on METAROUTER || MIPS_MIKROTIK
+	tristate "MetaFS on Mikrotik MetaRouters"
diff -puNrb linux-2.6.35/fs/metafs/Makefile linux/fs/metafs/Makefile
--- linux-2.6.35/fs/metafs/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/metafs/Makefile	2011-05-02 10:08:27.901584034 +0300
@@ -0,0 +1,3 @@
+obj-y += metafs.o
+
+metafs-objs := inode.o
diff -puNrb linux-2.6.35/fs/yaffs/devextras.h linux/fs/yaffs/devextras.h
--- linux-2.6.35/fs/yaffs/devextras.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/devextras.h	2011-05-02 10:08:27.911589683 +0300
@@ -0,0 +1,265 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * devextras.h
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ * This file is just holds extra declarations used during development.
+ * Most of these are from kernel includes placed here so we can use them in 
+ * applications.
+ *
+ * $Id: devextras.h,v 1.2 2005/08/11 02:37:49 marty Exp $
+ *
+ */
+
+#ifndef __EXTRAS_H__
+#define __EXTRAS_H__
+
+#if defined WIN32
+#define __inline__ __inline
+#define new newHack
+#endif
+
+#if !(defined __KERNEL__) || (defined WIN32)
+
+/* User space defines */
+
+typedef unsigned char __u8;
+typedef unsigned short __u16;
+typedef unsigned __u32;
+
+/*
+ * Simple doubly linked list implementation.
+ *
+ * Some of the internal functions ("__xxx") are useful when
+ * manipulating whole lists rather than single entries, as
+ * sometimes we already know the next/prev entries and we can
+ * generate better code by using them directly rather than
+ * using the generic single-entry routines.
+ */
+
+#define prefetch(x) 1
+
+struct list_head {
+	struct list_head *next, *prev;
+};
+
+#define LIST_HEAD_INIT(name) { &(name), &(name) }
+
+#define LIST_HEAD(name) \
+	struct list_head name = LIST_HEAD_INIT(name)
+
+#define INIT_LIST_HEAD(ptr) do { \
+	(ptr)->next = (ptr); (ptr)->prev = (ptr); \
+} while (0)
+
+/*
+ * Insert a new entry between two known consecutive entries.
+ *
+ * This is only for internal list manipulation where we know
+ * the prev/next entries already!
+ */
+static __inline__ void __list_add(struct list_head *new,
+				  struct list_head *prev,
+				  struct list_head *next)
+{
+	next->prev = new;
+	new->next = next;
+	new->prev = prev;
+	prev->next = new;
+}
+
+/**
+ * list_add - add a new entry
+ * @new: new entry to be added
+ * @head: list head to add it after
+ *
+ * Insert a new entry after the specified head.
+ * This is good for implementing stacks.
+ */
+static __inline__ void list_add(struct list_head *new, struct list_head *head)
+{
+	__list_add(new, head, head->next);
+}
+
+/**
+ * list_add_tail - add a new entry
+ * @new: new entry to be added
+ * @head: list head to add it before
+ *
+ * Insert a new entry before the specified head.
+ * This is useful for implementing queues.
+ */
+static __inline__ void list_add_tail(struct list_head *new,
+				     struct list_head *head)
+{
+	__list_add(new, head->prev, head);
+}
+
+/*
+ * Delete a list entry by making the prev/next entries
+ * point to each other.
+ *
+ * This is only for internal list manipulation where we know
+ * the prev/next entries already!
+ */
+static __inline__ void __list_del(struct list_head *prev,
+				  struct list_head *next)
+{
+	next->prev = prev;
+	prev->next = next;
+}
+
+/**
+ * list_del - deletes entry from list.
+ * @entry: the element to delete from the list.
+ * Note: list_empty on entry does not return true after this, the entry is
+ * in an undefined state.
+ */
+static __inline__ void list_del(struct list_head *entry)
+{
+	__list_del(entry->prev, entry->next);
+}
+
+/**
+ * list_del_init - deletes entry from list and reinitialize it.
+ * @entry: the element to delete from the list.
+ */
+static __inline__ void list_del_init(struct list_head *entry)
+{
+	__list_del(entry->prev, entry->next);
+	INIT_LIST_HEAD(entry);
+}
+
+/**
+ * list_empty - tests whether a list is empty
+ * @head: the list to test.
+ */
+static __inline__ int list_empty(struct list_head *head)
+{
+	return head->next == head;
+}
+
+/**
+ * list_splice - join two lists
+ * @list: the new list to add.
+ * @head: the place to add it in the first list.
+ */
+static __inline__ void list_splice(struct list_head *list,
+				   struct list_head *head)
+{
+	struct list_head *first = list->next;
+
+	if (first != list) {
+		struct list_head *last = list->prev;
+		struct list_head *at = head->next;
+
+		first->prev = head;
+		head->next = first;
+
+		last->next = at;
+		at->prev = last;
+	}
+}
+
+/**
+ * list_entry - get the struct for this entry
+ * @ptr:	the &struct list_head pointer.
+ * @type:	the type of the struct this is embedded in.
+ * @member:	the name of the list_struct within the struct.
+ */
+#define list_entry(ptr, type, member) \
+	((type *)((char *)(ptr)-(unsigned long)(&((type *)0)->member)))
+
+/**
+ * list_for_each	-	iterate over a list
+ * @pos:	the &struct list_head to use as a loop counter.
+ * @head:	the head for your list.
+ */
+#define list_for_each(pos, head) \
+	for (pos = (head)->next, prefetch(pos->next); pos != (head); \
+        	pos = pos->next, prefetch(pos->next))
+
+/**
+ * list_for_each_safe	-	iterate over a list safe against removal
+ *                              of list entry
+ * @pos:	the &struct list_head to use as a loop counter.
+ * @n:		another &struct list_head to use as temporary storage
+ * @head:	the head for your list.
+ */
+#define list_for_each_safe(pos, n, head) \
+	for (pos = (head)->next, n = pos->next; pos != (head); \
+		pos = n, n = pos->next)
+
+/*
+ * File types
+ */
+#define DT_UNKNOWN	0
+#define DT_FIFO		1
+#define DT_CHR		2
+#define DT_DIR		4
+#define DT_BLK		6
+#define DT_REG		8
+#define DT_LNK		10
+#define DT_SOCK		12
+#define DT_WHT		14
+
+#ifndef WIN32
+#include <sys/stat.h>
+#endif
+
+/*
+ * Attribute flags.  These should be or-ed together to figure out what
+ * has been changed!
+ */
+#define ATTR_MODE	1
+#define ATTR_UID	2
+#define ATTR_GID	4
+#define ATTR_SIZE	8
+#define ATTR_ATIME	16
+#define ATTR_MTIME	32
+#define ATTR_CTIME	64
+#define ATTR_ATIME_SET	128
+#define ATTR_MTIME_SET	256
+#define ATTR_FORCE	512	/* Not a change, but a change it */
+#define ATTR_ATTR_FLAG	1024
+
+struct iattr {
+	unsigned int ia_valid;
+	unsigned ia_mode;
+	unsigned ia_uid;
+	unsigned ia_gid;
+	unsigned ia_size;
+	unsigned ia_atime;
+	unsigned ia_mtime;
+	unsigned ia_ctime;
+	unsigned int ia_attr_flags;
+};
+
+#define KERN_DEBUG
+
+#else
+
+#ifndef WIN32
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/fs.h>
+#include <linux/stat.h>
+#endif
+
+#endif
+
+#if defined WIN32
+#undef new
+#endif
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/Kconfig linux/fs/yaffs/Kconfig
--- linux-2.6.35/fs/yaffs/Kconfig	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/Kconfig	2011-05-02 10:08:27.931588851 +0300
@@ -0,0 +1,129 @@
+#
+# YAFFS file system configurations
+#
+
+config YAFFS_FS
+	tristate "YAFFS2 file system support"
+	default n
+	depends on MTD
+	select YAFFS_YAFFS1
+	select YAFFS_YAFFS2
+	help
+	  YAFFS2, or Yet Another Flash Filing System, is a filing system
+	  optimised for NAND Flash chips.
+
+	  To compile the YAFFS2 file system support as a module, choose M here:
+	  the module will be called yaffs2.
+
+	  If unsure, say N.
+
+	  Further information on YAFFS2 is available at
+	  <http://www.aleph1.co.uk/yaffs/>.
+
+config YAFFS_YAFFS1
+	bool "512 byte / page devices"
+	depends on YAFFS_FS
+	default y
+	help
+	  Enable YAFFS1 support -- yaffs for 512 byte / page devices
+
+	  If unsure, say Y.
+
+config YAFFS_DOES_ECC
+	bool "Lets Yaffs do its own ECC"
+	depends on YAFFS_FS && YAFFS_YAFFS1
+	default n
+	help
+	  This enables Yaffs to use its own ECC functions instead of using
+	  the ones from the generic MTD-NAND driver.
+
+	  If unsure, say N.
+
+config YAFFS_ECC_WRONG_ORDER
+	bool "Use the same ecc byte order as Steven Hill's nand_ecc.c"
+	depends on YAFFS_FS && YAFFS_DOES_ECC
+	default n
+	help
+	  This makes yaffs_ecc.c use the same ecc byte order as
+	  Steven Hill's nand_ecc.c. If not set, then you get the
+	  same ecc byte order as SmartMedia.
+
+	  If unsure, say N.
+
+config YAFFS_YAFFS2
+	bool "2048 byte (or larger) / page devices"
+	depends on YAFFS_FS
+	default y
+	help
+	  Enable YAFFS2 support -- yaffs for >= 2048 byte / page larger devices
+
+	  If unsure, say Y.
+
+config YAFFS_AUTO_YAFFS2
+	bool "Autoselect yaffs2 format"
+	depends on YAFFS_YAFFS2
+	default y
+	help
+	  Without this, you need to explicitely use yaffs2 as the file
+	  system type. With this, you can say "yaffs" and yaffs or yaffs2
+          will be used depending on the device page size.
+
+	  If unsure, say Y.
+
+config YAFFS_DISABLE_LAZY_LOAD
+	bool "Disable lazy loading"
+	depends on YAFFS_YAFFS2
+	default n
+	help
+	  "Lazy loading" defers loading file details until they are
+	  required. This saves mount time, but makes the first look-up
+	  a bit longer.
+
+	  Lazy loading will only happen if enabled by this option being 'n'
+	  and if the appropriate tags are available, else yaffs2 will
+	  automatically fall back to immediate loading and do the right
+	  thing.
+
+	  Lazy laoding will be required by checkpointing.
+
+	  Setting this to 'y' will disable lazy loading.
+
+	  If unsure, say N.
+
+config YAFFS_DISABLE_WIDE_TNODES
+	bool "Turn off wide tnodes"
+	depends on YAFFS_FS
+	default n
+	help
+	  Wide tnodes are only used for large NAND arrays (>=32MB for
+	  512-byte page devices and >=128MB for 2k page devices). They use 
+	  slightly more RAM but are faster since they eliminate chunk group
+	  searching.
+
+	  Setting this to 'y' will force tnode width to 16 bits and make
+	  large arrays slower.
+
+	  If unsure, say N.
+
+config YAFFS_DISABLE_CHUNK_ERASED_CHECK
+	bool "Turn off debug chunk erase check"
+	depends on YAFFS_FS
+	default y
+	help
+	  Enabling this turns off the test that chunks are erased in flash
+	  before writing to them.  This is safe, since the write verification
+	  will fail.  Suggest enabling the test (ie. say N)
+	  during development to help debug things.
+
+	  If unsure, say Y.
+
+config YAFFS_SHORT_NAMES_IN_RAM
+	bool "Cache short names in RAM"
+	depends on YAFFS_FS
+	default y
+	help
+	  If this config is set, then short names are stored with the
+	  yaffs_Object.  This costs an extra 16 bytes of RAM per object,
+	  but makes look-ups faster.
+
+	  If unsure, say Y.
diff -puNrb linux-2.6.35/fs/yaffs/Makefile linux/fs/yaffs/Makefile
--- linux-2.6.35/fs/yaffs/Makefile	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/Makefile	2011-05-02 10:08:27.941590647 +0300
@@ -0,0 +1,10 @@
+#
+# Makefile for the linux YAFFS filesystem routines.
+#
+
+obj-$(CONFIG_YAFFS_FS) += yaffs.o
+
+yaffs-y := yaffs_ecc.o yaffs_ecc_mlc.o yaffs_fs.o yaffs_guts.o yaffs_checkptrw.o
+yaffs-y += yaffs_packedtags2.o yaffs_nand.o yaffs_qsort.o
+yaffs-y += yaffs_tagscompat.o yaffs_tagsvalidity.o
+yaffs-y += yaffs_mtdif.o yaffs_mtdif2.o
diff -puNrb linux-2.6.35/fs/yaffs/moduleconfig.h linux/fs/yaffs/moduleconfig.h
--- linux-2.6.35/fs/yaffs/moduleconfig.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/moduleconfig.h	2011-05-02 10:08:27.951545020 +0300
@@ -0,0 +1,32 @@
+#ifndef __YAFFS_CONFIG_H__
+#define __YAFFS_CONFIG_H__
+
+#ifdef YAFFS_OUT_OF_TREE
+
+/* DO NOT UNSET THESE THREE. YAFFS2 will not compile if you do. */
+#define CONFIG_YAFFS_FS
+#define CONFIG_YAFFS_YAFFS1
+#define CONFIG_YAFFS_YAFFS2
+
+/* These options are independent of each other.  Select those that matter. */
+
+/* Default: Not selected */
+/* Meaning: Yaffs does its own ECC, rather than using MTD ECC */
+//#define CONFIG_YAFFS_DOES_ECC
+
+/* Default: Not selected */
+/* Meaning: ECC byte order is 'wrong'.  Only meaningful if */
+/*          CONFIG_YAFFS_DOES_ECC is set */
+//#define CONFIG_YAFFS_ECC_WRONG_ORDER
+
+/* Default: Selected */
+/* Meaning: Disables testing whether chunks are erased before writing to them*/
+#define CONFIG_YAFFS_DISABLE_CHUNK_ERASED_CHECK
+
+/* Default: Selected */
+/* Meaning: Cache short names, taking more RAM, but faster look-ups */
+#define CONFIG_YAFFS_SHORT_NAMES_IN_RAM
+
+#endif /* YAFFS_OUT_OF_TREE */
+
+#endif /* __YAFFS_CONFIG_H__ */
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_checkptrw.c linux/fs/yaffs/yaffs_checkptrw.c
--- linux-2.6.35/fs/yaffs/yaffs_checkptrw.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_checkptrw.c	2011-05-02 10:08:27.961587463 +0300
@@ -0,0 +1,366 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+const char *yaffs_checkptrw_c_version =
+    "$Id: yaffs_checkptrw.c,v 1.4 2006/05/23 19:08:41 charles Exp $";
+
+
+#include "yaffs_checkptrw.h"
+
+
+static int yaffs_CheckpointSpaceOk(yaffs_Device *dev)
+{
+
+	int blocksAvailable = dev->nErasedBlocks - dev->nReservedBlocks;
+	
+	T(YAFFS_TRACE_CHECKPOINT,
+		(TSTR("checkpt blocks available = %d" TENDSTR),
+		blocksAvailable));
+		
+	
+	return (blocksAvailable <= 0) ? 0 : 1;
+}
+
+
+
+static int yaffs_CheckpointErase(yaffs_Device *dev)
+{
+	
+	int i;
+	
+
+	if(!dev->eraseBlockInNAND)	
+		return 0;
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("checking blocks %d to %d"TENDSTR),
+		dev->startBlock,dev->endBlock));
+		
+	for(i = dev->startBlock; i <= dev->endBlock; i++) {
+		yaffs_BlockInfo *bi = &dev->blockInfo[i];
+		if(bi->blockState == YAFFS_BLOCK_STATE_CHECKPOINT){
+			T(YAFFS_TRACE_CHECKPOINT,(TSTR("erasing checkpt block %d"TENDSTR),i));
+			if(dev->eraseBlockInNAND(dev,i)){
+				bi->blockState = YAFFS_BLOCK_STATE_EMPTY;
+				dev->nErasedBlocks++;
+				dev->nFreeChunks += dev->nChunksPerBlock;
+			}
+			else {
+				dev->markNANDBlockBad(dev,i);
+				bi->blockState = YAFFS_BLOCK_STATE_DEAD;
+			}
+		}
+	}
+	
+	dev->blocksInCheckpoint = 0;
+	
+	return 1;
+}
+
+
+static void yaffs_CheckpointFindNextErasedBlock(yaffs_Device *dev)
+{
+	int  i;
+	int blocksAvailable = dev->nErasedBlocks - dev->nReservedBlocks;
+		
+	if(dev->checkpointNextBlock >= 0 &&
+	   dev->checkpointNextBlock <= dev->endBlock &&
+	   blocksAvailable > 0){
+	
+		for(i = dev->checkpointNextBlock; i <= dev->endBlock; i++){
+			yaffs_BlockInfo *bi = &dev->blockInfo[i];
+			if(bi->blockState == YAFFS_BLOCK_STATE_EMPTY){
+				dev->checkpointNextBlock = i + 1;
+				dev->checkpointCurrentBlock = i;
+				T(YAFFS_TRACE_CHECKPOINT,(TSTR("allocating checkpt block %d"TENDSTR),i));
+				return;
+			}
+		}
+	}
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("out of checkpt blocks"TENDSTR)));
+	
+	dev->checkpointNextBlock = -1;
+	dev->checkpointCurrentBlock = -1;
+}
+
+static void yaffs_CheckpointFindNextCheckpointBlock(yaffs_Device *dev)
+{
+	int  i;
+	yaffs_ExtendedTags tags;
+	
+	if(dev->blocksInCheckpoint < dev->checkpointMaxBlocks) 
+		for(i = dev->checkpointNextBlock; i <= dev->endBlock; i++){
+			int chunk = i * dev->nChunksPerBlock;
+
+			dev->readChunkWithTagsFromNAND(dev,chunk,NULL,&tags);
+						      
+			if(tags.sequenceNumber == YAFFS_SEQUENCE_CHECKPOINT_DATA){
+				/* Right kind of block */
+				dev->checkpointNextBlock = tags.objectId;
+				dev->checkpointCurrentBlock = i;
+				dev->checkpointBlockList[dev->blocksInCheckpoint] = i;
+				dev->blocksInCheckpoint++;
+				T(YAFFS_TRACE_CHECKPOINT,(TSTR("found checkpt block %d"TENDSTR),i));
+				return;
+			}
+		}
+
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("found no more checkpt blocks"TENDSTR)));
+
+	dev->checkpointNextBlock = -1;
+	dev->checkpointCurrentBlock = -1;
+}
+
+
+int yaffs_CheckpointOpen(yaffs_Device *dev, int forWriting)
+{
+	
+	/* Got the functions we need? */
+	if (!dev->writeChunkWithTagsToNAND ||
+	    !dev->readChunkWithTagsFromNAND ||
+	    !dev->eraseBlockInNAND ||
+	    !dev->markNANDBlockBad)
+		return 0;
+
+	if(forWriting && !yaffs_CheckpointSpaceOk(dev))
+		return 0;
+			
+	if(!dev->checkpointBuffer)
+		dev->checkpointBuffer = YMALLOC_DMA(dev->nBytesPerChunk);
+	if(!dev->checkpointBuffer)
+		return 0;
+
+	
+	dev->checkpointPageSequence = 0;
+	
+	dev->checkpointOpenForWrite = forWriting;
+	
+	dev->checkpointByteCount = 0;
+	dev->checkpointCurrentBlock = -1;
+	dev->checkpointCurrentChunk = -1;
+	dev->checkpointNextBlock = dev->startBlock;
+	
+	/* Erase all the blocks in the checkpoint area */
+	if(forWriting){
+		memset(dev->checkpointBuffer,0,dev->nBytesPerChunk);
+		dev->checkpointByteOffset = 0;
+		return yaffs_CheckpointErase(dev);
+		
+		
+	} else {
+		int i;
+		/* Set to a value that will kick off a read */
+		dev->checkpointByteOffset = dev->nBytesPerChunk;
+		/* A checkpoint block list of 1 checkpoint block per 16 block is (hopefully)
+		 * going to be way more than we need */
+		dev->blocksInCheckpoint = 0;
+		dev->checkpointMaxBlocks = (dev->endBlock - dev->startBlock)/16 + 2;
+		dev->checkpointBlockList = YMALLOC(sizeof(int) * dev->checkpointMaxBlocks);
+		for(i = 0; i < dev->checkpointMaxBlocks; i++)
+			dev->checkpointBlockList[i] = -1;
+	}
+	
+	return 1;
+}
+
+static int yaffs_CheckpointFlushBuffer(yaffs_Device *dev)
+{
+
+	int chunk;
+
+	yaffs_ExtendedTags tags;
+	
+	if(dev->checkpointCurrentBlock < 0){
+		yaffs_CheckpointFindNextErasedBlock(dev);
+		dev->checkpointCurrentChunk = 0;
+	}
+	
+	if(dev->checkpointCurrentBlock < 0)
+		return 0;
+	
+	tags.chunkDeleted = 0;
+	tags.objectId = dev->checkpointNextBlock; /* Hint to next place to look */
+	tags.chunkId = dev->checkpointPageSequence + 1;
+	tags.sequenceNumber =  YAFFS_SEQUENCE_CHECKPOINT_DATA;
+	tags.byteCount = dev->nBytesPerChunk;
+	if(dev->checkpointCurrentChunk == 0){
+		/* First chunk we write for the block? Set block state to
+		   checkpoint */
+		yaffs_BlockInfo *bi = &dev->blockInfo[dev->checkpointCurrentBlock];
+		bi->blockState = YAFFS_BLOCK_STATE_CHECKPOINT;
+		dev->blocksInCheckpoint++;
+	}
+	
+	chunk = dev->checkpointCurrentBlock * dev->nChunksPerBlock + dev->checkpointCurrentChunk;
+		
+	dev->writeChunkWithTagsToNAND(dev,chunk,dev->checkpointBuffer,&tags);
+	dev->checkpointByteOffset = 0;
+	dev->checkpointPageSequence++;	   
+	dev->checkpointCurrentChunk++;
+	if(dev->checkpointCurrentChunk >= dev->nChunksPerBlock){
+		dev->checkpointCurrentChunk = 0;
+		dev->checkpointCurrentBlock = -1;
+	}
+	memset(dev->checkpointBuffer,0,dev->nBytesPerChunk);
+	
+	return 1;
+}
+
+
+int yaffs_CheckpointWrite(yaffs_Device *dev,const void *data, int nBytes)
+{
+	int i=0;
+	int ok = 1;
+
+	
+	__u8 * dataBytes = (__u8 *)data;
+	
+	
+
+	if(!dev->checkpointBuffer)
+		return 0;
+
+	while(i < nBytes && ok) {
+		
+
+		
+		 dev->checkpointBuffer[dev->checkpointByteOffset] = *dataBytes ;
+		dev->checkpointByteOffset++;
+		i++;
+		dataBytes++;
+		dev->checkpointByteCount++;
+		
+		
+		if(dev->checkpointByteOffset < 0 ||
+		   dev->checkpointByteOffset >= dev->nBytesPerChunk) 
+			ok = yaffs_CheckpointFlushBuffer(dev);
+
+	}
+	
+	return 	i;
+}
+
+int yaffs_CheckpointRead(yaffs_Device *dev, void *data, int nBytes)
+{
+	int i=0;
+	int ok = 1;
+	yaffs_ExtendedTags tags;
+
+	
+	int chunk;
+
+	__u8 *dataBytes = (__u8 *)data;
+		
+	if(!dev->checkpointBuffer)
+		return 0;
+
+	while(i < nBytes && ok) {
+	
+	
+		if(dev->checkpointByteOffset < 0 ||
+		   dev->checkpointByteOffset >= dev->nBytesPerChunk) {
+		   
+		   	if(dev->checkpointCurrentBlock < 0){
+				yaffs_CheckpointFindNextCheckpointBlock(dev);
+				dev->checkpointCurrentChunk = 0;
+			}
+			
+			if(dev->checkpointCurrentBlock < 0)
+				ok = 0;
+			else {
+			
+				chunk = dev->checkpointCurrentBlock * dev->nChunksPerBlock + 
+				          dev->checkpointCurrentChunk;
+
+	   			/* read in the next chunk */
+	   			/* printf("read checkpoint page %d\n",dev->checkpointPage); */
+				dev->readChunkWithTagsFromNAND(dev, chunk, 
+							       dev->checkpointBuffer,
+							      &tags);
+						      
+				if(tags.chunkId != (dev->checkpointPageSequence + 1) ||
+				   tags.sequenceNumber != YAFFS_SEQUENCE_CHECKPOINT_DATA)
+				   ok = 0;
+
+				dev->checkpointByteOffset = 0;
+				dev->checkpointPageSequence++;
+				dev->checkpointCurrentChunk++;
+			
+				if(dev->checkpointCurrentChunk >= dev->nChunksPerBlock)
+					dev->checkpointCurrentBlock = -1;
+			}
+		}
+		
+		if(ok){
+			*dataBytes = dev->checkpointBuffer[dev->checkpointByteOffset];
+			dev->checkpointByteOffset++;
+			i++;
+			dataBytes++;
+			dev->checkpointByteCount++;
+		}
+	}
+	
+	return 	i;
+}
+
+int yaffs_CheckpointClose(yaffs_Device *dev)
+{
+
+	if(dev->checkpointOpenForWrite){	
+		if(dev->checkpointByteOffset != 0)
+			yaffs_CheckpointFlushBuffer(dev);
+	} else {
+		int i;
+		for(i = 0; i < dev->blocksInCheckpoint && dev->checkpointBlockList[i] >= 0; i++){
+			yaffs_BlockInfo *bi = &dev->blockInfo[dev->checkpointBlockList[i]];
+			if(bi->blockState == YAFFS_BLOCK_STATE_EMPTY)
+				bi->blockState = YAFFS_BLOCK_STATE_CHECKPOINT;
+			else {
+				// Todo this looks odd...
+			}
+		}
+		YFREE(dev->checkpointBlockList);
+		dev->checkpointBlockList = NULL;
+	}
+
+	dev->nFreeChunks -= dev->blocksInCheckpoint * dev->nChunksPerBlock;
+	dev->nErasedBlocks -= dev->blocksInCheckpoint;
+
+		
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("checkpoint byte count %d" TENDSTR),
+			dev->checkpointByteCount));
+			
+	if(dev->checkpointBuffer){
+		/* free the buffer */	
+		YFREE(dev->checkpointBuffer);
+		dev->checkpointBuffer = NULL;
+		return 1;
+	}
+	else
+		return 0;
+	
+}
+
+int yaffs_CheckpointInvalidateStream(yaffs_Device *dev)
+{
+	/* Erase the first checksum block */
+
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("checkpoint invalidate"TENDSTR)));
+
+	if(!yaffs_CheckpointSpaceOk(dev))
+		return 0;
+
+	return yaffs_CheckpointErase(dev);
+}
+
+
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_checkptrw.h linux/fs/yaffs/yaffs_checkptrw.h
--- linux-2.6.35/fs/yaffs/yaffs_checkptrw.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_checkptrw.h	2011-05-02 10:08:27.971591194 +0300
@@ -0,0 +1,18 @@
+#ifndef __YAFFS_CHECKPTRW_H__
+#define __YAFFS_CHECKPTRW_H__
+
+#include "yaffs_guts.h"
+
+int yaffs_CheckpointOpen(yaffs_Device *dev, int forWriting);
+
+int yaffs_CheckpointWrite(yaffs_Device *dev,const void *data, int nBytes);
+
+int yaffs_CheckpointRead(yaffs_Device *dev,void *data, int nBytes);
+
+int yaffs_CheckpointClose(yaffs_Device *dev);
+
+int yaffs_CheckpointInvalidateStream(yaffs_Device *dev);
+
+
+#endif
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_ecc.c linux/fs/yaffs/yaffs_ecc.c
--- linux-2.6.35/fs/yaffs/yaffs_ecc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_ecc.c	2011-05-02 10:08:27.991589266 +0300
@@ -0,0 +1,329 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * yaffs_ecc.c: ECC generation/correction algorithms.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * version 2.1 as published by the Free Software Foundation.
+ */
+
+ /*
+  * This code implements the ECC algorithm used in SmartMedia.
+  *
+  * The ECC comprises 22 bits of parity information and is stuffed into 3 bytes. 
+  * The two unused bit are set to 1.
+  * The ECC can correct single bit errors in a 256-byte page of data. Thus, two such ECC 
+  * blocks are used on a 512-byte NAND page.
+  *
+  */
+
+/* Table generated by gen-ecc.c
+ * Using a table means we do not have to calculate p1..p4 and p1'..p4'
+ * for each byte of data. These are instead provided in a table in bits7..2.
+ * Bit 0 of each entry indicates whether the entry has an odd or even parity, and therefore
+ * this bytes influence on the line parity.
+ */
+
+const char *yaffs_ecc_c_version =
+    "$Id: yaffs_ecc.c,v 1.6 2005/08/11 02:51:49 charles Exp $";
+
+#include "yportenv.h"
+
+#include "yaffs_ecc.h"
+
+static const unsigned char column_parity_table[] = {
+	0x00, 0x55, 0x59, 0x0c, 0x65, 0x30, 0x3c, 0x69,
+	0x69, 0x3c, 0x30, 0x65, 0x0c, 0x59, 0x55, 0x00,
+	0x95, 0xc0, 0xcc, 0x99, 0xf0, 0xa5, 0xa9, 0xfc,
+	0xfc, 0xa9, 0xa5, 0xf0, 0x99, 0xcc, 0xc0, 0x95,
+	0x99, 0xcc, 0xc0, 0x95, 0xfc, 0xa9, 0xa5, 0xf0,
+	0xf0, 0xa5, 0xa9, 0xfc, 0x95, 0xc0, 0xcc, 0x99,
+	0x0c, 0x59, 0x55, 0x00, 0x69, 0x3c, 0x30, 0x65,
+	0x65, 0x30, 0x3c, 0x69, 0x00, 0x55, 0x59, 0x0c,
+	0xa5, 0xf0, 0xfc, 0xa9, 0xc0, 0x95, 0x99, 0xcc,
+	0xcc, 0x99, 0x95, 0xc0, 0xa9, 0xfc, 0xf0, 0xa5,
+	0x30, 0x65, 0x69, 0x3c, 0x55, 0x00, 0x0c, 0x59,
+	0x59, 0x0c, 0x00, 0x55, 0x3c, 0x69, 0x65, 0x30,
+	0x3c, 0x69, 0x65, 0x30, 0x59, 0x0c, 0x00, 0x55,
+	0x55, 0x00, 0x0c, 0x59, 0x30, 0x65, 0x69, 0x3c,
+	0xa9, 0xfc, 0xf0, 0xa5, 0xcc, 0x99, 0x95, 0xc0,
+	0xc0, 0x95, 0x99, 0xcc, 0xa5, 0xf0, 0xfc, 0xa9,
+	0xa9, 0xfc, 0xf0, 0xa5, 0xcc, 0x99, 0x95, 0xc0,
+	0xc0, 0x95, 0x99, 0xcc, 0xa5, 0xf0, 0xfc, 0xa9,
+	0x3c, 0x69, 0x65, 0x30, 0x59, 0x0c, 0x00, 0x55,
+	0x55, 0x00, 0x0c, 0x59, 0x30, 0x65, 0x69, 0x3c,
+	0x30, 0x65, 0x69, 0x3c, 0x55, 0x00, 0x0c, 0x59,
+	0x59, 0x0c, 0x00, 0x55, 0x3c, 0x69, 0x65, 0x30,
+	0xa5, 0xf0, 0xfc, 0xa9, 0xc0, 0x95, 0x99, 0xcc,
+	0xcc, 0x99, 0x95, 0xc0, 0xa9, 0xfc, 0xf0, 0xa5,
+	0x0c, 0x59, 0x55, 0x00, 0x69, 0x3c, 0x30, 0x65,
+	0x65, 0x30, 0x3c, 0x69, 0x00, 0x55, 0x59, 0x0c,
+	0x99, 0xcc, 0xc0, 0x95, 0xfc, 0xa9, 0xa5, 0xf0,
+	0xf0, 0xa5, 0xa9, 0xfc, 0x95, 0xc0, 0xcc, 0x99,
+	0x95, 0xc0, 0xcc, 0x99, 0xf0, 0xa5, 0xa9, 0xfc,
+	0xfc, 0xa9, 0xa5, 0xf0, 0x99, 0xcc, 0xc0, 0x95,
+	0x00, 0x55, 0x59, 0x0c, 0x65, 0x30, 0x3c, 0x69,
+	0x69, 0x3c, 0x30, 0x65, 0x0c, 0x59, 0x55, 0x00,
+};
+
+/* Count the bits in an unsigned char or a U32 */
+
+static int yaffs_CountBits(unsigned char x)
+{
+	int r = 0;
+	while (x) {
+		if (x & 1)
+			r++;
+		x >>= 1;
+	}
+	return r;
+}
+
+static int yaffs_CountBits32(unsigned x)
+{
+	int r = 0;
+	while (x) {
+		if (x & 1)
+			r++;
+		x >>= 1;
+	}
+	return r;
+}
+
+/* Calculate the ECC for a 256-byte block of data */
+void yaffs_ECCCalculate(const unsigned char *data, unsigned char *ecc)
+{
+	unsigned int i;
+
+	unsigned char col_parity = 0;
+	unsigned char line_parity = 0;
+	unsigned char line_parity_prime = 0;
+	unsigned char t;
+	unsigned char b;
+
+	for (i = 0; i < 256; i++) {
+		b = column_parity_table[*data++];
+		col_parity ^= b;
+
+		if (b & 0x01)	// odd number of bits in the byte
+		{
+			line_parity ^= i;
+			line_parity_prime ^= ~i;
+		}
+
+	}
+
+	ecc[2] = (~col_parity) | 0x03;
+
+	t = 0;
+	if (line_parity & 0x80)
+		t |= 0x80;
+	if (line_parity_prime & 0x80)
+		t |= 0x40;
+	if (line_parity & 0x40)
+		t |= 0x20;
+	if (line_parity_prime & 0x40)
+		t |= 0x10;
+	if (line_parity & 0x20)
+		t |= 0x08;
+	if (line_parity_prime & 0x20)
+		t |= 0x04;
+	if (line_parity & 0x10)
+		t |= 0x02;
+	if (line_parity_prime & 0x10)
+		t |= 0x01;
+	ecc[1] = ~t;
+
+	t = 0;
+	if (line_parity & 0x08)
+		t |= 0x80;
+	if (line_parity_prime & 0x08)
+		t |= 0x40;
+	if (line_parity & 0x04)
+		t |= 0x20;
+	if (line_parity_prime & 0x04)
+		t |= 0x10;
+	if (line_parity & 0x02)
+		t |= 0x08;
+	if (line_parity_prime & 0x02)
+		t |= 0x04;
+	if (line_parity & 0x01)
+		t |= 0x02;
+	if (line_parity_prime & 0x01)
+		t |= 0x01;
+	ecc[0] = ~t;
+
+#ifdef CONFIG_YAFFS_ECC_WRONG_ORDER
+	// Swap the bytes into the wrong order
+	t = ecc[0];
+	ecc[0] = ecc[1];
+	ecc[1] = t;
+#endif
+}
+
+
+/* Correct the ECC on a 256 byte block of data */
+
+int yaffs_ECCCorrect(unsigned char *data, unsigned char *read_ecc,
+		     const unsigned char *test_ecc)
+{
+	unsigned char d0, d1, d2;	/* deltas */
+
+	d0 = read_ecc[0] ^ test_ecc[0];
+	d1 = read_ecc[1] ^ test_ecc[1];
+	d2 = read_ecc[2] ^ test_ecc[2];
+
+	if ((d0 | d1 | d2) == 0)
+		return 0; /* no error */
+
+	if (((d0 ^ (d0 >> 1)) & 0x55) == 0x55 &&
+	    ((d1 ^ (d1 >> 1)) & 0x55) == 0x55 &&
+	    ((d2 ^ (d2 >> 1)) & 0x54) == 0x54) {
+		/* Single bit (recoverable) error in data */
+
+		unsigned byte;
+		unsigned bit;
+
+#ifdef CONFIG_YAFFS_ECC_WRONG_ORDER
+		// swap the bytes to correct for the wrong order
+		unsigned char t;
+
+		t = d0;
+		d0 = d1;
+		d1 = t;
+#endif
+
+		bit = byte = 0;
+
+		if (d1 & 0x80)
+			byte |= 0x80;
+		if (d1 & 0x20)
+			byte |= 0x40;
+		if (d1 & 0x08)
+			byte |= 0x20;
+		if (d1 & 0x02)
+			byte |= 0x10;
+		if (d0 & 0x80)
+			byte |= 0x08;
+		if (d0 & 0x20)
+			byte |= 0x04;
+		if (d0 & 0x08)
+			byte |= 0x02;
+		if (d0 & 0x02)
+			byte |= 0x01;
+
+		if (d2 & 0x80)
+			bit |= 0x04;
+		if (d2 & 0x20)
+			bit |= 0x02;
+		if (d2 & 0x08)
+			bit |= 0x01;
+
+		data[byte] ^= (1 << bit);
+
+		return 1; /* Corrected the error */
+	}
+
+	if ((yaffs_CountBits(d0) + 
+	     yaffs_CountBits(d1) + 
+	     yaffs_CountBits(d2)) ==  1) {
+		/* Reccoverable error in ecc */
+
+		read_ecc[0] = test_ecc[0];
+		read_ecc[1] = test_ecc[1];
+		read_ecc[2] = test_ecc[2];
+
+		return 1; /* Corrected the error */
+	}
+	
+	/* Unrecoverable error */
+
+	return -1;
+
+}
+
+
+/*
+ * ECCxxxOther does ECC calcs on arbitrary n bytes of data
+ */
+void yaffs_ECCCalculateOther(const unsigned char *data, unsigned nBytes,
+			     yaffs_ECCOther * eccOther)
+{
+	unsigned int i;
+
+	unsigned char col_parity = 0;
+	unsigned line_parity = 0;
+	unsigned line_parity_prime = 0;
+	unsigned char b;
+
+	for (i = 0; i < nBytes; i++) {
+		b = column_parity_table[*data++];
+		col_parity ^= b;
+
+		if (b & 0x01)	 {
+			/* odd number of bits in the byte */
+			line_parity ^= i;
+			line_parity_prime ^= ~i;
+		}
+
+	}
+
+	eccOther->colParity = (col_parity >> 2) & 0x3f;
+	eccOther->lineParity = line_parity;
+	eccOther->lineParityPrime = line_parity_prime;
+}
+
+int yaffs_ECCCorrectOther(unsigned char *data, unsigned nBytes,
+			  yaffs_ECCOther * read_ecc,
+			  const yaffs_ECCOther * test_ecc)
+{
+	unsigned char cDelta;	/* column parity delta */
+	unsigned lDelta;	/* line parity delta */
+	unsigned lDeltaPrime;	/* line parity delta */
+	unsigned bit;
+
+	cDelta = read_ecc->colParity ^ test_ecc->colParity;
+	lDelta = read_ecc->lineParity ^ test_ecc->lineParity;
+	lDeltaPrime = read_ecc->lineParityPrime ^ test_ecc->lineParityPrime;
+
+	if ((cDelta | lDelta | lDeltaPrime) == 0)
+		return 0; /* no error */
+
+	if (lDelta == ~lDeltaPrime && (((cDelta ^ (cDelta >> 1)) & 0x15) == 0x15))
+	{
+		/* Single bit (recoverable) error in data */
+
+		bit = 0;
+
+		if (cDelta & 0x20)
+			bit |= 0x04;
+		if (cDelta & 0x08)
+			bit |= 0x02;
+		if (cDelta & 0x02)
+			bit |= 0x01;
+
+		data[lDelta] ^= (1 << bit);
+
+		return 1; /* corrected */
+	}
+
+	if ((yaffs_CountBits32(lDelta) + yaffs_CountBits32(lDeltaPrime) +
+	     yaffs_CountBits(cDelta)) == 1) {
+		/* Reccoverable error in ecc */
+
+		*read_ecc = *test_ecc;
+		return 1; /* corrected */
+	}
+
+	/* Unrecoverable error */
+
+	return -1;
+
+}
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_ecc.h linux/fs/yaffs/yaffs_ecc.h
--- linux-2.6.35/fs/yaffs/yaffs_ecc.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_ecc.h	2011-05-02 10:08:28.001588983 +0300
@@ -0,0 +1,44 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * yaffs_ecc.c: ECC generation/correction algorithms.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+ /*
+  * This code implements the ECC algorithm used in SmartMedia.
+  *
+  * The ECC comprises 22 bits of parity information and is stuffed into 3 bytes. 
+  * The two unused bit are set to 1.
+  * The ECC can correct single bit errors in a 256-byte page of data. Thus, two such ECC 
+  * blocks are used on a 512-byte NAND page.
+  *
+  */
+
+#ifndef __YAFFS_ECC_H__
+#define __YAFFS_ECC_H__
+
+typedef struct {
+	unsigned char colParity;
+	unsigned lineParity;
+	unsigned lineParityPrime;
+} yaffs_ECCOther;
+
+void yaffs_ECCCalculate(const unsigned char *data, unsigned char *ecc);
+int yaffs_ECCCorrect(unsigned char *data, unsigned char *read_ecc,
+		     const unsigned char *test_ecc);
+
+void yaffs_ECCCalculateOther(const unsigned char *data, unsigned nBytes,
+			     yaffs_ECCOther * ecc);
+int yaffs_ECCCorrectOther(unsigned char *data, unsigned nBytes,
+			  yaffs_ECCOther * read_ecc,
+			  const yaffs_ECCOther * test_ecc);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_ecc_mlc.c linux/fs/yaffs/yaffs_ecc_mlc.c
--- linux-2.6.35/fs/yaffs/yaffs_ecc_mlc.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_ecc_mlc.c	2011-05-02 10:08:28.011545272 +0300
@@ -0,0 +1,301 @@
+#include "yportenv.h"
+#include "yaffs_ecc_mlc.h"
+
+/*
+
+This is BCH(248,232,5) code with the following parameters:
+p(x) = 100011101
+g(x) = 10110111101100011
+g(x) = 111101110010110110100001011111101
+*/
+
+#define bch_assert(x)							\
+	if (!(x)) {							\
+		printk("yaffs ecc ASSERT at line %d\n", __LINE__);	\
+	}
+
+#define PRIME 0x8E
+//g(x) = 1 1110 1110 0101 1011 0100 0010 1111 1101
+#define gen1 0xEE5B42FC
+#define gen2 0x1
+
+#define POLY_SIZE 9
+//this is the length of error location polynomial, and root vector
+//it is way longer than necessary, but makes me sleep better
+#define LPOLY_SIZE POLY_SIZE + 2
+#define CHECK_BYTES 4
+#define CHECK_BITS (CHECK_BYTES * 8 - 0)
+#define DATA_BYTES 16
+#define DATA_BITS (DATA_BYTES * 8)
+#define CODE_BYTES (DATA_BYTES + CHECK_BYTES)
+#define CODE_BITS (DATA_BITS + CHECK_BITS)
+#define UNIT_SHIFT 8
+#define MODULO ((1 << UNIT_SHIFT) - 1)
+
+//Type TPNUM is used for tabular values from the "mod PRIME(x)" group.
+typedef unsigned char tpnum_t;
+//Type PNUM is used for temporary values from the "mod PRIME(x)" group.
+typedef int pnum_t;
+
+static void encode(const unsigned char *d, unsigned char *dst) {
+    const unsigned char *i;
+    unsigned sum1 = 0, sum2 = 0;
+
+    for (i = d; i != d + DATA_BYTES; i += 1) {
+	sum1 ^= *i;
+#define SHR(h, l, b) (b) ? (((h) << b) | ((l) >> (32 - b))) : (h)
+#define STEP(b) \
+	if (sum1 & (1 << (b))) { \
+	    sum1 ^= SHR(gen1, 0, b); \
+	    sum2 ^= SHR(gen2, gen1, b); \
+	}
+#define SHIFT(N) \
+	sum1 >>= N; \
+	sum1 |= sum2 << (32 - N); \
+	sum2 >>= N
+	STEP(0); STEP(1); STEP(2); STEP(3);
+	SHIFT(4);
+	STEP(0); STEP(1); STEP(2); STEP(3);
+	SHIFT(4);
+#undef SHIFT
+#undef STEP
+#undef SHR
+    }
+    bch_assert(!sum2);
+#define SAVE(n, i) *(dst++) = (sum##n >> i * 8) & 0xff
+    SAVE(1, 0); SAVE(1, 1); SAVE(1, 2); SAVE(1, 3);
+#undef SAVE
+}
+
+static tpnum_t pow[MODULO + 1];
+static tpnum_t log[MODULO + 1];
+
+static void precalc(void) {
+    int i;
+    pnum_t a = 1 << (UNIT_SHIFT - 1);
+    memset(pow, 0, sizeof(pow));
+    memset(log, 0, sizeof(log));
+    for (i = 0; i != MODULO; ++i) {
+	bch_assert(!log[a]);
+	bch_assert(a <= MODULO);
+	pow[i] = a;
+	log[a] = i;
+	if (a & 1) a ^= PRIME << 1;
+	a >>= 1;
+    }
+    bch_assert(a == (1 << (UNIT_SHIFT - 1)));
+    log[0] = MODULO;
+}
+
+static void syndrome(unsigned char *d, tpnum_t *s) {
+    int i;
+    s[0] = MODULO;
+    for (i = 1; i != POLY_SIZE; i += 2) {
+	pnum_t syn0 = 0;
+	pnum_t syn1 = 0;
+	pnum_t si0 = (i * CODE_BITS) % MODULO;
+	pnum_t si1 = ((i + 1) * CODE_BITS) % MODULO;
+	unsigned char *i2;
+	for (i2 = d; i2 != d + CODE_BYTES - !!(CODE_BITS % 8); ++i2) {
+	    unsigned char b = *i2;
+#define STEP(n) \
+	    if (si0 < i) si0 += MODULO; \
+	    si0 -= i; \
+	    if (si1 <= i) si1 += MODULO; \
+	    si1 -= i + 1; \
+	    if (b & (1 << (n))) { \
+		syn0 ^= pow[si0]; \
+		syn1 ^= pow[si1]; \
+	    }
+
+	    STEP(0); STEP(1); STEP(2); STEP(3);
+	    STEP(4); STEP(5); STEP(6); STEP(7);
+	}
+	if (CODE_BITS % 8) {
+	    unsigned char b = *i2;
+#define SSTEP(n) if (CODE_BITS % 8 > (n)) { STEP(n); } else (void) 0
+	    SSTEP(0); SSTEP(1); SSTEP(2); SSTEP(3);
+	    SSTEP(4); SSTEP(5); SSTEP(6); SSTEP(7);
+#undef SSTEP
+	}
+#undef STEP
+	bch_assert(!si0);
+	bch_assert(!si1);
+	s[i] = log[syn0];
+	s[i + 1] = log[syn1];
+    }
+}
+
+static int fix_single(unsigned char *d, tpnum_t *s) {
+    int i;
+    pnum_t dif = s[1];
+    if (dif == MODULO) return 0;
+    for (i = 2; i != POLY_SIZE; ++i) {
+        pnum_t t = s[i] - s[i - 1];
+
+	if (s[i] == MODULO) return 0;
+	if (t < 0) t += MODULO;
+	if (t != dif) return 0;
+    }
+    if (dif >= CODE_BITS) return 0;
+    dif = CODE_BITS - 1 - dif;
+    d[dif / 8] ^= 1 << (dif % 8);
+    printk("yaffs MLC single fix (orig %d pos %d)\n",
+	   (d[dif / 8] >> (dif % 8)) & 1, (int)dif);
+    return 1;
+}
+
+static inline pnum_t logmul(pnum_t x1, pnum_t x2) {
+    bch_assert(x1 <= MODULO);
+    bch_assert(x2 <= MODULO);
+    if (x1 == MODULO || x2 == MODULO) return MODULO; //multiplication by 0
+    x1 += x2;
+    if (x1 >= MODULO) x1 -= MODULO;
+    bch_assert(x1 < MODULO);
+    return x1;
+}
+
+static int bm(tpnum_t *s, tpnum_t *l) {
+    int n, i;
+    int k = -1;
+    int len = 0;
+    pnum_t d;
+    tpnum_t dif[LPOLY_SIZE];
+
+    for (i = 0; i != LPOLY_SIZE; ++i) l[i] = dif[i] = MODULO;
+    l[0] = dif[1] = 0;
+
+    for (n = 0; n < POLY_SIZE - 1; n += 1) {
+	d = 0;
+	for (i = 0; i <= len; ++i) d ^= pow[logmul(s[n - i + 1], l[i])];
+	if (n & 1) bch_assert(!d);
+	if (!d) {
+	    for (i = LPOLY_SIZE - 1; i != 0; --i) dif[i] = dif[i - 1];
+	    dif[0] = MODULO;
+	    continue;
+	}
+	d = log[d];
+	if (len < n - k) {
+	    int len1 = n - k;
+	    k = n - len;
+	    len = len1;
+
+	    for (i = LPOLY_SIZE - 1; i >= 0; --i) {
+		pnum_t t = (i > 0) ? t = l[i - 1] : MODULO;
+		if (d) t = logmul(t, MODULO - d);
+		l[i] = log[pow[l[i]] ^ pow[logmul(d, dif[i])]];
+		dif[i] = t;
+	    }
+	}
+	else {
+	    for (i = LPOLY_SIZE - 1; i >= 0; --i) {
+		l[i] = log[pow[l[i]] ^ pow[logmul(d, dif[i])]];
+		dif[i] = (i > 0) ? dif[i - 1] : MODULO;
+	    }
+	}
+    }
+    return len;
+}
+
+static int chien(tpnum_t *l, tpnum_t *roots) {
+    int i, ret, max, num;
+    tpnum_t poly[LPOLY_SIZE];
+    tpnum_t step[LPOLY_SIZE];
+    pnum_t i2 = 0;
+    ret = 0;
+    max = 0;
+    num = 0;
+    for (i = 0; i != LPOLY_SIZE; ++i) {
+	poly[i] = MODULO;
+	step[i] = MODULO;
+	if (l[i] != MODULO) {
+	    if (i) {
+		poly[num] = l[i];
+		step[num] = i;
+		++num;
+	    }
+	    max = i + 1;
+	}
+    }
+    if (max < 1) return 0;
+    for (i2 = 0; i2 != MODULO; ++i2) {
+	pnum_t val = pow[l[0]];
+	pnum_t x;
+
+#define STEP(n) \
+	x = poly[n]; \
+	val ^= pow[x]; \
+	x += step[n]; \
+	if (x >= MODULO) x -= MODULO; \
+	poly[n] = x; \
+
+	STEP(0); STEP(1); STEP(2);
+
+	for (i = 3; i < num; ++i) {
+	    x = poly[i];
+	    val ^= pow[x];
+	    x += step[i];
+	    if (x >= MODULO) x -= MODULO;
+	    poly[i] = x;
+	}
+	if (!val) {
+	    roots[ret++] = i2;
+	    //break when all roots found;
+	    if (ret == max - 1) break;
+	}
+    }
+    return ret;
+}
+
+
+void yaffs_ECCCalculateMLCOther(unsigned char *data) {
+    encode(data, data + DATA_BYTES);
+}
+
+static int ecc_fix_mult(unsigned char *data, tpnum_t s[POLY_SIZE]) {
+    int rnum;
+    int i;
+    int len;
+    tpnum_t roots[POLY_SIZE];
+    tpnum_t l[LPOLY_SIZE];
+
+    len = bm(s, l);
+    rnum = chien(l, roots);
+    if (rnum != len) {
+	    printk("yaffs MLC failed to fix %d vs %d\n", rnum, len);
+	    return -1;
+    }
+    for (i = 0; i != rnum; ++i) {
+	int pos = roots[i] - (MODULO - CODE_BITS) - 1;
+	if (pos < 0) pos += MODULO;
+	bch_assert(pos < CODE_BITS);
+	if (pos >= CODE_BITS) {
+		printk("yaffs MLC failed to fix %d/%d pos %d\n", i, rnum, pos);
+		return -1;
+	}
+	data[pos / 8] ^= 1 << (pos % 8);
+	printk("yaffs MLC mult fix (orig %d pos %d)\n",
+	       (data[pos / 8] >> (pos % 8)) & 1, pos);
+    }
+    printk("yaffs MLC fixed %d\n", rnum);
+    return 1;
+}
+
+static int ecc_fix(unsigned char *data) {
+    tpnum_t s[POLY_SIZE];
+    syndrome(data, s);
+    if (fix_single(data, s)) {
+	    return 1;
+    }
+    return ecc_fix_mult(data, s);
+}
+
+int yaffs_ECCCorrectMLCOther(unsigned char *data) {
+    unsigned char ecc[CHECK_BYTES];
+
+    encode(data, ecc);
+    if (!memcmp(data + DATA_BYTES, ecc, CHECK_BYTES)) return 0;
+    if (!*pow) precalc();
+    return ecc_fix(data);
+}
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_ecc_mlc.h linux/fs/yaffs/yaffs_ecc_mlc.h
--- linux-2.6.35/fs/yaffs/yaffs_ecc_mlc.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_ecc_mlc.h	2011-05-02 10:08:28.021544490 +0300
@@ -0,0 +1,5 @@
+#ifndef YAFFS_ECC_MLC_H
+#define YAFFS_ECC_MLC_H
+void yaffs_ECCCalculateMLCOther(unsigned char *data);
+int yaffs_ECCCorrectMLCOther(unsigned char *data);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_fs.c linux/fs/yaffs/yaffs_fs.c
--- linux-2.6.35/fs/yaffs/yaffs_fs.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_fs.c	2011-05-02 10:08:28.041587322 +0300
@@ -0,0 +1,2140 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system.
+ * yaffs_fs.c
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This is the file system front-end to YAFFS that hooks it up to
+ * the VFS.
+ *
+ * Special notes: 
+ * >> 2.4: sb->u.generic_sbp points to the yaffs_Device associated with
+ *         this superblock
+ * >> 2.6: sb->s_fs_info  points to the yaffs_Device associated with this
+ *         superblock
+ * >> inode->i_private points to the associated yaffs_Object.
+ *
+ * Acknowledgements:
+ * * Luc van OostenRyck for numerous patches.
+ * * Nick Bane for numerous patches.
+ * * Nick Bane for 2.5/2.6 integration.
+ * * Andras Toth for mknod rdev issue.
+ * * Michael Fischer for finding the problem with inode inconsistency.
+ * * Some code bodily lifted from JFFS2.
+ */
+
+const char *yaffs_fs_c_version =
+    "$Id: yaffs_fs.c,v 1.53 2006/10/03 10:13:03 charles Exp $";
+extern const char *yaffs_guts_c_version;
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/list.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/smp_lock.h>
+#include <linux/pagemap.h>
+#include <linux/mtd/mtd.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/ctype.h>
+#include <linux/namei.h>
+#include <linux/seq_file.h>
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+
+#include <linux/statfs.h>	/* Added NCB 15-8-2003 */
+#include <asm/statfs.h>
+#define UnlockPage(p) unlock_page(p)
+#define Page_Uptodate(page)	test_bit(PG_uptodate, &(page)->flags)
+
+/* FIXME: use sb->s_id instead ? */
+#define yaffs_devname(sb, buf)	bdevname(sb->s_bdev, buf)
+
+#else
+
+#include <linux/locks.h>
+#define	BDEVNAME_SIZE		0
+#define	yaffs_devname(sb, buf)	kdevname(sb->s_dev)
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0))
+/* added NCB 26/5/2006 for 2.4.25-vrs2-tcl1 kernel */
+#define __user
+#endif
+
+#endif
+
+#include <asm/uaccess.h>
+
+#include "yportenv.h"
+#include "yaffs_guts.h"
+
+unsigned yaffs_traceMask = YAFFS_TRACE_ALWAYS | 
+			   YAFFS_TRACE_BAD_BLOCKS
+			   /* | YAFFS_TRACE_CHECKPOINT */
+			   /* | 0xFFFFFFFF */; 
+
+static int cp_disabled = 0;
+
+#include <linux/mtd/mtd.h>
+#include "yaffs_mtdif.h"
+#include "yaffs_mtdif2.h"
+
+/*#define T(x) printk x */
+
+#define yaffs_InodeToObject(iptr) ((yaffs_Object *)((iptr)->i_private))
+#define yaffs_DentryToObject(dptr) yaffs_InodeToObject((dptr)->d_inode)
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+#define yaffs_SuperToDevice(sb)	((yaffs_Device *)sb->s_fs_info)
+#else
+#define yaffs_SuperToDevice(sb)	((yaffs_Device *)sb->u.generic_sbp)
+#endif
+
+static void yaffs_put_super(struct super_block *sb);
+
+static ssize_t yaffs_file_write(struct file *f, const char *buf, size_t n,
+				loff_t * pos);
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs_file_flush(struct file *file, fl_owner_t id);
+#else
+static int yaffs_file_flush(struct file *file);
+#endif
+
+static int yaffs_sync_object(struct file *file, int datasync);
+
+#ifdef MIPSEL
+static int yaffs_ioctl(struct inode *inode, struct file *filp,
+		       unsigned int cmd, unsigned long arg);
+#endif
+
+static int yaffs_readdir(struct file *f, void *dirent, filldir_t filldir);
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode,
+			struct nameidata *n);
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry,
+				   struct nameidata *n);
+#else
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode);
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry);
+#endif
+static int yaffs_link(struct dentry *old_dentry, struct inode *dir,
+		      struct dentry *dentry);
+static int yaffs_unlink(struct inode *dir, struct dentry *dentry);
+static int yaffs_symlink(struct inode *dir, struct dentry *dentry,
+			 const char *symname);
+static int yaffs_mkdir(struct inode *dir, struct dentry *dentry, int mode);
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       dev_t dev);
+#else
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       int dev);
+#endif
+static int yaffs_rename(struct inode *old_dir, struct dentry *old_dentry,
+			struct inode *new_dir, struct dentry *new_dentry);
+static int yaffs_setattr(struct dentry *dentry, struct iattr *attr);
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,17))
+static int yaffs_sync_fs(struct super_block *sb, int wait);
+static void yaffs_write_super(struct super_block *sb);
+#else
+static int yaffs_sync_fs(struct super_block *sb);
+static int yaffs_write_super(struct super_block *sb);
+#endif
+static int yaffs_remount_fs(struct super_block *sb, int *flags, char *data);
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs_statfs(struct dentry *dentry, struct kstatfs *buf);
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_statfs(struct super_block *sb, struct kstatfs *buf);
+#else
+static int yaffs_statfs(struct super_block *sb, struct statfs *buf);
+#endif
+static struct inode * yaffs_iget(struct super_block *sb, unsigned long ino);
+
+static void yaffs_delete_inode(struct inode *);
+static void yaffs_clear_inode(struct inode *);
+
+static int yaffs_readpage(struct file *file, struct page *page);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_writepage(struct page *page, struct writeback_control *wbc);
+#else
+static int yaffs_writepage(struct page *page);
+#endif
+static int yaffs_write_begin(struct file *file, struct address_space *mapping,
+			     loff_t pos, unsigned len, unsigned flags,
+			     struct page **pagep, void **fsdata);
+static int yaffs_write_end(struct file *file, struct address_space *mapping,
+			   loff_t pos, unsigned len, unsigned copied,
+			   struct page *page, void *fsdata);
+
+static void *yaffs_follow_link(struct dentry *dentry, struct nameidata *nd);
+static void yaffs_put_link(struct dentry *direntry,
+			   struct nameidata *nd, void *cookie);
+
+static struct address_space_operations yaffs_file_address_operations = {
+	.readpage = yaffs_readpage,
+	.writepage = yaffs_writepage,
+	.write_begin = yaffs_write_begin,
+	.write_end = yaffs_write_end,
+};
+
+static struct file_operations yaffs_file_operations = {
+	.aio_read = generic_file_aio_read,
+	.aio_write = generic_file_aio_write,
+	.mmap = generic_file_mmap,
+	.flush = yaffs_file_flush,
+	.fsync = yaffs_sync_object,
+#ifdef MIPSEL
+	.ioctl = yaffs_ioctl,
+#endif
+	.splice_read = generic_file_splice_read,
+	.splice_write = generic_file_splice_write,
+};
+
+static struct inode_operations yaffs_file_inode_operations = {
+	.setattr = yaffs_setattr,
+};
+
+static struct inode_operations yaffs_symlink_inode_operations = {
+	.readlink = generic_readlink,
+	.follow_link = yaffs_follow_link,
+	.put_link = yaffs_put_link,
+	.setattr = yaffs_setattr,
+};
+
+static struct inode_operations yaffs_dir_inode_operations = {
+	.create = yaffs_create,
+	.lookup = yaffs_lookup,
+	.link = yaffs_link,
+	.unlink = yaffs_unlink,
+	.symlink = yaffs_symlink,
+	.mkdir = yaffs_mkdir,
+	.rmdir = yaffs_unlink,
+	.mknod = yaffs_mknod,
+	.rename = yaffs_rename,
+	.setattr = yaffs_setattr,
+};
+
+static struct file_operations yaffs_dir_operations = {
+	.read = generic_read_dir,
+	.readdir = yaffs_readdir,
+	.fsync = yaffs_sync_object,
+};
+
+static struct super_operations yaffs_super_ops = {
+	.statfs = yaffs_statfs,
+	.put_super = yaffs_put_super,
+	.delete_inode = yaffs_delete_inode,
+	.clear_inode = yaffs_clear_inode,
+	.sync_fs = yaffs_sync_fs,
+	.write_super = yaffs_write_super,
+	.remount_fs = yaffs_remount_fs,
+};
+
+static void yaffs_GrossLock(yaffs_Device * dev)
+{
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs locking\n"));
+
+	down(&dev->grossLock);
+}
+
+static void yaffs_GrossUnlock(yaffs_Device * dev)
+{
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs unlocking\n"));
+	up(&dev->grossLock);
+
+}
+
+static void *yaffs_follow_link(struct dentry *dentry, struct nameidata *nd)
+{
+	unsigned char *alias;
+	yaffs_Device *dev = yaffs_DentryToObject(dentry)->myDev;
+
+	yaffs_GrossLock(dev);
+
+	alias = yaffs_GetSymlinkAlias(yaffs_DentryToObject(dentry));
+
+	yaffs_GrossUnlock(dev);
+
+	if (!alias)
+		return ERR_PTR(-ENOMEM);
+
+	nd_set_link(nd, alias);
+	return NULL;
+}
+
+static void yaffs_put_link(struct dentry *direntry,
+			   struct nameidata *nd, void *cookie)
+{
+	char *alias = nd_get_link(nd);
+
+	if (!IS_ERR(alias))
+		kfree(alias);
+}
+
+struct inode *yaffs_get_inode(struct super_block *sb, int mode, int dev,
+			      yaffs_Object * obj);
+
+/*
+ * Lookup is used to find objects in the fs
+ */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry,
+				   struct nameidata *n)
+#else
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry)
+#endif
+{
+	yaffs_Object *obj;
+	struct inode *inode = NULL;	/* NCB 2.5/2.6 needs NULL here */
+
+	yaffs_Device *dev = yaffs_InodeToObject(dir)->myDev;
+
+	yaffs_GrossLock(dev);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_lookup for %d:%s\n",
+	   yaffs_InodeToObject(dir)->objectId, dentry->d_name.name));
+
+	obj =
+	    yaffs_FindObjectByName(yaffs_InodeToObject(dir),
+				   dentry->d_name.name);
+
+	obj = yaffs_GetEquivalentObject(obj);	/* in case it was a hardlink */
+	
+	/* Can't hold gross lock when calling yaffs_get_inode() */
+	yaffs_GrossUnlock(dev);
+
+	if (obj) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_lookup found %d\n", obj->objectId));
+
+		inode = yaffs_get_inode(dir->i_sb, obj->yst_mode, 0, obj);
+
+		if (inode) {
+			T(YAFFS_TRACE_OS,
+			  (KERN_DEBUG "yaffs_loookup dentry \n"));
+/* #if 0 asserted by NCB for 2.5/6 compatability - falls through to
+ * d_add even if NULL inode */
+#if 0
+			/*dget(dentry); // try to solve directory bug */
+			d_add(dentry, inode);
+
+			/* return dentry; */
+			return NULL;
+#endif
+		}
+
+	} else {
+		T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_lookup not found\n"));
+
+	}
+
+/* added NCB for 2.5/6 compatability - forces add even if inode is
+ * NULL which creates dentry hash */
+	d_add(dentry, inode);
+
+	return NULL;
+	/*      return (ERR_PTR(-EIO)); */
+
+}
+
+/* clear is called to tell the fs to release any per-inode data it holds */
+static void yaffs_clear_inode(struct inode *inode)
+{
+	yaffs_Object *obj;
+	yaffs_Device *dev;
+
+	obj = yaffs_InodeToObject(inode);
+
+	T(YAFFS_TRACE_OS,
+	  ("yaffs_clear_inode: ino %d, count %d %s\n", (int)inode->i_ino,
+	   atomic_read(&inode->i_count),
+	   obj ? "object exists" : "null object"));
+
+	if (obj) {
+		dev = obj->myDev;
+		yaffs_GrossLock(dev);
+
+		/* Clear the association between the inode and
+		 * the yaffs_Object.
+		 */
+		obj->myInode = NULL;
+		inode->i_private = NULL;
+
+		/* If the object freeing was deferred, then the real
+		 * free happens now.
+		 * This should fix the inode inconsistency problem.
+		 */
+
+		yaffs_HandleDeferedFree(obj);
+
+		yaffs_GrossUnlock(dev);
+	}
+
+}
+
+/* delete is called when the link count is zero and the inode
+ * is put (ie. nobody wants to know about it anymore, time to
+ * delete the file).
+ * NB Must call clear_inode()
+ */
+static void yaffs_delete_inode(struct inode *inode)
+{
+	yaffs_Object *obj = yaffs_InodeToObject(inode);
+	yaffs_Device *dev;
+
+	T(YAFFS_TRACE_OS,
+	  ("yaffs_delete_inode: ino %d, count %d %s\n", (int)inode->i_ino,
+	   atomic_read(&inode->i_count),
+	   obj ? "object exists" : "null object"));
+
+	if (obj) {
+		dev = obj->myDev;
+		yaffs_GrossLock(dev);
+		yaffs_DeleteFile(obj);
+		yaffs_GrossUnlock(dev);
+	}
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,13))
+        truncate_inode_pages (&inode->i_data, 0);
+#endif
+	clear_inode(inode);
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs_file_flush(struct file *file, fl_owner_t id)
+#else
+static int yaffs_file_flush(struct file *file)
+#endif
+{
+	yaffs_Object *obj = yaffs_DentryToObject(file->f_path.dentry);
+
+	yaffs_Device *dev = obj->myDev;
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_file_flush object %d (%s)\n", obj->objectId,
+	   obj->dirty ? "dirty" : "clean"));
+
+	yaffs_GrossLock(dev);
+
+	yaffs_FlushFile(obj, 1);
+
+	yaffs_GrossUnlock(dev);
+
+	return 0;
+}
+
+static int yaffs_readpage_nolock(struct file *f, struct page *pg)
+{
+	/* Lifted from jffs2 */
+
+	yaffs_Object *obj;
+	unsigned char *pg_buf;
+	int ret;
+
+	yaffs_Device *dev;
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_readpage at %08x, size %08x\n",
+			   (unsigned)(pg->index << PAGE_CACHE_SHIFT),
+			   (unsigned)PAGE_CACHE_SIZE));
+
+	obj = yaffs_DentryToObject(f->f_path.dentry);
+
+	dev = obj->myDev;
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+	BUG_ON(!PageLocked(pg));
+#else
+	if (!PageLocked(pg))
+		PAGE_BUG(pg);
+#endif
+
+	pg_buf = kmap(pg);
+	/* FIXME: Can kmap fail? */
+
+	yaffs_GrossLock(dev);
+
+	ret =
+	    yaffs_ReadDataFromFile(obj, pg_buf, pg->index << PAGE_CACHE_SHIFT,
+				   PAGE_CACHE_SIZE);
+
+	yaffs_GrossUnlock(dev);
+
+	if (ret >= 0)
+		ret = 0;
+
+	if (ret) {
+		ClearPageUptodate(pg);
+		SetPageError(pg);
+	} else {
+		SetPageUptodate(pg);
+		ClearPageError(pg);
+	}
+
+	flush_dcache_page(pg);
+	kunmap(pg);
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_readpage done\n"));
+	return ret;
+}
+
+static int yaffs_readpage_unlock(struct file *f, struct page *pg)
+{
+	int ret = yaffs_readpage_nolock(f, pg);
+	UnlockPage(pg);
+	return ret;
+}
+
+static int yaffs_readpage(struct file *f, struct page *pg)
+{
+	return yaffs_readpage_unlock(f, pg);
+}
+
+/* writepage inspired by/stolen from smbfs */
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_writepage(struct page *page, struct writeback_control *wbc)
+#else
+static int yaffs_writepage(struct page *page)
+#endif
+{
+	struct address_space *mapping = page->mapping;
+	loff_t offset = (loff_t) page->index << PAGE_CACHE_SHIFT;
+	struct inode *inode;
+	unsigned long end_index;
+	char *buffer;
+	yaffs_Object *obj;
+	int nWritten = 0;
+	unsigned nBytes;
+
+	if (!mapping)
+		BUG();
+	inode = mapping->host;
+	if (!inode)
+		BUG();
+
+	if (offset > inode->i_size) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG
+		   "yaffs_writepage at %08x, inode size = %08x!!!\n",
+		   (unsigned)(page->index << PAGE_CACHE_SHIFT),
+		   (unsigned)inode->i_size));
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "                -> don't care!!\n"));
+		unlock_page(page);
+		return 0;
+	}
+
+	end_index = inode->i_size >> PAGE_CACHE_SHIFT;
+
+	/* easy case */
+	if (page->index < end_index) {
+		nBytes = PAGE_CACHE_SIZE;
+	} else {
+		nBytes = inode->i_size & (PAGE_CACHE_SIZE - 1);
+	}
+
+	get_page(page);
+
+	buffer = kmap(page);
+
+	obj = yaffs_InodeToObject(inode);
+	yaffs_GrossLock(obj->myDev);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_writepage at %08x, size %08x\n",
+	   (unsigned)(page->index << PAGE_CACHE_SHIFT), nBytes));
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "writepag0: obj = %05x, ino = %05x\n",
+	   (int)obj->variant.fileVariant.fileSize, (int)inode->i_size));
+
+	nWritten =
+	    yaffs_WriteDataToFile(obj, buffer, page->index << PAGE_CACHE_SHIFT,
+				  nBytes, 0);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "writepag1: obj = %05x, ino = %05x\n",
+	   (int)obj->variant.fileVariant.fileSize, (int)inode->i_size));
+
+	yaffs_GrossUnlock(obj->myDev);
+
+	kunmap(page);
+	SetPageUptodate(page);
+	UnlockPage(page);
+	put_page(page);
+
+	return (nWritten == nBytes) ? 0 : -ENOSPC;
+}
+
+static int yaffs_write_begin(struct file *f, struct address_space *mapping,
+			     loff_t pos, unsigned len, unsigned flags,
+			     struct page **pagep, void **fsdata)
+{
+	pgoff_t index = pos >> PAGE_CACHE_SHIFT;
+	unsigned offset = pos & (PAGE_CACHE_SIZE - 1);
+	unsigned to = offset + len;
+	struct inode *inode = mapping->host;
+	int ret = 0;
+
+	*pagep = grab_cache_page_write_begin(mapping, index, flags);
+	if (!*pagep)
+		return -ENOMEM;
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_prepair_write\n"));
+	if (!Page_Uptodate(*pagep) && (offset || to < PAGE_CACHE_SIZE)) {
+		ret = yaffs_readpage_nolock(f, *pagep);
+		if (ret)
+			goto err;
+	}
+
+	return 0;
+  err:
+	unlock_page(*pagep);
+	page_cache_release(*pagep);
+	if (pos + len > inode->i_size)
+		vmtruncate(inode, inode->i_size);
+	return ret;
+
+}
+
+static int yaffs_write_end(struct file *f, struct address_space *mapping,
+			   loff_t pos, unsigned nBytes, unsigned copied,
+			   struct page *pg, void *fsdata)
+{
+	unsigned offset = pos & (PAGE_CACHE_SIZE - 1);
+	void *addr = page_address(pg) + offset;
+	int nWritten;
+
+	unsigned spos = pos;
+	unsigned saddr = (unsigned)addr;
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_commit_write addr %x pos %x nBytes %d\n", saddr,
+	   spos, nBytes));
+
+	flush_dcache_page(pg);
+	nWritten = yaffs_file_write(f, addr, nBytes, &pos);
+
+	if (nWritten != nBytes) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG
+		   "yaffs_commit_write not same size nWritten %d  nBytes %d\n",
+		   nWritten, nBytes));
+		SetPageError(pg);
+		ClearPageUptodate(pg);
+	} else {
+		SetPageUptodate(pg);
+	}
+
+	unlock_page(pg);
+	page_cache_release(pg);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_commit_write returning %d\n",
+	   nWritten == nBytes ? 0 : nWritten));
+
+	return nWritten;
+
+}
+
+static void yaffs_FillInodeFromObject(struct inode *inode, yaffs_Object * obj)
+{
+	if (inode && obj) {
+
+
+		/* Check mode against the variant type and attempt to repair if broken. */
+ 		__u32 mode = obj->yst_mode;
+ 		switch( obj->variantType ){
+ 		case YAFFS_OBJECT_TYPE_FILE :
+ 		        if( ! S_ISREG(mode) ){
+ 			        obj->yst_mode &= ~S_IFMT;
+ 			        obj->yst_mode |= S_IFREG;
+ 			}
+ 
+ 			break;
+ 		case YAFFS_OBJECT_TYPE_SYMLINK :
+ 		        if( ! S_ISLNK(mode) ){
+ 			        obj->yst_mode &= ~S_IFMT;
+ 				obj->yst_mode |= S_IFLNK;
+ 			}
+ 
+ 			break;
+ 		case YAFFS_OBJECT_TYPE_DIRECTORY :
+ 		        if( ! S_ISDIR(mode) ){
+ 			        obj->yst_mode &= ~S_IFMT;
+ 			        obj->yst_mode |= S_IFDIR;
+ 			}
+ 
+ 			break;
+ 		case YAFFS_OBJECT_TYPE_UNKNOWN :
+ 		case YAFFS_OBJECT_TYPE_HARDLINK :
+ 		case YAFFS_OBJECT_TYPE_SPECIAL :
+ 		default:
+ 		        /* TODO? */
+ 		        break;
+ 		}
+
+		inode->i_ino = obj->objectId;
+		inode->i_mode = obj->yst_mode;
+		inode->i_uid = obj->yst_uid;
+		inode->i_gid = obj->yst_gid;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+
+		inode->i_rdev = old_decode_dev(obj->yst_rdev);
+		inode->i_atime.tv_sec = (time_t) (obj->yst_atime);
+		inode->i_atime.tv_nsec = 0;
+		inode->i_mtime.tv_sec = (time_t) obj->yst_mtime;
+		inode->i_mtime.tv_nsec = 0;
+		inode->i_ctime.tv_sec = (time_t) obj->yst_ctime;
+		inode->i_ctime.tv_nsec = 0;
+#else
+		inode->i_rdev = obj->yst_rdev;
+		inode->i_atime = obj->yst_atime;
+		inode->i_mtime = obj->yst_mtime;
+		inode->i_ctime = obj->yst_ctime;
+#endif
+		inode->i_size = yaffs_GetObjectFileLength(obj);
+		inode->i_blocks = (inode->i_size + 511) >> 9;
+
+		inode->i_nlink = yaffs_GetObjectLinkCount(obj);
+
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG
+		   "yaffs_FillInode mode %x uid %d gid %d size %d count %d\n",
+		   inode->i_mode, inode->i_uid, inode->i_gid,
+		   (int)inode->i_size, atomic_read(&inode->i_count)));
+
+		switch (obj->yst_mode & S_IFMT) {
+		default:	/* fifo, device or socket */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+			init_special_inode(inode, obj->yst_mode,
+					   old_decode_dev(obj->yst_rdev));
+#else
+			init_special_inode(inode, obj->yst_mode,
+					   (dev_t) (obj->yst_rdev));
+#endif
+			break;
+		case S_IFREG:	/* file */
+			inode->i_op = &yaffs_file_inode_operations;
+			inode->i_fop = &yaffs_file_operations;
+			inode->i_mapping->a_ops =
+			    &yaffs_file_address_operations;
+			break;
+		case S_IFDIR:	/* directory */
+			inode->i_op = &yaffs_dir_inode_operations;
+			inode->i_fop = &yaffs_dir_operations;
+			break;
+		case S_IFLNK:	/* symlink */
+			inode->i_op = &yaffs_symlink_inode_operations;
+			break;
+		}
+
+		inode->i_private = obj;
+		obj->myInode = inode;
+
+	} else {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_FileInode invalid parameters\n"));
+	}
+
+}
+
+struct inode *yaffs_get_inode(struct super_block *sb, int mode, int dev,
+			      yaffs_Object * obj)
+{
+	struct inode *inode;
+
+	if (!sb) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_get_inode for NULL super_block!!\n"));
+		return NULL;
+
+	}
+
+	if (!obj) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_get_inode for NULL object!!\n"));
+		return NULL;
+
+	}
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_get_inode for object %d\n", obj->objectId));
+
+	inode = yaffs_iget(sb, obj->objectId);
+
+	/* NB Side effect: iget calls back to yaffs_read_inode(). */
+	/* iget also increments the inode's i_count */
+	/* NB You can't be holding grossLock or deadlock will happen! */
+
+	return !IS_ERR(inode) ? inode : NULL;
+}
+
+static ssize_t yaffs_file_write(struct file *f, const char *buf, size_t n,
+				loff_t * pos)
+{
+	yaffs_Object *obj;
+	int nWritten, ipos;
+	struct inode *inode;
+	yaffs_Device *dev;
+
+	obj = yaffs_DentryToObject(f->f_path.dentry);
+
+	dev = obj->myDev;
+
+	yaffs_GrossLock(dev);
+
+	inode = f->f_path.dentry->d_inode;
+
+	if (!S_ISBLK(inode->i_mode) && f->f_flags & O_APPEND) {
+		ipos = inode->i_size;
+	} else {
+		ipos = *pos;
+	}
+
+	if (!obj) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_file_write: hey obj is null!\n"));
+	} else {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG
+		   "yaffs_file_write about to write writing %d bytes"
+		   "to object %d at %d\n",
+		   n, obj->objectId, ipos));
+	}
+
+	nWritten = yaffs_WriteDataToFile(obj, buf, ipos, n, 0);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_file_write writing %d bytes, %d written at %d\n",
+	   n, nWritten, ipos));
+	if (nWritten > 0) {
+		ipos += nWritten;
+		*pos = ipos;
+		if (ipos > inode->i_size) {
+			inode->i_size = ipos;
+			inode->i_blocks = (ipos + 511) >> 9;
+
+			T(YAFFS_TRACE_OS,
+			  (KERN_DEBUG
+			   "yaffs_file_write size updated to %d bytes, "
+			   "%d blocks\n",
+			   ipos, (int)(inode->i_blocks)));
+		}
+
+	}
+	yaffs_GrossUnlock(dev);
+	return nWritten == 0 ? -ENOSPC : nWritten;
+}
+
+static int yaffs_readdir(struct file *f, void *dirent, filldir_t filldir)
+{
+	yaffs_Object *obj;
+	yaffs_Device *dev;
+	struct inode *inode = f->f_path.dentry->d_inode;
+	unsigned long offset, curoffs;
+	struct list_head *i;
+	yaffs_Object *l;
+
+	char name[YAFFS_MAX_NAME_LENGTH + 1];
+
+	obj = yaffs_DentryToObject(f->f_path.dentry);
+	dev = obj->myDev;
+
+	yaffs_GrossLock(dev);
+
+	offset = f->f_pos;
+
+	T(YAFFS_TRACE_OS, ("yaffs_readdir: starting at %d\n", (int)offset));
+
+	if (offset == 0) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_readdir: entry . ino %d \n",
+		   (int)inode->i_ino));
+		if (filldir(dirent, ".", 1, offset, inode->i_ino, DT_DIR)
+		    < 0) {
+			goto out;
+		}
+		offset++;
+		f->f_pos++;
+	}
+	if (offset == 1) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_readdir: entry .. ino %d \n",
+		   (int) parent_ino(f->f_path.dentry)));
+		if (filldir
+		    (dirent, "..", 2, offset,
+		     parent_ino(f->f_path.dentry), DT_DIR) < 0) {
+			goto out;
+		}
+		offset++;
+		f->f_pos++;
+	}
+
+	curoffs = 1;
+
+#if 0	/* it makes possible to iterate over the same file twice - BAD! */
+	/* If the directory has changed since the open or last call to
+	   readdir, rewind to after the 2 canned entries. */
+
+	if (f->f_version != inode->i_version) {
+		offset = 2;
+		f->f_pos = offset;
+		f->f_version = inode->i_version;
+	}
+#endif
+
+	list_for_each(i, &obj->variant.directoryVariant.children) {
+		curoffs++;
+		if (curoffs >= offset) {
+			l = list_entry(i, yaffs_Object, siblings);
+
+			yaffs_GetObjectName(l, name,
+					    YAFFS_MAX_NAME_LENGTH + 1);
+			T(YAFFS_TRACE_OS,
+			  (KERN_DEBUG "yaffs_readdir: %s inode %d\n", name,
+			   yaffs_GetObjectInode(l)));
+
+			if (filldir(dirent,
+				    name,
+				    strlen(name),
+				    offset,
+				    yaffs_GetObjectInode(l),
+				    yaffs_GetObjectType(l))
+			    < 0) {
+				goto up_and_out;
+			}
+
+			offset++;
+			f->f_pos++;
+		}
+	}
+
+      up_and_out:
+      out:
+
+	yaffs_GrossUnlock(dev);
+
+	return 0;
+}
+
+/*
+ * File creation. Allocate an inode, and we're done..
+ */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       dev_t rdev)
+#else
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       int rdev)
+#endif
+{
+	struct inode *inode;
+
+	yaffs_Object *obj = NULL;
+	yaffs_Device *dev;
+
+	yaffs_Object *parent = yaffs_InodeToObject(dir);
+
+	int error = -ENOSPC;
+	uid_t uid = current_fsuid();
+	gid_t gid = (dir->i_mode & S_ISGID) ? dir->i_gid : current_fsgid();
+	
+	if((dir->i_mode & S_ISGID) && S_ISDIR(mode))
+		mode |= S_ISGID;
+
+	if (parent) {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_mknod: parent object %d type %d\n",
+		   parent->objectId, parent->variantType));
+	} else {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_mknod: could not get parent object\n"));
+		return -EPERM;
+	}
+
+	T(YAFFS_TRACE_OS, ("yaffs_mknod: making oject for %s, "
+			   "mode %x dev %x\n",
+			   dentry->d_name.name, mode, rdev));
+
+	dev = parent->myDev;
+
+	yaffs_GrossLock(dev);
+
+	switch (mode & S_IFMT) {
+	default:
+		/* Special (socket, fifo, device...) */
+		T(YAFFS_TRACE_OS, (KERN_DEBUG
+				   "yaffs_mknod: making special\n"));
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+		obj =
+		    yaffs_MknodSpecial(parent, dentry->d_name.name, mode, uid,
+				       gid, old_encode_dev(rdev));
+#else
+		obj =
+		    yaffs_MknodSpecial(parent, dentry->d_name.name, mode, uid,
+				       gid, rdev);
+#endif
+		break;
+	case S_IFREG:		/* file          */
+		T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_mknod: making file\n"));
+		obj =
+		    yaffs_MknodFile(parent, dentry->d_name.name, mode, uid,
+				    gid);
+		break;
+	case S_IFDIR:		/* directory */
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_mknod: making directory\n"));
+		obj =
+		    yaffs_MknodDirectory(parent, dentry->d_name.name, mode,
+					 uid, gid);
+		break;
+	case S_IFLNK:		/* symlink */
+		T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_mknod: making file\n"));
+		obj = NULL;	/* Do we ever get here? */
+		break;
+	}
+	
+	/* Can not call yaffs_get_inode() with gross lock held */
+	yaffs_GrossUnlock(dev);
+
+	if (obj) {
+		inode = yaffs_get_inode(dir->i_sb, mode, rdev, obj);
+		d_instantiate(dentry, inode);
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_mknod created object %d count = %d\n",
+		   obj->objectId, atomic_read(&inode->i_count)));
+		error = 0;
+	} else {
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_mknod failed making object\n"));
+		error = -ENOMEM;
+	}
+
+	return error;
+}
+
+static int yaffs_mkdir(struct inode *dir, struct dentry *dentry, int mode)
+{
+	int retVal;
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_mkdir\n"));
+	retVal = yaffs_mknod(dir, dentry, mode | S_IFDIR, 0);
+#if 0
+	/* attempt to fix dir bug - didn't work */
+	if (!retVal) {
+		dget(dentry);
+	}
+#endif
+	return retVal;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode,
+			struct nameidata *n)
+#else
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode)
+#endif
+{
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_create\n"));
+	return yaffs_mknod(dir, dentry, mode | S_IFREG, 0);
+}
+
+static int yaffs_unlink(struct inode *dir, struct dentry *dentry)
+{
+	int retVal;
+
+	yaffs_Device *dev;
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_unlink %d:%s\n", (int)(dir->i_ino),
+	   dentry->d_name.name));
+
+	dev = yaffs_InodeToObject(dir)->myDev;
+
+	yaffs_GrossLock(dev);
+
+	retVal = yaffs_Unlink(yaffs_InodeToObject(dir), dentry->d_name.name);
+
+	if (retVal == YAFFS_OK) {
+		dentry->d_inode->i_nlink--;
+		dir->i_version++;
+		yaffs_GrossUnlock(dev);
+		mark_inode_dirty(dentry->d_inode);
+		return 0;
+	}
+	yaffs_GrossUnlock(dev);
+	return -ENOTEMPTY;
+}
+
+/*
+ * Create a link...
+ */
+static int yaffs_link(struct dentry *old_dentry, struct inode *dir,
+		      struct dentry *dentry)
+{
+	struct inode *inode = old_dentry->d_inode;
+	yaffs_Object *obj = NULL;
+	yaffs_Object *link = NULL;
+	yaffs_Device *dev;
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_link\n"));
+
+	obj = yaffs_InodeToObject(inode);
+	dev = obj->myDev;
+
+	yaffs_GrossLock(dev);
+
+	if (!S_ISDIR(inode->i_mode))	/* Don't link directories */
+	{
+		link =
+		    yaffs_Link(yaffs_InodeToObject(dir), dentry->d_name.name,
+			       obj);
+	}
+
+	if (link) {
+		old_dentry->d_inode->i_nlink = yaffs_GetObjectLinkCount(obj);
+		d_instantiate(dentry, old_dentry->d_inode);
+		atomic_inc(&old_dentry->d_inode->i_count);
+		T(YAFFS_TRACE_OS,
+		  (KERN_DEBUG "yaffs_link link count %d i_count %d\n",
+		   old_dentry->d_inode->i_nlink,
+		   atomic_read(&old_dentry->d_inode->i_count)));
+
+	}
+
+	yaffs_GrossUnlock(dev);
+
+	if (link) {
+
+		return 0;
+	}
+
+	return -EPERM;
+}
+
+static int yaffs_symlink(struct inode *dir, struct dentry *dentry,
+			 const char *symname)
+{
+	yaffs_Object *obj;
+	yaffs_Device *dev;
+	uid_t uid = current_fsuid();
+	gid_t gid = (dir->i_mode & S_ISGID) ? dir->i_gid : current_fsgid();
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_symlink\n"));
+
+	dev = yaffs_InodeToObject(dir)->myDev;
+	yaffs_GrossLock(dev);
+	obj = yaffs_MknodSymLink(yaffs_InodeToObject(dir), dentry->d_name.name,
+				 S_IFLNK | S_IRWXUGO, uid, gid, symname);
+	yaffs_GrossUnlock(dev);
+
+	if (obj) {
+
+		struct inode *inode;
+
+		inode = yaffs_get_inode(dir->i_sb, obj->yst_mode, 0, obj);
+		d_instantiate(dentry, inode);
+		T(YAFFS_TRACE_OS, (KERN_DEBUG "symlink created OK\n"));
+		return 0;
+	} else {
+		T(YAFFS_TRACE_OS, (KERN_DEBUG "symlink not created\n"));
+
+	}
+
+	return -ENOMEM;
+}
+
+static int yaffs_sync_object(struct file *file, int datasync)
+{
+
+	yaffs_Object *obj;
+	yaffs_Device *dev;
+
+	obj = yaffs_InodeToObject(file->f_mapping->host);
+
+	dev = obj->myDev;
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_sync_object\n"));
+	yaffs_GrossLock(dev);
+	yaffs_FlushFile(obj, 1);
+	yaffs_GrossUnlock(dev);
+	return 0;
+}
+
+#ifdef MIPSEL
+#define	YAFFS_IOC_REFRESH		_IO('f', 777)
+
+static int yaffs_ioctl(struct inode *inode, struct file *filp,
+		       unsigned int cmd, unsigned long arg) {
+	yaffs_Device *dev = yaffs_InodeToObject(inode)->myDev;
+	int ret;
+
+	if (cmd != YAFFS_IOC_REFRESH) {
+		return -ENOTTY;
+	}
+	if (!is_nand_bad()) {
+		return -ENOENT;
+	}
+
+	yaffs_GrossLock(dev);
+
+	ret = yaffs_RefreshOneBlock(dev);
+
+	yaffs_GrossUnlock(dev);
+	return ret;
+}
+#endif
+
+/*
+ * The VFS layer already does all the dentry stuff for rename.
+ *
+ * NB: POSIX says you can rename an object over an old object of the same name
+ */
+static int yaffs_rename(struct inode *old_dir, struct dentry *old_dentry,
+			struct inode *new_dir, struct dentry *new_dentry)
+{
+	yaffs_Device *dev;
+	int retVal = YAFFS_FAIL;
+	yaffs_Object *target;
+
+        T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_rename\n"));
+	dev = yaffs_InodeToObject(old_dir)->myDev;
+
+	yaffs_GrossLock(dev);
+
+	/* Check if the target is an existing directory that is not empty. */
+	target =
+	    yaffs_FindObjectByName(yaffs_InodeToObject(new_dir),
+				   new_dentry->d_name.name);
+	
+	
+
+	if (target &&
+	    target->variantType == YAFFS_OBJECT_TYPE_DIRECTORY &&
+	    !list_empty(&target->variant.directoryVariant.children)) {
+	    
+	        T(YAFFS_TRACE_OS, (KERN_DEBUG "target is non-empty dir\n"));
+
+		retVal = YAFFS_FAIL;
+	} else {
+
+		/* Now does unlinking internally using shadowing mechanism */
+	        T(YAFFS_TRACE_OS, (KERN_DEBUG "calling yaffs_RenameObject\n"));
+		
+		retVal =
+		    yaffs_RenameObject(yaffs_InodeToObject(old_dir),
+				       old_dentry->d_name.name,
+				       yaffs_InodeToObject(new_dir),
+				       new_dentry->d_name.name);
+
+	}
+	yaffs_GrossUnlock(dev);
+
+	if (retVal == YAFFS_OK) {
+		if(target) {
+			new_dentry->d_inode->i_nlink--;
+			mark_inode_dirty(new_dentry->d_inode);
+		}
+
+		return 0;
+	} else {
+		return -ENOTEMPTY;
+	}
+
+}
+
+static int yaffs_setattr(struct dentry *dentry, struct iattr *attr)
+{
+	struct inode *inode = dentry->d_inode;
+	int error;
+	yaffs_Device *dev;
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_setattr of object %d\n",
+	   yaffs_InodeToObject(inode)->objectId));
+
+	if ((error = inode_change_ok(inode, attr)) == 0) {
+
+		dev = yaffs_InodeToObject(inode)->myDev;
+		yaffs_GrossLock(dev);
+		if (yaffs_SetAttributes(yaffs_InodeToObject(inode), attr) ==
+		    YAFFS_OK) {
+			error = 0;
+		} else {
+			error = -EPERM;
+		}
+		yaffs_GrossUnlock(dev);
+		if (!error)
+			error = inode_setattr(inode, attr);
+	}
+	return error;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs_statfs(struct dentry *dentry, struct kstatfs *buf)
+{
+	yaffs_Device *dev = yaffs_DentryToObject(dentry)->myDev;
+	struct super_block *sb = dentry->d_sb;
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_statfs(struct super_block *sb, struct kstatfs *buf)
+{
+	yaffs_Device *dev = yaffs_SuperToDevice(sb);
+#else
+static int yaffs_statfs(struct super_block *sb, struct statfs *buf)
+{
+	yaffs_Device *dev = yaffs_SuperToDevice(sb);
+#endif
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_statfs\n"));
+
+	yaffs_GrossLock(dev);
+
+	buf->f_type = YAFFS_MAGIC;
+	buf->f_bsize = sb->s_blocksize;
+	buf->f_namelen = 255;
+	if (sb->s_blocksize > dev->nBytesPerChunk) {
+
+		buf->f_blocks =
+		    (dev->endBlock - dev->startBlock +
+		     1) * dev->nChunksPerBlock / (sb->s_blocksize /
+						  dev->nBytesPerChunk);
+		buf->f_bfree =
+		    yaffs_GetNumberOfFreeChunks(dev) / (sb->s_blocksize /
+							dev->nBytesPerChunk);
+	} else {
+
+		buf->f_blocks =
+		    (dev->endBlock - dev->startBlock +
+		     1) * dev->nChunksPerBlock * (dev->nBytesPerChunk /
+						  sb->s_blocksize);
+		buf->f_bfree =
+		    yaffs_GetNumberOfFreeChunks(dev) * (dev->nBytesPerChunk /
+							sb->s_blocksize);
+	}
+	buf->f_files = 0;
+	buf->f_ffree = 0;
+	buf->f_bavail = buf->f_bfree;
+
+	yaffs_GrossUnlock(dev);
+	return 0;
+}
+
+
+
+static int yaffs_do_sync_fs(struct super_block *sb, int save_cp)
+{
+
+	yaffs_Device *dev = yaffs_SuperToDevice(sb);
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_do_sync_fs %d\n", save_cp));
+
+	if(dev) {
+		yaffs_GrossLock(dev);
+
+		yaffs_FlushEntireDeviceCache(dev);
+		if (save_cp && !cp_disabled) yaffs_CheckpointSave(dev);
+		
+		yaffs_GrossUnlock(dev);
+
+		sb->s_dirt = 0;
+	}
+	return 0;
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,17))
+static void yaffs_write_super(struct super_block *sb)
+#else
+static int yaffs_write_super(struct super_block *sb)
+#endif
+{
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_write_super\n"));
+	yaffs_do_sync_fs(sb, 0);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,17))
+	return 0;
+#endif
+}
+
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,17))
+static int yaffs_sync_fs(struct super_block *sb, int wait)
+#else
+static int yaffs_sync_fs(struct super_block *sb)
+#endif
+{
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_sync_fs\n"));
+	
+	yaffs_do_sync_fs(sb, 0);
+	return 0;
+}
+
+
+static struct inode *yaffs_iget(struct super_block *sb, unsigned long ino)
+{
+	struct inode *inode;
+	yaffs_Object *obj;
+	yaffs_Device *dev = yaffs_SuperToDevice(sb);
+
+	T(YAFFS_TRACE_OS,
+	  (KERN_DEBUG "yaffs_iget for %lu\n", ino));
+
+	inode = iget_locked(sb, ino);
+	if (!inode)
+		return ERR_PTR(-ENOMEM);
+	if (!(inode->i_state & I_NEW))
+		return inode;
+
+	/* NB This is called as a side effect of other functions, but
+	 * we had to release the lock to prevent deadlocks, so 
+	 * need to lock again.
+	 */
+
+	yaffs_GrossLock(dev);
+	
+	obj = yaffs_FindObjectByNumber(dev, inode->i_ino);
+
+	yaffs_FillInodeFromObject(inode, obj);
+
+	yaffs_GrossUnlock(dev);
+
+	unlock_new_inode(inode);
+	return inode;
+}
+
+static LIST_HEAD(yaffs_dev_list);
+
+static void yaffs_put_super(struct super_block *sb)
+{
+	yaffs_Device *dev = yaffs_SuperToDevice(sb);
+
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_put_super\n"));
+
+	yaffs_GrossLock(dev);
+	
+	yaffs_FlushEntireDeviceCache(dev);
+	
+	if (dev->putSuperFunc) {
+		dev->putSuperFunc(sb);
+	}
+	
+	if (!cp_disabled) yaffs_CheckpointSave(dev);
+	yaffs_Deinitialise(dev);
+	
+	yaffs_GrossUnlock(dev);
+
+	/* we assume this is protected by lock_kernel() in mount/umount */
+	list_del(&dev->devList);
+	
+	if(dev->spareBuffer){
+		YFREE(dev->spareBuffer);
+		dev->spareBuffer = NULL;
+	}
+
+	kfree(dev);
+}
+
+static int yaffs_remount_fs(struct super_block *sb, int *flags, char *data)
+{
+	T(YAFFS_TRACE_OS, (KERN_INFO "yaffs_remount_fs\n"));
+
+	if ((*flags & MS_RDONLY) && !(sb->s_flags & MS_RDONLY)) {
+		yaffs_do_sync_fs(sb, 1);
+	}
+	return 0;
+}
+
+
+static void yaffs_MTDPutSuper(struct super_block *sb)
+{
+
+	struct mtd_info *mtd = yaffs_SuperToDevice(sb)->genericDevice;
+
+	if (mtd->sync) {
+		mtd->sync(mtd);
+	}
+
+	put_mtd_device(mtd);
+}
+
+
+static void yaffs_MarkSuperBlockDirty(void *vsb)
+{
+	struct super_block *sb = (struct super_block *)vsb;
+	
+	T(YAFFS_TRACE_OS, (KERN_DEBUG "yaffs_MarkSuperBlockDirty() sb = %p\n",sb));
+//	if(sb)
+//		sb->s_dirt = 1;
+}
+
+static struct super_block *yaffs_internal_read_super(int yaffsVersion,
+						     struct super_block *sb,
+						     void *data, int silent)
+{
+	int nBlocks;
+	struct inode *inode = NULL;
+	struct dentry *root;
+	yaffs_Device *dev = 0;
+	char devname_buf[BDEVNAME_SIZE + 1];
+	struct mtd_info *mtd;
+	int err;
+
+	sb->s_magic = YAFFS_MAGIC;
+	sb->s_op = &yaffs_super_ops;
+
+	if (!sb)
+		printk(KERN_INFO "yaffs: sb is NULL\n");
+	else if (!sb->s_dev)
+		printk(KERN_INFO "yaffs: sb->s_dev is NULL\n");
+	else if (!yaffs_devname(sb, devname_buf))
+		printk(KERN_INFO "yaffs: devname is NULL\n");
+	else
+		printk(KERN_INFO "yaffs: dev is %d name is \"%s\"\n",
+		       sb->s_dev,
+		       yaffs_devname(sb, devname_buf));
+
+	sb->s_blocksize = PAGE_CACHE_SIZE;
+	sb->s_blocksize_bits = PAGE_CACHE_SHIFT;
+	T(YAFFS_TRACE_OS, ("yaffs_read_super: Using yaffs%d\n", yaffsVersion));
+	T(YAFFS_TRACE_OS,
+	  ("yaffs_read_super: block size %d\n", (int)(sb->s_blocksize)));
+
+#ifdef CONFIG_YAFFS_DISABLE_WRITE_VERIFY
+	T(YAFFS_TRACE_OS,
+	  ("yaffs: Write verification disabled. All guarantees "
+	   "null and void\n"));
+#endif
+
+	T(YAFFS_TRACE_ALWAYS, ("yaffs: Attempting MTD mount on %u.%u, "
+			       "\"%s\"\n",
+			       MAJOR(sb->s_dev), MINOR(sb->s_dev),
+			       yaffs_devname(sb, devname_buf)));
+
+	/* Check it's an mtd device..... */
+	if (MAJOR(sb->s_dev) != MTD_BLOCK_MAJOR) {
+		return NULL;	/* This isn't an mtd device */
+	}
+	/* Get the device */
+	mtd = get_mtd_device(NULL, MINOR(sb->s_dev));
+	if (!mtd) {
+		T(YAFFS_TRACE_ALWAYS,
+		  ("yaffs: MTD device #%u doesn't appear to exist\n",
+		   MINOR(sb->s_dev)));
+		return NULL;
+	}
+	/* Check it's NAND */
+	if (mtd->type != MTD_NANDFLASH) {
+		T(YAFFS_TRACE_ALWAYS,
+		  ("yaffs: MTD device is not NAND it's type %d\n", mtd->type));
+		return NULL;
+	}
+
+	T(YAFFS_TRACE_OS, (" erase %p\n", mtd->erase));
+	T(YAFFS_TRACE_OS, (" read %p\n", mtd->read));
+	T(YAFFS_TRACE_OS, (" write %p\n", mtd->write));
+	T(YAFFS_TRACE_OS, (" readoob %p\n", mtd->read_oob));
+	T(YAFFS_TRACE_OS, (" writeoob %p\n", mtd->write_oob));
+	T(YAFFS_TRACE_OS, (" block_isbad %p\n", mtd->block_isbad));
+	T(YAFFS_TRACE_OS, (" block_markbad %p\n", mtd->block_markbad));
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	T(YAFFS_TRACE_OS, (" writesize %d\n", mtd->writesize));
+#else
+	T(YAFFS_TRACE_OS, (" oobblock %d\n", mtd->oobblock));
+#endif
+	T(YAFFS_TRACE_OS, (" oobsize %d\n", mtd->oobsize));
+	T(YAFFS_TRACE_OS, (" erasesize %d\n", mtd->erasesize));
+	T(YAFFS_TRACE_OS, (" size %lld\n", mtd->size));
+	
+#ifdef CONFIG_YAFFS_AUTO_YAFFS2
+
+	if (yaffsVersion == 1 && 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	    mtd->writesize >= 2048) {
+#else
+	    mtd->oobblock >= 2048) {
+#endif
+	    T(YAFFS_TRACE_ALWAYS,("yaffs: auto selecting yaffs2\n"));
+	    yaffsVersion = 2;
+	}	
+	
+	/* Added NCB 26/5/2006 for completeness */
+	if (yaffsVersion == 2 && 
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	    mtd->writesize == 512) {
+#else
+	    mtd->oobblock == 512) {
+#endif
+	    T(YAFFS_TRACE_ALWAYS,("yaffs: auto selecting yaffs1\n"));
+	    yaffsVersion = 1;
+	}	
+
+#endif
+
+	if (yaffsVersion == 2) {
+		/* Check for version 2 style functions */
+		if (!mtd->erase ||
+		    !mtd->block_isbad ||
+		    !mtd->block_markbad ||
+		    !mtd->read ||
+		    !mtd->write ||
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+		    !mtd->read_oob || !mtd->write_oob) {
+#else
+		    !mtd->write_ecc ||
+		    !mtd->read_ecc || !mtd->read_oob || !mtd->write_oob) {
+#endif
+			T(YAFFS_TRACE_ALWAYS,
+			  ("yaffs: MTD device does not support required "
+			   "functions\n"));;
+			return NULL;
+		}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+		if (mtd->writesize < YAFFS_MIN_YAFFS2_CHUNK_SIZE ||
+#else
+		if (mtd->oobblock < YAFFS_MIN_YAFFS2_CHUNK_SIZE ||
+#endif
+		    mtd->oobsize < YAFFS_MIN_YAFFS2_SPARE_SIZE) {
+			T(YAFFS_TRACE_ALWAYS,
+			  ("yaffs: MTD device does not have the "
+			   "right page sizes\n"));
+			return NULL;
+		}
+	} else {
+		/* Check for V1 style functions */
+		if (!mtd->erase ||
+		    !mtd->read ||
+		    !mtd->write ||
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+		    !mtd->read_oob || !mtd->write_oob) {
+#else
+		    !mtd->write_ecc ||
+		    !mtd->read_ecc || !mtd->read_oob || !mtd->write_oob) {
+#endif
+			T(YAFFS_TRACE_ALWAYS,
+			  ("yaffs: MTD device does not support required "
+			   "functions\n"));;
+			return NULL;
+		}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+		if (mtd->writesize < YAFFS_BYTES_PER_CHUNK ||
+#else
+		if (mtd->oobblock < YAFFS_BYTES_PER_CHUNK ||
+#endif
+		    mtd->oobsize != YAFFS_BYTES_PER_SPARE) {
+			T(YAFFS_TRACE_ALWAYS,
+			  ("yaffs: MTD device does not support have the "
+			   "right page sizes\n"));
+			return NULL;
+		}
+	}
+
+	/* OK, so if we got here, we have an MTD that's NAND and looks
+	 * like it has the right capabilities
+	 * Set the yaffs_Device up for mtd
+	 */
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+	sb->s_fs_info = dev = kmalloc(sizeof(yaffs_Device), GFP_KERNEL);
+#else
+	sb->u.generic_sbp = dev = kmalloc(sizeof(yaffs_Device), GFP_KERNEL);
+#endif
+	if (!dev) {
+		/* Deep shit could not allocate device structure */
+		T(YAFFS_TRACE_ALWAYS,
+		  ("yaffs_read_super: Failed trying to allocate "
+		   "yaffs_Device. \n"));
+		return NULL;
+	}
+
+	memset(dev, 0, sizeof(yaffs_Device));
+	dev->genericDevice = mtd;
+	dev->name = mtd->name;
+
+	/* Set up the memory size parameters.... */
+
+	nBlocks = mtd->size / (YAFFS_CHUNKS_PER_BLOCK * YAFFS_BYTES_PER_CHUNK);
+	dev->startBlock = 0;
+	dev->endBlock = nBlocks - 1;
+	dev->nChunksPerBlock = YAFFS_CHUNKS_PER_BLOCK;
+	dev->nBytesPerChunk = YAFFS_BYTES_PER_CHUNK;
+	dev->nReservedBlocks = 5;
+	dev->nShortOpCaches = 10;	/* Enable short op caching */
+
+	/* ... and the functions. */
+	if (yaffsVersion == 2) {
+		dev->writeChunkWithTagsToNAND =
+		    nandmtd2_WriteChunkWithTagsToNAND;
+		dev->readChunkWithTagsFromNAND =
+		    nandmtd2_ReadChunkWithTagsFromNAND;
+		dev->markNANDBlockBad = nandmtd2_MarkNANDBlockBad;
+		dev->queryNANDBlock = nandmtd2_QueryNANDBlock;
+		dev->spareBuffer = YMALLOC(mtd->oobsize);
+		dev->isYaffs2 = 1;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+		dev->nBytesPerChunk = mtd->writesize;
+		dev->nChunksPerBlock = mtd->erasesize / mtd->writesize;
+#else
+		dev->nBytesPerChunk = mtd->oobblock;
+		dev->nChunksPerBlock = mtd->erasesize / mtd->oobblock;
+#endif
+		nBlocks = (unsigned) mtd->size / mtd->erasesize;
+
+		dev->nCheckpointReservedBlocks = 10;
+		if (nBlocks < (dev->nReservedBlocks + 1 + 
+			       dev->nCheckpointReservedBlocks) * 10) {
+			dev->nCheckpointReservedBlocks = 0;
+			dev->nReservedBlocks = max(nBlocks / 10, 2);
+		}
+		dev->startBlock = 0;
+		dev->endBlock = nBlocks - 1;
+	} else {
+		dev->writeChunkToNAND = nandmtd_WriteChunkToNAND;
+		dev->readChunkFromNAND = nandmtd_ReadChunkFromNAND;
+		dev->isYaffs2 = 0;
+	}
+	/* ... and common functions */
+	dev->eraseBlockInNAND = nandmtd_EraseBlockInNAND;
+	dev->initialiseNAND = nandmtd_InitialiseNAND;
+
+	dev->putSuperFunc = yaffs_MTDPutSuper;
+	
+	dev->superBlock = (void *)sb;
+	dev->markSuperBlockDirty = yaffs_MarkSuperBlockDirty;
+	
+
+#ifndef CONFIG_YAFFS_DOES_ECC
+	dev->useNANDECC = 1;
+#endif
+
+#ifdef CONFIG_YAFFS_DISABLE_WIDE_TNODES
+	dev->wideTnodesDisabled = 1;
+#endif
+
+	/* we assume this is protected by lock_kernel() in mount/umount */
+	list_add_tail(&dev->devList, &yaffs_dev_list);
+
+	init_MUTEX(&dev->grossLock);
+
+	yaffs_GrossLock(dev);
+
+	err = yaffs_GutsInitialise(dev);
+
+	T(YAFFS_TRACE_OS,
+	  ("yaffs_read_super: guts initialised %s\n",
+	   (err == YAFFS_OK) ? "OK" : "FAILED"));
+	
+	/* Release lock before yaffs_get_inode() */
+	yaffs_GrossUnlock(dev);
+
+	/* Create root inode */
+	if (err == YAFFS_OK)
+		inode = yaffs_get_inode(sb, S_IFDIR | 0755, 0,
+					yaffs_Root(dev));
+
+	if (!inode)
+		return NULL;
+
+	inode->i_op = &yaffs_dir_inode_operations;
+	inode->i_fop = &yaffs_dir_operations;
+
+	T(YAFFS_TRACE_OS, ("yaffs_read_super: got root inode\n"));
+
+	root = d_alloc_root(inode);
+
+	T(YAFFS_TRACE_OS, ("yaffs_read_super: d_alloc_root done\n"));
+
+	if (!root) {
+		iput(inode);
+		return NULL;
+	}
+	sb->s_root = root;
+
+	T(YAFFS_TRACE_OS, ("yaffs_read_super: done\n"));
+	return sb;
+}
+
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs_internal_read_super_mtd(struct super_block *sb, void *data,
+					 int silent)
+{
+	return yaffs_internal_read_super(1, sb, data, silent) ? 0 : -EINVAL;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs_read_super(struct file_system_type *fs,
+			    int flags, const char *dev_name,
+			    void *data, struct vfsmount *mnt)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs_internal_read_super_mtd, mnt);
+}
+#else
+static struct super_block *yaffs_read_super(struct file_system_type *fs,
+					    int flags, const char *dev_name,
+					    void *data)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs_internal_read_super_mtd);
+}
+#endif
+
+static struct file_system_type yaffs_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "yaffs",
+	.get_sb = yaffs_read_super,
+	.kill_sb = kill_block_super,
+	.fs_flags = FS_REQUIRES_DEV,
+};
+#else
+static struct super_block *yaffs_read_super(struct super_block *sb, void *data,
+					    int silent)
+{
+	return yaffs_internal_read_super(1, sb, data, silent);
+}
+
+static DECLARE_FSTYPE(yaffs_fs_type, "yaffs", yaffs_read_super,
+		      FS_REQUIRES_DEV);
+#endif
+
+
+#ifdef CONFIG_YAFFS_YAFFS2
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+static int yaffs2_internal_read_super_mtd(struct super_block *sb, void *data,
+					  int silent)
+{
+	return yaffs_internal_read_super(2, sb, data, silent) ? 0 : -EINVAL;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static int yaffs2_read_super(struct file_system_type *fs,
+			int flags, const char *dev_name, void *data,
+			struct vfsmount *mnt)
+{
+	return get_sb_bdev(fs, flags, dev_name, data,
+			yaffs2_internal_read_super_mtd, mnt);
+}
+#else
+static struct super_block *yaffs2_read_super(struct file_system_type *fs,
+					     int flags, const char *dev_name,
+					     void *data)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs2_internal_read_super_mtd);
+}
+#endif
+
+static struct file_system_type yaffs2_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "yaffs2",
+	.get_sb = yaffs2_read_super,
+	.kill_sb = kill_block_super,
+	.fs_flags = FS_REQUIRES_DEV,
+};
+#else
+static struct super_block *yaffs2_read_super(struct super_block *sb,
+					     void *data, int silent)
+{
+	return yaffs_internal_read_super(2, sb, data, silent);
+}
+
+static DECLARE_FSTYPE(yaffs2_fs_type, "yaffs2", yaffs2_read_super,
+		      FS_REQUIRES_DEV);
+#endif
+
+#endif				/* CONFIG_YAFFS_YAFFS2 */
+
+static void yaffs_dump_dev(struct seq_file *m, yaffs_Device * dev)
+{
+	seq_printf(m, "startBlock......... %d\n", dev->startBlock);
+	seq_printf(m, "endBlock........... %d\n", dev->endBlock);
+	seq_printf(m, "chunkGroupBits..... %d\n", dev->chunkGroupBits);
+	seq_printf(m, "chunkGroupSize..... %d\n", dev->chunkGroupSize);
+	seq_printf(m, "nErasedBlocks...... %d\n", dev->nErasedBlocks);
+	seq_printf(m, "nTnodesCreated..... %d\n", dev->nTnodesCreated);
+	seq_printf(m, "nFreeTnodes........ %d\n", dev->nFreeTnodes);
+	seq_printf(m, "nObjectsCreated.... %d\n", dev->nObjectsCreated);
+	seq_printf(m, "nFreeObjects....... %d\n", dev->nFreeObjects);
+	seq_printf(m, "nFreeChunks........ %d\n", dev->nFreeChunks);
+	seq_printf(m, "nPageWrites........ %d\n", dev->nPageWrites);
+	seq_printf(m, "nPageReads......... %d\n", dev->nPageReads);
+	seq_printf(m, "nBlockErasures..... %d\n", dev->nBlockErasures);
+	seq_printf(m, "nGCCopies.......... %d\n", dev->nGCCopies);
+	seq_printf(m, "garbageCollections. %d\n", dev->garbageCollections);
+	seq_printf(m, "passiveGCs......... %d\n",
+		   dev->passiveGarbageCollections);
+	seq_printf(m, "nRetriedWrites..... %d\n", dev->nRetriedWrites);
+	seq_printf(m, "nRetireBlocks...... %d\n", dev->nRetiredBlocks);
+	seq_printf(m, "nBadBlocks......... %d\n", dev->nBadBlocks);
+	seq_printf(m, "eccFixed........... %d\n", dev->eccFixed);
+	seq_printf(m, "eccUnfixed......... %d\n", dev->eccUnfixed);
+	seq_printf(m, "tagsEccFixed....... %d\n", dev->tagsEccFixed);
+	seq_printf(m, "tagsEccUnfixed..... %d\n", dev->tagsEccUnfixed);
+	seq_printf(m, "cacheHits.......... %d\n", dev->cacheHits);
+	seq_printf(m, "nDeletedFiles...... %d\n", dev->nDeletedFiles);
+	seq_printf(m, "nUnlinkedFiles..... %d\n", dev->nUnlinkedFiles);
+	seq_printf(m, "nBackgroudDeletions %d\n", dev->nBackgroundDeletions);
+	seq_printf(m, "useNANDECC......... %d\n", dev->useNANDECC);
+	seq_printf(m, "isYaffs2........... %d\n", dev->isYaffs2);
+}
+
+static int yaffs_proc_show(struct seq_file *m, void *v)
+{
+	struct list_head *item;
+	int n = 0;
+
+	/* Print header first */
+	seq_printf(m, "YAFFS built:" __DATE__ " " __TIME__
+		   "\n%s\n%s\n", yaffs_fs_c_version,
+		   yaffs_guts_c_version);
+
+	/* hold lock_kernel while traversing yaffs_dev_list */
+	lock_kernel();
+
+	/* Locate and print the Nth entry.  Order N-squared but N is small. */
+	list_for_each(item, &yaffs_dev_list) {
+		yaffs_Device *dev = list_entry(item, yaffs_Device, devList);
+		seq_printf(m, "\nDevice %d \"%s\"\n", n, dev->name);
+		yaffs_dump_dev(m, dev);
+		++n;
+	}
+	unlock_kernel();
+
+	return 0;
+}
+
+static int yaffs_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, yaffs_proc_show, NULL);
+}
+
+/**
+ * Set the verbosity of the warnings and error messages.
+ *
+ */
+
+static struct {
+	char *mask_name;
+	unsigned mask_bitfield;
+} mask_flags[] = {
+	{"allocate", YAFFS_TRACE_ALLOCATE},
+	{"always", YAFFS_TRACE_ALWAYS},
+	{"bad_blocks", YAFFS_TRACE_BAD_BLOCKS},
+	{"buffers", YAFFS_TRACE_BUFFERS},
+	{"bug", YAFFS_TRACE_BUG},
+	{"deletion", YAFFS_TRACE_DELETION},
+	{"erase", YAFFS_TRACE_ERASE},
+	{"error", YAFFS_TRACE_ERROR},
+	{"gc_detail", YAFFS_TRACE_GC_DETAIL},
+	{"gc", YAFFS_TRACE_GC},
+	{"mtd", YAFFS_TRACE_MTD},
+	{"nandaccess", YAFFS_TRACE_NANDACCESS},
+	{"os", YAFFS_TRACE_OS},
+	{"scan_debug", YAFFS_TRACE_SCAN_DEBUG},
+	{"scan", YAFFS_TRACE_SCAN},
+	{"tracing", YAFFS_TRACE_TRACING},
+	{"write", YAFFS_TRACE_WRITE},
+	{"all", 0xffffffff},
+	{"none", 0},
+	{NULL, 0},
+};
+
+static ssize_t yaffs_proc_write(struct file *file, const char __user *buffer,
+				size_t count, loff_t *lpos)
+{
+	unsigned rg = 0, mask_bitfield;
+	char *end, *mask_name;
+	int i;
+	int done = 0;
+	int add, len;
+	int pos = 0;
+
+	char buf[128];
+
+	if (count > sizeof(buf)) count = sizeof(buf);
+	if (copy_from_user(buf, buffer, count) > 0) return -EINVAL;
+
+	rg = yaffs_traceMask;
+
+	while (!done && (pos < count)) {
+		done = 1;
+		while ((pos < count) && isspace(buf[pos])) {
+			pos++;
+		}
+
+		switch (buf[pos]) {
+		case '+':
+		case '-':
+		case '=':
+			add = buf[pos];
+			pos++;
+			break;
+
+		default:
+			add = ' ';
+			break;
+		}
+		mask_name = NULL;
+		mask_bitfield = simple_strtoul(buf + pos, &end, 0);
+		if (end > buf + pos) {
+			mask_name = "numeral";
+			len = end - (buf + pos);
+			done = 0;
+		} else if (strncmp(buf + pos, "disable_cp", 10) == 0) {
+			cp_disabled = (add != '-');
+		} else {
+
+			for (i = 0; mask_flags[i].mask_name != NULL; i++) {
+				len = strlen(mask_flags[i].mask_name);
+				if (strncmp(buf + pos, mask_flags[i].mask_name, len) == 0) {
+					mask_name = mask_flags[i].mask_name;
+					mask_bitfield = mask_flags[i].mask_bitfield;
+					done = 0;
+					break;
+				}
+			}
+		}
+
+		if (mask_name != NULL) {
+			pos += len;
+			done = 0;
+			switch(add) {
+			case '-':
+				rg &= ~mask_bitfield;
+				break;
+			case '+':
+				rg |= mask_bitfield;
+				break;
+			case '=':
+				rg = mask_bitfield;
+				break;
+			default:
+				rg |= mask_bitfield;
+				break;
+			}
+		}
+	}
+
+	yaffs_traceMask = rg;
+	if ((rg & YAFFS_TRACE_ALWAYS) && !cp_disabled) {
+		for (i = 0; mask_flags[i].mask_name != NULL; i++) {
+			char flag;
+			flag = ((rg & mask_flags[i].mask_bitfield) == mask_flags[i].mask_bitfield) ? '+' : '-';
+			printk("%c%s\n", flag, mask_flags[i].mask_name);
+		}
+	}
+
+	return count;
+}
+
+static const struct file_operations yaffs_proc_fops = {
+	.open		= yaffs_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+	.write		= yaffs_proc_write,
+};
+
+/* Stuff to handle installation of file systems */
+struct file_system_to_install {
+	struct file_system_type *fst;
+	int installed;
+};
+
+static struct file_system_to_install fs_to_install[] = {
+//#ifdef CONFIG_YAFFS_YAFFS1
+	{&yaffs_fs_type, 0},
+//#endif
+//#ifdef CONFIG_YAFFS_YAFFS2
+	{&yaffs2_fs_type, 0},
+//#endif
+	{NULL, 0}
+};
+
+static int __init init_yaffs_fs(void)
+{
+	int error = 0;
+	struct file_system_to_install *fsinst;
+
+	T(YAFFS_TRACE_ALWAYS,
+	  ("yaffs " __DATE__ " " __TIME__ " Installing. \n"));
+
+	proc_create_data("yaffs", 0644, NULL, &yaffs_proc_fops, NULL);
+
+	/* Now add the file system entries */
+
+	fsinst = fs_to_install;
+
+	while (fsinst->fst && !error) {
+		error = register_filesystem(fsinst->fst);
+		if (!error) {
+			fsinst->installed = 1;
+		}
+		fsinst++;
+	}
+
+	/* Any errors? uninstall  */
+	if (error) {
+		fsinst = fs_to_install;
+
+		while (fsinst->fst) {
+			if (fsinst->installed) {
+				unregister_filesystem(fsinst->fst);
+				fsinst->installed = 0;
+			}
+			fsinst++;
+		}
+	}
+
+	return error;
+}
+
+static void __exit exit_yaffs_fs(void)
+{
+
+	struct file_system_to_install *fsinst;
+
+	T(YAFFS_TRACE_ALWAYS, ("yaffs " __DATE__ " " __TIME__
+			       " removing. \n"));
+
+	remove_proc_entry("yaffs", NULL);
+
+	fsinst = fs_to_install;
+
+	while (fsinst->fst) {
+		if (fsinst->installed) {
+			unregister_filesystem(fsinst->fst);
+			fsinst->installed = 0;
+		}
+		fsinst++;
+	}
+
+}
+
+module_init(init_yaffs_fs)
+module_exit(exit_yaffs_fs)
+
+MODULE_DESCRIPTION("YAFFS2 - a NAND specific flash file system");
+MODULE_AUTHOR("Charles Manning, Aleph One Ltd., 2002-2006");
+MODULE_LICENSE("GPL");
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_guts.c linux/fs/yaffs/yaffs_guts.c
--- linux-2.6.35/fs/yaffs/yaffs_guts.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_guts.c	2011-05-02 10:08:28.061588810 +0300
@@ -0,0 +1,6577 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+const char *yaffs_guts_c_version =
+    "$Id: yaffs_guts.c,v 1.35 2006/06/05 04:10:49 charles Exp $";
+
+#include "yportenv.h"
+
+#include "yaffsinterface.h"
+#include "yaffs_guts.h"
+#include "yaffs_tagsvalidity.h"
+
+#include "yaffs_tagscompat.h"
+#ifndef CONFIG_YAFFS_OWN_SORT
+#include "yaffs_qsort.h"
+#endif
+#include "yaffs_nand.h"
+
+#include "yaffs_checkptrw.h"
+
+#include "yaffs_nand.h"
+
+
+#ifdef CONFIG_YAFFS_WINCE
+void yfsd_LockYAFFS(BOOL fsLockOnly);
+void yfsd_UnlockYAFFS(BOOL fsLockOnly);
+#endif
+
+#define YAFFS_PASSIVE_GC_CHUNKS 2
+
+#include "yaffs_ecc.h"
+
+
+/* Robustification (if it ever comes about...) */
+static void yaffs_RetireBlock(yaffs_Device * dev, int blockInNAND);
+static void yaffs_HandleWriteChunkOk(yaffs_Device * dev, int chunkInNAND,
+				     const __u8 * data,
+				     const yaffs_ExtendedTags * tags);
+static void yaffs_HandleUpdateChunk(yaffs_Device * dev, int chunkInNAND,
+				    const yaffs_ExtendedTags * tags);
+
+/* Other local prototypes */
+static int yaffs_UnlinkObject( yaffs_Object *obj);
+
+static void yaffs_HardlinkFixup(yaffs_Device *dev, yaffs_Object *hardList);
+
+static int yaffs_WriteNewChunkWithTagsToNAND(yaffs_Device * dev,
+					     const __u8 * buffer,
+					     yaffs_ExtendedTags * tags,
+					     int useReserve);
+static int yaffs_PutChunkIntoFile(yaffs_Object * in, int chunkInInode,
+				  int chunkInNAND, int inScan);
+
+static yaffs_Object *yaffs_CreateNewObject(yaffs_Device * dev, int number,
+					   yaffs_ObjectType type);
+static void yaffs_AddObjectToDirectory(yaffs_Object * directory,
+				       yaffs_Object * obj);
+static int yaffs_UpdateObjectHeader(yaffs_Object * in, const YCHAR * name,
+				    int force, int isShrink, int shadows);
+static void yaffs_RemoveObjectFromDirectory(yaffs_Object * obj);
+static int yaffs_CheckStructures(void);
+static int yaffs_DeleteWorker(yaffs_Object * in, yaffs_Tnode * tn, __u32 level,
+			      int chunkOffset, int *limit);
+static int yaffs_DoGenericObjectDeletion(yaffs_Object * in);
+static void yaffs_FlushFilesChunkCache(yaffs_Object * obj);
+
+static yaffs_BlockInfo *yaffs_GetBlockInfo(yaffs_Device * dev, int blockNo);
+
+static __u8 *yaffs_GetTempBuffer(yaffs_Device * dev, int lineNo);
+static void yaffs_ReleaseTempBuffer(yaffs_Device * dev, __u8 * buffer,
+				    int lineNo);
+
+static int yaffs_CheckChunkErased(struct yaffs_DeviceStruct *dev,
+				  int chunkInNAND);
+
+static int yaffs_UnlinkWorker(yaffs_Object * obj);
+static void yaffs_DestroyObject(yaffs_Object * obj);
+
+static int yaffs_TagsMatch(const yaffs_ExtendedTags * tags, int objectId,
+			   int chunkInObject);
+
+loff_t yaffs_GetFileSize(yaffs_Object * obj);
+
+static int yaffs_AllocateChunk(yaffs_Device * dev, int useReserve);
+
+static void yaffs_VerifyFreeChunks(yaffs_Device * dev);
+
+#ifdef YAFFS_PARANOID
+static int yaffs_CheckFileSanity(yaffs_Object * in);
+#else
+#define yaffs_CheckFileSanity(in)
+#endif
+
+static void yaffs_InvalidateWholeChunkCache(yaffs_Object * in);
+static void yaffs_InvalidateChunkCache(yaffs_Object * object, int chunkId);
+
+static void yaffs_InvalidateCheckpoint(yaffs_Device *dev);
+
+/* 
+ * Temporary buffer manipulations.
+ */
+
+static __u8 *yaffs_GetTempBuffer(yaffs_Device * dev, int lineNo)
+{
+	int i, j;
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		if (dev->tempBuffer[i].line == 0) {
+			dev->tempBuffer[i].line = lineNo;
+			if ((i + 1) > dev->maxTemp) {
+				dev->maxTemp = i + 1;
+				for (j = 0; j <= i; j++)
+					dev->tempBuffer[j].maxLine =
+					    dev->tempBuffer[j].line;
+			}
+
+			return dev->tempBuffer[i].buffer;
+		}
+	}
+
+	T(YAFFS_TRACE_BUFFERS,
+	  (TSTR("Out of temp buffers at line %d, other held by lines:"),
+	   lineNo));
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		T(YAFFS_TRACE_BUFFERS, (TSTR(" %d "), dev->tempBuffer[i].line));
+	}
+	T(YAFFS_TRACE_BUFFERS, (TSTR(" " TENDSTR)));
+
+	/*
+	 * If we got here then we have to allocate an unmanaged one
+	 * This is not good.
+	 */
+
+	dev->unmanagedTempAllocations++;
+	return YMALLOC(dev->nBytesPerChunk);
+
+}
+
+static void yaffs_ReleaseTempBuffer(yaffs_Device * dev, __u8 * buffer,
+				    int lineNo)
+{
+	int i;
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		if (dev->tempBuffer[i].buffer == buffer) {
+			dev->tempBuffer[i].line = 0;
+			return;
+		}
+	}
+
+	if (buffer) {
+		/* assume it is an unmanaged one. */
+		T(YAFFS_TRACE_BUFFERS,
+		  (TSTR("Releasing unmanaged temp buffer in line %d" TENDSTR),
+		   lineNo));
+		YFREE(buffer);
+		dev->unmanagedTempDeallocations++;
+	}
+
+}
+
+/*
+ * Determine if we have a managed buffer.
+ */
+int yaffs_IsManagedTempBuffer(yaffs_Device * dev, const __u8 * buffer)
+{
+	int i;
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		if (dev->tempBuffer[i].buffer == buffer)
+			return 1;
+
+	}
+
+    for (i = 0; i < dev->nShortOpCaches; i++) {
+        if( dev->srCache[i].data == buffer )
+            return 1;
+
+    }
+
+    if (buffer == dev->checkpointBuffer)
+      return 1;
+
+    T(YAFFS_TRACE_ALWAYS,
+	  (TSTR("yaffs: unmaged buffer detected.\n" TENDSTR)));
+    return 0;
+}
+
+/*
+ * Chunk bitmap manipulations
+ */
+
+static Y_INLINE __u8 *yaffs_BlockBits(yaffs_Device * dev, int blk)
+{
+	if (blk < dev->internalStartBlock || blk > dev->internalEndBlock) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR("**>> yaffs: BlockBits block %d is not valid" TENDSTR),
+		   blk));
+		YBUG();
+	}
+	return dev->chunkBits +
+	    (dev->chunkBitmapStride * (blk - dev->internalStartBlock));
+}
+
+static Y_INLINE void yaffs_ClearChunkBits(yaffs_Device * dev, int blk)
+{
+	__u8 *blkBits = yaffs_BlockBits(dev, blk);
+
+	memset(blkBits, 0, dev->chunkBitmapStride);
+}
+
+static Y_INLINE void yaffs_ClearChunkBit(yaffs_Device * dev, int blk, int chunk)
+{
+	__u8 *blkBits = yaffs_BlockBits(dev, blk);
+
+	blkBits[chunk / 8] &= ~(1 << (chunk & 7));
+}
+
+static Y_INLINE void yaffs_SetChunkBit(yaffs_Device * dev, int blk, int chunk)
+{
+	__u8 *blkBits = yaffs_BlockBits(dev, blk);
+
+	blkBits[chunk / 8] |= (1 << (chunk & 7));
+}
+
+static Y_INLINE int yaffs_CheckChunkBit(yaffs_Device * dev, int blk, int chunk)
+{
+	__u8 *blkBits = yaffs_BlockBits(dev, blk);
+	return (blkBits[chunk / 8] & (1 << (chunk & 7))) ? 1 : 0;
+}
+
+static Y_INLINE int yaffs_StillSomeChunkBits(yaffs_Device * dev, int blk)
+{
+	__u8 *blkBits = yaffs_BlockBits(dev, blk);
+	int i;
+	for (i = 0; i < dev->chunkBitmapStride; i++) {
+		if (*blkBits)
+			return 1;
+		blkBits++;
+	}
+	return 0;
+}
+
+/*
+ *  Simple hash function. Needs to have a reasonable spread
+ */
+ 
+static Y_INLINE int yaffs_HashFunction(int n)
+{
+	n = abs(n);
+	return (n % YAFFS_NOBJECT_BUCKETS);
+}
+
+/*
+ * Access functions to useful fake objects
+ */
+ 
+yaffs_Object *yaffs_Root(yaffs_Device * dev)
+{
+	return dev->rootDir;
+}
+
+yaffs_Object *yaffs_LostNFound(yaffs_Device * dev)
+{
+	return dev->lostNFoundDir;
+}
+
+
+/*
+ *  Erased NAND checking functions
+ */
+ 
+int yaffs_CheckFF(__u8 * buffer, int nBytes)
+{
+	/* Horrible, slow implementation */
+	while (nBytes--) {
+		if (*buffer != 0xFF)
+			return 0;
+		buffer++;
+	}
+	return 1;
+}
+
+static int yaffs_CheckChunkErased(struct yaffs_DeviceStruct *dev,
+				  int chunkInNAND)
+{
+
+	int retval = YAFFS_OK;
+	__u8 *data = yaffs_GetTempBuffer(dev, __LINE__);
+	yaffs_ExtendedTags tags;
+
+	yaffs_ReadChunkWithTagsFromNAND(dev, chunkInNAND, data, &tags);
+
+	if (!yaffs_CheckFF(data, dev->nBytesPerChunk) || tags.chunkUsed) {
+		T(YAFFS_TRACE_NANDACCESS,
+		  (TSTR("Chunk %d not erased" TENDSTR), chunkInNAND));
+		retval = YAFFS_FAIL;
+	}
+
+	yaffs_ReleaseTempBuffer(dev, data, __LINE__);
+
+	return retval;
+
+}
+
+static int yaffs_WriteNewChunkWithTagsToNAND(struct yaffs_DeviceStruct *dev,
+					     const __u8 * data,
+					     yaffs_ExtendedTags * tags,
+					     int useReserve)
+{
+	int chunk;
+
+	int writeOk = 1;
+	int attempts = 0;
+	
+	yaffs_InvalidateCheckpoint(dev);
+
+	do {
+		chunk = yaffs_AllocateChunk(dev, useReserve);
+
+		if (chunk >= 0) {
+
+			/* First check this chunk is erased... */
+#ifndef CONFIG_YAFFS_DISABLE_CHUNK_ERASED_CHECK
+			writeOk = yaffs_CheckChunkErased(dev, chunk);
+#else
+			writeOk = 1;
+#endif
+			if (!writeOk) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>> yaffs chunk %d was not erased"
+				    TENDSTR), chunk));
+			} else {
+				writeOk =
+				    yaffs_WriteChunkWithTagsToNAND(dev, chunk,
+								   data, tags);
+			}
+			attempts++;
+
+			if (writeOk) {
+				/*
+				 *  Copy the data into the robustification buffer.
+				 *  NB We do this at the end to prevent duplicates in the case of a write error.
+				 *  Todo
+				 */
+				yaffs_HandleWriteChunkOk(dev, chunk, data,
+							 tags);
+			} else {
+				yaffs_HandleWriteChunkError(dev, chunk);
+			}
+		}
+
+	} while (chunk >= 0 && !writeOk);
+
+	if (attempts > 1) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR("**>> yaffs write required %d attempts" TENDSTR),
+		   attempts));
+		dev->nRetriedWrites += (attempts - 1);
+	}
+
+	return chunk;
+}
+
+/*
+ * Block retiring for handling a broken block.
+ */
+ 
+static void yaffs_RetireBlock(yaffs_Device * dev, int blockInNAND)
+{
+
+	yaffs_InvalidateCheckpoint(dev);
+	
+	yaffs_MarkBlockBad(dev, blockInNAND);
+
+	yaffs_GetBlockInfo(dev, blockInNAND)->blockState =
+	    YAFFS_BLOCK_STATE_DEAD;
+
+	dev->nRetiredBlocks++;
+	dev->nBadBlocks++;
+}
+
+/*
+ * Functions for robustisizing TODO
+ *
+ */
+ 
+static void yaffs_HandleWriteChunkOk(yaffs_Device * dev, int chunkInNAND,
+				     const __u8 * data,
+				     const yaffs_ExtendedTags * tags)
+{
+}
+
+static void yaffs_HandleUpdateChunk(yaffs_Device * dev, int chunkInNAND,
+				    const yaffs_ExtendedTags * tags)
+{
+}
+
+void yaffs_HandleWriteChunkError(yaffs_Device * dev, int chunkInNAND)
+{
+	int blockInNAND = chunkInNAND / dev->nChunksPerBlock;
+	yaffs_BlockInfo *bi = yaffs_GetBlockInfo(dev, blockInNAND);
+
+	/* Mark the block for retirement */
+	bi->needsRetiring = 1;
+	bi->needsGC = 1;
+	/* Make sure nothing will be written to this block anymore */
+	if (dev->allocationBlock == blockInNAND) {
+		dev->allocationBlock = -1;
+		bi->blockState = YAFFS_BLOCK_STATE_FULL;
+	}
+	/* Delete the chunk */
+	yaffs_DeleteChunk(dev, chunkInNAND, 1, __LINE__);
+}
+
+void yaffs_HandleReadDataError(yaffs_Device * dev, int chunkInNAND,
+			       int softErr)
+{
+	int blockInNAND = chunkInNAND / dev->nChunksPerBlock;
+	yaffs_BlockInfo *bi = yaffs_GetBlockInfo(dev, blockInNAND);
+
+	if (!softErr) {
+		/* Mark the block for retirement */
+		bi->needsRetiring = 1;
+		T(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+		  (TSTR("**>>Block %d marked for retirement" TENDSTR),
+		   blockInNAND));
+	}
+
+	/* TODO:
+	 * Just do a garbage collection on the affected block
+	 * then retire the block
+	 * NB recursion
+	 */
+	bi->needsGC = 1;
+}
+
+
+/*---------------- Name handling functions ------------*/ 
+
+static __u16 yaffs_CalcNameSum(const YCHAR * name)
+{
+	__u16 sum = 0;
+	__u16 i = 1;
+
+	YUCHAR *bname = (YUCHAR *) name;
+	if (bname) {
+		while ((*bname) && (i <= YAFFS_MAX_NAME_LENGTH)) {
+
+#ifdef CONFIG_YAFFS_CASE_INSENSITIVE
+			sum += yaffs_toupper(*bname) * i;
+#else
+			sum += (*bname) * i;
+#endif
+			i++;
+			bname++;
+		}
+	}
+	return sum;
+}
+
+static void yaffs_SetObjectName(yaffs_Object * obj, const YCHAR * name)
+{
+#ifdef CONFIG_YAFFS_SHORT_NAMES_IN_RAM
+	if (name && yaffs_strlen(name) <= YAFFS_SHORT_NAME_LENGTH) {
+		yaffs_strcpy(obj->shortName, name);
+	} else {
+		obj->shortName[0] = _Y('\0');
+	}
+#endif
+	obj->sum = yaffs_CalcNameSum(name);
+}
+
+/*-------------------- TNODES -------------------
+
+ * List of spare tnodes
+ * The list is hooked together using the first pointer
+ * in the tnode.
+ */
+ 
+/* yaffs_CreateTnodes creates a bunch more tnodes and
+ * adds them to the tnode free list.
+ * Don't use this function directly
+ */
+
+static int yaffs_CreateTnodes(yaffs_Device * dev, int nTnodes)
+{
+	int i;
+	int tnodeSize;
+	yaffs_Tnode *newTnodes;
+	__u8 *mem;
+	yaffs_Tnode *curr;
+	yaffs_Tnode *next;
+	yaffs_TnodeList *tnl;
+
+	if (nTnodes < 1)
+		return YAFFS_OK;
+		
+	/* Calculate the tnode size in bytes for variable width tnode support.
+	 * Must be a multiple of 32-bits  */
+	tnodeSize = (dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8;
+
+	/* make these things */
+
+	newTnodes = YMALLOC(nTnodes * tnodeSize);
+	mem = (__u8 *)newTnodes;
+
+	if (!newTnodes) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR("yaffs: Could not allocate Tnodes" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	/* Hook them into the free list */
+#if 0
+	for (i = 0; i < nTnodes - 1; i++) {
+		newTnodes[i].internal[0] = &newTnodes[i + 1];
+#ifdef CONFIG_YAFFS_TNODE_LIST_DEBUG
+		newTnodes[i].internal[YAFFS_NTNODES_INTERNAL] = (void *)1;
+#endif
+	}
+
+	newTnodes[nTnodes - 1].internal[0] = dev->freeTnodes;
+#ifdef CONFIG_YAFFS_TNODE_LIST_DEBUG
+	newTnodes[nTnodes - 1].internal[YAFFS_NTNODES_INTERNAL] = (void *)1;
+#endif
+	dev->freeTnodes = newTnodes;
+#else
+	/* New hookup for wide tnodes */
+	for(i = 0; i < nTnodes -1; i++) {
+		curr = (yaffs_Tnode *) &mem[i * tnodeSize];
+		next = (yaffs_Tnode *) &mem[(i+1) * tnodeSize];
+		curr->internal[0] = next;
+	}
+	
+	curr = (yaffs_Tnode *) &mem[(nTnodes - 1) * tnodeSize];
+	curr->internal[0] = dev->freeTnodes;
+	dev->freeTnodes = (yaffs_Tnode *)mem;
+
+#endif
+
+
+	dev->nFreeTnodes += nTnodes;
+	dev->nTnodesCreated += nTnodes;
+
+	/* Now add this bunch of tnodes to a list for freeing up.
+	 * NB If we can't add this to the management list it isn't fatal
+	 * but it just means we can't free this bunch of tnodes later.
+	 */
+	 
+	tnl = YMALLOC(sizeof(yaffs_TnodeList));
+	if (!tnl) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR
+		   ("yaffs: Could not add tnodes to management list" TENDSTR)));
+
+	} else {
+		tnl->tnodes = newTnodes;
+		tnl->next = dev->allocatedTnodeList;
+		dev->allocatedTnodeList = tnl;
+	}
+
+	T(YAFFS_TRACE_ALLOCATE, (TSTR("yaffs: Tnodes added" TENDSTR)));
+
+	return YAFFS_OK;
+}
+
+/* GetTnode gets us a clean tnode. Tries to make allocate more if we run out */
+
+static yaffs_Tnode *yaffs_GetTnodeRaw(yaffs_Device * dev)
+{
+	yaffs_Tnode *tn = NULL;
+
+	/* If there are none left make more */
+	if (!dev->freeTnodes) {
+		yaffs_CreateTnodes(dev, YAFFS_ALLOCATION_NTNODES);
+	}
+
+	if (dev->freeTnodes) {
+		tn = dev->freeTnodes;
+#ifdef CONFIG_YAFFS_TNODE_LIST_DEBUG
+		if (tn->internal[YAFFS_NTNODES_INTERNAL] != (void *)1) {
+			/* Hoosterman, this thing looks like it isn't in the list */
+			T(YAFFS_TRACE_ALWAYS,
+			  (TSTR("yaffs: Tnode list bug 1" TENDSTR)));
+		}
+#endif
+		dev->freeTnodes = dev->freeTnodes->internal[0];
+		dev->nFreeTnodes--;
+	}
+
+	return tn;
+}
+
+static yaffs_Tnode *yaffs_GetTnode(yaffs_Device * dev)
+{
+	yaffs_Tnode *tn = yaffs_GetTnodeRaw(dev);
+	
+	if(tn)
+		memset(tn, 0, (dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8);
+
+	return tn;	
+}
+
+/* FreeTnode frees up a tnode and puts it back on the free list */
+static void yaffs_FreeTnode(yaffs_Device * dev, yaffs_Tnode * tn)
+{
+	if (tn) {
+#ifdef CONFIG_YAFFS_TNODE_LIST_DEBUG
+		if (tn->internal[YAFFS_NTNODES_INTERNAL] != 0) {
+			/* Hoosterman, this thing looks like it is already in the list */
+			T(YAFFS_TRACE_ALWAYS,
+			  (TSTR("yaffs: Tnode list bug 2" TENDSTR)));
+		}
+		tn->internal[YAFFS_NTNODES_INTERNAL] = (void *)1;
+#endif
+		tn->internal[0] = dev->freeTnodes;
+		dev->freeTnodes = tn;
+		dev->nFreeTnodes++;
+	}
+}
+
+static void yaffs_DeinitialiseTnodes(yaffs_Device * dev)
+{
+	/* Free the list of allocated tnodes */
+	yaffs_TnodeList *tmp;
+
+	while (dev->allocatedTnodeList) {
+		tmp = dev->allocatedTnodeList->next;
+
+		YFREE(dev->allocatedTnodeList->tnodes);
+		YFREE(dev->allocatedTnodeList);
+		dev->allocatedTnodeList = tmp;
+
+	}
+
+	dev->freeTnodes = NULL;
+	dev->nFreeTnodes = 0;
+}
+
+static void yaffs_InitialiseTnodes(yaffs_Device * dev)
+{
+	dev->allocatedTnodeList = NULL;
+	dev->freeTnodes = NULL;
+	dev->nFreeTnodes = 0;
+	dev->nTnodesCreated = 0;
+
+}
+
+
+void yaffs_PutLevel0Tnode(yaffs_Device *dev, yaffs_Tnode *tn, unsigned pos, unsigned val)
+{
+  __u32 *map = (__u32 *)tn;
+  __u32 bitInMap;
+  __u32 bitInWord;
+  __u32 wordInMap;
+  __u32 mask;
+  
+  pos &= YAFFS_TNODES_LEVEL0_MASK;
+  val >>= dev->chunkGroupBits;
+  
+  bitInMap = pos * dev->tnodeWidth;
+  wordInMap = bitInMap /32;
+  bitInWord = bitInMap & (32 -1);
+  
+  mask = dev->tnodeMask << bitInWord;
+  
+  map[wordInMap] &= ~mask;
+  map[wordInMap] |= (mask & (val << bitInWord));
+  
+  if(dev->tnodeWidth > (32-bitInWord)) {
+    bitInWord = (32 - bitInWord);
+    wordInMap++;;
+    mask = dev->tnodeMask >> (/*dev->tnodeWidth -*/ bitInWord);
+    map[wordInMap] &= ~mask;
+    map[wordInMap] |= (mask & (val >> bitInWord));
+  }
+}
+
+__u32 yaffs_GetChunkGroupBase(yaffs_Device *dev, yaffs_Tnode *tn, unsigned pos)
+{
+  __u32 *map = (__u32 *)tn;
+  __u32 bitInMap;
+  __u32 bitInWord;
+  __u32 wordInMap;
+  __u32 val;
+  
+  pos &= YAFFS_TNODES_LEVEL0_MASK;
+  
+  bitInMap = pos * dev->tnodeWidth;
+  wordInMap = bitInMap /32;
+  bitInWord = bitInMap & (32 -1);
+  
+  val = map[wordInMap] >> bitInWord;
+  
+  if(dev->tnodeWidth > (32-bitInWord)) {
+    bitInWord = (32 - bitInWord);
+    wordInMap++;;
+    val |= (map[wordInMap] << bitInWord);
+  }
+  
+  val &= dev->tnodeMask;
+  val <<= dev->chunkGroupBits;
+  
+  return val;
+}
+
+/* ------------------- End of individual tnode manipulation -----------------*/
+
+/* ---------Functions to manipulate the look-up tree (made up of tnodes) ------
+ * The look up tree is represented by the top tnode and the number of topLevel
+ * in the tree. 0 means only the level 0 tnode is in the tree.
+ */
+
+/* FindLevel0Tnode finds the level 0 tnode, if one exists. */
+static yaffs_Tnode *yaffs_FindLevel0Tnode(yaffs_Device * dev,
+					  yaffs_FileStructure * fStruct,
+					  __u32 chunkId)
+{
+
+	yaffs_Tnode *tn = fStruct->top;
+	__u32 i;
+	int requiredTallness;
+	int level = fStruct->topLevel;
+
+	/* Check sane level and chunk Id */
+	if (level < 0 || level > YAFFS_TNODES_MAX_LEVEL) {
+		return NULL;
+	}
+
+	if (chunkId > YAFFS_MAX_CHUNK_ID) {
+		return NULL;
+	}
+
+	/* First check we're tall enough (ie enough topLevel) */
+
+	i = chunkId >> YAFFS_TNODES_LEVEL0_BITS;
+	requiredTallness = 0;
+	while (i) {
+		i >>= YAFFS_TNODES_INTERNAL_BITS;
+		requiredTallness++;
+	}
+
+	if (requiredTallness > fStruct->topLevel) {
+		/* Not tall enough, so we can't find it, return NULL. */
+		return NULL;
+	}
+
+	/* Traverse down to level 0 */
+	while (level > 0 && tn) {
+		tn = tn->
+		    internal[(chunkId >>
+			       ( YAFFS_TNODES_LEVEL0_BITS + 
+			         (level - 1) *
+			         YAFFS_TNODES_INTERNAL_BITS)
+			      ) &
+			     YAFFS_TNODES_INTERNAL_MASK];
+		level--;
+
+	}
+
+	return tn;
+}
+
+/* AddOrFindLevel0Tnode finds the level 0 tnode if it exists, otherwise first expands the tree.
+ * This happens in two steps:
+ *  1. If the tree isn't tall enough, then make it taller.
+ *  2. Scan down the tree towards the level 0 tnode adding tnodes if required.
+ *
+ * Used when modifying the tree.
+ *
+ *  If the tn argument is NULL, then a fresh tnode will be added otherwise the specified tn will
+ *  be plugged into the ttree.
+ */
+ 
+static yaffs_Tnode *yaffs_AddOrFindLevel0Tnode(yaffs_Device * dev,
+					       yaffs_FileStructure * fStruct,
+					       __u32 chunkId,
+					       yaffs_Tnode *passedTn)
+{
+
+	int requiredTallness;
+	int i;
+	int l;
+	yaffs_Tnode *tn;
+
+	__u32 x;
+
+
+	/* Check sane level and page Id */
+	if (fStruct->topLevel < 0 || fStruct->topLevel > YAFFS_TNODES_MAX_LEVEL) {
+		return NULL;
+	}
+
+	if (chunkId > YAFFS_MAX_CHUNK_ID) {
+		return NULL;
+	}
+
+	/* First check we're tall enough (ie enough topLevel) */
+
+	x = chunkId >> YAFFS_TNODES_LEVEL0_BITS;
+	requiredTallness = 0;
+	while (x) {
+		x >>= YAFFS_TNODES_INTERNAL_BITS;
+		requiredTallness++;
+	}
+
+
+	if (requiredTallness > fStruct->topLevel) {
+		/* Not tall enough,gotta make the tree taller */
+		for (i = fStruct->topLevel; i < requiredTallness; i++) {
+		
+			tn = yaffs_GetTnode(dev);
+
+			if (tn) {
+				tn->internal[0] = fStruct->top;
+				fStruct->top = tn;
+			} else {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR("yaffs: no more tnodes" TENDSTR)));
+			}
+		}
+
+		fStruct->topLevel = requiredTallness;
+	}
+
+	/* Traverse down to level 0, adding anything we need */
+
+	l = fStruct->topLevel;
+	tn = fStruct->top;
+	
+	if(l > 0) {
+		while (l > 0 && tn) {
+			x = (chunkId >>
+			     ( YAFFS_TNODES_LEVEL0_BITS +
+			      (l - 1) * YAFFS_TNODES_INTERNAL_BITS)) &
+			    YAFFS_TNODES_INTERNAL_MASK;
+
+
+			if((l>1) && !tn->internal[x]){
+				/* Add missing non-level-zero tnode */
+				tn->internal[x] = yaffs_GetTnode(dev);
+
+			} else if(l == 1) {
+				/* Looking from level 1 at level 0 */
+			 	if (passedTn) {
+					/* If we already have one, then release it.*/
+					if(tn->internal[x])
+						yaffs_FreeTnode(dev,tn->internal[x]);
+					tn->internal[x] = passedTn;
+			
+				} else if(!tn->internal[x]) {
+					/* Don't have one, none passed in */
+					tn->internal[x] = yaffs_GetTnode(dev);
+				}
+			}
+		
+			tn = tn->internal[x];
+			l--;
+		}
+	} else {
+		/* top is level 0 */
+		if(passedTn) {
+			memcpy(tn,passedTn,(dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8);
+			yaffs_FreeTnode(dev,passedTn);
+		}
+	}
+
+	return tn;
+}
+
+static int yaffs_FindChunkInGroup(yaffs_Device * dev, int theChunk,
+				  yaffs_ExtendedTags * tags, int objectId,
+				  int chunkInInode)
+{
+	int j;
+
+	for (j = 0; theChunk && j < dev->chunkGroupSize; j++) {
+		if (yaffs_CheckChunkBit
+		    (dev, theChunk / dev->nChunksPerBlock,
+		     theChunk % dev->nChunksPerBlock)) {
+			yaffs_ReadChunkWithTagsFromNAND(dev, theChunk, NULL,
+							tags);
+			if (yaffs_TagsMatch(tags, objectId, chunkInInode)) {
+				/* found it; */
+				return theChunk;
+
+			}
+		}
+		theChunk++;
+	}
+	return -1;
+}
+
+
+/* DeleteWorker scans backwards through the tnode tree and deletes all the
+ * chunks and tnodes in the file
+ * Returns 1 if the tree was deleted. 
+ * Returns 0 if it stopped early due to hitting the limit and the delete is incomplete.
+ */
+
+static int yaffs_DeleteWorker(yaffs_Object * in, yaffs_Tnode * tn, __u32 level,
+			      int chunkOffset, int *limit)
+{
+	int i;
+	int chunkInInode;
+	int theChunk;
+	yaffs_ExtendedTags tags;
+	int foundChunk;
+	yaffs_Device *dev = in->myDev;
+
+	int allDone = 1;
+
+	if (tn) {
+		if (level > 0) {
+
+			for (i = YAFFS_NTNODES_INTERNAL - 1; allDone && i >= 0;
+			     i--) {
+				if (tn->internal[i]) {
+					if (limit && (*limit) < 0) {
+						allDone = 0;
+					} else {
+						allDone =
+						    yaffs_DeleteWorker(in,
+								       tn->
+								       internal
+								       [i],
+								       level -
+								       1,
+								       (chunkOffset
+									<<
+									YAFFS_TNODES_INTERNAL_BITS)
+								       + i,
+								       limit);
+					}
+					if (allDone) {
+						yaffs_FreeTnode(dev,
+								tn->
+								internal[i]);
+						tn->internal[i] = NULL;
+					}
+				}
+
+			}
+			return (allDone) ? 1 : 0;
+		} else if (level == 0) {
+			int hitLimit = 0;
+
+			for (i = YAFFS_NTNODES_LEVEL0 - 1; i >= 0 && !hitLimit;
+			     i--) {
+			        theChunk = yaffs_GetChunkGroupBase(dev,tn,i);
+				if (theChunk) {
+
+					chunkInInode =
+					    (chunkOffset <<
+					     YAFFS_TNODES_LEVEL0_BITS) + i;
+
+					foundChunk =
+					    yaffs_FindChunkInGroup(dev,
+								   theChunk,
+								   &tags,
+								   in->objectId,
+								   chunkInInode);
+
+					if (foundChunk > 0) {
+						yaffs_DeleteChunk(dev,
+								  foundChunk, 1,
+								  __LINE__);
+						in->nDataChunks--;
+						if (limit) {
+							*limit = *limit - 1;
+							if (*limit <= 0) {
+								hitLimit = 1;
+							}
+						}
+
+					}
+
+					yaffs_PutLevel0Tnode(dev,tn,i,0);
+				}
+
+			}
+			return (i < 0) ? 1 : 0;
+
+		}
+
+	}
+
+	return 1;
+
+}
+
+static void yaffs_SoftDeleteChunk(yaffs_Device * dev, int chunk)
+{
+
+	yaffs_BlockInfo *theBlock;
+
+	T(YAFFS_TRACE_DELETION, (TSTR("soft delete chunk %d" TENDSTR), chunk));
+
+	theBlock = yaffs_GetBlockInfo(dev, chunk / dev->nChunksPerBlock);
+	if (theBlock) {
+		theBlock->softDeletions++;
+		dev->nFreeChunks++;
+	}
+}
+
+/* SoftDeleteWorker scans backwards through the tnode tree and soft deletes all the chunks in the file.
+ * All soft deleting does is increment the block's softdelete count and pulls the chunk out
+ * of the tnode.
+ * Thus, essentially this is the same as DeleteWorker except that the chunks are soft deleted.
+ */
+ 
+static int yaffs_SoftDeleteWorker(yaffs_Object * in, yaffs_Tnode * tn,
+				  __u32 level, int chunkOffset)
+{
+	int i;
+	int theChunk;
+	int allDone = 1;
+	yaffs_Device *dev = in->myDev;
+
+	if (tn) {
+		if (level > 0) {
+
+			for (i = YAFFS_NTNODES_INTERNAL - 1; allDone && i >= 0;
+			     i--) {
+				if (tn->internal[i]) {
+					allDone =
+					    yaffs_SoftDeleteWorker(in,
+								   tn->
+								   internal[i],
+								   level - 1,
+								   (chunkOffset
+								    <<
+								    YAFFS_TNODES_INTERNAL_BITS)
+								   + i);
+					if (allDone) {
+						yaffs_FreeTnode(dev,
+								tn->
+								internal[i]);
+						tn->internal[i] = NULL;
+					} else {
+						/* Hoosterman... how could this happen? */
+					}
+				}
+			}
+			return (allDone) ? 1 : 0;
+		} else if (level == 0) {
+
+			for (i = YAFFS_NTNODES_LEVEL0 - 1; i >= 0; i--) {
+				theChunk = yaffs_GetChunkGroupBase(dev,tn,i);
+				if (theChunk) {
+					/* Note this does not find the real chunk, only the chunk group.
+					 * We make an assumption that a chunk group is not larger than 
+					 * a block.
+					 */
+					yaffs_SoftDeleteChunk(dev, theChunk);
+					yaffs_PutLevel0Tnode(dev,tn,i,0);
+				}
+
+			}
+			return 1;
+
+		}
+
+	}
+
+	return 1;
+
+}
+
+static void yaffs_SoftDeleteFile(yaffs_Object * obj)
+{
+	if (obj->deleted &&
+	    obj->variantType == YAFFS_OBJECT_TYPE_FILE && !obj->softDeleted) {
+		if (obj->nDataChunks <= 0) {
+			/* Empty file with no duplicate object headers, just delete it immediately */
+			yaffs_FreeTnode(obj->myDev,
+					obj->variant.fileVariant.top);
+			obj->variant.fileVariant.top = NULL;
+			T(YAFFS_TRACE_TRACING,
+			  (TSTR("yaffs: Deleting empty file %d" TENDSTR),
+			   obj->objectId));
+			yaffs_DoGenericObjectDeletion(obj);
+		} else {
+			yaffs_SoftDeleteWorker(obj,
+					       obj->variant.fileVariant.top,
+					       obj->variant.fileVariant.
+					       topLevel, 0);
+			obj->softDeleted = 1;
+		}
+	}
+}
+
+/* Pruning removes any part of the file structure tree that is beyond the
+ * bounds of the file (ie that does not point to chunks).
+ *
+ * A file should only get pruned when its size is reduced.
+ *
+ * Before pruning, the chunks must be pulled from the tree and the
+ * level 0 tnode entries must be zeroed out.
+ * Could also use this for file deletion, but that's probably better handled
+ * by a special case.
+ */
+
+static yaffs_Tnode *yaffs_PruneWorker(yaffs_Device * dev, yaffs_Tnode * tn,
+				      __u32 level, int del0)
+{
+	int i;
+	int hasData;
+
+	if (tn) {
+		hasData = 0;
+
+		for (i = 0; i < YAFFS_NTNODES_INTERNAL; i++) {
+			if (tn->internal[i] && level > 0) {
+				tn->internal[i] =
+				    yaffs_PruneWorker(dev, tn->internal[i],
+						      level - 1,
+						      (i == 0) ? del0 : 1);
+			}
+
+			if (tn->internal[i]) {
+				hasData++;
+			}
+		}
+
+		if (hasData == 0 && del0) {
+			/* Free and return NULL */
+
+			yaffs_FreeTnode(dev, tn);
+			tn = NULL;
+		}
+
+	}
+
+	return tn;
+
+}
+
+static int yaffs_PruneFileStructure(yaffs_Device * dev,
+				    yaffs_FileStructure * fStruct)
+{
+	int i;
+	int hasData;
+	int done = 0;
+	yaffs_Tnode *tn;
+
+	if (fStruct->topLevel > 0) {
+		fStruct->top =
+		    yaffs_PruneWorker(dev, fStruct->top, fStruct->topLevel, 0);
+
+		/* Now we have a tree with all the non-zero branches NULL but the height
+		 * is the same as it was.
+		 * Let's see if we can trim internal tnodes to shorten the tree.
+		 * We can do this if only the 0th element in the tnode is in use 
+		 * (ie all the non-zero are NULL)
+		 */
+
+		while (fStruct->topLevel && !done) {
+			tn = fStruct->top;
+
+			hasData = 0;
+			for (i = 1; i < YAFFS_NTNODES_INTERNAL; i++) {
+				if (tn->internal[i]) {
+					hasData++;
+				}
+			}
+
+			if (!hasData) {
+				fStruct->top = tn->internal[0];
+				fStruct->topLevel--;
+				yaffs_FreeTnode(dev, tn);
+			} else {
+				done = 1;
+			}
+		}
+	}
+
+	return YAFFS_OK;
+}
+
+/*-------------------- End of File Structure functions.-------------------*/
+
+/* yaffs_CreateFreeObjects creates a bunch more objects and
+ * adds them to the object free list.
+ */
+static int yaffs_CreateFreeObjects(yaffs_Device * dev, int nObjects)
+{
+	int i;
+	yaffs_Object *newObjects;
+	yaffs_ObjectList *list;
+
+	if (nObjects < 1)
+		return YAFFS_OK;
+
+	/* make these things */
+	newObjects = YMALLOC(nObjects * sizeof(yaffs_Object));
+
+	if (!newObjects) {
+		T(YAFFS_TRACE_ALLOCATE,
+		  (TSTR("yaffs: Could not allocate more objects" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+	
+	/* Hook them into the free list */
+	for (i = 0; i < nObjects - 1; i++) {
+		newObjects[i].siblings.next =
+		    (struct list_head *)(&newObjects[i + 1]);
+	}
+
+	newObjects[nObjects - 1].siblings.next = (void *)dev->freeObjects;
+	dev->freeObjects = newObjects;
+	dev->nFreeObjects += nObjects;
+	dev->nObjectsCreated += nObjects;
+
+	/* Now add this bunch of Objects to a list for freeing up. */
+
+	list = YMALLOC(sizeof(yaffs_ObjectList));
+	if (!list) {
+		T(YAFFS_TRACE_ALLOCATE,
+		  (TSTR("Could not add objects to management list" TENDSTR)));
+	} else {
+		list->objects = newObjects;
+		list->next = dev->allocatedObjectList;
+		dev->allocatedObjectList = list;
+	}
+
+	return YAFFS_OK;
+}
+
+
+/* AllocateEmptyObject gets us a clean Object. Tries to make allocate more if we run out */
+static yaffs_Object *yaffs_AllocateEmptyObject(yaffs_Device * dev)
+{
+	yaffs_Object *tn = NULL;
+
+	/* If there are none left make more */
+	if (!dev->freeObjects) {
+		yaffs_CreateFreeObjects(dev, YAFFS_ALLOCATION_NOBJECTS);
+	}
+
+	if (dev->freeObjects) {
+		tn = dev->freeObjects;
+		dev->freeObjects =
+		    (yaffs_Object *) (dev->freeObjects->siblings.next);
+		dev->nFreeObjects--;
+
+		/* Now sweeten it up... */
+
+		memset(tn, 0, sizeof(yaffs_Object));
+		tn->myDev = dev;
+		tn->hdrChunk = 0;
+		tn->variantType = YAFFS_OBJECT_TYPE_UNKNOWN;
+		INIT_LIST_HEAD(&(tn->hardLinks));
+		INIT_LIST_HEAD(&(tn->hashLink));
+		INIT_LIST_HEAD(&tn->siblings);
+
+		/* Add it to the lost and found directory.
+		 * NB Can't put root or lostNFound in lostNFound so
+		 * check if lostNFound exists first
+		 */
+		if (dev->lostNFoundDir) {
+			yaffs_AddObjectToDirectory(dev->lostNFoundDir, tn);
+		}
+	}
+
+	return tn;
+}
+
+static yaffs_Object *yaffs_CreateFakeDirectory(yaffs_Device * dev, int number,
+					       __u32 mode)
+{
+
+	yaffs_Object *obj =
+	    yaffs_CreateNewObject(dev, number, YAFFS_OBJECT_TYPE_DIRECTORY);
+	if (obj) {
+		obj->fake = 1;		/* it is fake so it has no NAND presence... */
+		obj->renameAllowed = 0;	/* ... and we're not allowed to rename it... */
+		obj->unlinkAllowed = 0;	/* ... or unlink it */
+		obj->deleted = 0;
+		obj->unlinked = 0;
+		obj->yst_mode = mode;
+		obj->myDev = dev;
+		obj->hdrChunk = 0;	/* Not a valid chunk. */
+	}
+
+	return obj;
+
+}
+
+static void yaffs_UnhashObject(yaffs_Object * tn)
+{
+	int bucket;
+	yaffs_Device *dev = tn->myDev;
+
+	/* If it is still linked into the bucket list, free from the list */
+	if (!list_empty(&tn->hashLink)) {
+		list_del_init(&tn->hashLink);
+		bucket = yaffs_HashFunction(tn->objectId);
+		dev->objectBucket[bucket].count--;
+	}
+
+}
+
+/*  FreeObject frees up a Object and puts it back on the free list */
+static void yaffs_FreeObject(yaffs_Object * tn)
+{
+
+	yaffs_Device *dev = tn->myDev;
+
+#ifdef  __KERNEL__
+	if (tn->myInode) {
+		/* We're still hooked up to a cached inode.
+		 * Don't delete now, but mark for later deletion
+		 */
+		tn->deferedFree = 1;
+		return;
+	}
+#endif
+
+	yaffs_UnhashObject(tn);
+
+	/* Link into the free list. */
+	tn->siblings.next = (struct list_head *)(dev->freeObjects);
+	dev->freeObjects = tn;
+	dev->nFreeObjects++;
+}
+
+#ifdef __KERNEL__
+
+void yaffs_HandleDeferedFree(yaffs_Object * obj)
+{
+	if (obj->deferedFree) {
+		yaffs_FreeObject(obj);
+	}
+}
+
+#endif
+
+static void yaffs_DeinitialiseObjects(yaffs_Device * dev)
+{
+	/* Free the list of allocated Objects */
+
+	yaffs_ObjectList *tmp;
+
+	while (dev->allocatedObjectList) {
+		tmp = dev->allocatedObjectList->next;
+		YFREE(dev->allocatedObjectList->objects);
+		YFREE(dev->allocatedObjectList);
+
+		dev->allocatedObjectList = tmp;
+	}
+
+	dev->freeObjects = NULL;
+	dev->nFreeObjects = 0;
+}
+
+static void yaffs_InitialiseObjects(yaffs_Device * dev)
+{
+	int i;
+
+	dev->allocatedObjectList = NULL;
+	dev->freeObjects = NULL;
+	dev->nFreeObjects = 0;
+
+	for (i = 0; i < YAFFS_NOBJECT_BUCKETS; i++) {
+		INIT_LIST_HEAD(&dev->objectBucket[i].list);
+		dev->objectBucket[i].count = 0;
+	}
+
+}
+
+static int yaffs_FindNiceObjectBucket(yaffs_Device * dev)
+{
+	static int x = 0;
+	int i;
+	int l = 999;
+	int lowest = 999999;
+
+	/* First let's see if we can find one that's empty. */
+
+	for (i = 0; i < 10 && lowest > 0; i++) {
+		x++;
+		x %= YAFFS_NOBJECT_BUCKETS;
+		if (dev->objectBucket[x].count < lowest) {
+			lowest = dev->objectBucket[x].count;
+			l = x;
+		}
+
+	}
+
+	/* If we didn't find an empty list, then try
+	 * looking a bit further for a short one
+	 */
+
+	for (i = 0; i < 10 && lowest > 3; i++) {
+		x++;
+		x %= YAFFS_NOBJECT_BUCKETS;
+		if (dev->objectBucket[x].count < lowest) {
+			lowest = dev->objectBucket[x].count;
+			l = x;
+		}
+
+	}
+
+	return l;
+}
+
+static int yaffs_CreateNewObjectNumber(yaffs_Device * dev)
+{
+	int bucket = yaffs_FindNiceObjectBucket(dev);
+
+	/* Now find an object value that has not already been taken
+	 * by scanning the list.
+	 */
+
+	int found = 0;
+	struct list_head *i;
+
+	__u32 n = (__u32) bucket;
+
+	/* yaffs_CheckObjectHashSanity();  */
+
+	while (!found) {
+		found = 1;
+		n += YAFFS_NOBJECT_BUCKETS;
+		if (1 || dev->objectBucket[bucket].count > 0) {
+			list_for_each(i, &dev->objectBucket[bucket].list) {
+				/* If there is already one in the list */
+				if (i
+				    && list_entry(i, yaffs_Object,
+						  hashLink)->objectId == n) {
+					found = 0;
+				}
+			}
+		}
+	}
+
+
+	return n;
+}
+
+static void yaffs_HashObject(yaffs_Object * in)
+{
+	int bucket = yaffs_HashFunction(in->objectId);
+	yaffs_Device *dev = in->myDev;
+
+	list_add(&in->hashLink, &dev->objectBucket[bucket].list);
+	dev->objectBucket[bucket].count++;
+
+}
+
+yaffs_Object *yaffs_FindObjectByNumber(yaffs_Device * dev, __u32 number)
+{
+	int bucket = yaffs_HashFunction(number);
+	struct list_head *i;
+	yaffs_Object *in;
+
+	list_for_each(i, &dev->objectBucket[bucket].list) {
+		/* Look if it is in the list */
+		if (i) {
+			in = list_entry(i, yaffs_Object, hashLink);
+			if (in->objectId == number) {
+#ifdef __KERNEL__
+				/* Don't tell the VFS about this one if it is defered free */
+				if (in->deferedFree)
+					return NULL;
+#endif
+
+				return in;
+			}
+		}
+	}
+
+	return NULL;
+}
+
+yaffs_Object *yaffs_CreateNewObject(yaffs_Device * dev, int number,
+				    yaffs_ObjectType type)
+{
+
+	yaffs_Object *theObject;
+
+	if (number < 0) {
+		number = yaffs_CreateNewObjectNumber(dev);
+	}
+
+	theObject = yaffs_AllocateEmptyObject(dev);
+
+	if (theObject) {
+		theObject->fake = 0;
+		theObject->renameAllowed = 1;
+		theObject->unlinkAllowed = 1;
+		theObject->objectId = number;
+		yaffs_HashObject(theObject);
+		theObject->variantType = type;
+#ifdef CONFIG_YAFFS_WINCE
+		yfsd_WinFileTimeNow(theObject->win_atime);
+		theObject->win_ctime[0] = theObject->win_mtime[0] =
+		    theObject->win_atime[0];
+		theObject->win_ctime[1] = theObject->win_mtime[1] =
+		    theObject->win_atime[1];
+
+#else
+
+		theObject->yst_atime = theObject->yst_mtime =
+		    theObject->yst_ctime = Y_CURRENT_TIME;
+#endif
+		switch (type) {
+		case YAFFS_OBJECT_TYPE_FILE:
+			theObject->variant.fileVariant.fileSize = 0;
+			theObject->variant.fileVariant.scannedFileSize = 0;
+			theObject->variant.fileVariant.shrinkSize = 0xFFFFFFFF;	/* max __u32 */
+			theObject->variant.fileVariant.topLevel = 0;
+			theObject->variant.fileVariant.top =
+			    yaffs_GetTnode(dev);
+			break;
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+			INIT_LIST_HEAD(&theObject->variant.directoryVariant.
+				       children);
+			break;
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+			/* No action required */
+			break;
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+			/* todo this should not happen */
+			break;
+		}
+	}
+
+	return theObject;
+}
+
+static yaffs_Object *yaffs_FindOrCreateObjectByNumber(yaffs_Device * dev,
+						      int number,
+						      yaffs_ObjectType type)
+{
+	yaffs_Object *theObject = NULL;
+
+	if (number > 0) {
+		theObject = yaffs_FindObjectByNumber(dev, number);
+	}
+
+	if (!theObject) {
+		theObject = yaffs_CreateNewObject(dev, number, type);
+	}
+
+	return theObject;
+
+}
+			
+
+static YCHAR *yaffs_CloneString(const YCHAR * str)
+{
+	YCHAR *newStr = NULL;
+
+	if (str && *str) {
+		newStr = YMALLOC((yaffs_strlen(str) + 1) * sizeof(YCHAR));
+		yaffs_strcpy(newStr, str);
+	}
+
+	return newStr;
+
+}
+
+/*
+ * Mknod (create) a new object.
+ * equivalentObject only has meaning for a hard link;
+ * aliasString only has meaning for a sumlink.
+ * rdev only has meaning for devices (a subset of special objects)
+ */
+ 
+static yaffs_Object *yaffs_MknodObject(yaffs_ObjectType type,
+				       yaffs_Object * parent,
+				       const YCHAR * name,
+				       __u32 mode,
+				       __u32 uid,
+				       __u32 gid,
+				       yaffs_Object * equivalentObject,
+				       const YCHAR * aliasString, __u32 rdev)
+{
+	yaffs_Object *in;
+
+	yaffs_Device *dev = parent->myDev;
+
+	/* Check if the entry exists. If it does then fail the call since we don't want a dup.*/
+	if (yaffs_FindObjectByName(parent, name)) {
+		return NULL;
+	}
+
+	in = yaffs_CreateNewObject(dev, -1, type);
+
+	if (in) {
+		in->hdrChunk = 0;
+		in->valid = 1;
+		in->variantType = type;
+
+		in->yst_mode = mode;
+
+#ifdef CONFIG_YAFFS_WINCE
+		yfsd_WinFileTimeNow(in->win_atime);
+		in->win_ctime[0] = in->win_mtime[0] = in->win_atime[0];
+		in->win_ctime[1] = in->win_mtime[1] = in->win_atime[1];
+
+#else
+		in->yst_atime = in->yst_mtime = in->yst_ctime = Y_CURRENT_TIME;
+
+		in->yst_rdev = rdev;
+		in->yst_uid = uid;
+		in->yst_gid = gid;
+#endif
+		in->nDataChunks = 0;
+
+		yaffs_SetObjectName(in, name);
+		in->dirty = 1;
+
+		yaffs_AddObjectToDirectory(parent, in);
+
+		in->myDev = parent->myDev;
+
+		switch (type) {
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+			in->variant.symLinkVariant.alias =
+			    yaffs_CloneString(aliasString);
+			break;
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+			in->variant.hardLinkVariant.equivalentObject =
+			    equivalentObject;
+			in->variant.hardLinkVariant.equivalentObjectId =
+			    equivalentObject->objectId;
+			list_add(&in->hardLinks, &equivalentObject->hardLinks);
+			break;
+		case YAFFS_OBJECT_TYPE_FILE:	
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+			/* do nothing */
+			break;
+		}
+
+		if (yaffs_UpdateObjectHeader(in, name, 0, 0, 0) < 0) {
+			/* Could not create the object header, fail the creation */
+			yaffs_DestroyObject(in);
+			in = NULL;
+		}
+
+	}
+
+	return in;
+}
+
+yaffs_Object *yaffs_MknodFile(yaffs_Object * parent, const YCHAR * name,
+			      __u32 mode, __u32 uid, __u32 gid)
+{
+	return yaffs_MknodObject(YAFFS_OBJECT_TYPE_FILE, parent, name, mode,
+				 uid, gid, NULL, NULL, 0);
+}
+
+yaffs_Object *yaffs_MknodDirectory(yaffs_Object * parent, const YCHAR * name,
+				   __u32 mode, __u32 uid, __u32 gid)
+{
+	return yaffs_MknodObject(YAFFS_OBJECT_TYPE_DIRECTORY, parent, name,
+				 mode, uid, gid, NULL, NULL, 0);
+}
+
+yaffs_Object *yaffs_MknodSpecial(yaffs_Object * parent, const YCHAR * name,
+				 __u32 mode, __u32 uid, __u32 gid, __u32 rdev)
+{
+	return yaffs_MknodObject(YAFFS_OBJECT_TYPE_SPECIAL, parent, name, mode,
+				 uid, gid, NULL, NULL, rdev);
+}
+
+yaffs_Object *yaffs_MknodSymLink(yaffs_Object * parent, const YCHAR * name,
+				 __u32 mode, __u32 uid, __u32 gid,
+				 const YCHAR * alias)
+{
+	return yaffs_MknodObject(YAFFS_OBJECT_TYPE_SYMLINK, parent, name, mode,
+				 uid, gid, NULL, alias, 0);
+}
+
+/* yaffs_Link returns the object id of the equivalent object.*/
+yaffs_Object *yaffs_Link(yaffs_Object * parent, const YCHAR * name,
+			 yaffs_Object * equivalentObject)
+{
+	/* Get the real object in case we were fed a hard link as an equivalent object */
+	equivalentObject = yaffs_GetEquivalentObject(equivalentObject);
+
+	if (yaffs_MknodObject
+	    (YAFFS_OBJECT_TYPE_HARDLINK, parent, name, 0, 0, 0,
+	     equivalentObject, NULL, 0)) {
+		return equivalentObject;
+	} else {
+		return NULL;
+	}
+
+}
+
+static int yaffs_ChangeObjectName(yaffs_Object * obj, yaffs_Object * newDir,
+				  const YCHAR * newName, int force, int shadows)
+{
+	int unlinkOp;
+	int deleteOp;
+
+	yaffs_Object *existingTarget;
+
+	if (newDir == NULL) {
+		newDir = obj->parent;	/* use the old directory */
+	}
+
+	if (newDir->variantType != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragendy: yaffs_ChangeObjectName: newDir is not a directory"
+		    TENDSTR)));
+		YBUG();
+	}
+	
+	/* TODO: Do we need this different handling for YAFFS2 and YAFFS1?? */
+	if (obj->myDev->isYaffs2) {
+		unlinkOp = (newDir == obj->myDev->unlinkedDir);
+	} else {
+		unlinkOp = (newDir == obj->myDev->unlinkedDir
+			    && obj->variantType == YAFFS_OBJECT_TYPE_FILE);
+	}
+
+	deleteOp = (newDir == obj->myDev->deletedDir);
+
+	existingTarget = yaffs_FindObjectByName(newDir, newName);
+
+	/* If the object is a file going into the unlinked directory, 
+	 *   then it is OK to just stuff it in since duplicate names are allowed.
+	 *   else only proceed if the new name does not exist and if we're putting 
+	 *   it into a directory.
+	 */
+	if ((unlinkOp ||
+	     deleteOp ||
+	     force ||
+	     (shadows > 0) ||
+	     !existingTarget) &&
+	    newDir->variantType == YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_SetObjectName(obj, newName);
+		obj->dirty = 1;
+
+		yaffs_AddObjectToDirectory(newDir, obj);
+
+		if (unlinkOp)
+			obj->unlinked = 1;
+
+		/* If it is a deletion then we mark it as a shrink for gc purposes. */
+		if (yaffs_UpdateObjectHeader(obj, newName, 0, deleteOp, shadows)>= 0)
+			return YAFFS_OK;
+	}
+
+	return YAFFS_FAIL;
+}
+
+int yaffs_RenameObject(yaffs_Object * oldDir, const YCHAR * oldName,
+		       yaffs_Object * newDir, const YCHAR * newName)
+{
+	yaffs_Object *obj;
+	yaffs_Object *existingTarget;
+	int force = 0;
+
+#ifdef CONFIG_YAFFS_CASE_INSENSITIVE
+	/* Special case for case insemsitive systems (eg. WinCE).
+	 * While look-up is case insensitive, the name isn't.
+	 * Therefore we might want to change x.txt to X.txt
+	*/
+	if (oldDir == newDir && yaffs_strcmp(oldName, newName) == 0) {
+		force = 1;
+	}
+#endif
+
+	obj = yaffs_FindObjectByName(oldDir, oldName);
+	/* Check new name to long. */
+	if (obj->variantType == YAFFS_OBJECT_TYPE_SYMLINK &&
+	    yaffs_strlen(newName) > YAFFS_MAX_ALIAS_LENGTH)
+	  /* ENAMETOOLONG */
+	  return YAFFS_FAIL;
+	else if (obj->variantType != YAFFS_OBJECT_TYPE_SYMLINK &&
+		 yaffs_strlen(newName) > YAFFS_MAX_NAME_LENGTH)
+	  /* ENAMETOOLONG */
+	  return YAFFS_FAIL;
+
+	if (obj && obj->renameAllowed) {
+
+		/* Now do the handling for an existing target, if there is one */
+
+		existingTarget = yaffs_FindObjectByName(newDir, newName);
+		if (existingTarget &&
+		    existingTarget->variantType == YAFFS_OBJECT_TYPE_DIRECTORY &&
+		    !list_empty(&existingTarget->variant.directoryVariant.children)) {
+			/* There is a target that is a non-empty directory, so we fail */
+			return YAFFS_FAIL;	/* EEXIST or ENOTEMPTY */
+		} else if (existingTarget && existingTarget != obj) {
+			/* Nuke the target first, using shadowing, 
+			 * but only if it isn't the same object
+			 */
+			yaffs_ChangeObjectName(obj, newDir, newName, force,
+					       existingTarget->objectId);
+			yaffs_UnlinkObject(existingTarget);
+		}
+
+		return yaffs_ChangeObjectName(obj, newDir, newName, 1, 0);
+	}
+	return YAFFS_FAIL;
+}
+
+/*------------------------- Block Management and Page Allocation ----------------*/
+
+static int yaffs_InitialiseBlocks(yaffs_Device * dev)
+{
+	int nBlocks = dev->internalEndBlock - dev->internalStartBlock + 1;
+	
+	dev->allocationBlock = -1;	/* force it to get a new one */
+
+	/* Todo we're assuming the malloc will pass. */
+	dev->blockInfo = YMALLOC(nBlocks * sizeof(yaffs_BlockInfo));
+	if(!dev->blockInfo){
+		dev->blockInfo = YMALLOC_ALT(nBlocks * sizeof(yaffs_BlockInfo));
+		dev->blockInfoAlt = 1;
+	}
+	else
+		dev->blockInfoAlt = 0;
+	
+	/* Set up dynamic blockinfo stuff. */
+	dev->chunkBitmapStride = (dev->nChunksPerBlock + 7) / 8; // round up bytes
+	dev->chunkBits = YMALLOC(dev->chunkBitmapStride * nBlocks);
+	if(!dev->chunkBits){
+		dev->chunkBits = YMALLOC_ALT(dev->chunkBitmapStride * nBlocks);
+		dev->chunkBitsAlt = 1;
+	}
+	else
+		dev->chunkBitsAlt = 0;
+	
+	if (dev->blockInfo && dev->chunkBits) {
+		memset(dev->blockInfo, 0, nBlocks * sizeof(yaffs_BlockInfo));
+		memset(dev->chunkBits, 0, dev->chunkBitmapStride * nBlocks);
+		return YAFFS_OK;
+	}
+
+	return YAFFS_FAIL;
+
+}
+
+static void yaffs_DeinitialiseBlocks(yaffs_Device * dev)
+{
+	if(dev->blockInfoAlt)
+		YFREE_ALT(dev->blockInfo);
+	else
+		YFREE(dev->blockInfo);
+	dev->blockInfoAlt = 0;
+
+	dev->blockInfo = NULL;
+	
+	if(dev->chunkBitsAlt)
+		YFREE_ALT(dev->chunkBits);
+	else
+		YFREE(dev->chunkBits);
+	dev->chunkBitsAlt = 0;
+	dev->chunkBits = NULL;
+}
+
+static int yaffs_BlockNotDisqualifiedFromGC(yaffs_Device * dev,
+					    yaffs_BlockInfo * bi)
+{
+	int i;
+	__u32 seq;
+	yaffs_BlockInfo *b;
+
+	if (!dev->isYaffs2)
+		return 1;	/* disqualification only applies to yaffs2. */
+
+	if (!bi->hasShrinkHeader)
+		return 1;	/* can gc */
+
+	/* Find the oldest dirty sequence number if we don't know it and save it
+	 * so we don't have to keep recomputing it.
+	 */
+	if (!dev->oldestDirtySequence) {
+		seq = dev->sequenceNumber;
+
+		for (i = dev->internalStartBlock; i <= dev->internalEndBlock;
+		     i++) {
+			b = yaffs_GetBlockInfo(dev, i);
+			if (b->blockState == YAFFS_BLOCK_STATE_FULL &&
+			    (b->pagesInUse - b->softDeletions) <
+			    dev->nChunksPerBlock && b->sequenceNumber < seq) {
+				seq = b->sequenceNumber;
+			}
+		}
+		dev->oldestDirtySequence = seq;
+	}
+
+	/* Can't do gc of this block if there are any blocks older than this one that have
+	 * discarded pages.
+	 */
+	return (bi->sequenceNumber <= dev->oldestDirtySequence);
+
+	return 1;
+
+}
+
+/* FindDiretiestBlock is used to select the dirtiest block (or close enough)
+ * for garbage collection.
+ */
+
+static int yaffs_FindBlockForGarbageCollection(yaffs_Device * dev,
+					       int aggressive)
+{
+
+	int b = dev->currentDirtyChecker;
+
+	int i;
+	int iterations;
+	int dirtiest = -1;
+	int pagesInUse;
+	yaffs_BlockInfo *bi;
+	static int nonAggressiveSkip = 0;
+
+	/* If we're doing aggressive GC then we are happy to take a less-dirty block, and
+	 * search harder.
+	 * else (we're doing a leasurely gc), then we only bother to do this if the
+	 * block has only a few pages in use.
+	 */
+
+	nonAggressiveSkip--;
+
+	if (!aggressive && (nonAggressiveSkip > 0)) {
+		return -1;
+	}
+
+	pagesInUse =
+	    (aggressive) ? dev->nChunksPerBlock : YAFFS_PASSIVE_GC_CHUNKS + 1;
+
+	if (aggressive) {
+		iterations =
+		    dev->internalEndBlock - dev->internalStartBlock + 1;
+	} else {
+		iterations =
+		    dev->internalEndBlock - dev->internalStartBlock + 1;
+		iterations = iterations / 16;
+		if (iterations > 200) {
+			iterations = 200;
+		}
+	}
+
+	for (i = 0; i <= iterations && pagesInUse > 0; i++) {
+		b++;
+		if (b < dev->internalStartBlock || b > dev->internalEndBlock) {
+			b = dev->internalStartBlock;
+		}
+
+		if (b < dev->internalStartBlock || b > dev->internalEndBlock) {
+			T(YAFFS_TRACE_ERROR,
+			  (TSTR("**>> Block %d is not valid" TENDSTR), b));
+			YBUG();
+		}
+
+		bi = yaffs_GetBlockInfo(dev, b);
+
+#if 0
+		if (bi->blockState == YAFFS_BLOCK_STATE_CHECKPOINT) {
+			dirtiest = b;
+			pagesInUse = 0;
+		}
+		else 
+#endif
+
+		if (bi->blockState == YAFFS_BLOCK_STATE_FULL &&
+		      ((bi->pagesInUse - bi->softDeletions) < pagesInUse ||
+		       (bi->needsGC && !aggressive)) &&
+		        yaffs_BlockNotDisqualifiedFromGC(dev, bi)) {
+			dirtiest = b;
+			pagesInUse = (bi->pagesInUse - bi->softDeletions);
+			if (bi->needsGC) break;
+		}
+	}
+
+	dev->currentDirtyChecker = b;
+
+	if (dirtiest > 0) {
+		T(YAFFS_TRACE_GC,
+		  (TSTR("GC Selected block %d with %d free" TENDSTR), dirtiest,
+		   dev->nChunksPerBlock - pagesInUse));
+	}
+
+	dev->oldestDirtySequence = 0;
+
+	if (dirtiest > 0) {
+		nonAggressiveSkip = 4;
+	}
+
+	return dirtiest;
+}
+
+static void yaffs_BlockBecameDirty(yaffs_Device * dev, int blockNo)
+{
+	yaffs_BlockInfo *bi = yaffs_GetBlockInfo(dev, blockNo);
+
+	int erasedOk = 0;
+
+	/* If the block is still healthy erase it and mark as clean.
+	 * If the block has had a data failure, then retire it.
+	 */
+	bi->blockState = YAFFS_BLOCK_STATE_DIRTY;
+
+	if (!bi->needsRetiring) {
+		yaffs_InvalidateCheckpoint(dev);
+		erasedOk = yaffs_EraseBlockInNAND(dev, blockNo);
+		if (!erasedOk) {
+			dev->nErasureFailures++;
+			T(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+			  (TSTR("**>> Erasure failed %d" TENDSTR), blockNo));
+		}
+	}
+
+	if (erasedOk && (yaffs_traceMask & YAFFS_TRACE_ERASE)) {
+		int i;
+		for (i = 0; i < dev->nChunksPerBlock; i++) {
+			if (!yaffs_CheckChunkErased
+			    (dev, blockNo * dev->nChunksPerBlock + i)) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   (">>Block %d erasure supposedly OK, but chunk %d not erased"
+				    TENDSTR), blockNo, i));
+			}
+		}
+	}
+
+	if (erasedOk) {
+		/* Clean it up... */
+		bi->blockState = YAFFS_BLOCK_STATE_EMPTY;
+		dev->nErasedBlocks++;
+		bi->pagesInUse = 0;
+		bi->softDeletions = 0;
+		bi->hasShrinkHeader = 0;
+		bi->needsGC = 0;
+		yaffs_ClearChunkBits(dev, blockNo);
+
+		T(YAFFS_TRACE_ERASE,
+		  (TSTR("Erased block %d" TENDSTR), blockNo));
+	} else {
+		dev->nFreeChunks -= dev->nChunksPerBlock;	/* We lost a block of free space */
+
+		yaffs_RetireBlock(dev, blockNo);
+		T(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+		  (TSTR("**>> Block %d retired" TENDSTR), blockNo));
+	}
+}
+
+static int yaffs_FindBlockForAllocation(yaffs_Device * dev)
+{
+	int i;
+
+	yaffs_BlockInfo *bi;
+
+	if (dev->nErasedBlocks < 1) {
+		/* Hoosterman we've got a problem.
+		 * Can't get space to gc
+		 */
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR("yaffs tragedy: no more eraased blocks" TENDSTR)));
+
+		return -1;
+	}
+	
+#ifdef MIPSEL
+	if (dev->internalEndBlock == 992 &&
+	    dev->allocationBlockFinder > (992 - 512) &&
+	    is_nand_bad() &&
+	    dev->nFreeChunks > (512 + 112) * dev->nChunksPerBlock) {
+		printk(KERN_INFO "yaffs_alloc: preserve backup area\n");
+		dev->allocationBlockFinder = dev->internalEndBlock + 1;
+	}
+#endif
+	/* Find an empty block. */
+
+	for (i = dev->internalStartBlock; i <= dev->internalEndBlock; i++) {
+		dev->allocationBlockFinder++;
+		if (dev->allocationBlockFinder < dev->internalStartBlock
+		    || dev->allocationBlockFinder > dev->internalEndBlock) {
+			dev->allocationBlockFinder = dev->internalStartBlock;
+		}
+
+		bi = yaffs_GetBlockInfo(dev, dev->allocationBlockFinder);
+
+		if (bi->blockState == YAFFS_BLOCK_STATE_EMPTY) {
+			bi->blockState = YAFFS_BLOCK_STATE_ALLOCATING;
+			dev->sequenceNumber++;
+			bi->sequenceNumber = dev->sequenceNumber;
+			dev->nErasedBlocks--;
+			T(YAFFS_TRACE_ALLOCATE,
+			  (TSTR("Allocated block %d, seq  %d, %d left" TENDSTR),
+			   dev->allocationBlockFinder, dev->sequenceNumber,
+			   dev->nErasedBlocks));
+			return dev->allocationBlockFinder;
+		}
+	}
+
+	T(YAFFS_TRACE_ALWAYS,
+	  (TSTR
+	   ("yaffs tragedy: no more eraased blocks, but there should have been %d"
+	    TENDSTR), dev->nErasedBlocks));
+
+	return -1;
+}
+
+
+// Check if there's space to allocate...
+// Thinks.... do we need top make this ths same as yaffs_GetFreeChunks()?
+static int yaffs_CheckSpaceForAllocation(yaffs_Device * dev)
+{
+	int reservedChunks;
+	int reservedBlocks = dev->nReservedBlocks;
+	int checkpointBlocks;
+	
+	checkpointBlocks =  dev->nCheckpointReservedBlocks - dev->blocksInCheckpoint;
+	if(checkpointBlocks < 0)
+		checkpointBlocks = 0;
+	
+	reservedChunks = ((reservedBlocks + checkpointBlocks) * dev->nChunksPerBlock);
+	
+	return (dev->nFreeChunks > reservedChunks);
+}
+
+static int yaffs_AllocateChunk(yaffs_Device * dev, int useReserve)
+{
+	int retVal;
+	yaffs_BlockInfo *bi;
+
+	if (dev->allocationBlock < 0) {
+		/* Get next block to allocate off */
+		dev->allocationBlock = yaffs_FindBlockForAllocation(dev);
+		dev->allocationPage = 0;
+	}
+
+	if (!useReserve && !yaffs_CheckSpaceForAllocation(dev)) {
+		/* Not enough space to allocate unless we're allowed to use the reserve. */
+		return -1;
+	}
+
+	if (dev->nErasedBlocks < dev->nReservedBlocks
+	    && dev->allocationPage == 0) {
+		T(YAFFS_TRACE_ALLOCATE, (TSTR("Allocating reserve" TENDSTR)));
+	}
+
+	/* Next page please.... */
+	if (dev->allocationBlock >= 0) {
+		bi = yaffs_GetBlockInfo(dev, dev->allocationBlock);
+
+		retVal = (dev->allocationBlock * dev->nChunksPerBlock) +
+		    dev->allocationPage;
+		bi->pagesInUse++;
+		yaffs_SetChunkBit(dev, dev->allocationBlock,
+				  dev->allocationPage);
+
+		dev->allocationPage++;
+
+		dev->nFreeChunks--;
+
+		/* If the block is full set the state to full */
+		if (dev->allocationPage >= dev->nChunksPerBlock) {
+			bi->blockState = YAFFS_BLOCK_STATE_FULL;
+			dev->allocationBlock = -1;
+		}
+
+		return retVal;
+	}
+	
+	T(YAFFS_TRACE_ERROR,
+	  (TSTR("!!!!!!!!! Allocator out !!!!!!!!!!!!!!!!!" TENDSTR)));
+
+	return -1;
+}
+
+static int yaffs_GetErasedChunks(yaffs_Device * dev)
+{
+	int n;
+
+	n = dev->nErasedBlocks * dev->nChunksPerBlock;
+
+	if (dev->allocationBlock > 0) {
+		n += (dev->nChunksPerBlock - dev->allocationPage);
+	}
+
+	return n;
+
+}
+
+static int yaffs_GarbageCollectBlock(yaffs_Device * dev, int block)
+{
+	int oldChunk;
+	int newChunk;
+	int chunkInBlock;
+	int markNAND;
+	int retVal = YAFFS_OK;
+	int cleanups = 0;
+	int i;
+	int isCheckpointBlock;
+
+	int chunksBefore = yaffs_GetErasedChunks(dev);
+	int chunksAfter;
+
+	yaffs_ExtendedTags tags;
+
+	yaffs_BlockInfo *bi = yaffs_GetBlockInfo(dev, block);
+
+	yaffs_Object *object;
+
+	isCheckpointBlock = (bi->blockState == YAFFS_BLOCK_STATE_CHECKPOINT);
+	
+	bi->blockState = YAFFS_BLOCK_STATE_COLLECTING;
+
+	T(YAFFS_TRACE_TRACING,
+	  (TSTR("Collecting block %d, in use %d, shrink %d, " TENDSTR), block,
+	   bi->pagesInUse, bi->hasShrinkHeader));
+
+	/*yaffs_VerifyFreeChunks(dev); */
+
+	bi->hasShrinkHeader = 0;	/* clear the flag so that the block can erase */
+
+	/* Take off the number of soft deleted entries because
+	 * they're going to get really deleted during GC.
+	 */
+	dev->nFreeChunks -= bi->softDeletions;
+
+	dev->isDoingGC = 1;
+
+	if (isCheckpointBlock ||
+	    !yaffs_StillSomeChunkBits(dev, block)) {
+		T(YAFFS_TRACE_TRACING,
+		  (TSTR
+		   ("Collecting block %d that has no chunks in use" TENDSTR),
+		   block));
+		yaffs_BlockBecameDirty(dev, block);
+	} else {
+
+		__u8 *buffer = yaffs_GetTempBuffer(dev, __LINE__);
+
+		for (chunkInBlock = 0, oldChunk = block * dev->nChunksPerBlock;
+		     chunkInBlock < dev->nChunksPerBlock
+		     && yaffs_StillSomeChunkBits(dev, block);
+		     chunkInBlock++, oldChunk++) {
+			if (yaffs_CheckChunkBit(dev, block, chunkInBlock)) {
+
+				/* This page is in use and might need to be copied off */
+
+				markNAND = 1;
+
+				yaffs_InitialiseTags(&tags);
+
+				yaffs_ReadChunkWithTagsFromNAND(dev, oldChunk,
+								buffer, &tags);
+
+				object =
+				    yaffs_FindObjectByNumber(dev,
+							     tags.objectId);
+
+				T(YAFFS_TRACE_GC_DETAIL,
+				  (TSTR
+				   ("Collecting page %d, %d %d %d " TENDSTR),
+				   chunkInBlock, tags.objectId, tags.chunkId,
+				   tags.byteCount));
+
+				if (!object) {
+					T(YAFFS_TRACE_ERROR,
+					  (TSTR
+					   ("page %d in gc has no object "
+					    TENDSTR), oldChunk));
+				}
+
+				if (object && object->deleted
+				    && tags.chunkId != 0) {
+					/* Data chunk in a deleted file, throw it away
+					 * It's a soft deleted data chunk,
+					 * No need to copy this, just forget about it and 
+					 * fix up the object.
+					 */
+
+					object->nDataChunks--;
+
+					if (object->nDataChunks <= 0) {
+						/* remeber to clean up the object */
+						dev->gcCleanupList[cleanups] =
+						    tags.objectId;
+						cleanups++;
+					}
+					markNAND = 0;
+				} else if (0
+					   /* Todo object && object->deleted && object->nDataChunks == 0 */
+					   ) {
+					/* Deleted object header with no data chunks.
+					 * Can be discarded and the file deleted.
+					 */
+					object->hdrChunk = 0;
+					yaffs_FreeTnode(object->myDev,
+							object->variant.
+							fileVariant.top);
+					object->variant.fileVariant.top = NULL;
+					yaffs_DoGenericObjectDeletion(object);
+
+				} else if (object) {
+					/* It's either a data chunk in a live file or
+					 * an ObjectHeader, so we're interested in it.
+					 * NB Need to keep the ObjectHeaders of deleted files
+					 * until the whole file has been deleted off
+					 */
+					tags.serialNumber++;
+
+					dev->nGCCopies++;
+
+					if (tags.chunkId == 0) {
+						/* It is an object Id,
+						 * We need to nuke the shrinkheader flags first
+						 * We no longer want the shrinkHeader flag since its work is done
+						 * and if it is left in place it will mess up scanning.
+						 * Also, clear out any shadowing stuff
+						 */
+
+						yaffs_ObjectHeader *oh;
+						oh = (yaffs_ObjectHeader *)buffer;
+						oh->isShrink = 0;
+						oh->shadowsObject = -1;
+						tags.extraShadows = 0;
+						tags.extraIsShrinkHeader = 0;
+					}
+
+					newChunk =
+					    yaffs_WriteNewChunkWithTagsToNAND(dev, buffer, &tags, 1);
+
+					if (newChunk < 0) {
+						retVal = YAFFS_FAIL;
+					} else {
+
+						/* Ok, now fix up the Tnodes etc. */
+
+						if (tags.chunkId == 0) {
+							/* It's a header */
+							object->hdrChunk =  newChunk;
+							object->serial =   tags.serialNumber;
+						} else {
+							/* It's a data chunk */
+							yaffs_PutChunkIntoFile
+							    (object,
+							     tags.chunkId,
+							     newChunk, 0);
+						}
+					}
+				}
+
+				yaffs_DeleteChunk(dev, oldChunk, markNAND, __LINE__);
+
+			}
+		}
+
+		yaffs_ReleaseTempBuffer(dev, buffer, __LINE__);
+
+
+		/* Do any required cleanups */
+		for (i = 0; i < cleanups; i++) {
+			/* Time to delete the file too */
+			object =
+			    yaffs_FindObjectByNumber(dev,
+						     dev->gcCleanupList[i]);
+			if (object) {
+				yaffs_FreeTnode(dev,
+						object->variant.fileVariant.
+						top);
+				object->variant.fileVariant.top = NULL;
+				T(YAFFS_TRACE_GC,
+				  (TSTR
+				   ("yaffs: About to finally delete object %d"
+				    TENDSTR), object->objectId));
+				yaffs_DoGenericObjectDeletion(object);
+				object->myDev->nDeletedFiles--;
+			}
+
+		}
+
+	}
+
+	if (chunksBefore >= (chunksAfter = yaffs_GetErasedChunks(dev))) {
+		T(YAFFS_TRACE_GC,
+		  (TSTR
+		   ("gc did not increase free chunks before %d after %d"
+		    TENDSTR), chunksBefore, chunksAfter));
+	}
+
+	dev->isDoingGC = 0;
+
+	return YAFFS_OK;
+}
+
+/* New garbage collector
+ * If we're very low on erased blocks then we do aggressive garbage collection
+ * otherwise we do "leasurely" garbage collection.
+ * Aggressive gc looks further (whole array) and will accept less dirty blocks.
+ * Passive gc only inspects smaller areas and will only accept more dirty blocks.
+ *
+ * The idea is to help clear out space in a more spread-out manner.
+ * Dunno if it really does anything useful.
+ */
+static int yaffs_CheckGarbageCollection(yaffs_Device * dev)
+{
+	int block;
+	int aggressive;
+	int gcOk = YAFFS_OK;
+	int maxTries = 0;
+	
+	int checkpointBlockAdjust;
+
+	if (dev->isDoingGC) {
+		/* Bail out so we don't get recursive gc */
+		return YAFFS_OK;
+	}
+	
+	/* This loop should pass the first time.
+	 * We'll only see looping here if the erase of the collected block fails.
+	 */
+
+	do {
+		maxTries++;
+		
+		checkpointBlockAdjust = (dev->nCheckpointReservedBlocks - dev->blocksInCheckpoint);
+		if(checkpointBlockAdjust < 0)
+			checkpointBlockAdjust = 0;
+
+		if (dev->nErasedBlocks < (dev->nReservedBlocks + checkpointBlockAdjust)) {
+			/* We need a block soon...*/
+			aggressive = 1;
+		} else {
+			/* We're in no hurry */
+			aggressive = 0;
+		}
+
+		block = yaffs_FindBlockForGarbageCollection(dev, aggressive);
+
+		if (block > 0) {
+			dev->garbageCollections++;
+			if (!aggressive) {
+				dev->passiveGarbageCollections++;
+			}
+
+			T(YAFFS_TRACE_GC,
+			  (TSTR
+			   ("yaffs: GC erasedBlocks %d aggressive %d" TENDSTR),
+			   dev->nErasedBlocks, aggressive));
+
+			gcOk = yaffs_GarbageCollectBlock(dev, block);
+		}
+
+		if (dev->nErasedBlocks < (dev->nReservedBlocks) && block > 0) {
+			T(YAFFS_TRACE_GC,
+			  (TSTR
+			   ("yaffs: GC !!!no reclaim!!! erasedBlocks %d after try %d block %d"
+			    TENDSTR), dev->nErasedBlocks, maxTries, block));
+		}
+	} while ((dev->nErasedBlocks < dev->nReservedBlocks) && (block > 0)
+		 && (maxTries < 2));
+
+	return aggressive ? gcOk : YAFFS_OK;
+}
+
+/*-------------------------  TAGS --------------------------------*/
+
+static int yaffs_TagsMatch(const yaffs_ExtendedTags * tags, int objectId,
+			   int chunkInObject)
+{
+	return (tags->chunkId == chunkInObject &&
+		tags->objectId == objectId && !tags->chunkDeleted) ? 1 : 0;
+
+}
+
+
+/*-------------------- Data file manipulation -----------------*/
+
+static int yaffs_FindChunkInFile(yaffs_Object * in, int chunkInInode,
+				 yaffs_ExtendedTags * tags)
+{
+	/*Get the Tnode, then get the level 0 offset chunk offset */
+	yaffs_Tnode *tn;
+	int theChunk = -1;
+	yaffs_ExtendedTags localTags;
+	int retVal = -1;
+
+	yaffs_Device *dev = in->myDev;
+
+	if (!tags) {
+		/* Passed a NULL, so use our own tags space */
+		tags = &localTags;
+	}
+
+	tn = yaffs_FindLevel0Tnode(dev, &in->variant.fileVariant, chunkInInode);
+
+	if (tn) {
+		theChunk = yaffs_GetChunkGroupBase(dev,tn,chunkInInode);
+
+		retVal =
+		    yaffs_FindChunkInGroup(dev, theChunk, tags, in->objectId,
+					   chunkInInode);
+	}
+	return retVal;
+}
+
+static int yaffs_FindAndDeleteChunkInFile(yaffs_Object * in, int chunkInInode,
+					  yaffs_ExtendedTags * tags)
+{
+	/* Get the Tnode, then get the level 0 offset chunk offset */
+	yaffs_Tnode *tn;
+	int theChunk = -1;
+	yaffs_ExtendedTags localTags;
+
+	yaffs_Device *dev = in->myDev;
+	int retVal = -1;
+
+	if (!tags) {
+		/* Passed a NULL, so use our own tags space */
+		tags = &localTags;
+	}
+
+	tn = yaffs_FindLevel0Tnode(dev, &in->variant.fileVariant, chunkInInode);
+
+	if (tn) {
+
+		theChunk = yaffs_GetChunkGroupBase(dev,tn,chunkInInode);
+
+		retVal =
+		    yaffs_FindChunkInGroup(dev, theChunk, tags, in->objectId,
+					   chunkInInode);
+
+		/* Delete the entry in the filestructure (if found) */
+		if (retVal != -1) {
+			yaffs_PutLevel0Tnode(dev,tn,chunkInInode,0);
+		}
+	} else {
+		/*T(("No level 0 found for %d\n", chunkInInode)); */
+	}
+
+	if (retVal == -1) {
+		/* T(("Could not find %d to delete\n",chunkInInode)); */
+	}
+	return retVal;
+}
+
+#ifdef YAFFS_PARANOID
+
+static int yaffs_CheckFileSanity(yaffs_Object * in)
+{
+	int chunk;
+	int nChunks;
+	int fSize;
+	int failed = 0;
+	int objId;
+	yaffs_Tnode *tn;
+	yaffs_Tags localTags;
+	yaffs_Tags *tags = &localTags;
+	int theChunk;
+	int chunkDeleted;
+
+	if (in->variantType != YAFFS_OBJECT_TYPE_FILE) {
+		/* T(("Object not a file\n")); */
+		return YAFFS_FAIL;
+	}
+
+	objId = in->objectId;
+	fSize = in->variant.fileVariant.fileSize;
+	nChunks =
+	    (fSize + in->myDev->nBytesPerChunk - 1) / in->myDev->nBytesPerChunk;
+
+	for (chunk = 1; chunk <= nChunks; chunk++) {
+		tn = yaffs_FindLevel0Tnode(in->myDev, &in->variant.fileVariant,
+					   chunk);
+
+		if (tn) {
+
+			theChunk = yaffs_GetChunkGroupBase(dev,tn,chunk);
+
+			if (yaffs_CheckChunkBits
+			    (dev, theChunk / dev->nChunksPerBlock,
+			     theChunk % dev->nChunksPerBlock)) {
+
+				yaffs_ReadChunkTagsFromNAND(in->myDev, theChunk,
+							    tags,
+							    &chunkDeleted);
+				if (yaffs_TagsMatch
+				    (tags, in->objectId, chunk, chunkDeleted)) {
+					/* found it; */
+
+				}
+			} else {
+
+				failed = 1;
+			}
+
+		} else {
+			/* T(("No level 0 found for %d\n", chunk)); */
+		}
+	}
+
+	return failed ? YAFFS_FAIL : YAFFS_OK;
+}
+
+#endif
+
+static int yaffs_PutChunkIntoFile(yaffs_Object * in, int chunkInInode,
+				  int chunkInNAND, int inScan)
+{
+	/* NB inScan is zero unless scanning. 
+	 * For forward scanning, inScan is > 0; 
+	 * for backward scanning inScan is < 0
+	 */
+	 
+	yaffs_Tnode *tn;
+	yaffs_Device *dev = in->myDev;
+	int existingChunk;
+	yaffs_ExtendedTags existingTags;
+	yaffs_ExtendedTags newTags;
+	unsigned existingSerial, newSerial;
+
+	if (in->variantType != YAFFS_OBJECT_TYPE_FILE) {
+		/* Just ignore an attempt at putting a chunk into a non-file during scanning
+		 * If it is not during Scanning then something went wrong!
+		 */
+		if (!inScan) {
+			T(YAFFS_TRACE_ERROR,
+			  (TSTR
+			   ("yaffs tragedy:attempt to put data chunk into a non-file"
+			    TENDSTR)));
+			YBUG();
+		}
+
+		yaffs_DeleteChunk(dev, chunkInNAND, 1, __LINE__);
+		return YAFFS_OK;
+	}
+
+	tn = yaffs_AddOrFindLevel0Tnode(dev, 
+					&in->variant.fileVariant,
+					chunkInInode,
+					NULL);
+	if (!tn) {
+		return YAFFS_FAIL;
+	}
+
+	existingChunk = yaffs_GetChunkGroupBase(dev,tn,chunkInInode);
+
+	if (inScan != 0) {
+		/* If we're scanning then we need to test for duplicates
+		 * NB This does not need to be efficient since it should only ever 
+		 * happen when the power fails during a write, then only one
+		 * chunk should ever be affected.
+		 *
+		 * Correction for YAFFS2: This could happen quite a lot and we need to think about efficiency! TODO
+		 * Update: For backward scanning we don't need to re-read tags so this is quite cheap.
+		 */
+
+		if (existingChunk > 0) {
+			/* NB Right now existing chunk will not be real chunkId if the device >= 32MB
+			 *    thus we have to do a FindChunkInFile to get the real chunk id.
+			 *
+			 * We have a duplicate now we need to decide which one to use:
+			 *
+			 * Backwards scanning YAFFS2: The old one is what we use, dump the new one.
+			 * Forward scanning YAFFS2: The new one is what we use, dump the old one.
+			 * YAFFS1: Get both sets of tags and compare serial numbers.
+			 */
+
+			if (inScan > 0) {
+				/* Only do this for forward scanning */
+				yaffs_ReadChunkWithTagsFromNAND(dev,
+								chunkInNAND,
+								NULL, &newTags);
+
+				/* Do a proper find */
+				existingChunk =
+				    yaffs_FindChunkInFile(in, chunkInInode,
+							  &existingTags);
+			}
+
+			if (existingChunk <= 0) {
+				/*Hoosterman - how did this happen? */
+
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("yaffs tragedy: existing chunk < 0 in scan"
+				    TENDSTR)));
+
+			}
+
+			/* NB The deleted flags should be false, otherwise the chunks will 
+			 * not be loaded during a scan
+			 */
+
+			newSerial = newTags.serialNumber;
+			existingSerial = existingTags.serialNumber;
+
+			if ((inScan > 0) &&
+			    (in->myDev->isYaffs2 ||
+			     existingChunk <= 0 ||
+			     ((existingSerial + 1) & 3) == newSerial)) {
+				/* Forward scanning.                            
+				 * Use new
+				 * Delete the old one and drop through to update the tnode
+				 */
+				yaffs_DeleteChunk(dev, existingChunk, 1,
+						  __LINE__);
+			} else {
+				/* Backward scanning or we want to use the existing one
+				 * Use existing.
+				 * Delete the new one and return early so that the tnode isn't changed
+				 */
+				yaffs_DeleteChunk(dev, chunkInNAND, 1,
+						  __LINE__);
+				return YAFFS_OK;
+			}
+		}
+
+	}
+
+	if (existingChunk == 0) {
+		in->nDataChunks++;
+	}
+
+	yaffs_PutLevel0Tnode(dev,tn,chunkInInode,chunkInNAND);
+
+	return YAFFS_OK;
+}
+
+static int yaffs_ReadChunkDataFromObject(yaffs_Object * in, int chunkInInode,
+					 __u8 * buffer)
+{
+	int chunkInNAND = yaffs_FindChunkInFile(in, chunkInInode, NULL);
+
+	if (chunkInNAND >= 0) {
+		return yaffs_ReadChunkWithTagsFromNAND(in->myDev, chunkInNAND,
+						       buffer, NULL);
+	} else {
+		T(YAFFS_TRACE_NANDACCESS,
+		  (TSTR("Chunk %d not found zero instead" TENDSTR),
+		   chunkInNAND));
+		/* get sane (zero) data if you read a hole */
+		memset(buffer, 0, in->myDev->nBytesPerChunk);	
+		return 0;
+	}
+
+}
+
+void yaffs_DeleteChunk(yaffs_Device * dev, int chunkId, int markNAND, int lyn)
+{
+	int block;
+	int page;
+	yaffs_ExtendedTags tags;
+	yaffs_BlockInfo *bi;
+
+	if (chunkId <= 0)
+		return;
+
+	dev->nDeletions++;
+	block = chunkId / dev->nChunksPerBlock;
+	page = chunkId % dev->nChunksPerBlock;
+
+	bi = yaffs_GetBlockInfo(dev, block);
+
+	T(YAFFS_TRACE_DELETION,
+	  (TSTR("line %d delete of chunk %d" TENDSTR), lyn, chunkId));
+
+	if (markNAND &&
+	    bi->blockState != YAFFS_BLOCK_STATE_COLLECTING && !dev->isYaffs2) {
+
+		yaffs_InitialiseTags(&tags);
+
+		tags.chunkDeleted = 1;
+
+		yaffs_WriteChunkWithTagsToNAND(dev, chunkId, NULL, &tags);
+		yaffs_HandleUpdateChunk(dev, chunkId, &tags);
+	} else {
+		dev->nUnmarkedDeletions++;
+	}
+
+	/* Pull out of the management area.
+	 * If the whole block became dirty, this will kick off an erasure.
+	 */
+	if (bi->blockState == YAFFS_BLOCK_STATE_ALLOCATING ||
+	    bi->blockState == YAFFS_BLOCK_STATE_FULL ||
+	    bi->blockState == YAFFS_BLOCK_STATE_NEEDS_SCANNING ||
+	    bi->blockState == YAFFS_BLOCK_STATE_COLLECTING) {
+		dev->nFreeChunks++;
+
+		yaffs_ClearChunkBit(dev, block, page);
+
+		bi->pagesInUse--;
+
+		if (bi->pagesInUse == 0 &&
+		    !bi->hasShrinkHeader &&
+		    bi->blockState != YAFFS_BLOCK_STATE_ALLOCATING &&
+		    bi->blockState != YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+			yaffs_BlockBecameDirty(dev, block);
+		}
+
+	} else {
+		/* T(("Bad news deleting chunk %d\n",chunkId)); */
+	}
+
+}
+
+static int yaffs_WriteChunkDataToObject(yaffs_Object * in, int chunkInInode,
+					const __u8 * buffer, int nBytes,
+					int useReserve)
+{
+	/* Find old chunk Need to do this to get serial number
+	 * Write new one and patch into tree.
+	 * Invalidate old tags.
+	 */
+
+	int prevChunkId;
+	yaffs_ExtendedTags prevTags;
+
+	int newChunkId;
+	yaffs_ExtendedTags newTags;
+
+	yaffs_Device *dev = in->myDev;
+
+	yaffs_CheckGarbageCollection(dev);
+
+	/* Get the previous chunk at this location in the file if it exists */
+	prevChunkId = yaffs_FindChunkInFile(in, chunkInInode, &prevTags);
+
+	/* Set up new tags */
+	yaffs_InitialiseTags(&newTags);
+
+	newTags.chunkId = chunkInInode;
+	newTags.objectId = in->objectId;
+	newTags.serialNumber =
+	    (prevChunkId >= 0) ? prevTags.serialNumber + 1 : 1;
+	newTags.byteCount = nBytes;
+
+	newChunkId =
+	    yaffs_WriteNewChunkWithTagsToNAND(dev, buffer, &newTags,
+					      useReserve);
+
+	if (newChunkId >= 0) {
+		yaffs_PutChunkIntoFile(in, chunkInInode, newChunkId, 0);
+
+		if (prevChunkId >= 0) {
+			yaffs_DeleteChunk(dev, prevChunkId, 1, __LINE__);
+
+		}
+
+		yaffs_CheckFileSanity(in);
+	}
+	return newChunkId;
+
+}
+
+/* UpdateObjectHeader updates the header on NAND for an object.
+ * If name is not NULL, then that new name is used.
+ */
+int yaffs_UpdateObjectHeader(yaffs_Object * in, const YCHAR * name, int force,
+			     int isShrink, int shadows)
+{
+
+	yaffs_BlockInfo *bi;
+
+	yaffs_Device *dev = in->myDev;
+
+	int prevChunkId;
+	int retVal = 0;
+
+	int newChunkId;
+	yaffs_ExtendedTags newTags;
+
+	__u8 *buffer = NULL;
+	YCHAR oldName[YAFFS_MAX_NAME_LENGTH + 1];
+
+	yaffs_ObjectHeader *oh = NULL;
+
+	if (!in->fake ||
+	    in == dev->rootDir || /* The rootDir should also be saved */
+	    force) {
+
+		yaffs_CheckGarbageCollection(dev);
+
+		buffer = yaffs_GetTempBuffer(in->myDev, __LINE__);
+		oh = (yaffs_ObjectHeader *) buffer;
+
+		prevChunkId = in->hdrChunk;
+
+		if (prevChunkId > 0) {
+			yaffs_ReadChunkWithTagsFromNAND(dev, prevChunkId,
+							buffer, NULL);
+			memcpy(oldName, oh->name, sizeof(oh->name));
+		}
+
+		memset(buffer, 0xFF, dev->nBytesPerChunk);
+
+		oh->type = in->variantType;
+		oh->yst_mode = in->yst_mode;
+		oh->shadowsObject = shadows;
+
+#ifdef CONFIG_YAFFS_WINCE
+		oh->win_atime[0] = in->win_atime[0];
+		oh->win_ctime[0] = in->win_ctime[0];
+		oh->win_mtime[0] = in->win_mtime[0];
+		oh->win_atime[1] = in->win_atime[1];
+		oh->win_ctime[1] = in->win_ctime[1];
+		oh->win_mtime[1] = in->win_mtime[1];
+#else
+		oh->yst_uid = in->yst_uid;
+		oh->yst_gid = in->yst_gid;
+		oh->yst_atime = in->yst_atime;
+		oh->yst_mtime = in->yst_mtime;
+		oh->yst_ctime = in->yst_ctime;
+		oh->yst_rdev = in->yst_rdev;
+#endif
+		if (in->parent) {
+			oh->parentObjectId = in->parent->objectId;
+		} else {
+			oh->parentObjectId = 0;
+		}
+
+		if (name && *name) {
+			memset(oh->name, 0, sizeof(oh->name));
+			yaffs_strncpy(oh->name, name, YAFFS_MAX_NAME_LENGTH);
+		} else if (prevChunkId) {
+			memcpy(oh->name, oldName, sizeof(oh->name));
+		} else {
+			memset(oh->name, 0, sizeof(oh->name));
+		}
+
+		oh->isShrink = isShrink;
+
+		switch (in->variantType) {
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+			/* Should not happen */
+			break;
+		case YAFFS_OBJECT_TYPE_FILE:
+			oh->fileSize =
+			    (oh->parentObjectId == YAFFS_OBJECTID_DELETED
+			     || oh->parentObjectId ==
+			     YAFFS_OBJECTID_UNLINKED) ? 0 : in->variant.
+			    fileVariant.fileSize;
+			break;
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+			oh->equivalentObjectId =
+			    in->variant.hardLinkVariant.equivalentObjectId;
+			break;
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+			/* Do nothing */
+			break;
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+			/* Do nothing */
+			break;
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+			yaffs_strncpy(oh->alias,
+				      in->variant.symLinkVariant.alias,
+				      YAFFS_MAX_ALIAS_LENGTH);
+			oh->alias[YAFFS_MAX_ALIAS_LENGTH] = 0;
+			break;
+		}
+
+		/* Tags */
+		yaffs_InitialiseTags(&newTags);
+		in->serial++;
+		newTags.chunkId = 0;
+		newTags.objectId = in->objectId;
+		newTags.serialNumber = in->serial;
+
+		/* Add extra info for file header */
+
+		newTags.extraHeaderInfoAvailable = 1;
+		newTags.extraParentObjectId = oh->parentObjectId;
+		newTags.extraFileLength = oh->fileSize;
+		newTags.extraIsShrinkHeader = oh->isShrink;
+		newTags.extraEquivalentObjectId = oh->equivalentObjectId;
+		newTags.extraShadows = (oh->shadowsObject > 0) ? 1 : 0;
+		newTags.extraObjectType = in->variantType;
+
+		/* Create new chunk in NAND */
+		newChunkId =
+		    yaffs_WriteNewChunkWithTagsToNAND(dev, buffer, &newTags,
+						      (prevChunkId >= 0) ? 1 : 0);
+
+		if (newChunkId >= 0) {
+
+			in->hdrChunk = newChunkId;
+
+			if (prevChunkId >= 0) {
+				yaffs_DeleteChunk(dev, prevChunkId, 1,
+						  __LINE__);
+			}
+
+			if (in->dirty) yaffs_FlushFilesChunkCache(in);
+			in->dirty = 0;
+
+			/* If this was a shrink, then mark the block that the chunk lives on */
+			if (isShrink) {
+				bi = yaffs_GetBlockInfo(in->myDev,
+							newChunkId /in->myDev->	nChunksPerBlock);
+				bi->hasShrinkHeader = 1;
+			}
+
+		}
+
+		retVal = newChunkId;
+
+	}
+
+	if (buffer)
+		yaffs_ReleaseTempBuffer(dev, buffer, __LINE__);
+
+	return retVal;
+}
+
+/*------------------------ Short Operations Cache ----------------------------------------
+ *   In many situations where there is no high level buffering (eg WinCE) a lot of
+ *   reads might be short sequential reads, and a lot of writes may be short 
+ *   sequential writes. eg. scanning/writing a jpeg file.
+ *   In these cases, a short read/write cache can provide a huge perfomance benefit 
+ *   with dumb-as-a-rock code.
+ *   In Linux, the page cache provides read buffering aand the short op cache provides write 
+ *   buffering.
+ *
+ *   There are a limited number (~10) of cache chunks per device so that we don't
+ *   need a very intelligent search.
+ */
+
+static void yaffs_FlushFilesChunkCache(yaffs_Object * obj)
+{
+	yaffs_Device *dev = obj->myDev;
+	int lowest = -99;	/* Stop compiler whining. */
+	int i;
+	yaffs_ChunkCache *cache;
+	int chunkWritten = 0;
+	int nCaches = obj->myDev->nShortOpCaches;
+
+	if (nCaches > 0) {
+		do {
+			cache = NULL;
+
+			/* Find the dirty cache for this object with the lowest chunk id. */
+			for (i = 0; i < nCaches; i++) {
+				if (dev->srCache[i].object == obj &&
+				    dev->srCache[i].dirty) {
+					if (!cache
+					    || dev->srCache[i].chunkId <
+					    lowest) {
+						cache = &dev->srCache[i];
+						lowest = cache->chunkId;
+					}
+				}
+			}
+
+			if (cache && !cache->locked) {
+				/* Write it out and free it up */
+
+				chunkWritten =
+				    yaffs_WriteChunkDataToObject(cache->object,
+								 cache->chunkId,
+								 cache->data,
+								 cache->nBytes,
+								 1);
+				cache->dirty = 0;
+				cache->object = NULL;
+			}
+
+		} while (cache && chunkWritten > 0);
+
+		if (cache) {
+			/* Hoosterman, disk full while writing cache out. */
+			T(YAFFS_TRACE_ERROR,
+			  (TSTR("yaffs tragedy: no space during cache write" TENDSTR)));
+
+		}
+	}
+
+}
+
+/*yaffs_FlushEntireDeviceCache(dev)
+ *
+ *
+ */
+
+void yaffs_FlushEntireDeviceCache(yaffs_Device *dev)
+{
+	yaffs_Object *obj;
+	int nCaches = dev->nShortOpCaches;
+	int i;
+	
+	/* Find a dirty object in the cache and flush it...
+	 * until there are no further dirty objects.
+	 */
+	do {
+		obj = NULL;
+		for( i = 0; i < nCaches && !obj; i++) {
+			if (dev->srCache[i].object &&
+			    dev->srCache[i].dirty)
+				obj = dev->srCache[i].object;
+			    
+		}
+		if(obj)
+			yaffs_FlushFilesChunkCache(obj);
+			
+	} while(obj);
+	
+}
+
+
+/* Grab us a cache chunk for use.
+ * First look for an empty one. 
+ * Then look for the least recently used non-dirty one.
+ * Then look for the least recently used dirty one...., flush and look again.
+ */
+static yaffs_ChunkCache *yaffs_GrabChunkCacheWorker(yaffs_Device * dev)
+{
+	int i;
+	int usage;
+	int theOne;
+
+	if (dev->nShortOpCaches > 0) {
+		for (i = 0; i < dev->nShortOpCaches; i++) {
+			if (!dev->srCache[i].object) 
+				return &dev->srCache[i];
+		}
+
+		return NULL;
+
+		theOne = -1;
+		usage = 0;	/* just to stop the compiler grizzling */
+
+		for (i = 0; i < dev->nShortOpCaches; i++) {
+			if (!dev->srCache[i].dirty &&
+			    ((dev->srCache[i].lastUse < usage && theOne >= 0) ||
+			     theOne < 0)) {
+				usage = dev->srCache[i].lastUse;
+				theOne = i;
+			}
+		}
+
+
+		return theOne >= 0 ? &dev->srCache[theOne] : NULL;
+	} else {
+		return NULL;
+	}
+
+}
+
+static yaffs_ChunkCache *yaffs_GrabChunkCache(yaffs_Device * dev)
+{
+	yaffs_ChunkCache *cache;
+	yaffs_Object *theObj;
+	int usage;
+	int i;
+	int pushout;
+
+	if (dev->nShortOpCaches > 0) {
+		/* Try find a non-dirty one... */
+
+		cache = yaffs_GrabChunkCacheWorker(dev);
+
+		if (!cache) {
+			/* They were all dirty, find the last recently used object and flush
+			 * its cache, then  find again.
+			 * NB what's here is not very accurate, we actually flush the object
+			 * the last recently used page.
+			 */
+
+			/* With locking we can't assume we can use entry zero */
+
+			theObj = NULL;
+			usage = -1;
+			cache = NULL;
+			pushout = -1;
+
+			for (i = 0; i < dev->nShortOpCaches; i++) {
+				if (dev->srCache[i].object &&
+				    !dev->srCache[i].locked &&
+				    (dev->srCache[i].lastUse < usage || !cache))
+				{
+					usage = dev->srCache[i].lastUse;
+					theObj = dev->srCache[i].object;
+					cache = &dev->srCache[i];
+					pushout = i;
+				}
+			}
+
+			if (!cache || cache->dirty) {
+				/* Flush and try again */
+				yaffs_FlushFilesChunkCache(theObj);
+				cache = yaffs_GrabChunkCacheWorker(dev);
+			}
+
+		}
+		return cache;
+	} else
+		return NULL;
+
+}
+
+/* Find a cached chunk */
+static yaffs_ChunkCache *yaffs_FindChunkCache(const yaffs_Object * obj,
+					      int chunkId)
+{
+	yaffs_Device *dev = obj->myDev;
+	int i;
+	if (dev->nShortOpCaches > 0) {
+		for (i = 0; i < dev->nShortOpCaches; i++) {
+			if (dev->srCache[i].object == obj &&
+			    dev->srCache[i].chunkId == chunkId) {
+				dev->cacheHits++;
+
+				return &dev->srCache[i];
+			}
+		}
+	}
+	return NULL;
+}
+
+/* Mark the chunk for the least recently used algorithym */
+static void yaffs_UseChunkCache(yaffs_Device * dev, yaffs_ChunkCache * cache,
+				int isAWrite)
+{
+
+	if (dev->nShortOpCaches > 0) {
+		if (dev->srLastUse < 0 || dev->srLastUse > 100000000) {
+			/* Reset the cache usages */
+			int i;
+			for (i = 1; i < dev->nShortOpCaches; i++) {
+				dev->srCache[i].lastUse = 0;
+			}
+			dev->srLastUse = 0;
+		}
+
+		dev->srLastUse++;
+
+		cache->lastUse = dev->srLastUse;
+
+		if (isAWrite) {
+			cache->dirty = 1;
+		}
+	}
+}
+
+/* Invalidate a single cache page.
+ * Do this when a whole page gets written,
+ * ie the short cache for this page is no longer valid.
+ */
+static void yaffs_InvalidateChunkCache(yaffs_Object * object, int chunkId)
+{
+	if (object->myDev->nShortOpCaches > 0) {
+		yaffs_ChunkCache *cache = yaffs_FindChunkCache(object, chunkId);
+
+		if (cache) {
+			cache->object = NULL;
+		}
+	}
+}
+
+/* Invalidate all the cache pages associated with this object
+ * Do this whenever ther file is deleted or resized.
+ */
+static void yaffs_InvalidateWholeChunkCache(yaffs_Object * in)
+{
+	int i;
+	yaffs_Device *dev = in->myDev;
+
+	if (dev->nShortOpCaches > 0) {
+		/* Invalidate it. */
+		for (i = 0; i < dev->nShortOpCaches; i++) {
+			if (dev->srCache[i].object == in) {
+				dev->srCache[i].object = NULL;
+			}
+		}
+	}
+}
+
+/*--------------------- Checkpointing --------------------*/
+
+
+static int yaffs_WriteCheckpointValidityMarker(yaffs_Device *dev,int head)
+{
+	yaffs_CheckpointValidity cp;
+	cp.structType = sizeof(cp);
+	cp.magic = YAFFS_MAGIC;
+	cp.version = 1;
+	cp.head = (head) ? 1 : 0;
+	
+	return (yaffs_CheckpointWrite(dev,&cp,sizeof(cp)) == sizeof(cp))?
+		1 : 0;
+}
+
+static int yaffs_ReadCheckpointValidityMarker(yaffs_Device *dev, int head)
+{
+	yaffs_CheckpointValidity cp;
+	int ok;
+	
+	ok = (yaffs_CheckpointRead(dev,&cp,sizeof(cp)) == sizeof(cp));
+	
+	if(ok)
+		ok = (cp.structType == sizeof(cp)) &&
+		     (cp.magic == YAFFS_MAGIC) &&
+		     (cp.version == 1) &&
+		     (cp.head == ((head) ? 1 : 0));
+	return ok ? 1 : 0;
+}
+
+static void yaffs_DeviceToCheckpointDevice(yaffs_CheckpointDevice *cp, 
+					   yaffs_Device *dev)
+{
+	cp->nErasedBlocks = dev->nErasedBlocks;
+	cp->allocationBlock = dev->allocationBlock;
+	cp->allocationPage = dev->allocationPage;
+	cp->nFreeChunks = dev->nFreeChunks;
+	
+	cp->nDeletedFiles = dev->nDeletedFiles;
+	cp->nUnlinkedFiles = dev->nUnlinkedFiles;
+	cp->nBackgroundDeletions = dev->nBackgroundDeletions;
+	cp->sequenceNumber = dev->sequenceNumber;
+	cp->oldestDirtySequence = dev->oldestDirtySequence;
+	
+}
+
+static void yaffs_CheckpointDeviceToDevice(yaffs_Device *dev,
+					   yaffs_CheckpointDevice *cp)
+{
+	dev->nErasedBlocks = cp->nErasedBlocks;
+	dev->allocationBlock = cp->allocationBlock;
+	dev->allocationPage = cp->allocationPage;
+	dev->nFreeChunks = cp->nFreeChunks;
+	
+	dev->nDeletedFiles = cp->nDeletedFiles;
+	dev->nUnlinkedFiles = cp->nUnlinkedFiles;
+	dev->nBackgroundDeletions = cp->nBackgroundDeletions;
+	dev->sequenceNumber = cp->sequenceNumber;
+	dev->oldestDirtySequence = cp->oldestDirtySequence;
+}
+
+
+static int yaffs_WriteCheckpointDevice(yaffs_Device *dev)
+{
+	yaffs_CheckpointDevice cp;
+	__u32 nBytes;
+	__u32 nBlocks = (dev->internalEndBlock - dev->internalStartBlock + 1);
+
+	int ok;
+		
+	/* Write device runtime values*/
+	yaffs_DeviceToCheckpointDevice(&cp,dev);
+	cp.structType = sizeof(cp);
+	
+	ok = (yaffs_CheckpointWrite(dev,&cp,sizeof(cp)) == sizeof(cp));
+	
+	/* Write block info */
+	if(ok) {
+		nBytes = nBlocks * sizeof(yaffs_BlockInfo);
+		ok = (yaffs_CheckpointWrite(dev,dev->blockInfo,nBytes) == nBytes);
+	}
+		
+	/* Write chunk bits */		
+	if(ok) {
+		nBytes = nBlocks * dev->chunkBitmapStride;
+		ok = (yaffs_CheckpointWrite(dev,dev->chunkBits,nBytes) == nBytes);
+	}
+	return	 ok ? 1 : 0;
+
+}
+
+static int yaffs_ReadCheckpointDevice(yaffs_Device *dev)
+{
+	yaffs_CheckpointDevice cp;
+	__u32 nBytes;
+	__u32 nBlocks = (dev->internalEndBlock - dev->internalStartBlock + 1);
+
+	int ok;	
+	
+	ok = (yaffs_CheckpointRead(dev,&cp,sizeof(cp)) == sizeof(cp));
+	if(!ok)
+		return 0;
+		
+	if(cp.structType != sizeof(cp))
+		return 0;
+		
+	
+	yaffs_CheckpointDeviceToDevice(dev,&cp);
+	
+	nBytes = nBlocks * sizeof(yaffs_BlockInfo);
+	
+	ok = (yaffs_CheckpointRead(dev,dev->blockInfo,nBytes) == nBytes);
+	
+	if(!ok)
+		return 0;
+	nBytes = nBlocks * dev->chunkBitmapStride;
+	
+	ok = (yaffs_CheckpointRead(dev,dev->chunkBits,nBytes) == nBytes);
+	
+	return ok ? 1 : 0;
+}
+
+static void yaffs_ObjectToCheckpointObject(yaffs_CheckpointObject *cp,
+					   yaffs_Object *obj)
+{
+
+	cp->objectId = obj->objectId;
+	cp->parentId = (obj->parent) ? obj->parent->objectId : 0;
+	cp->hdrChunk = obj->hdrChunk;
+	cp->variantType = obj->variantType;			
+	cp->deleted = obj->deleted;
+	cp->softDeleted = obj->softDeleted;
+	cp->unlinked = obj->unlinked;
+	cp->fake = obj->fake;
+	cp->renameAllowed = obj->renameAllowed;
+	cp->unlinkAllowed = obj->unlinkAllowed;
+	cp->serial = obj->serial;
+	cp->nDataChunks = obj->nDataChunks;
+	
+	if(obj->variantType == YAFFS_OBJECT_TYPE_FILE)
+		cp->fileSizeOrEquivalentObjectId = obj->variant.fileVariant.fileSize;
+	else if(obj->variantType == YAFFS_OBJECT_TYPE_HARDLINK)
+		cp->fileSizeOrEquivalentObjectId = obj->variant.hardLinkVariant.equivalentObjectId;
+}
+
+static void yaffs_CheckpointObjectToObject( yaffs_Object *obj,yaffs_CheckpointObject *cp)
+{
+
+	yaffs_Object *parent;
+	
+	obj->objectId = cp->objectId;
+	
+	if(cp->parentId)
+		parent = yaffs_FindOrCreateObjectByNumber(
+					obj->myDev,
+					cp->parentId,
+					YAFFS_OBJECT_TYPE_DIRECTORY);
+	else
+		parent = NULL;
+		
+	if(parent)
+		yaffs_AddObjectToDirectory(parent, obj);
+		
+	obj->hdrChunk = cp->hdrChunk;
+	obj->variantType = cp->variantType;			
+	obj->deleted = cp->deleted;
+	obj->softDeleted = cp->softDeleted;
+	obj->unlinked = cp->unlinked;
+	obj->fake = cp->fake;
+	obj->renameAllowed = cp->renameAllowed;
+	obj->unlinkAllowed = cp->unlinkAllowed;
+	obj->serial = cp->serial;
+	obj->nDataChunks = cp->nDataChunks;
+	
+	if(obj->variantType == YAFFS_OBJECT_TYPE_FILE)
+		obj->variant.fileVariant.fileSize = cp->fileSizeOrEquivalentObjectId;
+	else if(obj->variantType == YAFFS_OBJECT_TYPE_HARDLINK)
+		obj->variant.hardLinkVariant.equivalentObjectId = cp->fileSizeOrEquivalentObjectId;
+		
+	if(obj->objectId > 0)
+		obj->lazyLoaded = 1;
+}
+
+
+
+static int yaffs_CheckpointTnodeWorker(yaffs_Object * in, yaffs_Tnode * tn,
+				  	__u32 level, int chunkOffset)
+{
+	int i;
+	yaffs_Device *dev = in->myDev;
+	int ok = 1;
+	int nTnodeBytes = (dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8;
+
+	if (tn) {
+		if (level > 0) {
+
+			for (i = 0; i < YAFFS_NTNODES_INTERNAL && ok; i++){
+				if (tn->internal[i]) {
+					ok = yaffs_CheckpointTnodeWorker(in,
+							tn->internal[i],
+							level - 1,
+							(chunkOffset<<YAFFS_TNODES_INTERNAL_BITS) + i);
+				}
+			}
+		} else if (level == 0) {
+			__u32 baseOffset = chunkOffset <<  YAFFS_TNODES_LEVEL0_BITS;
+			/* printf("write tnode at %d\n",baseOffset); */
+			ok = (yaffs_CheckpointWrite(dev,&baseOffset,sizeof(baseOffset)) == sizeof(baseOffset));
+			if(ok)
+				ok = (yaffs_CheckpointWrite(dev,tn,nTnodeBytes) == nTnodeBytes);
+		}
+	}
+
+	return ok;
+
+}
+
+static int yaffs_WriteCheckpointTnodes(yaffs_Object *obj)
+{
+	__u32 endMarker = ~0;
+	int ok = 1;
+	
+	if(obj->variantType == YAFFS_OBJECT_TYPE_FILE){
+		ok = yaffs_CheckpointTnodeWorker(obj,
+					    obj->variant.fileVariant.top,
+					    obj->variant.fileVariant.topLevel,
+					    0);
+		if(ok)
+			ok = (yaffs_CheckpointWrite(obj->myDev,&endMarker,sizeof(endMarker)) == 
+				sizeof(endMarker));
+	}
+	
+	return ok ? 1 : 0;
+}
+
+static int yaffs_ReadCheckpointTnodes(yaffs_Object *obj)
+{
+	__u32 baseChunk;
+	int ok = 1;
+	yaffs_Device *dev = obj->myDev;
+	yaffs_FileStructure *fileStructPtr = &obj->variant.fileVariant;
+	yaffs_Tnode *tn;
+	
+	ok = (yaffs_CheckpointRead(dev,&baseChunk,sizeof(baseChunk)) == sizeof(baseChunk));
+	
+	while(ok && (~baseChunk)){
+		/* Read level 0 tnode */
+		
+		/* printf("read  tnode at %d\n",baseChunk); */
+		tn = yaffs_GetTnodeRaw(dev);
+		if(tn)
+			ok = (yaffs_CheckpointRead(dev,tn,(dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8) ==
+			      (dev->tnodeWidth * YAFFS_NTNODES_LEVEL0)/8);
+		else
+			ok = 0;
+			
+		if(tn && ok){
+			ok = yaffs_AddOrFindLevel0Tnode(dev,
+					       		fileStructPtr,
+					       		baseChunk,
+					       		tn) ? 1 : 0;
+		}
+			
+		if(ok)
+			ok = (yaffs_CheckpointRead(dev,&baseChunk,sizeof(baseChunk)) == sizeof(baseChunk));
+		
+	}
+
+	return ok ? 1 : 0;	
+}
+ 
+
+static int yaffs_WriteCheckpointObjects(yaffs_Device *dev)
+{
+	yaffs_Object *obj;
+	yaffs_CheckpointObject cp;
+	int i;
+	int ok = 1;
+	struct list_head *lh;
+
+	
+	/* Iterate through the objects in each hash entry,
+	 * dumping them to the checkpointing stream.
+	 */
+	 
+	 for(i = 0; ok &&  i <  YAFFS_NOBJECT_BUCKETS; i++){
+	 	list_for_each(lh, &dev->objectBucket[i].list) {
+			if (lh) {
+				obj = list_entry(lh, yaffs_Object, hashLink);
+				if (!obj->deferedFree) {
+					yaffs_ObjectToCheckpointObject(&cp,obj);
+					cp.structType = sizeof(cp);
+					/* printf("Write out object %d type %d\n",obj->objectId,obj->variantType); */
+					ok = (yaffs_CheckpointWrite(dev,&cp,sizeof(cp)) == sizeof(cp));
+					
+					if(ok && obj->variantType == YAFFS_OBJECT_TYPE_FILE){
+						ok = yaffs_WriteCheckpointTnodes(obj);
+					}
+				}
+			}
+		}
+	 }
+	 
+	 /* Dump end of list */
+	memset(&cp,0xFF,sizeof(yaffs_CheckpointObject));
+	cp.structType = sizeof(cp);
+	
+	if(ok)
+		ok = (yaffs_CheckpointWrite(dev,&cp,sizeof(cp)) == sizeof(cp));
+		
+	return ok ? 1 : 0;
+}
+
+static int yaffs_ReadCheckpointObjects(yaffs_Device *dev)
+{
+	yaffs_Object *obj;
+	yaffs_CheckpointObject cp;
+	int ok = 1;
+	int done = 0;
+	yaffs_Object *hardList = NULL;
+	
+	while(ok && !done) {
+		ok = (yaffs_CheckpointRead(dev,&cp,sizeof(cp)) == sizeof(cp));
+		if(cp.structType != sizeof(cp)) {
+			/* printf("structure parsing failed\n"); */
+			ok = 0;
+		}
+			
+		if(ok && cp.objectId == ~0)
+			done = 1;
+		else if(ok){
+			T(YAFFS_TRACE_CHECKPOINT,(TSTR("Read object %d parent %d type %d" TENDSTR),
+				cp.objectId,cp.parentId,cp.variantType));
+			obj = yaffs_FindOrCreateObjectByNumber(dev,cp.objectId, cp.variantType);
+			if(obj) {
+				yaffs_CheckpointObjectToObject(obj,&cp);
+				if(obj->variantType == YAFFS_OBJECT_TYPE_FILE) {
+					ok = yaffs_ReadCheckpointTnodes(obj);
+				} else if(obj->variantType == YAFFS_OBJECT_TYPE_HARDLINK) {
+					obj->hardLinks.next =
+						    (struct list_head *)
+						    hardList;
+					hardList = obj;
+				}
+			   
+			}
+		}
+	}
+	
+	if(ok)
+		yaffs_HardlinkFixup(dev,hardList);
+	
+	return ok ? 1 : 0;
+}
+
+static int yaffs_WriteCheckpointData(yaffs_Device *dev)
+{
+
+	int ok;
+	T(YAFFS_TRACE_ALWAYS,(TSTR("%s: save checkpoint"TENDSTR),dev->name));
+	
+	ok = yaffs_CheckpointOpen(dev,1);
+	
+	if(ok)
+		ok = yaffs_WriteCheckpointValidityMarker(dev,1);
+	if(ok)
+		ok = yaffs_WriteCheckpointDevice(dev);
+	if(ok)
+		ok = yaffs_WriteCheckpointObjects(dev);
+	if(ok)
+		ok = yaffs_WriteCheckpointValidityMarker(dev,0);
+		
+	if(!yaffs_CheckpointClose(dev))
+		 ok = 0;
+		 
+	if(ok)
+	    	dev->isCheckpointed = 1;
+	 else 
+	 	dev->isCheckpointed = 0;
+
+	return dev->isCheckpointed;
+}
+
+static int yaffs_ReadCheckpointData(yaffs_Device *dev)
+{
+	int ok;
+	
+	ok = yaffs_CheckpointOpen(dev,0); /* open for read */
+	
+	if(ok)
+		ok = yaffs_ReadCheckpointValidityMarker(dev,1);
+	if(ok)
+		ok = yaffs_ReadCheckpointDevice(dev);
+	if(ok)
+		ok = yaffs_ReadCheckpointObjects(dev);
+	if(ok)
+		ok = yaffs_ReadCheckpointValidityMarker(dev,0);
+		
+
+
+	if(!yaffs_CheckpointClose(dev))
+		ok = 0;
+
+	if(ok)
+	    	dev->isCheckpointed = 1;
+	 else 
+	 	dev->isCheckpointed = 0;
+
+	return ok ? 1 : 0;
+
+}
+
+static void yaffs_InvalidateCheckpoint(yaffs_Device *dev)
+{
+	if(dev->isCheckpointed || 
+	   dev->blocksInCheckpoint > 0){
+		dev->isCheckpointed = 0;
+		yaffs_CheckpointInvalidateStream(dev);
+		if(dev->superBlock && dev->markSuperBlockDirty)
+			dev->markSuperBlockDirty(dev->superBlock);
+	}
+}
+
+
+int yaffs_CheckpointSave(yaffs_Device *dev)
+{
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("save entry: isCheckpointed %d"TENDSTR),dev->isCheckpointed));
+
+	if(!dev->isCheckpointed)
+		yaffs_WriteCheckpointData(dev);
+	
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("save exit: isCheckpointed %d"TENDSTR),dev->isCheckpointed));
+
+	return dev->isCheckpointed;
+}
+
+int yaffs_CheckpointRestore(yaffs_Device *dev)
+{
+	int retval;
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("restore entry: isCheckpointed %d"TENDSTR),dev->isCheckpointed));
+	
+	retval = yaffs_ReadCheckpointData(dev);
+
+	T(YAFFS_TRACE_CHECKPOINT,(TSTR("restore exit: isCheckpointed %d"TENDSTR),dev->isCheckpointed));
+	
+	return retval;
+}
+
+/*--------------------- File read/write ------------------------
+ * Read and write have very similar structures.
+ * In general the read/write has three parts to it
+ * An incomplete chunk to start with (if the read/write is not chunk-aligned)
+ * Some complete chunks
+ * An incomplete chunk to end off with
+ *
+ * Curve-balls: the first chunk might also be the last chunk.
+ */
+
+int yaffs_ReadDataFromFile(yaffs_Object * in, __u8 * buffer, __u32 offset,
+			   int nBytes)
+{
+
+	int chunk;
+	int start;
+	int nToCopy;
+	int n = nBytes;
+	int nDone = 0;
+	yaffs_ChunkCache *cache;
+
+	yaffs_Device *dev;
+
+	dev = in->myDev;
+
+	while (n > 0) {
+		chunk = offset / dev->nBytesPerChunk + 1;   /* The first chunk is 1 */
+		start = offset % dev->nBytesPerChunk;
+
+		/* OK now check for the curveball where the start and end are in
+		 * the same chunk.      
+		 */
+		if ((start + n) < dev->nBytesPerChunk) {
+			nToCopy = n;
+		} else {
+			nToCopy = dev->nBytesPerChunk - start;
+		}
+
+		cache = yaffs_FindChunkCache(in, chunk);
+
+		/* If the chunk is already in the cache or it is less than a whole chunk
+		 * then use the cache (if there is caching)
+		 * else bypass the cache.
+		 */
+		if (cache || nToCopy != dev->nBytesPerChunk) {
+			if (dev->nShortOpCaches > 0) {
+
+				/* If we can't find the data in the cache, then load it up. */
+
+				if (!cache) {
+					cache = yaffs_GrabChunkCache(in->myDev);
+					cache->object = in;
+					cache->chunkId = chunk;
+					cache->dirty = 0;
+					cache->locked = 0;
+					yaffs_ReadChunkDataFromObject(in, chunk,
+								      cache->
+								      data);
+					cache->nBytes = 0;
+				}
+
+				yaffs_UseChunkCache(dev, cache, 0);
+
+				cache->locked = 1;
+
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_UnlockYAFFS(TRUE);
+#endif
+				memcpy(buffer, &cache->data[start], nToCopy);
+
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_LockYAFFS(TRUE);
+#endif
+				cache->locked = 0;
+			} else {
+				/* Read into the local buffer then copy..*/
+
+				__u8 *localBuffer =
+				    yaffs_GetTempBuffer(dev, __LINE__);
+				yaffs_ReadChunkDataFromObject(in, chunk,
+							      localBuffer);
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_UnlockYAFFS(TRUE);
+#endif
+				memcpy(buffer, &localBuffer[start], nToCopy);
+
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_LockYAFFS(TRUE);
+#endif
+				yaffs_ReleaseTempBuffer(dev, localBuffer,
+							__LINE__);
+			}
+
+		} else {
+#ifdef CONFIG_YAFFS_WINCE
+			__u8 *localBuffer = yaffs_GetTempBuffer(dev, __LINE__);
+
+			/* Under WinCE can't do direct transfer. Need to use a local buffer.
+			 * This is because we otherwise screw up WinCE's memory mapper
+			 */
+			yaffs_ReadChunkDataFromObject(in, chunk, localBuffer);
+
+#ifdef CONFIG_YAFFS_WINCE
+			yfsd_UnlockYAFFS(TRUE);
+#endif
+			memcpy(buffer, localBuffer, dev->nBytesPerChunk);
+
+#ifdef CONFIG_YAFFS_WINCE
+			yfsd_LockYAFFS(TRUE);
+			yaffs_ReleaseTempBuffer(dev, localBuffer, __LINE__);
+#endif
+
+#else
+			/* A full chunk. Read directly into the supplied buffer. */
+			yaffs_ReadChunkDataFromObject(in, chunk, buffer);
+#endif
+		}
+
+		n -= nToCopy;
+		offset += nToCopy;
+		buffer += nToCopy;
+		nDone += nToCopy;
+
+	}
+
+	return nDone;
+}
+
+int yaffs_WriteDataToFile(yaffs_Object * in, const __u8 * buffer, __u32 offset,
+			  int nBytes, int writeThrough)
+{
+
+	int chunk;
+	int start;
+	int nToCopy;
+	int n = nBytes;
+	int nDone = 0;
+	int nToWriteBack;
+	int startOfWrite = offset;
+	int chunkWritten = 0;
+	int nBytesRead;
+
+	yaffs_Device *dev;
+
+	dev = in->myDev;
+
+	while (n > 0 && chunkWritten >= 0) {
+		chunk = offset / dev->nBytesPerChunk + 1;
+		start = offset % dev->nBytesPerChunk;
+
+		/* OK now check for the curveball where the start and end are in
+		 * the same chunk.
+		 */
+
+		if ((start + n) < dev->nBytesPerChunk) {
+			nToCopy = n;
+
+			/* Now folks, to calculate how many bytes to write back....
+			 * If we're overwriting and not writing to then end of file then
+			 * we need to write back as much as was there before.
+			 */
+
+			nBytesRead =
+			    in->variant.fileVariant.fileSize -
+			    ((chunk - 1) * dev->nBytesPerChunk);
+
+			if (nBytesRead > dev->nBytesPerChunk) {
+				nBytesRead = dev->nBytesPerChunk;
+			}
+
+			nToWriteBack =
+			    (nBytesRead >
+			     (start + n)) ? nBytesRead : (start + n);
+
+		} else {
+			nToCopy = dev->nBytesPerChunk - start;
+			nToWriteBack = dev->nBytesPerChunk;
+		}
+
+		if (nToCopy != dev->nBytesPerChunk) {
+			/* An incomplete start or end chunk (or maybe both start and end chunk) */
+			if (dev->nShortOpCaches > 0) {
+				yaffs_ChunkCache *cache;
+				/* If we can't find the data in the cache, then load the cache */
+				cache = yaffs_FindChunkCache(in, chunk);
+				
+				if (!cache
+				    && yaffs_CheckSpaceForAllocation(in->
+								     myDev)) {
+					cache = yaffs_GrabChunkCache(in->myDev);
+					cache->object = in;
+					cache->chunkId = chunk;
+					cache->dirty = 0;
+					cache->locked = 0;
+					yaffs_ReadChunkDataFromObject(in, chunk,
+								      cache->
+								      data);
+				}
+				else if(cache && 
+				        !cache->dirty &&
+					!yaffs_CheckSpaceForAllocation(in->myDev)){
+					/* Drop the cache if it was a read cache item and
+					 * no space check has been made for it.
+					 */ 
+					 cache = NULL;
+				}
+
+				if (cache) {
+					yaffs_UseChunkCache(dev, cache, 1);
+					cache->locked = 1;
+#ifdef CONFIG_YAFFS_WINCE
+					yfsd_UnlockYAFFS(TRUE);
+#endif
+
+					memcpy(&cache->data[start], buffer,
+					       nToCopy);
+
+#ifdef CONFIG_YAFFS_WINCE
+					yfsd_LockYAFFS(TRUE);
+#endif
+					cache->locked = 0;
+					cache->nBytes = nToWriteBack;
+
+					if (writeThrough) {
+						chunkWritten =
+						    yaffs_WriteChunkDataToObject
+						    (cache->object,
+						     cache->chunkId,
+						     cache->data, cache->nBytes,
+						     1);
+						cache->dirty = 0;
+					}
+
+				} else {
+					chunkWritten = -1;	/* fail the write */
+				}
+			} else {
+				/* An incomplete start or end chunk (or maybe both start and end chunk)
+				 * Read into the local buffer then copy, then copy over and write back.
+				 */
+
+				__u8 *localBuffer =
+				    yaffs_GetTempBuffer(dev, __LINE__);
+
+				yaffs_ReadChunkDataFromObject(in, chunk,
+							      localBuffer);
+
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_UnlockYAFFS(TRUE);
+#endif
+
+				memcpy(&localBuffer[start], buffer, nToCopy);
+
+#ifdef CONFIG_YAFFS_WINCE
+				yfsd_LockYAFFS(TRUE);
+#endif
+				chunkWritten =
+				    yaffs_WriteChunkDataToObject(in, chunk,
+								 localBuffer,
+								 nToWriteBack,
+								 0);
+
+				yaffs_ReleaseTempBuffer(dev, localBuffer,
+							__LINE__);
+
+			}
+
+		} else {
+
+#ifdef CONFIG_YAFFS_WINCE
+			/* Under WinCE can't do direct transfer. Need to use a local buffer.
+			 * This is because we otherwise screw up WinCE's memory mapper
+			 */
+			__u8 *localBuffer = yaffs_GetTempBuffer(dev, __LINE__);
+#ifdef CONFIG_YAFFS_WINCE
+			yfsd_UnlockYAFFS(TRUE);
+#endif
+			memcpy(localBuffer, buffer, dev->nBytesPerChunk);
+#ifdef CONFIG_YAFFS_WINCE
+			yfsd_LockYAFFS(TRUE);
+#endif
+			chunkWritten =
+			    yaffs_WriteChunkDataToObject(in, chunk, localBuffer,
+							 dev->nBytesPerChunk,
+							 0);
+			yaffs_ReleaseTempBuffer(dev, localBuffer, __LINE__);
+#else
+			/* A full chunk. Write directly from the supplied buffer. */
+			chunkWritten =
+			    yaffs_WriteChunkDataToObject(in, chunk, buffer,
+							 dev->nBytesPerChunk,
+							 0);
+#endif
+			/* Since we've overwritten the cached data, we better invalidate it. */
+			yaffs_InvalidateChunkCache(in, chunk);
+		}
+
+		if (chunkWritten >= 0) {
+			n -= nToCopy;
+			offset += nToCopy;
+			buffer += nToCopy;
+			nDone += nToCopy;
+		}
+
+	}
+
+	/* Update file object */
+
+	if ((startOfWrite + nDone) > in->variant.fileVariant.fileSize) {
+		in->variant.fileVariant.fileSize = (startOfWrite + nDone);
+	}
+
+	in->dirty = 1;
+
+	return nDone;
+}
+
+
+/* ---------------------- File resizing stuff ------------------ */
+
+static void yaffs_PruneResizedChunks(yaffs_Object * in, int newSize)
+{
+
+	yaffs_Device *dev = in->myDev;
+	int oldFileSize = in->variant.fileVariant.fileSize;
+
+	int lastDel = 1 + (oldFileSize - 1) / dev->nBytesPerChunk;
+
+	int startDel = 1 + (newSize + dev->nBytesPerChunk - 1) /
+	    dev->nBytesPerChunk;
+	int i;
+	int chunkId;
+
+	/* Delete backwards so that we don't end up with holes if
+	 * power is lost part-way through the operation.
+	 */
+	for (i = lastDel; i >= startDel; i--) {
+		/* NB this could be optimised somewhat,
+		 * eg. could retrieve the tags and write them without
+		 * using yaffs_DeleteChunk
+		 */
+
+		chunkId = yaffs_FindAndDeleteChunkInFile(in, i, NULL);
+		if (chunkId > 0) {
+			if (chunkId <
+			    (dev->internalStartBlock * dev->nChunksPerBlock)
+			    || chunkId >=
+			    ((dev->internalEndBlock +
+			      1) * dev->nChunksPerBlock)) {
+				T(YAFFS_TRACE_ALWAYS,
+				  (TSTR("Found daft chunkId %d for %d" TENDSTR),
+				   chunkId, i));
+			} else {
+				in->nDataChunks--;
+				yaffs_DeleteChunk(dev, chunkId, 1, __LINE__);
+			}
+		}
+	}
+
+}
+
+int yaffs_ResizeFile(yaffs_Object * in, int newSize)
+{
+
+	int oldFileSize = in->variant.fileVariant.fileSize;
+	int sizeOfPartialChunk;
+	yaffs_Device *dev = in->myDev;
+
+	sizeOfPartialChunk = newSize % dev->nBytesPerChunk;
+
+	yaffs_FlushFilesChunkCache(in);
+	yaffs_InvalidateWholeChunkCache(in);
+
+	yaffs_CheckGarbageCollection(dev);
+
+	if (in->variantType != YAFFS_OBJECT_TYPE_FILE) {
+		return yaffs_GetFileSize(in);
+	}
+
+	if (newSize == oldFileSize) {
+		return oldFileSize;
+	}
+
+	if (newSize < oldFileSize) {
+
+		yaffs_PruneResizedChunks(in, newSize);
+
+		if (sizeOfPartialChunk != 0) {
+			int lastChunk = 1 + newSize / dev->nBytesPerChunk;
+			__u8 *localBuffer = yaffs_GetTempBuffer(dev, __LINE__);
+
+			/* Got to read and rewrite the last chunk with its new size and zero pad */
+			yaffs_ReadChunkDataFromObject(in, lastChunk,
+						      localBuffer);
+
+			memset(localBuffer + sizeOfPartialChunk, 0,
+			       dev->nBytesPerChunk - sizeOfPartialChunk);
+
+			yaffs_WriteChunkDataToObject(in, lastChunk, localBuffer,
+						     sizeOfPartialChunk, 1);
+
+			yaffs_ReleaseTempBuffer(dev, localBuffer, __LINE__);
+		}
+
+		in->variant.fileVariant.fileSize = newSize;
+
+		yaffs_PruneFileStructure(dev, &in->variant.fileVariant);
+	} else {
+		/* newsSize > oldFileSize */
+		in->variant.fileVariant.fileSize = newSize;
+	}
+
+
+
+	/* Write a new object header.
+	 * show we've shrunk the file, if need be
+	 * Do this only if the file is not in the deleted directories.
+	 */
+	if (in->parent->objectId != YAFFS_OBJECTID_UNLINKED &&
+	    in->parent->objectId != YAFFS_OBJECTID_DELETED) {
+		yaffs_UpdateObjectHeader(in, NULL, 0,
+					 (newSize < oldFileSize) ? 1 : 0, 0);
+	}
+
+	return newSize;
+}
+
+loff_t yaffs_GetFileSize(yaffs_Object * obj)
+{
+	obj = yaffs_GetEquivalentObject(obj);
+
+	switch (obj->variantType) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		return obj->variant.fileVariant.fileSize;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		return yaffs_strlen(obj->variant.symLinkVariant.alias);
+	default:
+		return 0;
+	}
+}
+
+
+
+int yaffs_FlushFile(yaffs_Object * in, int updateTime)
+{
+	int retVal;
+	if (in->dirty) {
+		if (updateTime) {
+#ifdef CONFIG_YAFFS_WINCE
+			yfsd_WinFileTimeNow(in->win_mtime);
+#else
+
+			in->yst_mtime = Y_CURRENT_TIME;
+
+#endif
+		}
+
+		retVal =
+		    (yaffs_UpdateObjectHeader(in, NULL, 0, 0, 0) >=
+		     0) ? YAFFS_OK : YAFFS_FAIL;
+		if (in->dirty) yaffs_FlushFilesChunkCache(in);
+	} else {
+		retVal = YAFFS_OK;
+	}
+
+	return retVal;
+
+}
+
+static int yaffs_DoGenericObjectDeletion(yaffs_Object * in)
+{
+
+	/* First off, invalidate the file's data in the cache, without flushing. */
+	yaffs_InvalidateWholeChunkCache(in);
+
+	if (in->myDev->isYaffs2 && (in->parent != in->myDev->deletedDir)) {
+		/* Move to the unlinked directory so we have a record that it was deleted. */
+		yaffs_ChangeObjectName(in, in->myDev->deletedDir, NULL, 0, 0);
+
+	}
+
+	yaffs_RemoveObjectFromDirectory(in);
+	yaffs_DeleteChunk(in->myDev, in->hdrChunk, 1, __LINE__);
+	in->hdrChunk = 0;
+
+	yaffs_FreeObject(in);
+	return YAFFS_OK;
+
+}
+
+/* yaffs_DeleteFile deletes the whole file data
+ * and the inode associated with the file.
+ * It does not delete the links associated with the file.
+ */
+static int yaffs_UnlinkFile(yaffs_Object * in)
+{
+
+	int retVal;
+	int immediateDeletion = 0;
+
+	if (1) {
+#ifdef __KERNEL__
+		if (!in->myInode) {
+			immediateDeletion = 1;
+
+		}
+#else
+		if (in->inUse <= 0) {
+			immediateDeletion = 1;
+
+		}
+#endif
+		if (immediateDeletion) {
+			retVal =
+			    yaffs_ChangeObjectName(in, in->myDev->deletedDir,
+						   NULL, 0, 0);
+			T(YAFFS_TRACE_TRACING,
+			  (TSTR("yaffs: immediate deletion of file %d" TENDSTR),
+			   in->objectId));
+			in->deleted = 1;
+			in->myDev->nDeletedFiles++;
+			if (0 && in->myDev->isYaffs2) {
+				yaffs_ResizeFile(in, 0);
+			}
+			yaffs_SoftDeleteFile(in);
+		} else {
+			retVal =
+			    yaffs_ChangeObjectName(in, in->myDev->unlinkedDir,
+						   NULL, 0, 0);
+		}
+
+	}
+	return retVal;
+}
+
+int yaffs_DeleteFile(yaffs_Object * in)
+{
+	int retVal = YAFFS_OK;
+
+	if (in->nDataChunks > 0) {
+		/* Use soft deletion if there is data in the file */
+		if (!in->unlinked) {
+			retVal = yaffs_UnlinkFile(in);
+		}
+		if (retVal == YAFFS_OK && in->unlinked && !in->deleted) {
+			in->deleted = 1;
+			in->myDev->nDeletedFiles++;
+			yaffs_SoftDeleteFile(in);
+		}
+		return in->deleted ? YAFFS_OK : YAFFS_FAIL;
+	} else {
+		/* The file has no data chunks so we toss it immediately */
+		yaffs_FreeTnode(in->myDev, in->variant.fileVariant.top);
+		in->variant.fileVariant.top = NULL;
+		yaffs_DoGenericObjectDeletion(in);
+
+		return YAFFS_OK;
+	}
+}
+
+static int yaffs_DeleteDirectory(yaffs_Object * in)
+{
+	/* First check that the directory is empty. */
+	if (list_empty(&in->variant.directoryVariant.children)) {
+		return yaffs_DoGenericObjectDeletion(in);
+	}
+
+	return YAFFS_FAIL;
+
+}
+
+static int yaffs_DeleteSymLink(yaffs_Object * in)
+{
+	YFREE(in->variant.symLinkVariant.alias);
+
+	return yaffs_DoGenericObjectDeletion(in);
+}
+
+static int yaffs_DeleteHardLink(yaffs_Object * in)
+{
+	/* remove this hardlink from the list assocaited with the equivalent
+	 * object
+	 */
+	list_del(&in->hardLinks);
+	return yaffs_DoGenericObjectDeletion(in);
+}
+
+static void yaffs_DestroyObject(yaffs_Object * obj)
+{
+	switch (obj->variantType) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		yaffs_DeleteFile(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		yaffs_DeleteDirectory(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		yaffs_DeleteSymLink(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		yaffs_DeleteHardLink(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		yaffs_DoGenericObjectDeletion(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+		break;		/* should not happen. */
+	}
+}
+
+static int yaffs_UnlinkWorker(yaffs_Object * obj)
+{
+
+	if (obj->variantType == YAFFS_OBJECT_TYPE_HARDLINK) {
+		return yaffs_DeleteHardLink(obj);
+	} else if (!list_empty(&obj->hardLinks)) {
+		/* Curve ball: We're unlinking an object that has a hardlink.
+		 *
+		 * This problem arises because we are not strictly following
+		 * The Linux link/inode model.
+		 *
+		 * We can't really delete the object.
+		 * Instead, we do the following:
+		 * - Select a hardlink.
+		 * - Unhook it from the hard links
+		 * - Unhook it from its parent directory (so that the rename can work)
+		 * - Rename the object to the hardlink's name.
+		 * - Delete the hardlink
+		 */
+
+		yaffs_Object *hl;
+		int retVal;
+		YCHAR name[YAFFS_MAX_NAME_LENGTH + 1];
+
+		hl = list_entry(obj->hardLinks.next, yaffs_Object, hardLinks);
+
+		list_del_init(&hl->hardLinks);
+		list_del_init(&hl->siblings);
+
+		yaffs_GetObjectName(hl, name, YAFFS_MAX_NAME_LENGTH + 1);
+
+		retVal = yaffs_ChangeObjectName(obj, hl->parent, name, 0, 0);
+
+		if (retVal == YAFFS_OK) {
+			retVal = yaffs_DoGenericObjectDeletion(hl);
+		}
+		return retVal;
+
+	} else {
+		switch (obj->variantType) {
+		case YAFFS_OBJECT_TYPE_FILE:
+			return yaffs_UnlinkFile(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+			return yaffs_DeleteDirectory(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+			return yaffs_DeleteSymLink(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+			return yaffs_DoGenericObjectDeletion(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+		default:
+			return YAFFS_FAIL;
+		}
+	}
+}
+
+
+static int yaffs_UnlinkObject( yaffs_Object *obj)
+{
+
+	if (obj && obj->unlinkAllowed) {
+		return yaffs_UnlinkWorker(obj);
+	}
+
+	return YAFFS_FAIL;
+
+}
+int yaffs_Unlink(yaffs_Object * dir, const YCHAR * name)
+{
+	yaffs_Object *obj;
+
+	obj = yaffs_FindObjectByName(dir, name);
+	return yaffs_UnlinkObject(obj);
+}
+
+/*----------------------- Initialisation Scanning ---------------------- */
+
+static void yaffs_HandleShadowedObject(yaffs_Device * dev, int objId,
+				       int backwardScanning)
+{
+	yaffs_Object *obj;
+
+	if (!backwardScanning) {
+		/* Handle YAFFS1 forward scanning case
+		 * For YAFFS1 we always do the deletion
+		 */
+
+	} else {
+		/* Handle YAFFS2 case (backward scanning)
+		 * If the shadowed object exists then ignore.
+		 */
+		if (yaffs_FindObjectByNumber(dev, objId)) {
+			return;
+		}
+	}
+
+	/* Let's create it (if it does not exist) assuming it is a file so that it can do shrinking etc.
+	 * We put it in unlinked dir to be cleaned up after the scanning
+	 */
+	obj =
+	    yaffs_FindOrCreateObjectByNumber(dev, objId,
+					     YAFFS_OBJECT_TYPE_FILE);
+	yaffs_AddObjectToDirectory(dev->unlinkedDir, obj);
+	obj->variant.fileVariant.shrinkSize = 0;
+	obj->valid = 1;		/* So that we don't read any other info for this file */
+
+}
+
+typedef struct {
+	int seq;
+	int block;
+} yaffs_BlockIndex;
+
+
+static void yaffs_HardlinkFixup(yaffs_Device *dev, yaffs_Object *hardList)
+{
+	yaffs_Object *hl;
+	yaffs_Object *in;
+	
+	while (hardList) {
+		hl = hardList;
+		hardList = (yaffs_Object *) (hardList->hardLinks.next);
+
+		in = yaffs_FindObjectByNumber(dev,
+					      hl->variant.hardLinkVariant.
+					      equivalentObjectId);
+
+		if (in) {
+			/* Add the hardlink pointers */
+			hl->variant.hardLinkVariant.equivalentObject = in;
+			list_add(&hl->hardLinks, &in->hardLinks);
+		} else {
+			/* Todo Need to report/handle this better.
+			 * Got a problem... hardlink to a non-existant object
+			 */
+			hl->variant.hardLinkVariant.equivalentObject = NULL;
+			INIT_LIST_HEAD(&hl->hardLinks);
+
+		}
+
+	}
+
+}
+
+
+
+
+
+static int ybicmp(const void *a, const void *b){
+    register int aseq = ((yaffs_BlockIndex *)a)->seq;
+    register int bseq = ((yaffs_BlockIndex *)b)->seq;
+    register int ablock = ((yaffs_BlockIndex *)a)->block;
+    register int bblock = ((yaffs_BlockIndex *)b)->block;
+    if( aseq == bseq )
+        return ablock - bblock;
+    else
+        return aseq - bseq;
+
+}
+
+static int yaffs_Scan(yaffs_Device * dev)
+{
+	yaffs_ExtendedTags tags;
+	int blk;
+	int blockIterator;
+	int startIterator;
+	int endIterator;
+	int nBlocksToScan = 0;
+
+	int chunk;
+	int c;
+	int deleted;
+	yaffs_BlockState state;
+	yaffs_Object *hardList = NULL;
+	yaffs_BlockInfo *bi;
+	int sequenceNumber;
+	yaffs_ObjectHeader *oh;
+	yaffs_Object *in;
+	yaffs_Object *parent;
+	int nBlocks = dev->internalEndBlock - dev->internalStartBlock + 1;
+
+	__u8 *chunkData;
+
+	yaffs_BlockIndex *blockIndex = NULL;
+
+	if (dev->isYaffs2) {
+		T(YAFFS_TRACE_SCAN,
+		  (TSTR("yaffs_Scan is not for YAFFS2!" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+	
+	//TODO  Throw all the yaffs2 stuuf out of yaffs_Scan since it is only for yaffs1 format.
+	
+	T(YAFFS_TRACE_SCAN,
+	  (TSTR("yaffs_Scan starts  intstartblk %d intendblk %d..." TENDSTR),
+	   dev->internalStartBlock, dev->internalEndBlock));
+
+	chunkData = yaffs_GetTempBuffer(dev, __LINE__);
+
+	dev->sequenceNumber = YAFFS_LOWEST_SEQUENCE_NUMBER;
+
+	if (dev->isYaffs2) {
+		blockIndex = YMALLOC(nBlocks * sizeof(yaffs_BlockIndex));
+	}
+
+	/* Scan all the blocks to determine their state */
+	for (blk = dev->internalStartBlock; blk <= dev->internalEndBlock; blk++) {
+		bi = yaffs_GetBlockInfo(dev, blk);
+		yaffs_ClearChunkBits(dev, blk);
+		bi->pagesInUse = 0;
+		bi->softDeletions = 0;
+
+		yaffs_QueryInitialBlockState(dev, blk, &state, &sequenceNumber);
+
+		bi->blockState = state;
+		bi->sequenceNumber = sequenceNumber;
+
+		T(YAFFS_TRACE_SCAN_DEBUG,
+		  (TSTR("Block scanning block %d state %d seq %d" TENDSTR), blk,
+		   state, sequenceNumber));
+
+		if (state == YAFFS_BLOCK_STATE_DEAD) {
+			T(YAFFS_TRACE_BAD_BLOCKS,
+			  (TSTR("block %d is bad" TENDSTR), blk));
+		} else if (state == YAFFS_BLOCK_STATE_EMPTY) {
+			T(YAFFS_TRACE_SCAN_DEBUG,
+			  (TSTR("Block empty " TENDSTR)));
+			dev->nErasedBlocks++;
+			dev->nFreeChunks += dev->nChunksPerBlock;
+		} else if (state == YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+
+			/* Determine the highest sequence number */
+			if (dev->isYaffs2 &&
+			    sequenceNumber >= YAFFS_LOWEST_SEQUENCE_NUMBER &&
+			    sequenceNumber < YAFFS_HIGHEST_SEQUENCE_NUMBER) {
+
+				blockIndex[nBlocksToScan].seq = sequenceNumber;
+				blockIndex[nBlocksToScan].block = blk;
+
+				nBlocksToScan++;
+
+				if (sequenceNumber >= dev->sequenceNumber) {
+					dev->sequenceNumber = sequenceNumber;
+				}
+			} else if (dev->isYaffs2) {
+				/* TODO: Nasty sequence number! */
+				T(YAFFS_TRACE_SCAN,
+				  (TSTR
+				   ("Block scanning block %d has bad sequence number %d"
+				    TENDSTR), blk, sequenceNumber));
+
+			}
+		}
+	}
+
+	/* Sort the blocks
+	 * Dungy old bubble sort for now...
+	 */
+	if (dev->isYaffs2) {
+		yaffs_BlockIndex temp;
+		int i;
+		int j;
+
+		for (i = 0; i < nBlocksToScan; i++)
+			for (j = i + 1; j < nBlocksToScan; j++)
+				if (blockIndex[i].seq > blockIndex[j].seq) {
+					temp = blockIndex[j];
+					blockIndex[j] = blockIndex[i];
+					blockIndex[i] = temp;
+				}
+	}
+
+	/* Now scan the blocks looking at the data. */
+	if (dev->isYaffs2) {
+		startIterator = 0;
+		endIterator = nBlocksToScan - 1;
+		T(YAFFS_TRACE_SCAN_DEBUG,
+		  (TSTR("%d blocks to be scanned" TENDSTR), nBlocksToScan));
+	} else {
+		startIterator = dev->internalStartBlock;
+		endIterator = dev->internalEndBlock;
+	}
+
+	/* For each block.... */
+	for (blockIterator = startIterator; blockIterator <= endIterator;
+	     blockIterator++) {
+
+		if (dev->isYaffs2) {
+			/* get the block to scan in the correct order */
+			blk = blockIndex[blockIterator].block;
+		} else {
+			blk = blockIterator;
+		}
+
+		bi = yaffs_GetBlockInfo(dev, blk);
+		state = bi->blockState;
+
+		deleted = 0;
+
+		/* For each chunk in each block that needs scanning....*/
+		for (c = 0; c < dev->nChunksPerBlock &&
+		     state == YAFFS_BLOCK_STATE_NEEDS_SCANNING; c++) {
+			/* Read the tags and decide what to do */
+			chunk = blk * dev->nChunksPerBlock + c;
+
+			yaffs_ReadChunkWithTagsFromNAND(dev, chunk, NULL,
+							&tags);
+
+			/* Let's have a good look at this chunk... */
+
+			if (!dev->isYaffs2 && tags.chunkDeleted) {
+				/* YAFFS1 only...
+				 * A deleted chunk
+				 */
+				deleted++;
+				dev->nFreeChunks++;
+				/*T((" %d %d deleted\n",blk,c)); */
+			} else if (!tags.chunkUsed) {
+				/* An unassigned chunk in the block
+				 * This means that either the block is empty or 
+				 * this is the one being allocated from
+				 */
+
+				if (c == 0) {
+					/* We're looking at the first chunk in the block so the block is unused */
+					state = YAFFS_BLOCK_STATE_EMPTY;
+					dev->nErasedBlocks++;
+				} else {
+					/* this is the block being allocated from */
+					T(YAFFS_TRACE_SCAN,
+					  (TSTR
+					   (" Allocating from %d %d" TENDSTR),
+					   blk, c));
+					state = YAFFS_BLOCK_STATE_ALLOCATING;
+					dev->allocationBlock = blk;
+					dev->allocationPage = c;
+					dev->allocationBlockFinder = blk;	
+					/* Set it to here to encourage the allocator to go forth from here. */
+					
+					/* Yaffs2 sanity check:
+					 * This should be the one with the highest sequence number
+					 */
+					if (dev->isYaffs2
+					    && (dev->sequenceNumber !=
+						bi->sequenceNumber)) {
+						T(YAFFS_TRACE_ALWAYS,
+						  (TSTR
+						   ("yaffs: Allocation block %d was not highest sequence id:"
+						    " block seq = %d, dev seq = %d"
+						    TENDSTR), blk,bi->sequenceNumber,dev->sequenceNumber));
+					}
+				}
+
+				dev->nFreeChunks += (dev->nChunksPerBlock - c);
+			} else if (tags.chunkId > 0) {
+				/* chunkId > 0 so it is a data chunk... */
+				unsigned int endpos;
+
+				yaffs_SetChunkBit(dev, blk, c);
+				bi->pagesInUse++;
+
+				in = yaffs_FindOrCreateObjectByNumber(dev,
+								      tags.
+								      objectId,
+								      YAFFS_OBJECT_TYPE_FILE);
+				/* PutChunkIntoFile checks for a clash (two data chunks with
+				 * the same chunkId).
+				 */
+				yaffs_PutChunkIntoFile(in, tags.chunkId, chunk,
+						       1);
+				endpos =
+				    (tags.chunkId - 1) * dev->nBytesPerChunk +
+				    tags.byteCount;
+				if (in->variantType == YAFFS_OBJECT_TYPE_FILE
+				    && in->variant.fileVariant.scannedFileSize <
+				    endpos) {
+					in->variant.fileVariant.
+					    scannedFileSize = endpos;
+					if (!dev->useHeaderFileSize) {
+						in->variant.fileVariant.
+						    fileSize =
+						    in->variant.fileVariant.
+						    scannedFileSize;
+					}
+
+				}
+				/* T((" %d %d data %d %d\n",blk,c,tags.objectId,tags.chunkId));   */
+			} else {
+				/* chunkId == 0, so it is an ObjectHeader.
+				 * Thus, we read in the object header and make the object
+				 */
+				yaffs_SetChunkBit(dev, blk, c);
+				bi->pagesInUse++;
+
+				yaffs_ReadChunkWithTagsFromNAND(dev, chunk,
+								chunkData,
+								NULL);
+
+				oh = (yaffs_ObjectHeader *) chunkData;
+
+				in = yaffs_FindObjectByNumber(dev,
+							      tags.objectId);
+				if (in && in->variantType != oh->type) {
+					/* This should not happen, but somehow
+					 * Wev'e ended up with an objectId that has been reused but not yet 
+					 * deleted, and worse still it has changed type. Delete the old object.
+					 */
+
+					yaffs_DestroyObject(in);
+
+					in = 0;
+				}
+
+				in = yaffs_FindOrCreateObjectByNumber(dev,
+								      tags.
+								      objectId,
+								      oh->type);
+
+				if (oh->shadowsObject > 0) {
+					yaffs_HandleShadowedObject(dev,
+								   oh->
+								   shadowsObject,
+								   0);
+				}
+
+				if (in->valid) {
+					/* We have already filled this one. We have a duplicate and need to resolve it. */
+
+					unsigned existingSerial = in->serial;
+					unsigned newSerial = tags.serialNumber;
+
+					if (dev->isYaffs2 ||
+					    ((existingSerial + 1) & 3) ==
+					    newSerial) {
+						/* Use new one - destroy the exisiting one */
+						yaffs_DeleteChunk(dev,
+								  in->hdrChunk,
+								  1, __LINE__);
+						in->valid = 0;
+					} else {
+						/* Use existing - destroy this one. */
+						yaffs_DeleteChunk(dev, chunk, 1,
+								  __LINE__);
+					}
+				}
+
+				if (!in->valid &&
+				    (tags.objectId == YAFFS_OBJECTID_ROOT ||
+				     tags.objectId == YAFFS_OBJECTID_LOSTNFOUND)) {
+					/* We only load some info, don't fiddle with directory structure */
+					in->valid = 1;
+					in->variantType = oh->type;
+
+					in->yst_mode = oh->yst_mode;
+#ifdef CONFIG_YAFFS_WINCE
+					in->win_atime[0] = oh->win_atime[0];
+					in->win_ctime[0] = oh->win_ctime[0];
+					in->win_mtime[0] = oh->win_mtime[0];
+					in->win_atime[1] = oh->win_atime[1];
+					in->win_ctime[1] = oh->win_ctime[1];
+					in->win_mtime[1] = oh->win_mtime[1];
+#else
+					in->yst_uid = oh->yst_uid;
+					in->yst_gid = oh->yst_gid;
+					in->yst_atime = oh->yst_atime;
+					in->yst_mtime = oh->yst_mtime;
+					in->yst_ctime = oh->yst_ctime;
+					in->yst_rdev = oh->yst_rdev;
+#endif
+					in->hdrChunk = chunk;
+
+				} else if (!in->valid) {
+					/* we need to load this info */
+
+					in->valid = 1;
+					in->variantType = oh->type;
+
+					in->yst_mode = oh->yst_mode;
+#ifdef CONFIG_YAFFS_WINCE
+					in->win_atime[0] = oh->win_atime[0];
+					in->win_ctime[0] = oh->win_ctime[0];
+					in->win_mtime[0] = oh->win_mtime[0];
+					in->win_atime[1] = oh->win_atime[1];
+					in->win_ctime[1] = oh->win_ctime[1];
+					in->win_mtime[1] = oh->win_mtime[1];
+#else
+					in->yst_uid = oh->yst_uid;
+					in->yst_gid = oh->yst_gid;
+					in->yst_atime = oh->yst_atime;
+					in->yst_mtime = oh->yst_mtime;
+					in->yst_ctime = oh->yst_ctime;
+					in->yst_rdev = oh->yst_rdev;
+#endif
+					in->hdrChunk = chunk;
+
+					yaffs_SetObjectName(in, oh->name);
+					in->dirty = 0;
+
+					/* directory stuff...
+					 * hook up to parent
+					 */
+
+					parent =
+					    yaffs_FindOrCreateObjectByNumber
+					    (dev, oh->parentObjectId,
+					     YAFFS_OBJECT_TYPE_DIRECTORY);
+					if (parent->variantType ==
+					    YAFFS_OBJECT_TYPE_UNKNOWN) {
+						/* Set up as a directory */
+						parent->variantType =
+						    YAFFS_OBJECT_TYPE_DIRECTORY;
+						INIT_LIST_HEAD(&parent->variant.
+							       directoryVariant.
+							       children);
+					} else if (parent->variantType !=
+						   YAFFS_OBJECT_TYPE_DIRECTORY)
+					{
+						/* Hoosterman, another problem....
+						 * We're trying to use a non-directory as a directory
+						 */
+
+						T(YAFFS_TRACE_ERROR,
+						  (TSTR
+						   ("yaffs tragedy: attempting to use non-directory as"
+						    " a directory in scan. Put in lost+found."
+						    TENDSTR)));
+						parent = dev->lostNFoundDir;
+					}
+
+					yaffs_AddObjectToDirectory(parent, in);
+
+					if (0 && (parent == dev->deletedDir ||
+						  parent == dev->unlinkedDir)) {
+						in->deleted = 1;	/* If it is unlinked at start up then it wants deleting */
+						dev->nDeletedFiles++;
+					}
+					/* Note re hardlinks.
+					 * Since we might scan a hardlink before its equivalent object is scanned
+					 * we put them all in a list.
+					 * After scanning is complete, we should have all the objects, so we run through this
+					 * list and fix up all the chains.              
+					 */
+
+					switch (in->variantType) {
+					case YAFFS_OBJECT_TYPE_UNKNOWN:	
+						/* Todo got a problem */
+						break;
+					case YAFFS_OBJECT_TYPE_FILE:
+						if (dev->isYaffs2
+						    && oh->isShrink) {
+							/* Prune back the shrunken chunks */
+							yaffs_PruneResizedChunks
+							    (in, oh->fileSize);
+							/* Mark the block as having a shrinkHeader */
+							bi->hasShrinkHeader = 1;
+						}
+
+						if (dev->useHeaderFileSize)
+
+							in->variant.fileVariant.
+							    fileSize =
+							    oh->fileSize;
+
+						break;
+					case YAFFS_OBJECT_TYPE_HARDLINK:
+						in->variant.hardLinkVariant.
+						    equivalentObjectId =
+						    oh->equivalentObjectId;
+						in->hardLinks.next =
+						    (struct list_head *)
+						    hardList;
+						hardList = in;
+						break;
+					case YAFFS_OBJECT_TYPE_DIRECTORY:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SPECIAL:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SYMLINK:	
+						in->variant.symLinkVariant.
+						    alias =
+						    yaffs_CloneString(oh->alias);
+						break;
+					}
+
+					if (parent == dev->deletedDir) {
+						yaffs_DestroyObject(in);
+						bi->hasShrinkHeader = 1;
+					}
+				}
+			}
+		}
+
+		if (state == YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+			/* If we got this far while scanning, then the block is fully allocated.*/
+			state = YAFFS_BLOCK_STATE_FULL;
+		}
+
+		bi->blockState = state;
+
+		/* Now let's see if it was dirty */
+		if (bi->pagesInUse == 0 &&
+		    !bi->hasShrinkHeader &&
+		    bi->blockState == YAFFS_BLOCK_STATE_FULL) {
+			yaffs_BlockBecameDirty(dev, blk);
+		}
+
+	}
+
+	if (blockIndex) {
+		YFREE(blockIndex);
+	}
+	
+	
+	/* Ok, we've done all the scanning.
+	 * Fix up the hard link chains.
+	 * We should now have scanned all the objects, now it's time to add these 
+	 * hardlinks.
+	 */
+
+	yaffs_HardlinkFixup(dev,hardList);
+
+	/* Handle the unlinked files. Since they were left in an unlinked state we should
+	 * just delete them.
+	 */
+	{
+		struct list_head *i;
+		struct list_head *n;
+
+		yaffs_Object *l;
+		/* Soft delete all the unlinked files */
+		list_for_each_safe(i, n,
+				   &dev->unlinkedDir->variant.directoryVariant.
+				   children) {
+			if (i) {
+				l = list_entry(i, yaffs_Object, siblings);
+				yaffs_DestroyObject(l);
+			}
+		}
+	}
+
+	yaffs_ReleaseTempBuffer(dev, chunkData, __LINE__);
+
+	T(YAFFS_TRACE_SCAN, (TSTR("yaffs_Scan ends" TENDSTR)));
+
+	return YAFFS_OK;
+}
+
+static void yaffs_CheckObjectDetailsLoaded(yaffs_Object *in)
+{
+	__u8 *chunkData;
+	yaffs_ObjectHeader *oh;
+	yaffs_Device *dev = in->myDev;
+	
+	if(in->lazyLoaded && in->hdrChunk > 0){
+		in->lazyLoaded = 0;
+		chunkData = yaffs_GetTempBuffer(dev, __LINE__);
+
+		yaffs_ReadChunkWithTagsFromNAND(dev,in->hdrChunk,chunkData,NULL);
+		oh = (yaffs_ObjectHeader *) chunkData;		
+
+		in->yst_mode = oh->yst_mode;
+#ifdef CONFIG_YAFFS_WINCE
+		in->win_atime[0] = oh->win_atime[0];
+		in->win_ctime[0] = oh->win_ctime[0];
+		in->win_mtime[0] = oh->win_mtime[0];
+		in->win_atime[1] = oh->win_atime[1];
+		in->win_ctime[1] = oh->win_ctime[1];
+		in->win_mtime[1] = oh->win_mtime[1];
+#else
+		in->yst_uid = oh->yst_uid;
+		in->yst_gid = oh->yst_gid;
+		in->yst_atime = oh->yst_atime;
+		in->yst_mtime = oh->yst_mtime;
+		in->yst_ctime = oh->yst_ctime;
+		in->yst_rdev = oh->yst_rdev;
+		
+#endif
+		yaffs_SetObjectName(in, oh->name);
+		
+		if(in->variantType == YAFFS_OBJECT_TYPE_SYMLINK)
+			 in->variant.symLinkVariant.alias =
+						    yaffs_CloneString(oh->alias);
+						    
+		yaffs_ReleaseTempBuffer(dev,chunkData, __LINE__);
+	}
+}
+
+static int yaffs_ScanBackwards(yaffs_Device * dev)
+{
+	yaffs_ExtendedTags tags;
+	int blk;
+	int blockIterator;
+	int startIterator;
+	int endIterator;
+	int nBlocksToScan = 0;
+
+	int chunk;
+	int c;
+	int deleted;
+	yaffs_BlockState state;
+	yaffs_Object *hardList = NULL;
+	yaffs_BlockInfo *bi;
+	int sequenceNumber;
+	yaffs_ObjectHeader *oh;
+	yaffs_Object *in;
+	yaffs_Object *parent;
+	int nBlocks = dev->internalEndBlock - dev->internalStartBlock + 1;
+	int itsUnlinked;
+	__u8 *chunkData;
+	
+	int fileSize;
+	int isShrink;
+	int equivalentObjectId;
+	
+
+	yaffs_BlockIndex *blockIndex = NULL;
+	int altBlockIndex = 0;
+
+	if (!dev->isYaffs2) {
+		T(YAFFS_TRACE_SCAN,
+		  (TSTR("yaffs_ScanBackwards is only for YAFFS2!" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	T(YAFFS_TRACE_SCAN,
+	  (TSTR
+	   ("yaffs_ScanBackwards starts  intstartblk %d intendblk %d..."
+	    TENDSTR), dev->internalStartBlock, dev->internalEndBlock));
+
+
+	dev->sequenceNumber = YAFFS_LOWEST_SEQUENCE_NUMBER;
+
+	blockIndex = YMALLOC(nBlocks * sizeof(yaffs_BlockIndex));
+	
+	if(!blockIndex) {
+		blockIndex = YMALLOC_ALT(nBlocks * sizeof(yaffs_BlockIndex));
+		altBlockIndex = 1;
+	}
+	
+	if(!blockIndex) {
+		T(YAFFS_TRACE_SCAN,
+		  (TSTR("yaffs_Scan() could not allocate block index!" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+	
+	chunkData = yaffs_GetTempBuffer(dev, __LINE__);
+
+	/* Scan all the blocks to determine their state */
+	for (blk = dev->internalStartBlock; blk <= dev->internalEndBlock; blk++) {
+		bi = yaffs_GetBlockInfo(dev, blk);
+		yaffs_ClearChunkBits(dev, blk);
+		bi->pagesInUse = 0;
+		bi->softDeletions = 0;
+
+		yaffs_QueryInitialBlockState(dev, blk, &state, &sequenceNumber);
+
+		bi->blockState = state;
+		bi->sequenceNumber = sequenceNumber;
+
+		if(bi->sequenceNumber == YAFFS_SEQUENCE_CHECKPOINT_DATA)
+			bi->blockState = state = YAFFS_BLOCK_STATE_CHECKPOINT;
+			
+		T(YAFFS_TRACE_SCAN_DEBUG,
+		  (TSTR("Block scanning block %d state %d seq %d" TENDSTR), blk,
+		   state, sequenceNumber));
+
+		
+		if(state == YAFFS_BLOCK_STATE_CHECKPOINT){
+			/* todo .. fix free space ? */
+			
+		} else if (state == YAFFS_BLOCK_STATE_DEAD) {
+			T(YAFFS_TRACE_BAD_BLOCKS,
+			  (TSTR("block %d is bad" TENDSTR), blk));
+		} else if (state == YAFFS_BLOCK_STATE_EMPTY) {
+			T(YAFFS_TRACE_SCAN_DEBUG,
+			  (TSTR("Block empty " TENDSTR)));
+			dev->nErasedBlocks++;
+			dev->nFreeChunks += dev->nChunksPerBlock;
+		} else if (state == YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+
+			/* Determine the highest sequence number */
+			if (dev->isYaffs2 &&
+			    sequenceNumber >= YAFFS_LOWEST_SEQUENCE_NUMBER &&
+			    sequenceNumber < YAFFS_HIGHEST_SEQUENCE_NUMBER) {
+
+				blockIndex[nBlocksToScan].seq = sequenceNumber;
+				blockIndex[nBlocksToScan].block = blk;
+
+				nBlocksToScan++;
+
+				if (sequenceNumber >= dev->sequenceNumber) {
+					dev->sequenceNumber = sequenceNumber;
+				}
+			} else if (dev->isYaffs2) {
+				/* TODO: Nasty sequence number! */
+				T(YAFFS_TRACE_SCAN,
+				  (TSTR
+				   ("Block scanning block %d has bad sequence number %d"
+				    TENDSTR), blk, sequenceNumber));
+
+			}
+		}
+	}
+
+	T(YAFFS_TRACE_SCAN,
+	(TSTR("%d blocks to be sorted..." TENDSTR), nBlocksToScan));
+
+
+
+	YYIELD();
+
+	/* Sort the blocks */
+#ifndef CONFIG_YAFFS_USE_OWN_SORT
+	{
+		/* Use qsort now. */
+		qsort(blockIndex, nBlocksToScan, sizeof(yaffs_BlockIndex), ybicmp);
+	}
+#else
+	{
+	 	/* Dungy old bubble sort... */
+	 	
+		yaffs_BlockIndex temp;
+		int i;
+		int j;
+
+		for (i = 0; i < nBlocksToScan; i++)
+			for (j = i + 1; j < nBlocksToScan; j++)
+				if (blockIndex[i].seq > blockIndex[j].seq) {
+					temp = blockIndex[j];
+					blockIndex[j] = blockIndex[i];
+					blockIndex[i] = temp;
+				}
+	}
+#endif
+
+	YYIELD();
+
+    	T(YAFFS_TRACE_SCAN, (TSTR("...done" TENDSTR)));
+
+	/* Now scan the blocks looking at the data. */
+	startIterator = 0;
+	endIterator = nBlocksToScan - 1;
+	T(YAFFS_TRACE_SCAN_DEBUG,
+	  (TSTR("%d blocks to be scanned" TENDSTR), nBlocksToScan));
+
+	/* For each block.... backwards */
+	for (blockIterator = endIterator; blockIterator >= startIterator;
+	     blockIterator--) {
+	        /* Cooperative multitasking! This loop can run for so
+		   long that watchdog timers expire. */
+	        YYIELD();
+
+		/* get the block to scan in the correct order */
+		blk = blockIndex[blockIterator].block;
+
+		bi = yaffs_GetBlockInfo(dev, blk);
+		state = bi->blockState;
+
+		deleted = 0;
+
+		/* For each chunk in each block that needs scanning.... */
+		for (c = dev->nChunksPerBlock - 1; c >= 0 &&
+		     (state == YAFFS_BLOCK_STATE_NEEDS_SCANNING ||
+		      state == YAFFS_BLOCK_STATE_ALLOCATING); c--) {
+			/* Scan backwards... 
+			 * Read the tags and decide what to do
+			 */
+			chunk = blk * dev->nChunksPerBlock + c;
+
+			yaffs_ReadChunkWithTagsFromNAND(dev, chunk, NULL,
+							&tags);
+
+			/* Let's have a good look at this chunk... */
+
+			if (!tags.chunkUsed) {
+				// An unassigned chunk in the block
+				// This means that either the block is empty or 
+				// this is the one being allocated from
+
+				if (c == 0) {
+					/* We're looking at the first chunk in the block so the block is unused */
+					state = YAFFS_BLOCK_STATE_EMPTY;
+					dev->nErasedBlocks++;
+				} else {
+					/* this is the block being allocated from */
+					if (state ==
+					    YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+						T(YAFFS_TRACE_SCAN,
+						  (TSTR
+						   (" Allocating from %d %d"
+						    TENDSTR), blk, c));
+					}
+					state = YAFFS_BLOCK_STATE_ALLOCATING;
+					dev->allocationBlock = blk;
+					dev->allocationPage = c;
+					dev->allocationBlockFinder = blk;	
+					/* Set it to here to encourage the allocator to 
+					 *  go forth from here.
+					 */
+					 
+					/* Yaffs2 sanity check:
+					 * This should be the one with the highest sequence number
+					 */
+					if (dev->isYaffs2
+					    && (dev->sequenceNumber !=
+						bi->sequenceNumber)) {
+						T(YAFFS_TRACE_ALWAYS,
+						  (TSTR
+						   ("yaffs: Allocation block %d was not highest sequence "
+						    "id: block seq = %d, dev seq = %d"
+						    TENDSTR), blk,
+						   bi->sequenceNumber,
+						   dev->sequenceNumber));
+					}
+				}
+
+				dev->nFreeChunks++;
+			} else if (tags.chunkId > 0) {
+				/* chunkId > 0 so it is a data chunk... */
+				unsigned int endpos;
+
+				__u32 chunkBase =
+				    (tags.chunkId - 1) * dev->nBytesPerChunk;
+
+				yaffs_SetChunkBit(dev, blk, c);
+				bi->pagesInUse++;
+
+				in = yaffs_FindOrCreateObjectByNumber(dev,
+								      tags.
+								      objectId,
+								      YAFFS_OBJECT_TYPE_FILE);
+				if (in->variantType == YAFFS_OBJECT_TYPE_FILE
+				    && chunkBase <
+				    in->variant.fileVariant.shrinkSize) {
+					/* This has not been invalidated by a resize */
+					yaffs_PutChunkIntoFile(in, tags.chunkId,
+							       chunk, -1);
+
+					/* File size is calculated by looking at the data chunks if we have not 
+					 * seen an object header yet. Stop this practice once we find an object header.
+					 */
+					endpos =
+					    (tags.chunkId -
+					     1) * dev->nBytesPerChunk +
+					    tags.byteCount;
+					    
+					if (!in->valid &&	/* have not got an object header yet */
+					    in->variant.fileVariant.
+					    scannedFileSize < endpos) {
+						in->variant.fileVariant.
+						    scannedFileSize = endpos;
+						in->variant.fileVariant.
+						    fileSize =
+						    in->variant.fileVariant.
+						    scannedFileSize;
+					}
+
+				} else {
+					/* This chunk has been invalidated by a resize, so delete */
+					yaffs_DeleteChunk(dev, chunk, 1, __LINE__);
+
+				}
+			} else {
+				/* chunkId == 0, so it is an ObjectHeader.
+				 * Thus, we read in the object header and make the object
+				 */
+				yaffs_SetChunkBit(dev, blk, c);
+				bi->pagesInUse++;
+
+				oh = NULL;
+				in = NULL;
+
+				if (tags.extraHeaderInfoAvailable) {
+					in = yaffs_FindOrCreateObjectByNumber
+					    (dev, tags.objectId,
+					     tags.extraObjectType);
+				}
+
+				if (!in ||
+#ifdef CONFIG_YAFFS_DISABLE_LAZY_LOAD
+				    !in->valid ||
+#endif
+				    tags.extraShadows ||
+				    (!in->valid &&
+				    (tags.objectId == YAFFS_OBJECTID_ROOT ||
+				     tags.objectId == YAFFS_OBJECTID_LOSTNFOUND))
+				    ) {
+
+					/* If we don't have  valid info then we need to read the chunk
+					 * TODO In future we can probably defer reading the chunk and 
+					 * living with invalid data until needed.
+					 */
+
+					yaffs_ReadChunkWithTagsFromNAND(dev,
+									chunk,
+									chunkData,
+									NULL);
+
+					oh = (yaffs_ObjectHeader *) chunkData;
+
+					if (!in)
+						in = yaffs_FindOrCreateObjectByNumber(dev, tags.objectId, oh->type);
+
+				}
+
+				if (!in) {
+					/* TODO Hoosterman we have a problem! */
+					T(YAFFS_TRACE_ERROR,
+					  (TSTR
+					   ("yaffs tragedy: Could not make object for object  %d  "
+					    "at chunk %d during scan"
+					    TENDSTR), tags.objectId, chunk));
+
+				}
+
+				if (in->valid) {
+					/* We have already filled this one.
+					 * We have a duplicate that will be discarded, but 
+					 * we first have to suck out resize info if it is a file.
+					 */
+
+					if ((in->variantType == YAFFS_OBJECT_TYPE_FILE) && 
+					     ((oh && 
+					       oh-> type == YAFFS_OBJECT_TYPE_FILE)||
+					      (tags.extraHeaderInfoAvailable  &&
+					       tags.extraObjectType == YAFFS_OBJECT_TYPE_FILE))
+					    ) {
+						__u32 thisSize =
+						    (oh) ? oh->fileSize : tags.
+						    extraFileLength;
+						__u32 parentObjectId =
+						    (oh) ? oh->
+						    parentObjectId : tags.
+						    extraParentObjectId;
+						unsigned isShrink =
+						    (oh) ? oh->isShrink : tags.
+						    extraIsShrinkHeader;
+
+						/* If it is deleted (unlinked at start also means deleted)
+						 * we treat the file size as being zeroed at this point.
+						 */
+						if (parentObjectId ==
+						    YAFFS_OBJECTID_DELETED
+						    || parentObjectId ==
+						    YAFFS_OBJECTID_UNLINKED) {
+							thisSize = 0;
+							isShrink = 1;
+						}
+
+						if (isShrink &&
+						    in->variant.fileVariant.
+						    shrinkSize > thisSize) {
+							in->variant.fileVariant.
+							    shrinkSize =
+							    thisSize;
+						}
+
+						if (isShrink) {
+							bi->hasShrinkHeader = 1;
+						}
+
+					}
+					/* Use existing - destroy this one. */
+					yaffs_DeleteChunk(dev, chunk, 1, __LINE__);
+
+				}
+
+				if (!in->valid &&
+				    (tags.objectId == YAFFS_OBJECTID_ROOT ||
+				     tags.objectId ==
+				     YAFFS_OBJECTID_LOSTNFOUND)) {
+					/* We only load some info, don't fiddle with directory structure */
+					in->valid = 1;
+					
+					if(oh) {
+						in->variantType = oh->type;
+
+						in->yst_mode = oh->yst_mode;
+#ifdef CONFIG_YAFFS_WINCE
+						in->win_atime[0] = oh->win_atime[0];
+						in->win_ctime[0] = oh->win_ctime[0];
+						in->win_mtime[0] = oh->win_mtime[0];
+						in->win_atime[1] = oh->win_atime[1];
+						in->win_ctime[1] = oh->win_ctime[1];
+						in->win_mtime[1] = oh->win_mtime[1];
+#else
+						in->yst_uid = oh->yst_uid;
+						in->yst_gid = oh->yst_gid;
+						in->yst_atime = oh->yst_atime;
+						in->yst_mtime = oh->yst_mtime;
+						in->yst_ctime = oh->yst_ctime;
+						in->yst_rdev = oh->yst_rdev;
+		
+#endif
+					} else {
+						in->variantType = tags.extraObjectType;
+						in->lazyLoaded = 1;
+					}
+						
+					in->hdrChunk = chunk;
+
+				} else if (!in->valid) {
+					/* we need to load this info */
+
+					in->valid = 1;
+					in->hdrChunk = chunk;
+					
+					if(oh) {
+						in->variantType = oh->type;
+
+						in->yst_mode = oh->yst_mode;
+#ifdef CONFIG_YAFFS_WINCE
+						in->win_atime[0] = oh->win_atime[0];
+						in->win_ctime[0] = oh->win_ctime[0];
+						in->win_mtime[0] = oh->win_mtime[0];
+						in->win_atime[1] = oh->win_atime[1];
+						in->win_ctime[1] = oh->win_ctime[1];
+						in->win_mtime[1] = oh->win_mtime[1];
+#else
+						in->yst_uid = oh->yst_uid;
+						in->yst_gid = oh->yst_gid;
+						in->yst_atime = oh->yst_atime;
+						in->yst_mtime = oh->yst_mtime;
+						in->yst_ctime = oh->yst_ctime;
+						in->yst_rdev = oh->yst_rdev;
+#endif
+
+						if (oh->shadowsObject > 0) 
+							yaffs_HandleShadowedObject(dev,
+									   oh->
+									   shadowsObject,
+									   1);
+					
+
+						yaffs_SetObjectName(in, oh->name);
+						parent =
+						    yaffs_FindOrCreateObjectByNumber
+					    		(dev, oh->parentObjectId,
+					     		 YAFFS_OBJECT_TYPE_DIRECTORY);
+
+						 fileSize = oh->fileSize;
+ 						 isShrink = oh->isShrink;
+						 equivalentObjectId = oh->equivalentObjectId;
+
+					}
+					else {
+						in->variantType = tags.extraObjectType;
+						parent =
+						    yaffs_FindOrCreateObjectByNumber
+					    		(dev, tags.extraParentObjectId,
+					     		 YAFFS_OBJECT_TYPE_DIRECTORY);
+						 fileSize = tags.extraFileLength;
+						 isShrink = tags.extraIsShrinkHeader;
+						 equivalentObjectId = tags.extraEquivalentObjectId;
+						in->lazyLoaded = 1;
+
+					}
+					in->dirty = 0;
+
+					/* directory stuff...
+					 * hook up to parent
+					 */
+
+					if (parent->variantType ==
+					    YAFFS_OBJECT_TYPE_UNKNOWN) {
+						/* Set up as a directory */
+						parent->variantType =
+						    YAFFS_OBJECT_TYPE_DIRECTORY;
+						INIT_LIST_HEAD(&parent->variant.
+							       directoryVariant.
+							       children);
+					} else if (parent->variantType !=
+						   YAFFS_OBJECT_TYPE_DIRECTORY)
+					{
+						/* Hoosterman, another problem....
+						 * We're trying to use a non-directory as a directory
+						 */
+
+						T(YAFFS_TRACE_ERROR,
+						  (TSTR
+						   ("yaffs tragedy: attempting to use non-directory as"
+						    " a directory in scan. Put in lost+found."
+						    TENDSTR)));
+						parent = dev->lostNFoundDir;
+					}
+
+					yaffs_AddObjectToDirectory(parent, in);
+
+					itsUnlinked = (parent == dev->deletedDir) ||
+						      (parent == dev->unlinkedDir);
+
+					if (isShrink) {
+						/* Mark the block as having a shrinkHeader */
+						bi->hasShrinkHeader = 1;
+					}
+
+					/* Note re hardlinks.
+					 * Since we might scan a hardlink before its equivalent object is scanned
+					 * we put them all in a list.
+					 * After scanning is complete, we should have all the objects, so we run
+					 * through this list and fix up all the chains.              
+					 */
+
+					switch (in->variantType) {
+					case YAFFS_OBJECT_TYPE_UNKNOWN:	
+						/* Todo got a problem */
+						break;
+					case YAFFS_OBJECT_TYPE_FILE:
+
+						if (in->variant.fileVariant.
+						    scannedFileSize < fileSize) {
+							/* This covers the case where the file size is greater
+							 * than where the data is
+							 * This will happen if the file is resized to be larger 
+							 * than its current data extents.
+							 */
+							in->variant.fileVariant.fileSize = fileSize;
+							in->variant.fileVariant.scannedFileSize =
+							    in->variant.fileVariant.fileSize;
+						}
+
+						if (isShrink &&
+						    in->variant.fileVariant.shrinkSize > fileSize) {
+							in->variant.fileVariant.shrinkSize = fileSize;
+						}
+
+						break;
+					case YAFFS_OBJECT_TYPE_HARDLINK:
+						if(!itsUnlinked) {
+						  in->variant.hardLinkVariant.equivalentObjectId =
+						    equivalentObjectId;
+						  in->hardLinks.next =
+						    (struct list_head *) hardList;
+						  hardList = in;
+						}
+						break;
+					case YAFFS_OBJECT_TYPE_DIRECTORY:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SPECIAL:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SYMLINK:
+						if(oh)
+						   in->variant.symLinkVariant.alias =
+						    yaffs_CloneString(oh->
+								      alias);
+						break;
+					}
+
+				}
+			}
+		}
+
+		if (state == YAFFS_BLOCK_STATE_NEEDS_SCANNING) {
+			/* If we got this far while scanning, then the block is fully allocated. */
+			state = YAFFS_BLOCK_STATE_FULL;
+		}
+
+		bi->blockState = state;
+
+		/* Now let's see if it was dirty */
+		if (bi->pagesInUse == 0 &&
+		    !bi->hasShrinkHeader &&
+		    bi->blockState == YAFFS_BLOCK_STATE_FULL) {
+			yaffs_BlockBecameDirty(dev, blk);
+		}
+
+	}
+
+	if (altBlockIndex) 
+		YFREE_ALT(blockIndex);
+	else
+		YFREE(blockIndex);
+	
+	/* Ok, we've done all the scanning.
+	 * Fix up the hard link chains.
+	 * We should now have scanned all the objects, now it's time to add these 
+	 * hardlinks.
+	 */
+	yaffs_HardlinkFixup(dev,hardList);
+	
+	
+	/*
+	*  Sort out state of unlinked and deleted objects.
+	*/
+	{
+		struct list_head *i;
+		struct list_head *n;
+
+		yaffs_Object *l;
+
+		/* Soft delete all the unlinked files */
+		list_for_each_safe(i, n,
+				   &dev->unlinkedDir->variant.directoryVariant.
+				   children) {
+			if (i) {
+				l = list_entry(i, yaffs_Object, siblings);
+				yaffs_DestroyObject(l);
+			}
+		}
+
+		/* Soft delete all the deletedDir files */
+		list_for_each_safe(i, n,
+				   &dev->deletedDir->variant.directoryVariant.
+				   children) {
+			if (i) {
+				l = list_entry(i, yaffs_Object, siblings);
+				yaffs_DestroyObject(l);
+
+			}
+		}
+	}
+
+	yaffs_ReleaseTempBuffer(dev, chunkData, __LINE__);
+
+	T(YAFFS_TRACE_SCAN, (TSTR("yaffs_ScanBackwards ends" TENDSTR)));
+
+	return YAFFS_OK;
+}
+
+/*------------------------------  Directory Functions ----------------------------- */
+
+static void yaffs_RemoveObjectFromDirectory(yaffs_Object * obj)
+{
+	yaffs_Device *dev = obj->myDev;
+	
+	if(dev && dev->removeObjectCallback)
+		dev->removeObjectCallback(obj);
+	   
+	list_del_init(&obj->siblings);
+	obj->parent = NULL;
+}
+
+
+static void yaffs_AddObjectToDirectory(yaffs_Object * directory,
+				       yaffs_Object * obj)
+{
+
+	if (!directory) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: Trying to add an object to a null pointer directory"
+		    TENDSTR)));
+		YBUG();
+	}
+	if (directory->variantType != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: Trying to add an object to a non-directory"
+		    TENDSTR)));
+		YBUG();
+	}
+
+	if (obj->siblings.prev == NULL) {
+		/* Not initialised */
+		INIT_LIST_HEAD(&obj->siblings);
+
+	} else if (!list_empty(&obj->siblings)) {
+		/* If it is holed up somewhere else, un hook it */
+		yaffs_RemoveObjectFromDirectory(obj);
+	}
+	/* Now add it */
+	list_add(&obj->siblings, &directory->variant.directoryVariant.children);
+	obj->parent = directory;
+
+	if (directory == obj->myDev->unlinkedDir
+	    || directory == obj->myDev->deletedDir) {
+		obj->unlinked = 1;
+		obj->myDev->nUnlinkedFiles++;
+		obj->renameAllowed = 0;
+	}
+}
+
+yaffs_Object *yaffs_FindObjectByName(yaffs_Object * directory,
+				     const YCHAR * name)
+{
+	int sum;
+
+	struct list_head *i;
+	YCHAR buffer[YAFFS_MAX_NAME_LENGTH + 1];
+
+	yaffs_Object *l;
+
+	if (!name) {
+		return NULL;
+	}
+
+	if (!directory) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: yaffs_FindObjectByName: null pointer directory"
+		    TENDSTR)));
+		YBUG();
+	}
+	if (directory->variantType != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: yaffs_FindObjectByName: non-directory" TENDSTR)));
+		YBUG();
+	}
+
+	sum = yaffs_CalcNameSum(name);
+
+	list_for_each(i, &directory->variant.directoryVariant.children) {
+		if (i) {
+			l = list_entry(i, yaffs_Object, siblings);
+			
+			yaffs_CheckObjectDetailsLoaded(l);
+
+			/* Special case for lost-n-found */
+			if (l->objectId == YAFFS_OBJECTID_LOSTNFOUND) {
+				if (yaffs_strcmp(name, YAFFS_LOSTNFOUND_NAME) == 0) {
+					return l;
+				}
+			} else if (yaffs_SumCompare(l->sum, sum) || l->hdrChunk <= 0)	
+			{
+				/* LostnFound cunk called Objxxx
+				 * Do a real check
+				 */
+				yaffs_GetObjectName(l, buffer,
+						    YAFFS_MAX_NAME_LENGTH);
+				if (yaffs_strcmp(name, buffer) == 0) {
+					return l;
+				}
+
+			}
+		}
+	}
+
+	return NULL;
+}
+
+
+#if 0
+int yaffs_ApplyToDirectoryChildren(yaffs_Object * theDir,
+				   int (*fn) (yaffs_Object *))
+{
+	struct list_head *i;
+	yaffs_Object *l;
+
+	if (!theDir) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: yaffs_FindObjectByName: null pointer directory"
+		    TENDSTR)));
+		YBUG();
+	}
+	if (theDir->variantType != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("tragedy: yaffs_FindObjectByName: non-directory" TENDSTR)));
+		YBUG();
+	}
+
+	list_for_each(i, &theDir->variant.directoryVariant.children) {
+		if (i) {
+			l = list_entry(i, yaffs_Object, siblings);
+			if (l && !fn(l)) {
+				return YAFFS_FAIL;
+			}
+		}
+	}
+
+	return YAFFS_OK;
+
+}
+#endif
+
+/* GetEquivalentObject dereferences any hard links to get to the
+ * actual object.
+ */
+
+yaffs_Object *yaffs_GetEquivalentObject(yaffs_Object * obj)
+{
+	if (obj && obj->variantType == YAFFS_OBJECT_TYPE_HARDLINK) {
+		/* We want the object id of the equivalent object, not this one */
+		obj = obj->variant.hardLinkVariant.equivalentObject;
+	}
+	return obj;
+
+}
+
+int yaffs_GetObjectName(yaffs_Object * obj, YCHAR * name, int buffSize)
+{
+	memset(name, 0, buffSize * sizeof(YCHAR));
+	
+	yaffs_CheckObjectDetailsLoaded(obj);
+
+	if (obj->objectId == YAFFS_OBJECTID_LOSTNFOUND) {
+		yaffs_strncpy(name, YAFFS_LOSTNFOUND_NAME, buffSize - 1);
+	} else if (obj->hdrChunk <= 0) {
+		YCHAR locName[20];
+		/* make up a name */
+		yaffs_sprintf(locName, _Y("%s%d"), YAFFS_LOSTNFOUND_PREFIX,
+			      obj->objectId);
+		yaffs_strncpy(name, locName, buffSize - 1);
+
+	}
+#ifdef CONFIG_YAFFS_SHORT_NAMES_IN_RAM
+	else if (obj->shortName[0]) {
+		yaffs_strcpy(name, obj->shortName);
+	}
+#endif
+	else {
+		__u8 *buffer = yaffs_GetTempBuffer(obj->myDev, __LINE__);
+
+		yaffs_ObjectHeader *oh = (yaffs_ObjectHeader *) buffer;
+
+		memset(buffer, 0, obj->myDev->nBytesPerChunk);
+
+		if (obj->hdrChunk > 0) {
+			yaffs_ReadChunkWithTagsFromNAND(obj->myDev,
+							obj->hdrChunk, buffer,
+							NULL);
+		}
+		yaffs_strncpy(name, oh->name, buffSize - 1);
+
+		yaffs_ReleaseTempBuffer(obj->myDev, buffer, __LINE__);
+	}
+
+	return yaffs_strlen(name);
+}
+
+int yaffs_GetObjectFileLength(yaffs_Object * obj)
+{
+
+	/* Dereference any hard linking */
+	obj = yaffs_GetEquivalentObject(obj);
+
+	if (obj->variantType == YAFFS_OBJECT_TYPE_FILE) {
+		return obj->variant.fileVariant.fileSize;
+	}
+	if (obj->variantType == YAFFS_OBJECT_TYPE_SYMLINK) {
+		return yaffs_strlen(obj->variant.symLinkVariant.alias);
+	} else {
+		/* Only a directory should drop through to here */
+		return obj->myDev->nBytesPerChunk;
+	}
+}
+
+int yaffs_GetObjectLinkCount(yaffs_Object * obj)
+{
+	int count = 0;
+	struct list_head *i;
+
+	if (!obj->unlinked) {
+		count++;	/* the object itself */
+	}
+	list_for_each(i, &obj->hardLinks) {
+		count++;	/* add the hard links; */
+	}
+	return count;
+
+}
+
+int yaffs_GetObjectInode(yaffs_Object * obj)
+{
+	obj = yaffs_GetEquivalentObject(obj);
+
+	return obj->objectId;
+}
+
+unsigned yaffs_GetObjectType(yaffs_Object * obj)
+{
+	obj = yaffs_GetEquivalentObject(obj);
+
+	switch (obj->variantType) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		return DT_REG;
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		return DT_DIR;
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		return DT_LNK;
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		return DT_REG;
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		if (S_ISFIFO(obj->yst_mode))
+			return DT_FIFO;
+		if (S_ISCHR(obj->yst_mode))
+			return DT_CHR;
+		if (S_ISBLK(obj->yst_mode))
+			return DT_BLK;
+		if (S_ISSOCK(obj->yst_mode))
+			return DT_SOCK;
+	default:
+		return DT_REG;
+		break;
+	}
+}
+
+YCHAR *yaffs_GetSymlinkAlias(yaffs_Object * obj)
+{
+	obj = yaffs_GetEquivalentObject(obj);
+	if (obj->variantType == YAFFS_OBJECT_TYPE_SYMLINK) {
+		return yaffs_CloneString(obj->variant.symLinkVariant.alias);
+	} else {
+		return yaffs_CloneString(_Y(""));
+	}
+}
+
+#ifndef CONFIG_YAFFS_WINCE
+
+int yaffs_SetAttributes(yaffs_Object * obj, struct iattr *attr)
+{
+	unsigned int valid = attr->ia_valid;
+
+	if (valid & ATTR_MODE)
+		obj->yst_mode = attr->ia_mode;
+	if (valid & ATTR_UID)
+		obj->yst_uid = attr->ia_uid;
+	if (valid & ATTR_GID)
+		obj->yst_gid = attr->ia_gid;
+
+	if (valid & ATTR_ATIME)
+		obj->yst_atime = Y_TIME_CONVERT(attr->ia_atime);
+	if (valid & ATTR_CTIME)
+		obj->yst_ctime = Y_TIME_CONVERT(attr->ia_ctime);
+	if (valid & ATTR_MTIME)
+		obj->yst_mtime = Y_TIME_CONVERT(attr->ia_mtime);
+
+	if (valid & ATTR_SIZE)
+		yaffs_ResizeFile(obj, attr->ia_size);
+
+	yaffs_UpdateObjectHeader(obj, NULL, 1, 0, 0);
+
+	return YAFFS_OK;
+
+}
+int yaffs_GetAttributes(yaffs_Object * obj, struct iattr *attr)
+{
+	unsigned int valid = 0;
+
+	attr->ia_mode = obj->yst_mode;
+	valid |= ATTR_MODE;
+	attr->ia_uid = obj->yst_uid;
+	valid |= ATTR_UID;
+	attr->ia_gid = obj->yst_gid;
+	valid |= ATTR_GID;
+
+	Y_TIME_CONVERT(attr->ia_atime) = obj->yst_atime;
+	valid |= ATTR_ATIME;
+	Y_TIME_CONVERT(attr->ia_ctime) = obj->yst_ctime;
+	valid |= ATTR_CTIME;
+	Y_TIME_CONVERT(attr->ia_mtime) = obj->yst_mtime;
+	valid |= ATTR_MTIME;
+
+	attr->ia_size = yaffs_GetFileSize(obj);
+	valid |= ATTR_SIZE;
+
+	attr->ia_valid = valid;
+
+	return YAFFS_OK;
+
+}
+
+#endif
+
+#if 0
+int yaffs_DumpObject(yaffs_Object * obj)
+{
+	YCHAR name[257];
+
+	yaffs_GetObjectName(obj, name, 256);
+
+	T(YAFFS_TRACE_ALWAYS,
+	  (TSTR
+	   ("Object %d, inode %d \"%s\"\n dirty %d valid %d serial %d sum %d"
+	    " chunk %d type %d size %d\n"
+	    TENDSTR), obj->objectId, yaffs_GetObjectInode(obj), name,
+	   obj->dirty, obj->valid, obj->serial, obj->sum, obj->chunkId,
+	   yaffs_GetObjectType(obj), yaffs_GetObjectFileLength(obj)));
+
+	return YAFFS_OK;
+}
+#endif
+
+#ifdef MIPSEL
+/* ----------------- dealing with bad NANDs, which need refresh ------------- */
+
+static int yaffs_FindBlockForRefresh(yaffs_Device *dev)
+{
+	int block = dev->allocationBlockFinder;
+	int i;
+
+	for (i = dev->internalStartBlock; i <= dev->internalEndBlock; i++) {
+		yaffs_BlockInfo *bi;
+
+		block++;
+		if (block < dev->internalStartBlock ||
+		    block > dev->internalEndBlock) {
+			block = dev->internalStartBlock;
+		}
+
+		bi = yaffs_GetBlockInfo(dev, block);
+
+		if (bi->blockState == YAFFS_BLOCK_STATE_FULL)
+			return block;
+	}
+	return -1;
+}
+
+static int yaffs_tryEnableBackup(yaffs_Device *dev) {
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+	const int blocksLess = 512;
+	int newEndBlock;
+	int block;
+	int emptyBlocks = 0;
+
+	if (dev->internalEndBlock != 992) return 0;
+	newEndBlock = dev->internalEndBlock - blocksLess;
+
+	if (dev->allocationBlock > newEndBlock ||
+	    dev->allocationBlockFinder > newEndBlock) {
+		return 0;
+	}
+	if (dev->nFreeChunks < (blocksLess + 112) * dev->nChunksPerBlock) {
+		printk(KERN_INFO "yaffs_truncate failed - "
+		       "not enough free space\n");
+		return 0;
+	}
+
+	for (block = newEndBlock + 1; block <= dev->internalEndBlock; block++) {
+		yaffs_BlockInfo *bi = yaffs_GetBlockInfo(dev, block);
+
+		if (bi->blockState == YAFFS_BLOCK_STATE_EMPTY) {
+			++emptyBlocks;
+		}
+		else if (bi->blockState != YAFFS_BLOCK_STATE_DEAD) {
+			printk(KERN_INFO "yaffs_truncate failed - "
+			       "block %u is not empty\n", block);
+			return 0;
+		}
+	}
+
+	if (!nand_enable_backup(mtd)) {
+		return 0;
+	}
+
+	dev->endBlock -= blocksLess;
+	dev->internalEndBlock -= blocksLess;
+	dev->nErasedBlocks -= emptyBlocks;
+	dev->nFreeChunks -= emptyBlocks * dev->nChunksPerBlock;
+
+	printk(KERN_INFO "yaffs_truncate - reduced size by %u blocks\n",
+	       blocksLess);
+	return 1;
+}
+
+int yaffs_RefreshOneBlock(yaffs_Device *dev)
+{
+	unsigned long js;
+	int blocksLeft;
+	int block;
+
+	block = yaffs_FindBlockForRefresh(dev);
+	if (block < 0)
+		return dev->internalEndBlock - dev->internalStartBlock;
+
+	blocksLeft = dev->allocationBlockFinder - block;
+	if (blocksLeft < 0) {
+		blocksLeft = (dev->internalEndBlock -
+			      dev->internalStartBlock + 1 +
+			      blocksLeft);
+	}
+
+	js = jiffies;
+	yaffs_GarbageCollectBlock(dev, block);
+	js = jiffies - js;
+
+	printk(KERN_INFO "%s: block %u refresh took %lu ms, %u blocks left\n",
+	       dev->name, block, js * 1000 / HZ, blocksLeft);
+
+	if (dev->allocationBlockFinder > block) {
+		yaffs_tryEnableBackup(dev);
+	}
+
+	return blocksLeft;
+}
+#endif
+
+/*---------------------------- Initialisation code -------------------------------------- */
+
+static int yaffs_CheckDevFunctions(const yaffs_Device * dev)
+{
+
+	/* Common functions, gotta have */
+	if (!dev->eraseBlockInNAND || !dev->initialiseNAND)
+		return 0;
+
+#ifdef CONFIG_YAFFS_YAFFS2
+
+	/* Can use the "with tags" style interface for yaffs1 or yaffs2 */
+	if (dev->writeChunkWithTagsToNAND &&
+	    dev->readChunkWithTagsFromNAND &&
+	    !dev->writeChunkToNAND &&
+	    !dev->readChunkFromNAND &&
+	    dev->markNANDBlockBad && dev->queryNANDBlock)
+		return 1;
+#endif
+
+	/* Can use the "spare" style interface for yaffs1 */
+	if (!dev->isYaffs2 &&
+	    !dev->writeChunkWithTagsToNAND &&
+	    !dev->readChunkWithTagsFromNAND &&
+	    dev->writeChunkToNAND &&
+	    dev->readChunkFromNAND &&
+	    !dev->markNANDBlockBad && !dev->queryNANDBlock)
+		return 1;
+
+	return 0;		/* bad */
+}
+
+
+static void yaffs_CreateInitialDirectories(yaffs_Device *dev)
+{
+	/* Initialise the unlinked, deleted, root and lost and found directories */
+	
+	dev->lostNFoundDir = dev->rootDir =  NULL;
+	dev->unlinkedDir = dev->deletedDir = NULL;
+
+	dev->unlinkedDir =
+	    yaffs_CreateFakeDirectory(dev, YAFFS_OBJECTID_UNLINKED, S_IFDIR);
+	dev->deletedDir =
+	    yaffs_CreateFakeDirectory(dev, YAFFS_OBJECTID_DELETED, S_IFDIR);
+
+	dev->rootDir =
+	    yaffs_CreateFakeDirectory(dev, YAFFS_OBJECTID_ROOT,
+				      YAFFS_ROOT_MODE | S_IFDIR);
+	dev->lostNFoundDir =
+	    yaffs_CreateFakeDirectory(dev, YAFFS_OBJECTID_LOSTNFOUND,
+				      YAFFS_LOSTNFOUND_MODE | S_IFDIR);
+	yaffs_AddObjectToDirectory(dev->rootDir, dev->lostNFoundDir);
+}
+
+int yaffs_GutsInitialise(yaffs_Device * dev)
+{
+	unsigned x;
+	int bits;
+	int extraBits;
+
+	T(YAFFS_TRACE_TRACING, (TSTR("yaffs: yaffs_GutsInitialise()" TENDSTR)));
+
+	/* Check stuff that must be set */
+
+	if (!dev) {
+		T(YAFFS_TRACE_ALWAYS, (TSTR("yaffs: Need a device" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	dev->internalStartBlock = dev->startBlock;
+	dev->internalEndBlock = dev->endBlock;
+	dev->blockOffset = 0;
+	dev->chunkOffset = 0;
+	dev->nFreeChunks = 0;
+
+	if (dev->startBlock == 0) {
+		dev->internalStartBlock = dev->startBlock + 1;
+		dev->internalEndBlock = dev->endBlock + 1;
+		dev->blockOffset = 1;
+		dev->chunkOffset = dev->nChunksPerBlock;
+	}
+
+	/* Check geometry parameters. */
+
+	if ((dev->isYaffs2 && dev->nBytesPerChunk < 1024) || 
+	    (!dev->isYaffs2 && dev->nBytesPerChunk != 512) || 
+	     dev->nChunksPerBlock < 2 || 
+	     dev->nReservedBlocks < 2 || 
+	     dev->internalStartBlock <= 0 || 
+	     dev->internalEndBlock <= 0 || 
+	     dev->internalEndBlock <= (dev->internalStartBlock + dev->nReservedBlocks + 2)	// otherwise it is too small
+	    ) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("yaffs: NAND geometry problems: chunk size %d, type is yaffs%s "
+		    TENDSTR), dev->nBytesPerChunk, dev->isYaffs2 ? "2" : ""));
+		return YAFFS_FAIL;
+	}
+
+	if (yaffs_InitialiseNAND(dev) != YAFFS_OK) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR("yaffs: InitialiseNAND failed" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	/* Got the right mix of functions? */
+	if (!yaffs_CheckDevFunctions(dev)) {
+		/* Function missing */
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR
+		   ("yaffs: device function(s) missing or wrong\n" TENDSTR)));
+
+		return YAFFS_FAIL;
+	}
+
+	/* This is really a compilation check. */
+	if (!yaffs_CheckStructures()) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR("yaffs_CheckStructures failed\n" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	if (dev->isMounted) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR("yaffs: device already mounted\n" TENDSTR)));
+		return YAFFS_FAIL;
+	}
+
+	/* Finished with most checks. One or two more checks happen later on too. */
+
+	dev->isMounted = 1;
+
+
+
+	/* OK now calculate a few things for the device
+	 * Calculate chunkGroupBits.
+	 * We need to find the next power of 2 > than internalEndBlock
+	 */
+
+	x = dev->nChunksPerBlock * (dev->internalEndBlock + 1);
+
+	for (bits = extraBits = 0; x > 1; bits++) {
+		if (x & 1)
+			extraBits++;
+		x >>= 1;
+	}
+
+	if (extraBits > 0)
+		bits++;
+	
+	/* Set up tnode width if wide tnodes are enabled. */
+	if(!dev->wideTnodesDisabled){
+		/* bits must be even so that we end up with 32-bit words */
+		if(bits & 1)
+			bits++;
+		if(bits < 16)
+			dev->tnodeWidth = 16;
+		else
+			dev->tnodeWidth = bits;
+	}
+	else
+		dev->tnodeWidth = 16;
+ 
+	dev->tnodeMask = (1<<dev->tnodeWidth)-1;
+		
+	/* Level0 Tnodes are 16 bits or wider (if wide tnodes are enabled),
+	 * so if the bitwidth of the
+	 * chunk range we're using is greater than 16 we need
+	 * to figure out chunk shift and chunkGroupSize
+	 */
+		 
+	if (bits <= dev->tnodeWidth)
+		dev->chunkGroupBits = 0;
+	else
+		dev->chunkGroupBits = bits - dev->tnodeWidth;
+		
+
+	dev->chunkGroupSize = 1 << dev->chunkGroupBits;
+
+	if (dev->nChunksPerBlock < dev->chunkGroupSize) {
+		/* We have a problem because the soft delete won't work if
+		 * the chunk group size > chunks per block.
+		 * This can be remedied by using larger "virtual blocks".
+		 */
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR("yaffs: chunk group too large\n" TENDSTR)));
+
+		return YAFFS_FAIL;
+	}
+
+	/* OK, we've finished verifying the device, lets continue with initialisation */
+
+	/* More device initialisation */
+	dev->garbageCollections = 0;
+	dev->passiveGarbageCollections = 0;
+	dev->currentDirtyChecker = 0;
+	dev->bufferedBlock = -1;
+	dev->doingBufferedBlockRewrite = 0;
+	dev->nDeletedFiles = 0;
+	dev->nBackgroundDeletions = 0;
+	dev->nUnlinkedFiles = 0;
+	dev->eccFixed = 0;
+	dev->eccUnfixed = 0;
+	dev->tagsEccFixed = 0;
+	dev->tagsEccUnfixed = 0;
+	dev->nErasureFailures = 0;
+	dev->nErasedBlocks = 0;
+	dev->nBadBlocks = 0;
+	dev->isDoingGC = 0;
+
+	/* Initialise temporary buffers and caches. */
+	{
+		int i;
+		for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+			dev->tempBuffer[i].line = 0;	/* not in use */
+			dev->tempBuffer[i].buffer =
+			    YMALLOC_DMA(dev->nBytesPerChunk);
+		}
+	}
+	
+	if (dev->nShortOpCaches > 0) {
+		int i;
+
+		if (dev->nShortOpCaches > YAFFS_MAX_SHORT_OP_CACHES) {
+			dev->nShortOpCaches = YAFFS_MAX_SHORT_OP_CACHES;
+		}
+
+		dev->srCache =
+		    YMALLOC(dev->nShortOpCaches * sizeof(yaffs_ChunkCache));
+
+		for (i = 0; i < dev->nShortOpCaches; i++) {
+			dev->srCache[i].object = NULL;
+			dev->srCache[i].lastUse = 0;
+			dev->srCache[i].dirty = 0;
+			dev->srCache[i].data = YMALLOC_DMA(dev->nBytesPerChunk);
+		}
+		dev->srLastUse = 0;
+	}
+
+	dev->cacheHits = 0;
+	
+	dev->gcCleanupList = YMALLOC(dev->nChunksPerBlock * sizeof(__u32));
+
+	if (dev->isYaffs2) {
+		dev->useHeaderFileSize = 1;
+	}
+
+	yaffs_InitialiseBlocks(dev);
+	yaffs_InitialiseTnodes(dev);
+	yaffs_InitialiseObjects(dev);
+
+	yaffs_CreateInitialDirectories(dev);
+
+
+	/* Now scan the flash. */
+	if (dev->isYaffs2) {
+		if(yaffs_CheckpointRestore(dev)) {
+			yaffs_CheckObjectDetailsLoaded(dev->rootDir);
+			T(YAFFS_TRACE_ALWAYS,
+			  (TSTR("yaffs: restored from checkpoint" TENDSTR)));
+		} else {
+
+			/* Clean up the mess caused by an aborted checkpoint load 
+			 * and scan backwards. 
+			 */
+			yaffs_DeinitialiseBlocks(dev);
+			yaffs_DeinitialiseTnodes(dev);
+			yaffs_DeinitialiseObjects(dev);
+			yaffs_InitialiseBlocks(dev);
+			yaffs_InitialiseTnodes(dev);
+			yaffs_InitialiseObjects(dev);
+			yaffs_CreateInitialDirectories(dev);
+
+			yaffs_ScanBackwards(dev);
+		}
+	}else
+		yaffs_Scan(dev);
+
+	/* Zero out stats */
+	dev->nPageReads = 0;
+	dev->nPageWrites = 0;
+	dev->nBlockErasures = 0;
+	dev->nGCCopies = 0;
+	dev->nRetriedWrites = 0;
+
+	dev->nRetiredBlocks = 0;
+
+	yaffs_VerifyFreeChunks(dev);
+
+#ifdef MIPSEL
+	yaffs_tryEnableBackup(dev);
+#endif
+
+	T(YAFFS_TRACE_TRACING,
+	  (TSTR("yaffs: yaffs_GutsInitialise() done.\n" TENDSTR)));
+	return YAFFS_OK;
+
+}
+
+void yaffs_Deinitialise(yaffs_Device * dev)
+{
+	if (dev->isMounted) {
+		int i;
+
+		yaffs_DeinitialiseBlocks(dev);
+		yaffs_DeinitialiseTnodes(dev);
+		yaffs_DeinitialiseObjects(dev);
+		if (dev->nShortOpCaches > 0) {
+
+			for (i = 0; i < dev->nShortOpCaches; i++) {
+				YFREE(dev->srCache[i].data);
+			}
+
+			YFREE(dev->srCache);
+		}
+
+		YFREE(dev->gcCleanupList);
+
+		for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+			YFREE(dev->tempBuffer[i].buffer);
+		}
+
+		dev->isMounted = 0;
+	}
+
+}
+
+static int yaffs_CountFreeChunks(yaffs_Device * dev)
+{
+	int nFree;
+	int b;
+
+	yaffs_BlockInfo *blk;
+
+	dev->nBadBlocks = 0;
+	for (nFree = 0, b = dev->internalStartBlock; b <= dev->internalEndBlock;
+	     b++) {
+		blk = yaffs_GetBlockInfo(dev, b);
+
+		switch (blk->blockState) {
+		case YAFFS_BLOCK_STATE_EMPTY:
+		case YAFFS_BLOCK_STATE_ALLOCATING:
+		case YAFFS_BLOCK_STATE_COLLECTING:
+		case YAFFS_BLOCK_STATE_FULL:
+			nFree +=
+			    (dev->nChunksPerBlock - blk->pagesInUse +
+			     blk->softDeletions);
+			break;
+		case YAFFS_BLOCK_STATE_DEAD:
+			++dev->nBadBlocks;
+			/* fall through */
+		default:
+			break;
+		}
+
+	}
+
+	return nFree;
+}
+
+int yaffs_GetNumberOfFreeChunks(yaffs_Device * dev)
+{
+	/* This is what we report to the outside world */
+
+	int nFree;
+	int nDirtyCacheChunks;
+	int blocksForCheckpoint;
+
+#if 1
+	nFree = dev->nFreeChunks;
+#else
+	nFree = yaffs_CountFreeChunks(dev);
+#endif
+
+	nFree += dev->nDeletedFiles;
+	
+	/* Now count the number of dirty chunks in the cache and subtract those */
+
+	{
+		int i;
+		for (nDirtyCacheChunks = 0, i = 0; i < dev->nShortOpCaches; i++) {
+			if (dev->srCache[i].dirty)
+				nDirtyCacheChunks++;
+		}
+	}
+
+	nFree -= nDirtyCacheChunks;
+
+	nFree -= ((dev->nReservedBlocks + 1) * dev->nChunksPerBlock);
+	
+	/* Now we figure out how much to reserve for the checkpoint and report that... */
+	blocksForCheckpoint = dev->nCheckpointReservedBlocks - dev->blocksInCheckpoint;
+	if(blocksForCheckpoint < 0)
+		blocksForCheckpoint = 0;
+		
+	nFree -= (blocksForCheckpoint * dev->nChunksPerBlock);
+
+	if (nFree < 0)
+		nFree = 0;
+
+	return nFree;
+
+}
+
+static int yaffs_freeVerificationFailures;
+
+static void yaffs_VerifyFreeChunks(yaffs_Device * dev)
+{
+	int counted = yaffs_CountFreeChunks(dev);
+
+	int difference = dev->nFreeChunks - counted;
+
+	if (difference) {
+		T(YAFFS_TRACE_ALWAYS,
+		  (TSTR("Freechunks verification failure %d %d %d" TENDSTR),
+		   dev->nFreeChunks, counted, difference));
+		yaffs_freeVerificationFailures++;
+	}
+}
+
+/*---------------------------------------- YAFFS test code ----------------------*/
+
+#define yaffs_CheckStruct(structure,syze, name) \
+           if(sizeof(structure) != syze) \
+	       { \
+	         T(YAFFS_TRACE_ALWAYS,(TSTR("%s should be %d but is %d\n" TENDSTR),\
+		 name,syze,sizeof(structure))); \
+	         return YAFFS_FAIL; \
+		}
+
+static int yaffs_CheckStructures(void)
+{
+/*      yaffs_CheckStruct(yaffs_Tags,8,"yaffs_Tags") */
+/*      yaffs_CheckStruct(yaffs_TagsUnion,8,"yaffs_TagsUnion") */
+/*      yaffs_CheckStruct(yaffs_Spare,16,"yaffs_Spare") */
+#ifndef CONFIG_YAFFS_TNODE_LIST_DEBUG
+	yaffs_CheckStruct(yaffs_Tnode, 2 * YAFFS_NTNODES_LEVEL0, "yaffs_Tnode")
+#endif
+	    yaffs_CheckStruct(yaffs_ObjectHeader, 512, "yaffs_ObjectHeader")
+
+	    return YAFFS_OK;
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_guts.h linux/fs/yaffs/yaffs_guts.h
--- linux-2.6.35/fs/yaffs/yaffs_guts.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_guts.h	2011-05-02 10:08:28.071591107 +0300
@@ -0,0 +1,884 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system.
+ * yaffs_guts.h: Configuration etc for yaffs_guts
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ * $Id: yaffs_guts.h,v 1.22 2006/05/17 09:31:06 charles Exp $
+ */
+
+#ifndef __YAFFS_GUTS_H__
+#define __YAFFS_GUTS_H__
+
+#include "devextras.h"
+#include "yportenv.h"
+
+#define YAFFS_OK	1
+#define YAFFS_FAIL  0
+
+/* Give us a  Y=0x59, 
+ * Give us an A=0x41, 
+ * Give us an FF=0xFF 
+ * Give us an S=0x53
+ * And what have we got... 
+ */
+#define YAFFS_MAGIC			0x5941FF53
+
+#define YAFFS_NTNODES_LEVEL0	  	16
+#define YAFFS_TNODES_LEVEL0_BITS	4
+#define YAFFS_TNODES_LEVEL0_MASK	0xf
+
+#define YAFFS_NTNODES_INTERNAL 		(YAFFS_NTNODES_LEVEL0 / 2)
+#define YAFFS_TNODES_INTERNAL_BITS 	(YAFFS_TNODES_LEVEL0_BITS - 1)
+#define YAFFS_TNODES_INTERNAL_MASK	0x7
+#define YAFFS_TNODES_MAX_LEVEL		6
+
+#ifndef CONFIG_YAFFS_NO_YAFFS1
+#define YAFFS_BYTES_PER_SPARE		16
+#define YAFFS_BYTES_PER_CHUNK		512
+#define YAFFS_CHUNK_SIZE_SHIFT		9
+#define YAFFS_CHUNKS_PER_BLOCK		32
+#define YAFFS_BYTES_PER_BLOCK		(YAFFS_CHUNKS_PER_BLOCK*YAFFS_BYTES_PER_CHUNK)
+#endif
+
+#define YAFFS_MIN_YAFFS2_CHUNK_SIZE 	1024
+#define YAFFS_MIN_YAFFS2_SPARE_SIZE	32
+
+#define YAFFS_MAX_CHUNK_ID		0x000FFFFF
+
+#define YAFFS_UNUSED_OBJECT_ID		0x0003FFFF
+
+#define YAFFS_ALLOCATION_NOBJECTS	100
+#define YAFFS_ALLOCATION_NTNODES	100
+#define YAFFS_ALLOCATION_NLINKS		100
+
+#define YAFFS_NOBJECT_BUCKETS		256
+
+
+#define YAFFS_OBJECT_SPACE		0x40000
+
+#define YAFFS_NCHECKPOINT_OBJECTS	5000
+
+#ifdef CONFIG_YAFFS_UNICODE
+#define YAFFS_MAX_NAME_LENGTH		127
+#define YAFFS_MAX_ALIAS_LENGTH		79
+#else
+#define YAFFS_MAX_NAME_LENGTH		255
+#define YAFFS_MAX_ALIAS_LENGTH		159
+#endif
+
+#define YAFFS_SHORT_NAME_LENGTH		15
+
+/* Some special object ids for pseudo objects */
+#define YAFFS_OBJECTID_ROOT		1
+#define YAFFS_OBJECTID_LOSTNFOUND	2
+#define YAFFS_OBJECTID_UNLINKED		3
+#define YAFFS_OBJECTID_DELETED		4
+
+/* Sseudo object ids for checkpointing */
+#define YAFFS_OBJECTID_SB_HEADER	0x10
+#define YAFFS_OBJECTID_CHECKPOINT_DATA	0x20
+#define YAFFS_SEQUENCE_CHECKPOINT_DATA  0x21
+
+/* */
+
+#define YAFFS_MAX_SHORT_OP_CACHES	20
+
+#define YAFFS_N_TEMP_BUFFERS		4
+
+/* Sequence numbers are used in YAFFS2 to determine block allocation order.
+ * The range is limited slightly to help distinguish bad numbers from good.
+ * This also allows us to perhaps in the future use special numbers for
+ * special purposes.
+ * EFFFFF00 allows the allocation of 8 blocks per second (~1Mbytes) for 15 years, 
+ * and is a larger number than the lifetime of a 2GB device.
+ */
+#define YAFFS_LOWEST_SEQUENCE_NUMBER	0x00001000
+#define YAFFS_HIGHEST_SEQUENCE_NUMBER	0xEFFFFF00
+
+/* ChunkCache is used for short read/write operations.*/
+typedef struct {
+	struct yaffs_ObjectStruct *object;
+	int chunkId;
+	int lastUse;
+	int dirty;
+	int nBytes;		/* Only valid if the cache is dirty */
+	int locked;		/* Can't push out or flush while locked. */
+#ifdef CONFIG_YAFFS_YAFFS2
+	__u8 *data;
+#else
+	__u8 data[YAFFS_BYTES_PER_CHUNK];
+#endif
+} yaffs_ChunkCache;
+
+
+
+/* Tags structures in RAM
+ * NB This uses bitfield. Bitfields should not straddle a u32 boundary otherwise
+ * the structure size will get blown out.
+ */
+
+#ifndef CONFIG_YAFFS_NO_YAFFS1
+typedef struct {
+	unsigned chunkId:20;
+	unsigned serialNumber:2;
+	unsigned byteCount:10;
+	unsigned objectId:18;
+	unsigned ecc:12;
+	unsigned unusedStuff:2;
+
+} yaffs_Tags;
+
+typedef union {
+	yaffs_Tags asTags;
+	__u8 asBytes[8];
+} yaffs_TagsUnion;
+
+#endif
+
+/* Stuff used for extended tags in YAFFS2 */
+
+typedef enum {
+	YAFFS_ECC_RESULT_UNKNOWN,
+	YAFFS_ECC_RESULT_NO_ERROR,
+	YAFFS_ECC_RESULT_FIXED,
+	YAFFS_ECC_RESULT_UNFIXED
+} yaffs_ECCResult;
+
+typedef enum {
+	YAFFS_OBJECT_TYPE_UNKNOWN,
+	YAFFS_OBJECT_TYPE_FILE,
+	YAFFS_OBJECT_TYPE_SYMLINK,
+	YAFFS_OBJECT_TYPE_DIRECTORY,
+	YAFFS_OBJECT_TYPE_HARDLINK,
+	YAFFS_OBJECT_TYPE_SPECIAL
+} yaffs_ObjectType;
+
+typedef struct {
+
+	unsigned validMarker0;
+	unsigned chunkUsed;	/*  Status of the chunk: used or unused */
+	unsigned objectId;	/* If 0 then this is not part of an object (unused) */
+	unsigned chunkId;	/* If 0 then this is a header, else a data chunk */
+	unsigned byteCount;	/* Only valid for data chunks */
+
+	/* The following stuff only has meaning when we read */
+	yaffs_ECCResult eccResult;
+	unsigned blockBad;	
+
+	/* YAFFS 1 stuff */
+	unsigned chunkDeleted;	/* The chunk is marked deleted */
+	unsigned serialNumber;	/* Yaffs1 2-bit serial number */
+
+	/* YAFFS2 stuff */
+	unsigned sequenceNumber;	/* The sequence number of this block */
+
+	/* Extra info if this is an object header (YAFFS2 only) */
+
+	unsigned extraHeaderInfoAvailable;	/* There is extra info available if this is not zero */
+	unsigned extraParentObjectId;	/* The parent object */
+	unsigned extraIsShrinkHeader;	/* Is it a shrink header? */
+	unsigned extraShadows;		/* Does this shadow another object? */
+
+	yaffs_ObjectType extraObjectType;	/* What object type? */
+
+	unsigned extraFileLength;		/* Length if it is a file */
+	unsigned extraEquivalentObjectId;	/* Equivalent object Id if it is a hard link */
+
+	unsigned validMarker1;
+
+} yaffs_ExtendedTags;
+
+/* Spare structure for YAFFS1 */
+typedef struct {
+	__u8 tagByte0;
+	__u8 tagByte1;
+	__u8 tagByte2;
+	__u8 tagByte3;
+	__u8 pageStatus;	/* set to 0 to delete the chunk */
+	__u8 blockStatus;
+	__u8 tagByte4;
+	__u8 tagByte5;
+	__u8 ecc1[3];
+	__u8 tagByte6;
+	__u8 tagByte7;
+	__u8 ecc2[3];
+} yaffs_Spare;
+
+/*Special structure for passing through to mtd */
+struct yaffs_NANDSpare {
+	yaffs_Spare spare;
+	int eccres1;
+	int eccres2;
+};
+
+/* Block data in RAM */
+
+typedef enum {
+	YAFFS_BLOCK_STATE_UNKNOWN = 0,
+
+	YAFFS_BLOCK_STATE_SCANNING,
+	YAFFS_BLOCK_STATE_NEEDS_SCANNING,
+	/* The block might have something on it (ie it is allocating or full, perhaps empty)
+	 * but it needs to be scanned to determine its true state.
+	 * This state is only valid during yaffs_Scan.
+	 * NB We tolerate empty because the pre-scanner might be incapable of deciding
+	 * However, if this state is returned on a YAFFS2 device, then we expect a sequence number
+	 */
+
+	YAFFS_BLOCK_STATE_EMPTY,
+	/* This block is empty */
+
+	YAFFS_BLOCK_STATE_ALLOCATING,
+	/* This block is partially allocated. 
+	 * At least one page holds valid data.
+	 * This is the one currently being used for page
+	 * allocation. Should never be more than one of these
+	 */
+
+	YAFFS_BLOCK_STATE_FULL,	
+	/* All the pages in this block have been allocated.
+	 */
+
+	YAFFS_BLOCK_STATE_DIRTY,
+	/* All pages have been allocated and deleted. 
+	 * Erase me, reuse me.
+	 */
+
+	YAFFS_BLOCK_STATE_CHECKPOINT,	
+	/* This block is assigned to holding checkpoint data.
+	 */
+
+	YAFFS_BLOCK_STATE_COLLECTING,	
+	/* This block is being garbage collected */
+
+	YAFFS_BLOCK_STATE_DEAD	
+	/* This block has failed and is not in use */
+} yaffs_BlockState;
+
+typedef struct {
+
+	int softDeletions:12;	/* number of soft deleted pages */
+	int pagesInUse:12;	/* number of pages in use */
+	yaffs_BlockState blockState:4;	/* One of the above block states */
+	__u32 needsRetiring:1;	/* Data has failed on this block, need to get valid data off */
+                        	/* and retire the block. */
+	__u32 needsGC:1;	/* Data has failed on this block, need to get valid data off */
+#ifdef CONFIG_YAFFS_YAFFS2
+	__u32 hasShrinkHeader:1; /* This block has at least one shrink object header */
+	__u32 sequenceNumber;	 /* block sequence number for yaffs2 */
+#endif
+
+} yaffs_BlockInfo;
+
+/* -------------------------- Object structure -------------------------------*/
+/* This is the object structure as stored on NAND */
+
+typedef struct {
+	yaffs_ObjectType type;
+
+	/* Apply to everything  */
+	int parentObjectId;
+	__u16 sum__NoLongerUsed;	/* checksum of name. No longer used */
+	YCHAR name[YAFFS_MAX_NAME_LENGTH + 1];
+
+	/* Thes following apply to directories, files, symlinks - not hard links */
+	__u32 yst_mode;		/* protection */
+
+#ifdef CONFIG_YAFFS_WINCE
+	__u32 notForWinCE[5];
+#else
+	__u32 yst_uid;
+	__u32 yst_gid;
+	__u32 yst_atime;
+	__u32 yst_mtime;
+	__u32 yst_ctime;
+#endif
+
+	/* File size  applies to files only */
+	int fileSize;
+
+	/* Equivalent object id applies to hard links only. */
+	int equivalentObjectId;
+
+	/* Alias is for symlinks only. */
+	YCHAR alias[YAFFS_MAX_ALIAS_LENGTH + 1];
+
+	__u32 yst_rdev;		/* device stuff for block and char devices (major/min) */
+
+#ifdef CONFIG_YAFFS_WINCE
+	__u32 win_ctime[2];
+	__u32 win_atime[2];
+	__u32 win_mtime[2];
+	__u32 roomToGrow[4];
+#else
+	__u32 roomToGrow[10];
+#endif
+
+	int shadowsObject;	/* This object header shadows the specified object if > 0 */
+
+	/* isShrink applies to object headers written when we shrink the file (ie resize) */
+	__u32 isShrink;
+
+} yaffs_ObjectHeader;
+
+/*--------------------------- Tnode -------------------------- */
+
+union yaffs_Tnode_union {
+#ifdef CONFIG_YAFFS_TNODE_LIST_DEBUG
+	union yaffs_Tnode_union *internal[YAFFS_NTNODES_INTERNAL + 1];
+#else
+	union yaffs_Tnode_union *internal[YAFFS_NTNODES_INTERNAL];
+#endif
+/*	__u16 level0[YAFFS_NTNODES_LEVEL0]; */
+
+};
+
+typedef union yaffs_Tnode_union yaffs_Tnode;
+
+struct yaffs_TnodeList_struct {
+	struct yaffs_TnodeList_struct *next;
+	yaffs_Tnode *tnodes;
+};
+
+typedef struct yaffs_TnodeList_struct yaffs_TnodeList;
+
+/*------------------------  Object -----------------------------*/
+/* An object can be one of:
+ * - a directory (no data, has children links
+ * - a regular file (data.... not prunes :->).
+ * - a symlink [symbolic link] (the alias).
+ * - a hard link
+ */
+
+typedef struct {
+	__u32 fileSize;
+	__u32 scannedFileSize;
+	__u32 shrinkSize;
+	int topLevel;
+	yaffs_Tnode *top;
+} yaffs_FileStructure;
+
+typedef struct {
+	struct list_head children;	/* list of child links */
+} yaffs_DirectoryStructure;
+
+typedef struct {
+	YCHAR *alias;
+} yaffs_SymLinkStructure;
+
+typedef struct {
+	struct yaffs_ObjectStruct *equivalentObject;
+	__u32 equivalentObjectId;
+} yaffs_HardLinkStructure;
+
+typedef union {
+	yaffs_FileStructure fileVariant;
+	yaffs_DirectoryStructure directoryVariant;
+	yaffs_SymLinkStructure symLinkVariant;
+	yaffs_HardLinkStructure hardLinkVariant;
+} yaffs_ObjectVariant;
+
+struct yaffs_ObjectStruct {
+	__u8 deleted:1;		/* This should only apply to unlinked files. */
+	__u8 softDeleted:1;	/* it has also been soft deleted */
+	__u8 unlinked:1;	/* An unlinked file. The file should be in the unlinked directory.*/
+	__u8 fake:1;		/* A fake object has no presence on NAND. */
+	__u8 renameAllowed:1;	/* Some objects are not allowed to be renamed. */
+	__u8 unlinkAllowed:1;
+	__u8 dirty:1;		/* the object needs to be written to flash */
+	__u8 valid:1;		/* When the file system is being loaded up, this 
+				 * object might be created before the data
+				 * is available (ie. file data records appear before the header).
+				 */
+	__u8 lazyLoaded:1;	/* This object has been lazy loaded and is missing some detail */
+
+	__u8 deferedFree:1;	/* For Linux kernel. Object is removed from NAND, but is
+				 * still in the inode cache. Free of object is defered.
+				 * until the inode is released.
+				 */
+
+	__u8 serial;		/* serial number of chunk in NAND. Cached here */
+	__u16 sum;		/* sum of the name to speed searching */
+
+	struct yaffs_DeviceStruct *myDev;	/* The device I'm on */
+
+	struct list_head hashLink;	/* list of objects in this hash bucket */
+
+	struct list_head hardLinks;	/* all the equivalent hard linked objects */
+
+	/* directory structure stuff */
+	/* also used for linking up the free list */
+	struct yaffs_ObjectStruct *parent; 
+	struct list_head siblings;
+
+	/* Where's my object header in NAND? */
+	int hdrChunk;		
+
+	int nDataChunks;	/* Number of data chunks attached to the file. */
+
+	__u32 objectId;		/* the object id value */
+
+	__u32 yst_mode;
+
+#ifdef CONFIG_YAFFS_SHORT_NAMES_IN_RAM
+	YCHAR shortName[YAFFS_SHORT_NAME_LENGTH + 1];
+#endif
+
+#ifndef __KERNEL__
+	__u32 inUse;
+#endif
+
+#ifdef CONFIG_YAFFS_WINCE
+	__u32 win_ctime[2];
+	__u32 win_mtime[2];
+	__u32 win_atime[2];
+#else
+	__u32 yst_uid;
+	__u32 yst_gid;
+	__u32 yst_atime;
+	__u32 yst_mtime;
+	__u32 yst_ctime;
+#endif
+
+	__u32 yst_rdev;
+
+#ifdef __KERNEL__
+	struct inode *myInode;
+
+#endif
+
+	yaffs_ObjectType variantType;
+
+	yaffs_ObjectVariant variant;
+
+};
+
+typedef struct yaffs_ObjectStruct yaffs_Object;
+
+struct yaffs_ObjectList_struct {
+	yaffs_Object *objects;
+	struct yaffs_ObjectList_struct *next;
+};
+
+typedef struct yaffs_ObjectList_struct yaffs_ObjectList;
+
+typedef struct {
+	struct list_head list;
+	int count;
+} yaffs_ObjectBucket;
+
+
+/* yaffs_CheckpointObject holds the definition of an object as dumped 
+ * by checkpointing.
+ */
+
+typedef struct {
+        int structType;
+	__u32 objectId;		
+	__u32 parentId;
+	int hdrChunk;
+			
+	yaffs_ObjectType variantType:3;
+	__u8 deleted:1;		
+	__u8 softDeleted:1;	
+	__u8 unlinked:1;	
+	__u8 fake:1;		
+	__u8 renameAllowed:1;
+	__u8 unlinkAllowed:1;
+	__u8 serial;		
+	
+	int nDataChunks;	
+	__u32 fileSizeOrEquivalentObjectId;
+
+}yaffs_CheckpointObject;
+
+/*--------------------- Temporary buffers ----------------
+ *
+ * These are chunk-sized working buffers. Each device has a few
+ */
+
+typedef struct {
+	__u8 *buffer;
+	int line;	/* track from whence this buffer was allocated */
+	int maxLine;
+} yaffs_TempBuffer;
+
+/*----------------- Device ---------------------------------*/
+
+struct yaffs_DeviceStruct {
+	struct list_head devList;
+	const char *name;
+
+	/* Entry parameters set up way early. Yaffs sets up the rest.*/
+	int nBytesPerChunk;	/* Should be a power of 2 >= 512 */
+	int nChunksPerBlock;	/* does not need to be a power of 2 */
+	int nBytesPerSpare;	/* spare area size */
+	int startBlock;		/* Start block we're allowed to use */
+	int endBlock;		/* End block we're allowed to use */
+	int nReservedBlocks;	/* We want this tuneable so that we can reduce */
+				/* reserved blocks on NOR and RAM. */
+	
+	/* Stuff used by the partitioned checkpointing mechanism */
+	int checkpointStartBlock;
+	int checkpointEndBlock;
+	
+	/* Stuff used by the shared space checkpointing mechanism */
+	/* If this value is zero, then this mechanism is disabled */
+	
+	int nCheckpointReservedBlocks; /* Blocks to reserve for checkpoint data */
+
+	
+
+
+	int nShortOpCaches;	/* If <= 0, then short op caching is disabled, else
+				 * the number of short op caches (don't use too many)
+				 */
+
+	int useHeaderFileSize;	/* Flag to determine if we should use file sizes from the header */
+
+	int useNANDECC;		/* Flag to decide whether or not to use NANDECC */
+
+	void *genericDevice;	/* Pointer to device context
+				 * On an mtd this holds the mtd pointer.
+				 */
+        void *superBlock;
+        
+	/* NAND access functions (Must be set before calling YAFFS)*/
+
+	int (*writeChunkToNAND) (struct yaffs_DeviceStruct * dev,
+				 int chunkInNAND, const __u8 * data,
+				 const yaffs_Spare * spare);
+	int (*readChunkFromNAND) (struct yaffs_DeviceStruct * dev,
+				  int chunkInNAND, __u8 * data,
+				  yaffs_Spare * spare);
+	int (*eraseBlockInNAND) (struct yaffs_DeviceStruct * dev,
+				 int blockInNAND);
+	int (*initialiseNAND) (struct yaffs_DeviceStruct * dev);
+
+#ifdef CONFIG_YAFFS_YAFFS2
+	int (*writeChunkWithTagsToNAND) (struct yaffs_DeviceStruct * dev,
+					 int chunkInNAND, const __u8 * data,
+					 const yaffs_ExtendedTags * tags);
+	int (*readChunkWithTagsFromNAND) (struct yaffs_DeviceStruct * dev,
+					  int chunkInNAND, __u8 * data,
+					  yaffs_ExtendedTags * tags);
+	int (*markNANDBlockBad) (struct yaffs_DeviceStruct * dev, int blockNo);
+	int (*queryNANDBlock) (struct yaffs_DeviceStruct * dev, int blockNo,
+			       yaffs_BlockState * state, int *sequenceNumber);
+#endif
+
+	int isYaffs2;
+	
+	/* The removeObjectCallback function must be supplied by OS flavours that 
+	 * need it. The Linux kernel does not use this, but yaffs direct does use
+	 * it to implement the faster readdir
+	 */
+	void (*removeObjectCallback)(struct yaffs_ObjectStruct *obj);
+	
+	/* Callback to mark the superblock dirsty */
+	void (*markSuperBlockDirty)(void * superblock);
+	
+	int wideTnodesDisabled; /* Set to disable wide tnodes */
+	
+
+	/* End of stuff that must be set before initialisation. */
+
+	/* Runtime parameters. Set up by YAFFS. */
+
+	__u16 chunkGroupBits;	/* 0 for devices <= 32MB. else log2(nchunks) - 16 */
+	__u16 chunkGroupSize;	/* == 2^^chunkGroupBits */
+	
+	/* Stuff to support wide tnodes */
+	__u32 tnodeWidth;
+	__u32 tnodeMask;
+	
+
+#ifdef __KERNEL__
+
+	struct semaphore sem;	/* Semaphore for waiting on erasure.*/
+	struct semaphore grossLock;	/* Gross locking semaphore */
+	__u8 *spareBuffer;	/* For mtdif2 use. Don't know the size of the buffer 
+				 * at compile time so we have to allocate it.
+				 */
+	void (*putSuperFunc) (struct super_block * sb);
+#endif
+
+	int isMounted;
+	
+	int isCheckpointed;
+
+	/* Stuff to support block offsetting to support start block zero */
+	int internalStartBlock;
+	int internalEndBlock;
+	int blockOffset;
+	int chunkOffset;
+	
+
+	/* Runtime checkpointing stuff */
+	int checkpointPageSequence;   /* running sequence number of checkpoint pages */
+	int checkpointByteCount;
+	int checkpointByteOffset;
+	__u8 *checkpointBuffer;
+	int checkpointOpenForWrite;
+	int blocksInCheckpoint;
+	int checkpointCurrentChunk;
+	int checkpointCurrentBlock;
+	int checkpointNextBlock;
+	int *checkpointBlockList;
+	int checkpointMaxBlocks;
+	
+	/* Block Info */
+	yaffs_BlockInfo *blockInfo;
+	__u8 *chunkBits;	/* bitmap of chunks in use */
+	unsigned blockInfoAlt:1;	/* was allocated using alternative strategy */
+	unsigned chunkBitsAlt:1;	/* was allocated using alternative strategy */
+	int chunkBitmapStride;	/* Number of bytes of chunkBits per block. 
+				 * Must be consistent with nChunksPerBlock.
+				 */
+
+	int nErasedBlocks;
+	int allocationBlock;	/* Current block being allocated off */
+	__u32 allocationPage;
+	int allocationBlockFinder;	/* Used to search for next allocation block */
+
+	/* Runtime state */
+	int nTnodesCreated;
+	yaffs_Tnode *freeTnodes;
+	int nFreeTnodes;
+	yaffs_TnodeList *allocatedTnodeList;
+
+	int isDoingGC;
+
+	int nObjectsCreated;
+	yaffs_Object *freeObjects;
+	int nFreeObjects;
+
+	yaffs_ObjectList *allocatedObjectList;
+
+	yaffs_ObjectBucket objectBucket[YAFFS_NOBJECT_BUCKETS];
+
+	int nFreeChunks;
+
+	int currentDirtyChecker;	/* Used to find current dirtiest block */
+
+	__u32 *gcCleanupList;	/* objects to delete at the end of a GC. */
+
+	/* Statistcs */
+	int nPageWrites;
+	int nPageReads;
+	int nBlockErasures;
+	int nErasureFailures;
+	int nGCCopies;
+	int garbageCollections;
+	int passiveGarbageCollections;
+	int nRetriedWrites;
+	int nRetiredBlocks;
+	int nBadBlocks;
+	int eccFixed;
+	int eccUnfixed;
+	int tagsEccFixed;
+	int tagsEccUnfixed;
+	int nDeletions;
+	int nUnmarkedDeletions;
+
+	/* Special directories */
+	yaffs_Object *rootDir;
+	yaffs_Object *lostNFoundDir;
+
+	/* Buffer areas for storing data to recover from write failures TODO
+	 *      __u8            bufferedData[YAFFS_CHUNKS_PER_BLOCK][YAFFS_BYTES_PER_CHUNK];
+	 *      yaffs_Spare bufferedSpare[YAFFS_CHUNKS_PER_BLOCK];
+	 */
+	
+	int bufferedBlock;	/* Which block is buffered here? */
+	int doingBufferedBlockRewrite;
+
+	yaffs_ChunkCache *srCache;
+	int srLastUse;
+
+	int cacheHits;
+
+	/* Stuff for background deletion and unlinked files.*/
+	yaffs_Object *unlinkedDir;	/* Directory where unlinked and deleted files live. */
+	yaffs_Object *deletedDir;	/* Directory where deleted objects are sent to disappear. */
+	yaffs_Object *unlinkedDeletion;	/* Current file being background deleted.*/
+	int nDeletedFiles;		/* Count of files awaiting deletion;*/
+	int nUnlinkedFiles;		/* Count of unlinked files. */
+	int nBackgroundDeletions;	/* Count of background deletions. */
+
+
+	yaffs_TempBuffer tempBuffer[YAFFS_N_TEMP_BUFFERS];
+	int maxTemp;
+	int unmanagedTempAllocations;
+	int unmanagedTempDeallocations;
+
+	/* yaffs2 runtime stuff */
+	unsigned sequenceNumber;	/* Sequence number of currently allocating block */
+	unsigned oldestDirtySequence;
+
+};
+
+typedef struct yaffs_DeviceStruct yaffs_Device;
+
+/* The static layout of bllock usage etc is stored in the super block header */
+typedef struct {
+        int StructType;
+	int version;
+	int checkpointStartBlock;
+	int checkpointEndBlock;
+	int startBlock;
+	int endBlock;
+	int rfu[100];
+} yaffs_SuperBlockHeader;
+	
+/* The CheckpointDevice structure holds the device information that changes at runtime and
+ * must be preserved over unmount/mount cycles.
+ */
+typedef struct {
+        int structType;
+	int nErasedBlocks;
+	int allocationBlock;	/* Current block being allocated off */
+	__u32 allocationPage;
+	int nFreeChunks;
+
+	int nDeletedFiles;		/* Count of files awaiting deletion;*/
+	int nUnlinkedFiles;		/* Count of unlinked files. */
+	int nBackgroundDeletions;	/* Count of background deletions. */
+
+	/* yaffs2 runtime stuff */
+	unsigned sequenceNumber;	/* Sequence number of currently allocating block */
+	unsigned oldestDirtySequence;
+
+} yaffs_CheckpointDevice;
+
+
+typedef struct {
+    int structType;
+    __u32 magic;
+    __u32 version;
+    __u32 head;
+} yaffs_CheckpointValidity;
+
+/* Function to manipulate block info */
+static Y_INLINE yaffs_BlockInfo *yaffs_GetBlockInfo(yaffs_Device * dev, int blk)
+{
+	if (blk < dev->internalStartBlock || blk > dev->internalEndBlock) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR
+		   ("**>> yaffs: getBlockInfo block %d is not valid" TENDSTR),
+		   blk));
+		YBUG();
+	}
+	return &dev->blockInfo[blk - dev->internalStartBlock];
+}
+
+/*----------------------- YAFFS Functions -----------------------*/
+
+int yaffs_GutsInitialise(yaffs_Device * dev);
+void yaffs_Deinitialise(yaffs_Device * dev);
+
+int yaffs_GetNumberOfFreeChunks(yaffs_Device * dev);
+
+int yaffs_RenameObject(yaffs_Object * oldDir, const YCHAR * oldName,
+		       yaffs_Object * newDir, const YCHAR * newName);
+
+int yaffs_Unlink(yaffs_Object * dir, const YCHAR * name);
+int yaffs_DeleteFile(yaffs_Object * obj);
+
+int yaffs_GetObjectName(yaffs_Object * obj, YCHAR * name, int buffSize);
+int yaffs_GetObjectFileLength(yaffs_Object * obj);
+int yaffs_GetObjectInode(yaffs_Object * obj);
+unsigned yaffs_GetObjectType(yaffs_Object * obj);
+int yaffs_GetObjectLinkCount(yaffs_Object * obj);
+
+int yaffs_SetAttributes(yaffs_Object * obj, struct iattr *attr);
+int yaffs_GetAttributes(yaffs_Object * obj, struct iattr *attr);
+
+/* File operations */
+int yaffs_ReadDataFromFile(yaffs_Object * obj, __u8 * buffer, __u32 offset,
+			   int nBytes);
+int yaffs_WriteDataToFile(yaffs_Object * obj, const __u8 * buffer, __u32 offset,
+			  int nBytes, int writeThrough);
+int yaffs_ResizeFile(yaffs_Object * obj, int newSize);
+
+yaffs_Object *yaffs_MknodFile(yaffs_Object * parent, const YCHAR * name,
+			      __u32 mode, __u32 uid, __u32 gid);
+int yaffs_FlushFile(yaffs_Object * obj, int updateTime);
+
+/* Flushing and checkpointing */
+void yaffs_FlushEntireDeviceCache(yaffs_Device *dev);
+
+int yaffs_CheckpointSave(yaffs_Device *dev);
+int yaffs_CheckpointRestore(yaffs_Device *dev);
+
+/* Directory operations */
+yaffs_Object *yaffs_MknodDirectory(yaffs_Object * parent, const YCHAR * name,
+				   __u32 mode, __u32 uid, __u32 gid);
+yaffs_Object *yaffs_FindObjectByName(yaffs_Object * theDir, const YCHAR * name);
+int yaffs_ApplyToDirectoryChildren(yaffs_Object * theDir,
+				   int (*fn) (yaffs_Object *));
+
+yaffs_Object *yaffs_FindObjectByNumber(yaffs_Device * dev, __u32 number);
+
+/* Link operations */
+yaffs_Object *yaffs_Link(yaffs_Object * parent, const YCHAR * name,
+			 yaffs_Object * equivalentObject);
+
+yaffs_Object *yaffs_GetEquivalentObject(yaffs_Object * obj);
+
+/* Symlink operations */
+yaffs_Object *yaffs_MknodSymLink(yaffs_Object * parent, const YCHAR * name,
+				 __u32 mode, __u32 uid, __u32 gid,
+				 const YCHAR * alias);
+YCHAR *yaffs_GetSymlinkAlias(yaffs_Object * obj);
+
+/* Special inodes (fifos, sockets and devices) */
+yaffs_Object *yaffs_MknodSpecial(yaffs_Object * parent, const YCHAR * name,
+				 __u32 mode, __u32 uid, __u32 gid, __u32 rdev);
+
+/* Special directories */
+yaffs_Object *yaffs_Root(yaffs_Device * dev);
+yaffs_Object *yaffs_LostNFound(yaffs_Device * dev);
+
+#ifdef CONFIG_YAFFS_WINCE
+/* CONFIG_YAFFS_WINCE special stuff */
+void yfsd_WinFileTimeNow(__u32 target[2]);
+#endif
+
+#ifdef __KERNEL__
+
+void yaffs_HandleDeferedFree(yaffs_Object * obj);
+void yaffs_HandleWriteChunkError(yaffs_Device * dev, int chunkInNAND);
+void yaffs_HandleReadDataError(yaffs_Device * dev, int chunkInNAND,
+			       int softErr);
+#endif
+
+/* Debug dump  */
+int yaffs_DumpObject(yaffs_Object * obj);
+
+void yaffs_GutsTest(yaffs_Device * dev);
+
+/* A few useful functions */
+void yaffs_InitialiseTags(yaffs_ExtendedTags * tags);
+void yaffs_DeleteChunk(yaffs_Device * dev, int chunkId, int markNAND, int lyn);
+int yaffs_CheckFF(__u8 * buffer, int nBytes);
+
+#ifdef MIPSEL
+/* for bad NAND refresh and backup */
+extern int is_nand_bad(void);
+extern int nand_enable_backup(struct mtd_info *mtd);
+int yaffs_RefreshOneBlock(yaffs_Device *dev);
+#endif
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffsinterface.h linux/fs/yaffs/yaffsinterface.h
--- linux-2.6.35/fs/yaffs/yaffsinterface.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffsinterface.h	2011-05-02 10:08:28.091590467 +0300
@@ -0,0 +1,23 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system.
+ * yaffsinterface.h: Interface to the guts of yaffs.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ */
+
+#ifndef __YAFFSINTERFACE_H__
+#define __YAFFSINTERFACE_H__
+
+int yaffs_Initialise(unsigned nBlocks);
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_mtdif2.c linux/fs/yaffs/yaffs_mtdif2.c
--- linux-2.6.35/fs/yaffs/yaffs_mtdif2.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_mtdif2.c	2011-05-02 10:08:28.101591215 +0300
@@ -0,0 +1,240 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_mtdif.c  NAND mtd wrapper functions.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+/* mtd interface for YAFFS2 */
+
+const char *yaffs_mtdif2_c_version =
+    "$Id: yaffs_mtdif2.c,v 1.14 2006/10/03 10:13:03 charles Exp $";
+
+#include "yportenv.h"
+
+
+#include "yaffs_mtdif2.h"
+
+#include "linux/mtd/mtd.h"
+#include "linux/types.h"
+#include "linux/time.h"
+
+#include "yaffs_packedtags2.h"
+
+int nandmtd2_WriteChunkWithTagsToNAND(yaffs_Device * dev, int chunkInNAND,
+				      const __u8 * data,
+				      const yaffs_ExtendedTags * tags)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	struct mtd_oob_ops ops;
+#else
+	size_t dummy;
+#endif
+	int retval = 0;
+
+	loff_t addr = ((loff_t) chunkInNAND) * dev->nBytesPerChunk;
+
+	yaffs_PackedTags2 pt;
+
+	T(YAFFS_TRACE_MTD,
+	  (TSTR
+	   ("nandmtd2_WriteChunkWithTagsToNAND chunk %d data %p tags %p"
+	    TENDSTR), chunkInNAND, data, tags));
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	if (data && tags) {
+		ops.mode = MTD_OOB_AUTO;
+		ops.ooblen = yaffs_PackTags2(&pt, tags, mtd->oobavail);;
+		ops.len = dev->nBytesPerChunk;
+		ops.ooboffs = 0;
+		ops.datbuf = (__u8 *)data;
+		ops.oobbuf = (void *)&pt;
+		retval = mtd->write_oob(mtd, addr, &ops);
+	} else
+		BUG(); /* both tags and data should always be present */
+#else
+	if (tags) {
+		yaffs_PackTags2(&pt, tags, mtd->oobavail);
+	}
+
+	if (data && tags) {
+		if (dev->useNANDECC)
+			retval =
+			    mtd->write_ecc(mtd, addr, dev->nBytesPerChunk,
+					   &dummy, data, (__u8 *) & pt, NULL);
+		else
+			retval =
+			    mtd->write_ecc(mtd, addr, dev->nBytesPerChunk,
+					   &dummy, data, (__u8 *) & pt, NULL);
+	} else {
+		if (data)
+			retval =
+			    mtd->write(mtd, addr, dev->nBytesPerChunk, &dummy,
+				       data);
+		if (tags)
+			retval =
+			    mtd->write_oob(mtd, addr, mtd->oobsize, &dummy,
+					   (__u8 *) & pt);
+
+	}
+#endif
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+int nandmtd2_ReadChunkWithTagsFromNAND(yaffs_Device * dev, int chunkInNAND,
+				       __u8 * data, yaffs_ExtendedTags * tags)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	struct mtd_oob_ops ops;
+#endif
+	size_t dummy;
+	int retval = 0;
+
+	loff_t addr = ((loff_t) chunkInNAND) * dev->nBytesPerChunk;
+
+	yaffs_PackedTags2 pt;
+
+	T(YAFFS_TRACE_MTD,
+	  (TSTR
+	   ("nandmtd2_ReadChunkWithTagsFromNAND chunk %d data %p tags %p"
+	    TENDSTR), chunkInNAND, data, tags));
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	if (data && !tags)
+		retval = mtd->read(mtd, addr, dev->nBytesPerChunk,
+				&dummy, data);
+	else if (tags) {
+		ops.mode = MTD_OOB_AUTO;
+		ops.ooblen = min(sizeof(pt), mtd->oobavail);
+		ops.len = data ? dev->nBytesPerChunk : sizeof(pt);
+		ops.ooboffs = 0;
+		ops.datbuf = data;
+		ops.oobbuf = dev->spareBuffer;
+		retval = mtd->read_oob(mtd, addr, &ops);
+	}
+	memcpy(&pt, dev->spareBuffer, sizeof(pt));
+#else
+	if (data && tags) {
+		if (dev->useNANDECC) {
+			retval =
+			    mtd->read_ecc(mtd, addr, dev->nBytesPerChunk,
+					  &dummy, data, dev->spareBuffer,
+					  NULL);
+		} else {
+			retval =
+			    mtd->read_ecc(mtd, addr, dev->nBytesPerChunk,
+					  &dummy, data, dev->spareBuffer,
+					  NULL);
+		}
+		memcpy(&pt, dev->spareBuffer, sizeof(pt));
+	} else {
+		if (data)
+			retval =
+			    mtd->read(mtd, addr, dev->nBytesPerChunk, &dummy,
+				      data);
+		if (tags) {
+			retval =
+			    mtd->read_oob(mtd, addr, mtd->oobsize, &dummy,
+					  dev->spareBuffer);
+			memcpy(&pt,
+			       mtd->oobinfo.oobfree[0][0] + (char *)dev->spareBuffer,
+			       sizeof(pt));
+		}
+	}
+#endif
+
+	if (tags)
+		yaffs_UnpackTags2(tags, &pt);
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	if (retval == -EUCLEAN) {
+		if (tags) tags->eccResult = YAFFS_ECC_RESULT_FIXED;
+		retval = 0;
+	}
+#endif
+	
+	if(tags && retval == -EBADMSG && tags->eccResult == YAFFS_ECC_RESULT_NO_ERROR)
+		tags->eccResult = YAFFS_ECC_RESULT_UNFIXED;
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+int nandmtd2_MarkNANDBlockBad(struct yaffs_DeviceStruct *dev, int blockNo)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+	int retval;
+	T(YAFFS_TRACE_MTD,
+	  (TSTR("nandmtd2_MarkNANDBlockBad %d" TENDSTR), blockNo));
+
+	retval =
+	    mtd->block_markbad(mtd,
+			       blockNo * dev->nChunksPerBlock *
+			       dev->nBytesPerChunk);
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+
+}
+
+int nandmtd2_QueryNANDBlock(struct yaffs_DeviceStruct *dev, int blockNo,
+			    yaffs_BlockState * state, int *sequenceNumber)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+	int retval;
+
+	T(YAFFS_TRACE_MTD,
+	  (TSTR("nandmtd2_QueryNANDBlock %d" TENDSTR), blockNo));
+	retval =
+	    mtd->block_isbad(mtd,
+			     blockNo * dev->nChunksPerBlock *
+			     dev->nBytesPerChunk);
+
+	if (retval) {
+		T(YAFFS_TRACE_MTD, (TSTR("block is bad" TENDSTR)));
+
+		*state = YAFFS_BLOCK_STATE_DEAD;
+		*sequenceNumber = 0;
+	} else {
+		yaffs_ExtendedTags t;
+		nandmtd2_ReadChunkWithTagsFromNAND(dev,
+						   blockNo *
+						   dev->nChunksPerBlock, NULL,
+						   &t);
+
+		if (t.chunkUsed) {
+			*sequenceNumber = t.sequenceNumber;
+			*state = YAFFS_BLOCK_STATE_NEEDS_SCANNING;
+		} else {
+			*sequenceNumber = 0;
+			*state = YAFFS_BLOCK_STATE_EMPTY;
+		}
+	}
+	T(YAFFS_TRACE_MTD,
+	  (TSTR("block is bad seq %d state %d" TENDSTR), *sequenceNumber,
+	   *state));
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_mtdif2.h linux/fs/yaffs/yaffs_mtdif2.h
--- linux-2.6.35/fs/yaffs/yaffs_mtdif2.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_mtdif2.h	2011-05-02 10:08:28.111545091 +0300
@@ -0,0 +1,29 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_mtdif.c  NAND mtd wrapper functions.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef __YAFFS_MTDIF2_H__
+#define __YAFFS_MTDIF2_H__
+
+#include "yaffs_guts.h"
+int nandmtd2_WriteChunkWithTagsToNAND(yaffs_Device * dev, int chunkInNAND,
+				      const __u8 * data,
+				      const yaffs_ExtendedTags * tags);
+int nandmtd2_ReadChunkWithTagsFromNAND(yaffs_Device * dev, int chunkInNAND,
+				       __u8 * data, yaffs_ExtendedTags * tags);
+int nandmtd2_MarkNANDBlockBad(struct yaffs_DeviceStruct *dev, int blockNo);
+int nandmtd2_QueryNANDBlock(struct yaffs_DeviceStruct *dev, int blockNo,
+			    yaffs_BlockState * state, int *sequenceNumber);
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_mtdif.c linux/fs/yaffs/yaffs_mtdif.c
--- linux-2.6.35/fs/yaffs/yaffs_mtdif.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_mtdif.c	2011-05-02 10:08:28.121589181 +0300
@@ -0,0 +1,241 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_mtdif.c  NAND mtd wrapper functions.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+const char *yaffs_mtdif_c_version =
+    "$Id: yaffs_mtdif.c,v 1.15 2006/10/03 10:13:03 charles Exp $";
+
+#include "yportenv.h"
+
+
+#include "yaffs_mtdif.h"
+
+#include "linux/mtd/mtd.h"
+#include "linux/types.h"
+#include "linux/time.h"
+#include "linux/mtd/nand.h"
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,18))
+static struct nand_oobinfo yaffs_oobinfo = {
+	.useecc = 1,
+	.eccbytes = 6,
+	.eccpos = {8, 9, 10, 13, 14, 15}
+};
+
+static struct nand_oobinfo yaffs_noeccinfo = {
+	.useecc = 0,
+};
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+static inline void translate_spare2oob(const yaffs_Spare *spare, __u8 *oob)
+{
+	oob[0] = spare->tagByte0;
+	oob[1] = spare->tagByte1;
+	oob[2] = spare->tagByte2;
+	oob[3] = spare->tagByte3;
+	oob[4] = spare->tagByte4;
+	oob[5] = spare->tagByte5 & 0x3f;
+	oob[5] |= spare->blockStatus == 'Y' ? 0: 0x80;
+	oob[5] |= spare->pageStatus == 0 ? 0: 0x40;
+	oob[6] = spare->tagByte6;
+	oob[7] = spare->tagByte7;
+}
+
+static inline void translate_oob2spare(yaffs_Spare *spare, __u8 *oob)
+{
+	struct yaffs_NANDSpare *nspare = (struct yaffs_NANDSpare *)spare;
+	spare->tagByte0 = oob[0];
+	spare->tagByte1 = oob[1];
+	spare->tagByte2 = oob[2];
+	spare->tagByte3 = oob[3];
+	spare->tagByte4 = oob[4];
+	spare->tagByte5 = oob[5] == 0xff ? 0xff : oob[5] & 0x3f;
+	spare->blockStatus = oob[5] & 0x80 ? 0xff : 'Y';
+	spare->pageStatus = oob[5] & 0x40 ? 0xff : 0;
+	spare->tagByte6 = oob[6];
+	spare->tagByte7 = oob[7];
+
+	nspare->eccres1 = nspare->eccres2 = 0; /* FIXME */
+}
+#endif
+
+int nandmtd_WriteChunkToNAND(yaffs_Device * dev, int chunkInNAND,
+			     const __u8 * data, const yaffs_Spare * spare)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	struct mtd_oob_ops ops;
+#endif
+	size_t dummy;
+	int retval = 0;
+
+	loff_t addr = ((loff_t) chunkInNAND) * dev->nBytesPerChunk;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	if (data && !spare)
+		retval = mtd->write(mtd, addr, dev->nBytesPerChunk,
+				&dummy, data);
+	else if (spare) {
+		if (dev->useNANDECC) {
+			ops.mode = MTD_OOB_PLACE;
+			ops.ooblen = YAFFS_BYTES_PER_SPARE;
+		} else {
+			ops.mode = MTD_OOB_RAW;
+			ops.ooblen = YAFFS_BYTES_PER_SPARE;
+		}
+		ops.len = data ? dev->nBytesPerChunk : YAFFS_BYTES_PER_SPARE;
+		ops.datbuf = (u8 *)data;
+		ops.ooboffs = 0;
+		ops.oobbuf = (char *) spare;
+		retval = mtd->write_oob(mtd, addr, &ops);
+	}
+#else
+	__u8 *spareAsBytes = (__u8 *) spare;
+
+	if (data && spare) {
+		if (dev->useNANDECC)
+			retval =
+			    mtd->write_ecc(mtd, addr, dev->nBytesPerChunk,
+					   &dummy, data, spareAsBytes,
+					   &yaffs_oobinfo);
+		else
+			retval =
+			    mtd->write_ecc(mtd, addr, dev->nBytesPerChunk,
+					   &dummy, data, spareAsBytes,
+					   &yaffs_noeccinfo);
+	} else {
+		if (data)
+			retval =
+			    mtd->write(mtd, addr, dev->nBytesPerChunk, &dummy,
+				       data);
+		if (spare)
+			retval =
+			    mtd->write_oob(mtd, addr, YAFFS_BYTES_PER_SPARE,
+					   &dummy, spareAsBytes);
+	}
+#endif
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+int nandmtd_ReadChunkFromNAND(yaffs_Device * dev, int chunkInNAND, __u8 * data,
+			      yaffs_Spare * spare)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	struct mtd_oob_ops ops;
+#endif
+	size_t dummy;
+	int retval = 0;
+
+	loff_t addr = ((loff_t) chunkInNAND) * dev->nBytesPerChunk;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,6,17))
+	if (data && !spare)
+		retval = mtd->read(mtd, addr, dev->nBytesPerChunk,
+				&dummy, data);
+	else if (spare) {
+		if (dev->useNANDECC) {
+			ops.mode = MTD_OOB_PLACE;
+			ops.ooblen = YAFFS_BYTES_PER_SPARE;
+		} else {
+			ops.mode = MTD_OOB_RAW;
+			ops.ooblen = YAFFS_BYTES_PER_SPARE;
+		}
+		ops.len = data ? dev->nBytesPerChunk : YAFFS_BYTES_PER_SPARE;
+		ops.datbuf = data;
+		ops.ooboffs = 0;
+		ops.oobbuf = (char *) spare;
+		retval = mtd->read_oob(mtd, addr, &ops);
+
+		if (dev->useNANDECC) {
+			struct yaffs_NANDSpare *nspare = (struct yaffs_NANDSpare *)spare;
+			nspare->eccres1 = nspare->eccres2 =
+			    (retval == 0) ? 0 : ((retval == -EUCLEAN) ? 1 : -1);
+		}
+	}
+	if (retval == -EUCLEAN) retval = 0;
+#else
+	__u8 *spareAsBytes = (__u8 *) spare;
+
+	if (data && spare) {
+		if (dev->useNANDECC) {	
+			/* Careful, this call adds 2 ints */
+			/* to the end of the spare data.  Calling function */
+			/* should allocate enough memory for spare, */
+			/* i.e. [YAFFS_BYTES_PER_SPARE+2*sizeof(int)]. */
+			retval =
+			    mtd->read_ecc(mtd, addr, dev->nBytesPerChunk,
+					  &dummy, data, spareAsBytes,
+					  &yaffs_oobinfo);
+		} else {
+			retval =
+			    mtd->read_ecc(mtd, addr, dev->nBytesPerChunk,
+					  &dummy, data, spareAsBytes,
+					  &yaffs_noeccinfo);
+		}
+	} else {
+		if (data)
+			retval =
+			    mtd->read(mtd, addr, dev->nBytesPerChunk, &dummy,
+				      data);
+		if (spare)
+			retval =
+			    mtd->read_oob(mtd, addr, YAFFS_BYTES_PER_SPARE,
+					  &dummy, spareAsBytes);
+	}
+#endif
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+int nandmtd_EraseBlockInNAND(yaffs_Device * dev, int blockNumber)
+{
+	struct mtd_info *mtd = (struct mtd_info *)(dev->genericDevice);
+	__u32 addr =
+	    ((loff_t) blockNumber) * dev->nBytesPerChunk
+		* dev->nChunksPerBlock;
+	struct erase_info ei;
+	int retval = 0;
+
+	ei.mtd = mtd;
+	ei.addr = addr;
+	ei.len = dev->nBytesPerChunk * dev->nChunksPerBlock;
+	ei.time = 1000;
+	ei.retries = 2;
+	ei.callback = NULL;
+	ei.priv = (u_long) dev;
+
+	/* Todo finish off the ei if required */
+
+	sema_init(&dev->sem, 0);
+
+	retval = mtd->erase(mtd, &ei);
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+int nandmtd_InitialiseNAND(yaffs_Device * dev)
+{
+	return YAFFS_OK;
+}
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_mtdif.h linux/fs/yaffs/yaffs_mtdif.h
--- linux-2.6.35/fs/yaffs/yaffs_mtdif.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_mtdif.h	2011-05-02 10:08:28.131590558 +0300
@@ -0,0 +1,31 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_mtdif.h  NAND mtd interface wrappers
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ * $Id: yaffs_mtdif.h,v 1.3 2005/08/11 01:07:43 marty Exp $
+ */
+
+#ifndef __YAFFS_MTDIF_H__
+#define __YAFFS_MTDIF_H__
+
+#include "yaffs_guts.h"
+
+int nandmtd_WriteChunkToNAND(yaffs_Device * dev, int chunkInNAND,
+			     const __u8 * data, const yaffs_Spare * spare);
+int nandmtd_ReadChunkFromNAND(yaffs_Device * dev, int chunkInNAND, __u8 * data,
+			      yaffs_Spare * spare);
+int nandmtd_EraseBlockInNAND(yaffs_Device * dev, int blockNumber);
+int nandmtd_InitialiseNAND(yaffs_Device * dev);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_nand.c linux/fs/yaffs/yaffs_nand.c
--- linux-2.6.35/fs/yaffs/yaffs_nand.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_nand.c	2011-05-02 10:08:28.151592347 +0300
@@ -0,0 +1,157 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+ 
+const char *yaffs_nand_c_version =
+    "$Id: yaffs_nand.c,v 1.1 2006/05/08 10:13:34 charles Exp $";
+
+#include "yaffs_nand.h"
+#include "yaffs_tagscompat.h"
+#include "yaffs_tagsvalidity.h"
+
+
+static int yaffs_ReadCDataWithTagsFromNAND(yaffs_Device * dev, int chunkInNAND,
+					   __u8 * buffer,
+					   yaffs_ExtendedTags * tags)
+{
+	chunkInNAND -= dev->chunkOffset;
+
+	dev->nPageReads++;
+
+	if (dev->readChunkWithTagsFromNAND)
+		return dev->readChunkWithTagsFromNAND(dev, chunkInNAND, buffer,
+						      tags);
+	else
+		return yaffs_TagsCompatabilityReadChunkWithTagsFromNAND(dev,
+									chunkInNAND,
+									buffer,
+									tags);
+}
+
+int yaffs_ReadChunkWithTagsFromNAND(yaffs_Device * dev, int chunkInNAND,
+				    __u8 * buffer,
+				    yaffs_ExtendedTags * tags)
+{
+	int retVal = yaffs_ReadCDataWithTagsFromNAND(dev, chunkInNAND,
+						     buffer, tags);
+	if (retVal == YAFFS_FAIL) {
+		yaffs_HandleReadDataError(dev, chunkInNAND, 0);
+
+		/* retry reading - may succeed in case of soft error */
+		retVal = yaffs_ReadCDataWithTagsFromNAND(dev, chunkInNAND,
+							 buffer, tags);
+		if (retVal == YAFFS_FAIL) {
+			retVal = yaffs_ReadCDataWithTagsFromNAND(dev,
+								 chunkInNAND,
+								 buffer, tags);
+		}
+		if (retVal == YAFFS_OK) {
+			T(YAFFS_TRACE_ERROR,
+			  (TSTR
+			   ("**>>succeeded to read chunk %d after read error"
+			    TENDSTR), chunkInNAND - dev->chunkOffset));
+		}
+	}
+	else if (tags != NULL && tags->eccResult == YAFFS_ECC_RESULT_FIXED) {
+		yaffs_HandleReadDataError(dev, chunkInNAND, 1);
+	}
+	return retVal;
+}
+
+int yaffs_WriteChunkWithTagsToNAND(yaffs_Device * dev,
+						   int chunkInNAND,
+						   const __u8 * buffer,
+						   yaffs_ExtendedTags * tags)
+{
+	chunkInNAND -= dev->chunkOffset;
+
+	
+	if (tags) {
+		tags->sequenceNumber = dev->sequenceNumber;
+		tags->chunkUsed = 1;
+		if (!yaffs_ValidateTags(tags)) {
+			T(YAFFS_TRACE_ERROR,
+			  (TSTR("Writing uninitialised tags" TENDSTR)));
+			YBUG();
+		}
+		T(YAFFS_TRACE_WRITE,
+		  (TSTR("Writing chunk %d tags %d %d" TENDSTR), chunkInNAND,
+		   tags->objectId, tags->chunkId));
+	} else {
+		T(YAFFS_TRACE_ERROR, (TSTR("Writing with no tags" TENDSTR)));
+		YBUG();
+	}
+
+	dev->nPageWrites++;
+
+	if (dev->writeChunkWithTagsToNAND)
+		return dev->writeChunkWithTagsToNAND(dev, chunkInNAND, buffer,
+						     tags);
+	else
+		return yaffs_TagsCompatabilityWriteChunkWithTagsToNAND(dev,
+								       chunkInNAND,
+								       buffer,
+								       tags);
+}
+
+int yaffs_MarkBlockBad(yaffs_Device * dev, int blockNo)
+{
+	blockNo -= dev->blockOffset;
+
+;
+	if (dev->markNANDBlockBad)
+		return dev->markNANDBlockBad(dev, blockNo);
+	else
+		return yaffs_TagsCompatabilityMarkNANDBlockBad(dev, blockNo);
+}
+
+int yaffs_QueryInitialBlockState(yaffs_Device * dev,
+						 int blockNo,
+						 yaffs_BlockState * state,
+						 unsigned *sequenceNumber)
+{
+	blockNo -= dev->blockOffset;
+
+	if (dev->queryNANDBlock)
+		return dev->queryNANDBlock(dev, blockNo, state, sequenceNumber);
+	else
+		return yaffs_TagsCompatabilityQueryNANDBlock(dev, blockNo,
+							     state,
+							     sequenceNumber);
+}
+
+
+int yaffs_EraseBlockInNAND(struct yaffs_DeviceStruct *dev,
+				  int blockInNAND)
+{
+	int result;
+
+	blockInNAND -= dev->blockOffset;
+
+
+	dev->nBlockErasures++;
+	result = dev->eraseBlockInNAND(dev, blockInNAND);
+
+	/* If at first we don't succeed, try again *once*.*/
+	if (!result)
+		result = dev->eraseBlockInNAND(dev, blockInNAND);	
+	return result;
+}
+
+int yaffs_InitialiseNAND(struct yaffs_DeviceStruct *dev)
+{
+	return dev->initialiseNAND(dev);
+}
+
+
+ 
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_nandemul2k.h linux/fs/yaffs/yaffs_nandemul2k.h
--- linux-2.6.35/fs/yaffs/yaffs_nandemul2k.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_nandemul2k.h	2011-05-02 10:08:28.161590310 +0300
@@ -0,0 +1,42 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ * yaffs_nandemul2k.h: Interface to emulated NAND functions (2k page size)
+ *
+ * $Id: yaffs_nandemul2k.h,v 1.2 2005/08/11 02:37:49 marty Exp $
+ */
+
+#ifndef __YAFFS_NANDEMUL2K_H__
+#define __YAFFS_NANDEMUL2K_H__
+
+#include "yaffs_guts.h"
+
+int nandemul2k_WriteChunkWithTagsToNAND(struct yaffs_DeviceStruct *dev,
+					int chunkInNAND, const __u8 * data,
+					yaffs_ExtendedTags * tags);
+int nandemul2k_ReadChunkWithTagsFromNAND(struct yaffs_DeviceStruct *dev,
+					 int chunkInNAND, __u8 * data,
+					 yaffs_ExtendedTags * tags);
+int nandemul2k_MarkNANDBlockBad(struct yaffs_DeviceStruct *dev, int blockNo);
+int nandemul2k_QueryNANDBlock(struct yaffs_DeviceStruct *dev, int blockNo,
+			      yaffs_BlockState * state, int *sequenceNumber);
+int nandemul2k_EraseBlockInNAND(struct yaffs_DeviceStruct *dev,
+				int blockInNAND);
+int nandemul2k_InitialiseNAND(struct yaffs_DeviceStruct *dev);
+int nandemul2k_GetBytesPerChunk(void);
+int nandemul2k_GetChunksPerBlock(void);
+int nandemul2k_GetNumberOfBlocks(void);
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_nand.h linux/fs/yaffs/yaffs_nand.h
--- linux-2.6.35/fs/yaffs/yaffs_nand.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_nand.h	2011-05-02 10:08:28.171545242 +0300
@@ -0,0 +1,43 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#ifndef __YAFFS_NAND_H__
+#define __YAFFS_NAND_H__
+#include "yaffs_guts.h"
+
+
+
+int yaffs_ReadChunkWithTagsFromNAND(yaffs_Device * dev, int chunkInNAND,
+					   __u8 * buffer,
+					   yaffs_ExtendedTags * tags);
+
+int yaffs_WriteChunkWithTagsToNAND(yaffs_Device * dev,
+						   int chunkInNAND,
+						   const __u8 * buffer,
+						   yaffs_ExtendedTags * tags);
+
+int yaffs_MarkBlockBad(yaffs_Device * dev, int blockNo);
+
+int yaffs_QueryInitialBlockState(yaffs_Device * dev,
+						 int blockNo,
+						 yaffs_BlockState * state,
+						 unsigned *sequenceNumber);
+
+int yaffs_EraseBlockInNAND(struct yaffs_DeviceStruct *dev,
+				  int blockInNAND);
+
+int yaffs_InitialiseNAND(struct yaffs_DeviceStruct *dev);
+
+#endif
+
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_packedtags1.c linux/fs/yaffs/yaffs_packedtags1.c
--- linux-2.6.35/fs/yaffs/yaffs_packedtags1.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_packedtags1.c	2011-05-02 10:08:28.181592430 +0300
@@ -0,0 +1,39 @@
+#include "yaffs_packedtags1.h"
+#include "yportenv.h"
+
+void yaffs_PackTags1(yaffs_PackedTags1 * pt, const yaffs_ExtendedTags * t)
+{
+	pt->chunkId = t->chunkId;
+	pt->serialNumber = t->serialNumber;
+	pt->byteCount = t->byteCount;
+	pt->objectId = t->objectId;
+	pt->ecc = 0;
+	pt->deleted = (t->chunkDeleted) ? 0 : 1;
+	pt->unusedStuff = 0;
+	pt->shouldBeFF = 0xFFFFFFFF;
+
+}
+
+void yaffs_UnpackTags1(yaffs_ExtendedTags * t, const yaffs_PackedTags1 * pt)
+{
+	static const __u8 allFF[] =
+	    { 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+0xff };
+
+	if (memcmp(allFF, pt, sizeof(yaffs_PackedTags1))) {
+		t->blockBad = 0;
+		if (pt->shouldBeFF != 0xFFFFFFFF) {
+			t->blockBad = 1;
+		}
+		t->chunkUsed = 1;
+		t->objectId = pt->objectId;
+		t->chunkId = pt->chunkId;
+		t->byteCount = pt->byteCount;
+		t->eccResult = YAFFS_ECC_RESULT_NO_ERROR;
+		t->chunkDeleted = (pt->deleted) ? 0 : 1;
+		t->serialNumber = pt->serialNumber;
+	} else {
+		memset(t, 0, sizeof(yaffs_ExtendedTags));
+
+	}
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_packedtags1.h linux/fs/yaffs/yaffs_packedtags1.h
--- linux-2.6.35/fs/yaffs/yaffs_packedtags1.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_packedtags1.h	2011-05-02 10:08:28.191589658 +0300
@@ -0,0 +1,22 @@
+// This is used to pack YAFFS1 tags, not YAFFS2 tags.
+
+#ifndef __YAFFS_PACKEDTAGS1_H__
+#define __YAFFS_PACKEDTAGS1_H__
+
+#include "yaffs_guts.h"
+
+typedef struct {
+	unsigned chunkId:20;
+	unsigned serialNumber:2;
+	unsigned byteCount:10;
+	unsigned objectId:18;
+	unsigned ecc:12;
+	unsigned deleted:1;
+	unsigned unusedStuff:1;
+	unsigned shouldBeFF;
+
+} yaffs_PackedTags1;
+
+void yaffs_PackTags1(yaffs_PackedTags1 * pt, const yaffs_ExtendedTags * t);
+void yaffs_UnpackTags1(yaffs_ExtendedTags * t, const yaffs_PackedTags1 * pt);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_packedtags2.c linux/fs/yaffs/yaffs_packedtags2.c
--- linux-2.6.35/fs/yaffs/yaffs_packedtags2.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_packedtags2.c	2011-05-02 10:08:28.211591344 +0300
@@ -0,0 +1,195 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * yaffs_packedtags2.c: Tags packing for YAFFS2
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public License
+ * version 2.1 as published by the Free Software Foundation.
+ */
+
+#include "yaffs_packedtags2.h"
+#include "yportenv.h"
+#include "yaffs_tagsvalidity.h"
+
+/* This code packs a set of extended tags into a binary structure for
+ * NAND storage
+ */
+
+/* Some of the information is "extra" struff which can be packed in to
+ * speed scanning
+ * This is defined by having the EXTRA_HEADER_INFO_FLAG set.
+ */
+
+/* Extra flags applied to chunkId */
+
+#define EXTRA_HEADER_INFO_FLAG	0x80000000
+#define EXTRA_SHRINK_FLAG	0x40000000
+#define EXTRA_SHADOWS_FLAG	0x20000000
+#define EXTRA_SPARE_FLAGS	0x10000000
+
+#define ALL_EXTRA_FLAGS		0xF0000000
+
+/* Also, the top 4 bits of the object Id are set to the object type. */
+#define EXTRA_OBJECT_TYPE_SHIFT (28)
+#define EXTRA_OBJECT_TYPE_MASK  ((0x0F) << EXTRA_OBJECT_TYPE_SHIFT)
+
+static void yaffs_DumpPackedTags2(const yaffs_PackedTags2 * pt)
+{
+	T(YAFFS_TRACE_MTD,
+	  (TSTR("packed tags obj %d chunk %d byte %d seq %d" TENDSTR),
+	   pt->t.objectId, pt->t.chunkId, pt->t.byteCount,
+	   pt->t.sequenceNumber));
+}
+
+static void yaffs_DumpTags2(const yaffs_ExtendedTags * t)
+{
+	T(YAFFS_TRACE_MTD,
+	  (TSTR
+	   ("ext.tags eccres %d blkbad %d chused %d obj %d chunk%d byte "
+	    "%d del %d ser %d seq %d"
+	    TENDSTR), t->eccResult, t->blockBad, t->chunkUsed, t->objectId,
+	   t->chunkId, t->byteCount, t->chunkDeleted, t->serialNumber,
+	   t->sequenceNumber));
+
+}
+
+int yaffs_PackTags2(yaffs_PackedTags2 * pt, const yaffs_ExtendedTags * t,
+		    unsigned maxPackedSize)
+{
+	pt->t.chunkId = t->chunkId;
+	pt->t.sequenceNumber = t->sequenceNumber;
+	pt->t.byteCount = t->byteCount;
+	pt->t.objectId = t->objectId;
+
+	if (t->chunkId == 0 && t->extraHeaderInfoAvailable) {
+		/* Store the extra header info instead */
+		/* We save the parent object in the chunkId */
+		pt->t.chunkId = EXTRA_HEADER_INFO_FLAG
+			| t->extraParentObjectId;
+		if (t->extraIsShrinkHeader) {
+			pt->t.chunkId |= EXTRA_SHRINK_FLAG;
+		}
+		if (t->extraShadows) {
+			pt->t.chunkId |= EXTRA_SHADOWS_FLAG;
+		}
+
+		pt->t.objectId &= ~EXTRA_OBJECT_TYPE_MASK;
+		pt->t.objectId |=
+		    (t->extraObjectType << EXTRA_OBJECT_TYPE_SHIFT);
+
+		if (t->extraObjectType == YAFFS_OBJECT_TYPE_HARDLINK) {
+			pt->t.byteCount = t->extraEquivalentObjectId;
+		} else if (t->extraObjectType == YAFFS_OBJECT_TYPE_FILE) {
+			pt->t.byteCount = t->extraFileLength;
+		} else {
+			pt->t.byteCount = 0;
+		}
+	}
+
+	yaffs_DumpPackedTags2(pt);
+	yaffs_DumpTags2(t);
+
+#ifndef YAFFS_IGNORE_TAGS_ECC
+	if (maxPackedSize < sizeof(yaffs_PackedTags2)) {
+		*(5 + (unsigned char *)&pt->ecc) = 0x55;
+		yaffs_ECCCalculateMLCOther((unsigned char *)&pt->t);
+		return maxPackedSize;
+	}
+	else
+	{
+		yaffs_ECCCalculateOther((unsigned char *)&pt->t,
+					sizeof(yaffs_PackedTags2TagsPart),
+					&pt->ecc);
+		return sizeof(yaffs_PackedTags2);
+	}
+#endif
+}
+
+static int count_bits(unsigned char val) {
+	int res = 0;
+	if (val == 0) return 0;
+	if (val == 0x55 || val == 0xaa) return 4;
+
+	for ( ; val != 0; val >>= 1) {
+		res += val & 1;
+	}
+	return res;
+}
+
+void yaffs_UnpackTags2(yaffs_ExtendedTags * t, yaffs_PackedTags2 * pt)
+{
+
+	memset(t, 0, sizeof(yaffs_ExtendedTags));
+
+	yaffs_InitialiseTags(t);
+
+	if (pt->t.sequenceNumber != 0xFFFFFFFF) {
+		/* Page is in use */
+#ifdef YAFFS_IGNORE_TAGS_ECC
+		{
+			t->eccResult = 0;
+		}
+#else
+		uint8_t mecc = *(5 + (unsigned char *)&pt->ecc) ^ 0x55;
+		if (count_bits(mecc) <= 2) {
+			t->eccResult =
+			    yaffs_ECCCorrectMLCOther((unsigned char *)&pt->t);
+		}
+		else
+		{
+			yaffs_ECCOther ecc;
+			yaffs_ECCCalculateOther((unsigned char *)&pt->t,
+						sizeof
+						(yaffs_PackedTags2TagsPart),
+						&ecc);
+			t->eccResult =
+			    yaffs_ECCCorrectOther((unsigned char *)&pt->t,
+						  sizeof
+						  (yaffs_PackedTags2TagsPart),
+						  &pt->ecc, &ecc);
+		}
+#endif
+		t->blockBad = 0;
+		t->chunkUsed = 1;
+		t->objectId = pt->t.objectId;
+		t->chunkId = pt->t.chunkId;
+		t->byteCount = pt->t.byteCount;
+		t->chunkDeleted = 0;
+		t->serialNumber = 0;
+		t->sequenceNumber = pt->t.sequenceNumber;
+
+		/* Do extra header info stuff */
+
+		if (pt->t.chunkId & EXTRA_HEADER_INFO_FLAG) {
+			t->chunkId = 0;
+			t->byteCount = 0;
+
+			t->extraHeaderInfoAvailable = 1;
+			t->extraParentObjectId =
+			    pt->t.chunkId & (~(ALL_EXTRA_FLAGS));
+			t->extraIsShrinkHeader =
+			    (pt->t.chunkId & EXTRA_SHRINK_FLAG) ? 1 : 0;
+			t->extraShadows =
+			    (pt->t.chunkId & EXTRA_SHADOWS_FLAG) ? 1 : 0;
+			t->extraObjectType =
+			    pt->t.objectId >> EXTRA_OBJECT_TYPE_SHIFT;
+			t->objectId &= ~EXTRA_OBJECT_TYPE_MASK;
+
+			if (t->extraObjectType == YAFFS_OBJECT_TYPE_HARDLINK) {
+				t->extraEquivalentObjectId = pt->t.byteCount;
+			} else {
+				t->extraFileLength = pt->t.byteCount;
+			}
+		}
+	}
+
+	yaffs_DumpPackedTags2(pt);
+	yaffs_DumpTags2(t);
+
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_packedtags2.h linux/fs/yaffs/yaffs_packedtags2.h
--- linux-2.6.35/fs/yaffs/yaffs_packedtags2.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_packedtags2.h	2011-05-02 10:08:28.221586478 +0300
@@ -0,0 +1,25 @@
+/* This is used to pack YAFFS2 tags, not YAFFS1tags. */
+
+#ifndef __YAFFS_PACKEDTAGS2_H__
+#define __YAFFS_PACKEDTAGS2_H__
+
+#include "yaffs_guts.h"
+#include "yaffs_ecc.h"
+#include "yaffs_ecc_mlc.h"
+
+typedef struct {
+	unsigned sequenceNumber;
+	unsigned objectId;
+	unsigned chunkId;
+	unsigned byteCount;
+} yaffs_PackedTags2TagsPart;
+
+typedef struct {
+	yaffs_PackedTags2TagsPart t;
+	yaffs_ECCOther ecc;
+} yaffs_PackedTags2;
+
+int yaffs_PackTags2(yaffs_PackedTags2 * pt, const yaffs_ExtendedTags * t,
+		    unsigned maxPackedSize);
+void yaffs_UnpackTags2(yaffs_ExtendedTags * t, yaffs_PackedTags2 * pt);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_qsort.c linux/fs/yaffs/yaffs_qsort.c
--- linux-2.6.35/fs/yaffs/yaffs_qsort.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_qsort.c	2011-05-02 10:08:28.231544545 +0300
@@ -0,0 +1,158 @@
+/*
+ * Copyright (c) 1992, 1993
+ *	The Regents of the University of California.  All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+#include "yportenv.h"
+//#include <linux/string.h>
+#undef swap
+
+/*
+ * Qsort routine from Bentley & McIlroy's "Engineering a Sort Function".
+ */
+#define swapcode(TYPE, parmi, parmj, n) { 		\
+	long i = (n) / sizeof (TYPE); 			\
+	register TYPE *pi = (TYPE *) (parmi); 		\
+	register TYPE *pj = (TYPE *) (parmj); 		\
+	do { 						\
+		register TYPE	t = *pi;		\
+		*pi++ = *pj;				\
+		*pj++ = t;				\
+        } while (--i > 0);				\
+}
+
+#define SWAPINIT(a, es) swaptype = ((char *)a - (char *)0) % sizeof(long) || \
+	es % sizeof(long) ? 2 : es == sizeof(long)? 0 : 1;
+
+static __inline void
+swapfunc(char *a, char *b, int n, int swaptype)
+{
+	if (swaptype <= 1) 
+		swapcode(long, a, b, n)
+	else
+		swapcode(char, a, b, n)
+}
+
+#define swap(a, b)					\
+	if (swaptype == 0) {				\
+		long t = *(long *)(a);			\
+		*(long *)(a) = *(long *)(b);		\
+		*(long *)(b) = t;			\
+	} else						\
+		swapfunc(a, b, es, swaptype)
+
+#define vecswap(a, b, n) 	if ((n) > 0) swapfunc(a, b, n, swaptype)
+
+static __inline char *
+med3(char *a, char *b, char *c, int (*cmp)(const void *, const void *))
+{
+	return cmp(a, b) < 0 ?
+	       (cmp(b, c) < 0 ? b : (cmp(a, c) < 0 ? c : a ))
+              :(cmp(b, c) > 0 ? b : (cmp(a, c) < 0 ? a : c ));
+}
+
+#undef min
+#define min(a,b) (((a) < (b)) ? (a) : (b))
+void
+qsort(void *aa, size_t n, size_t es, int (*cmp)(const void *, const void *))
+{
+	char *pa, *pb, *pc, *pd, *pl, *pm, *pn;
+	int d, r, swaptype, swap_cnt;
+	register char *a = aa;
+
+loop:	SWAPINIT(a, es);
+	swap_cnt = 0;
+	if (n < 7) {
+		for (pm = (char *)a + es; pm < (char *) a + n * es; pm += es)
+			for (pl = pm; pl > (char *) a && cmp(pl - es, pl) > 0;
+			     pl -= es)
+				swap(pl, pl - es);
+		return;
+	}
+	pm = (char *)a + (n / 2) * es;
+	if (n > 7) {
+		pl = (char *)a;
+		pn = (char *)a + (n - 1) * es;
+		if (n > 40) {
+			d = (n / 8) * es;
+			pl = med3(pl, pl + d, pl + 2 * d, cmp);
+			pm = med3(pm - d, pm, pm + d, cmp);
+			pn = med3(pn - 2 * d, pn - d, pn, cmp);
+		}
+		pm = med3(pl, pm, pn, cmp);
+	}
+	swap(a, pm);
+	pa = pb = (char *)a + es;
+
+	pc = pd = (char *)a + (n - 1) * es;
+	for (;;) {
+		while (pb <= pc && (r = cmp(pb, a)) <= 0) {
+			if (r == 0) {
+				swap_cnt = 1;
+				swap(pa, pb);
+				pa += es;
+			}
+			pb += es;
+		}
+		while (pb <= pc && (r = cmp(pc, a)) >= 0) {
+			if (r == 0) {
+				swap_cnt = 1;
+				swap(pc, pd);
+				pd -= es;
+			}
+			pc -= es;
+		}
+		if (pb > pc)
+			break;
+		swap(pb, pc);
+		swap_cnt = 1;
+		pb += es;
+		pc -= es;
+	}
+	if (swap_cnt == 0) {  /* Switch to insertion sort */
+		for (pm = (char *) a + es; pm < (char *) a + n * es; pm += es)
+			for (pl = pm; pl > (char *) a && cmp(pl - es, pl) > 0; 
+			     pl -= es)
+				swap(pl, pl - es);
+		return;
+	}
+
+	pn = (char *)a + n * es;
+	r = min(pa - (char *)a, pb - pa);
+	vecswap(a, pb - r, r);
+	r = min((long)(pd - pc), (long)(pn - pd - es));
+	vecswap(pb, pn - r, r);
+	if ((r = pb - pa) > es)
+		qsort(a, r / es, es, cmp);
+	if ((r = pd - pc) > es) { 
+		/* Iterate rather than recurse to save stack space */
+		a = pn - r;
+		n = r / es;
+		goto loop;
+	}
+/*		qsort(pn - r, r / es, es, cmp);*/
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_qsort.h linux/fs/yaffs/yaffs_qsort.h
--- linux-2.6.35/fs/yaffs/yaffs_qsort.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_qsort.h	2011-05-02 10:08:28.241589406 +0300
@@ -0,0 +1,41 @@
+/*
+ * Copyright (c) 2000-2002 Silicon Graphics, Inc.  All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it would be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ *
+ * Further, this software is distributed without any warranty that it is
+ * free of the rightful claim of any third person regarding infringement
+ * or the like.  Any license provided herein, whether implied or
+ * otherwise, applies only to this software file.  Patent licenses, if
+ * any, provided herein do not apply to combinations of this program with
+ * other software, or any other product whatsoever.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write the Free Software Foundation, Inc., 59
+ * Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ *
+ * Contact information: Silicon Graphics, Inc., 1600 Amphitheatre Pkwy,
+ * Mountain View, CA  94043, or:
+ *
+ * http://www.sgi.com
+ *
+ * For further information regarding this notice, see:
+ *
+ * http://oss.sgi.com/projects/GenInfo/SGIGPLNoticeExplan/
+ */
+
+#ifndef QSORT_H
+#define QSORT_H
+
+extern void qsort (void *const pbase,
+		    size_t total_elems,
+		    size_t size,
+		    int (*cmp)(const void *, const void *));
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_tagscompat.c linux/fs/yaffs/yaffs_tagscompat.c
--- linux-2.6.35/fs/yaffs/yaffs_tagscompat.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_tagscompat.c	2011-05-02 10:08:28.251592085 +0300
@@ -0,0 +1,508 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_tagscompat.h: Tags compatability layer to use YAFFS1 formatted NAND.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * $Id: yaffs_tagscompat.c,v 1.8 2005/11/29 20:54:32 marty Exp $
+ */
+
+#include "yaffs_guts.h"
+#include "yaffs_tagscompat.h"
+#include "yaffs_ecc.h"
+
+#ifdef NOTYET
+static void yaffs_CheckWrittenBlock(yaffs_Device * dev, int chunkInNAND);
+static void yaffs_HandleWriteChunkOk(yaffs_Device * dev, int chunkInNAND,
+				     const __u8 * data,
+				     const yaffs_Spare * spare);
+static void yaffs_HandleUpdateChunk(yaffs_Device * dev, int chunkInNAND,
+				    const yaffs_Spare * spare);
+static void yaffs_HandleWriteChunkError(yaffs_Device * dev, int chunkInNAND);
+#endif
+
+static const char yaffs_countBitsTable[256] = {
+	0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,
+	1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
+	1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
+	1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
+	2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
+	3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
+	3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
+	4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8
+};
+
+static int yaffs_CountBits(__u8 x)
+{
+	int retVal;
+	retVal = yaffs_countBitsTable[x];
+	return retVal;
+}
+
+/********** Tags ECC calculations  *********/
+
+void yaffs_CalcECC(const __u8 * data, yaffs_Spare * spare)
+{
+	yaffs_ECCCalculate(data, spare->ecc1);
+	yaffs_ECCCalculate(&data[256], spare->ecc2);
+}
+
+void yaffs_CalcTagsECC(yaffs_Tags * tags)
+{
+	/* Calculate an ecc */
+
+	unsigned char *b = ((yaffs_TagsUnion *) tags)->asBytes;
+	unsigned i, j;
+	unsigned ecc = 0;
+	unsigned bit = 0;
+
+	tags->ecc = 0;
+
+	for (i = 0; i < 8; i++) {
+		for (j = 1; j & 0xff; j <<= 1) {
+			bit++;
+			if (b[i] & j) {
+				ecc ^= bit;
+			}
+		}
+	}
+
+	tags->ecc = ecc;
+
+}
+
+int yaffs_CheckECCOnTags(yaffs_Tags * tags)
+{
+	unsigned ecc = tags->ecc;
+
+	yaffs_CalcTagsECC(tags);
+
+	ecc ^= tags->ecc;
+
+	if (ecc && ecc <= 64) {
+		/* TODO: Handle the failure better. Retire? */
+		unsigned char *b = ((yaffs_TagsUnion *) tags)->asBytes;
+
+		ecc--;
+
+		b[ecc / 8] ^= (1 << (ecc & 7));
+
+		/* Now recvalc the ecc */
+		yaffs_CalcTagsECC(tags);
+
+		return 1;	/* recovered error */
+	} else if (ecc) {
+		/* Wierd ecc failure value */
+		/* TODO Need to do somethiong here */
+		return -1;	/* unrecovered error */
+	}
+
+	return 0;
+}
+
+/********** Tags **********/
+
+static void yaffs_LoadTagsIntoSpare(yaffs_Spare * sparePtr,
+				    yaffs_Tags * tagsPtr)
+{
+	yaffs_TagsUnion *tu = (yaffs_TagsUnion *) tagsPtr;
+
+	yaffs_CalcTagsECC(tagsPtr);
+
+	sparePtr->tagByte0 = tu->asBytes[0];
+	sparePtr->tagByte1 = tu->asBytes[1];
+	sparePtr->tagByte2 = tu->asBytes[2];
+	sparePtr->tagByte3 = tu->asBytes[3];
+	sparePtr->tagByte4 = tu->asBytes[4];
+	sparePtr->tagByte5 = tu->asBytes[5];
+	sparePtr->tagByte6 = tu->asBytes[6];
+	sparePtr->tagByte7 = tu->asBytes[7];
+}
+
+static void yaffs_GetTagsFromSpare(yaffs_Device * dev, yaffs_Spare * sparePtr,
+				   yaffs_Tags * tagsPtr)
+{
+	yaffs_TagsUnion *tu = (yaffs_TagsUnion *) tagsPtr;
+	int result;
+
+	tu->asBytes[0] = sparePtr->tagByte0;
+	tu->asBytes[1] = sparePtr->tagByte1;
+	tu->asBytes[2] = sparePtr->tagByte2;
+	tu->asBytes[3] = sparePtr->tagByte3;
+	tu->asBytes[4] = sparePtr->tagByte4;
+	tu->asBytes[5] = sparePtr->tagByte5;
+	tu->asBytes[6] = sparePtr->tagByte6;
+	tu->asBytes[7] = sparePtr->tagByte7;
+
+	result = yaffs_CheckECCOnTags(tagsPtr);
+	if (result > 0) {
+		dev->tagsEccFixed++;
+	} else if (result < 0) {
+		dev->tagsEccUnfixed++;
+	}
+}
+
+static void yaffs_SpareInitialise(yaffs_Spare * spare)
+{
+	memset(spare, 0xFF, sizeof(yaffs_Spare));
+}
+
+static int yaffs_WriteChunkToNAND(struct yaffs_DeviceStruct *dev,
+				  int chunkInNAND, const __u8 * data,
+				  yaffs_Spare * spare)
+{
+	if (chunkInNAND < dev->startBlock * dev->nChunksPerBlock) {
+		T(YAFFS_TRACE_ERROR,
+		  (TSTR("**>> yaffs chunk %d is not valid" TENDSTR),
+		   chunkInNAND));
+		return YAFFS_FAIL;
+	}
+
+	return dev->writeChunkToNAND(dev, chunkInNAND, data, spare);
+}
+
+static int yaffs_ReadChunkFromNAND(struct yaffs_DeviceStruct *dev,
+				   int chunkInNAND,
+				   __u8 * data,
+				   yaffs_Spare * spare,
+				   yaffs_ECCResult * eccResult,
+				   int doErrorCorrection)
+{
+	int retVal;
+	yaffs_Spare localSpare;
+
+	if (!spare && data) {
+		/* If we don't have a real spare, then we use a local one. */
+		/* Need this for the calculation of the ecc */
+		spare = &localSpare;
+	}
+
+	if (!dev->useNANDECC) {
+		retVal = dev->readChunkFromNAND(dev, chunkInNAND, data, spare);
+		if (data && doErrorCorrection) {
+			/* Do ECC correction */
+			/* Todo handle any errors */
+			int eccResult1, eccResult2;
+			__u8 calcEcc[3];
+
+			yaffs_ECCCalculate(data, calcEcc);
+			eccResult1 =
+			    yaffs_ECCCorrect(data, spare->ecc1, calcEcc);
+			yaffs_ECCCalculate(&data[256], calcEcc);
+			eccResult2 =
+			    yaffs_ECCCorrect(&data[256], spare->ecc2, calcEcc);
+
+			if (eccResult1 > 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>yaffs ecc error fix performed on chunk %d:0"
+				    TENDSTR), chunkInNAND));
+				dev->eccFixed++;
+			} else if (eccResult1 < 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>yaffs ecc error unfixed on chunk %d:0"
+				    TENDSTR), chunkInNAND));
+				dev->eccUnfixed++;
+			}
+
+			if (eccResult2 > 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>yaffs ecc error fix performed on chunk %d:1"
+				    TENDSTR), chunkInNAND));
+				dev->eccFixed++;
+			} else if (eccResult2 < 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>yaffs ecc error unfixed on chunk %d:1"
+				    TENDSTR), chunkInNAND));
+				dev->eccUnfixed++;
+			}
+
+			if (eccResult1 || eccResult2) {
+				/* We had a data problem on this page */
+				int softErr = (eccResult1 >= 0 &&
+					       eccResult2 >= 0);
+				yaffs_HandleReadDataError(dev, chunkInNAND,
+							  softErr);
+			}
+
+			if (eccResult1 < 0 || eccResult2 < 0)
+				*eccResult = YAFFS_ECC_RESULT_UNFIXED;
+			else if (eccResult1 > 0 || eccResult2 > 0)
+				*eccResult = YAFFS_ECC_RESULT_FIXED;
+			else
+				*eccResult = YAFFS_ECC_RESULT_NO_ERROR;
+		}
+	} else {
+		/* Must allocate enough memory for spare+2*sizeof(int) */
+		/* for ecc results from device. */
+		struct yaffs_NANDSpare nspare;
+		retVal =
+		    dev->readChunkFromNAND(dev, chunkInNAND, data,
+					   (yaffs_Spare *) & nspare);
+		memcpy(spare, &nspare, sizeof(yaffs_Spare));
+		if (data && doErrorCorrection) {
+			if (nspare.eccres1 > 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>mtd ecc error fix performed on chunk %d:0"
+				    TENDSTR), chunkInNAND));
+			} else if (nspare.eccres1 < 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>mtd ecc error unfixed on chunk %d:0"
+				    TENDSTR), chunkInNAND));
+			}
+
+			if (nspare.eccres2 > 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>mtd ecc error fix performed on chunk %d:1"
+				    TENDSTR), chunkInNAND));
+			} else if (nspare.eccres2 < 0) {
+				T(YAFFS_TRACE_ERROR,
+				  (TSTR
+				   ("**>>mtd ecc error unfixed on chunk %d:1"
+				    TENDSTR), chunkInNAND));
+			}
+
+			if (nspare.eccres1 || nspare.eccres2) {
+				/* We had a data problem on this page */
+				int softErr = (nspare.eccres1 >= 0 &&
+					       nspare.eccres2 >= 0);
+				yaffs_HandleReadDataError(dev, chunkInNAND,
+							  softErr);
+			}
+
+			if (nspare.eccres1 < 0 || nspare.eccres2 < 0)
+				*eccResult = YAFFS_ECC_RESULT_UNFIXED;
+			else if (nspare.eccres1 > 0 || nspare.eccres2 > 0)
+				*eccResult = YAFFS_ECC_RESULT_FIXED;
+			else
+				*eccResult = YAFFS_ECC_RESULT_NO_ERROR;
+
+		}
+	}
+	return retVal;
+}
+
+#ifdef NOTYET
+static int yaffs_CheckChunkErased(struct yaffs_DeviceStruct *dev,
+				  int chunkInNAND)
+{
+
+	static int init = 0;
+	static __u8 cmpbuf[YAFFS_BYTES_PER_CHUNK];
+	static __u8 data[YAFFS_BYTES_PER_CHUNK];
+	/* Might as well always allocate the larger size for */
+	/* dev->useNANDECC == true; */
+	static __u8 spare[sizeof(struct yaffs_NANDSpare)];
+
+	dev->readChunkFromNAND(dev, chunkInNAND, data, (yaffs_Spare *) spare);
+
+	if (!init) {
+		memset(cmpbuf, 0xff, YAFFS_BYTES_PER_CHUNK);
+		init = 1;
+	}
+
+	if (memcmp(cmpbuf, data, YAFFS_BYTES_PER_CHUNK))
+		return YAFFS_FAIL;
+	if (memcmp(cmpbuf, spare, 16))
+		return YAFFS_FAIL;
+
+	return YAFFS_OK;
+
+}
+#endif
+
+/*
+ * Functions for robustisizing
+ */
+
+#ifdef NOTYET
+static void yaffs_CheckWrittenBlock(yaffs_Device * dev, int chunkInNAND)
+{
+}
+
+static void yaffs_HandleWriteChunkOk(yaffs_Device * dev, int chunkInNAND,
+				     const __u8 * data,
+				     const yaffs_Spare * spare)
+{
+}
+
+static void yaffs_HandleUpdateChunk(yaffs_Device * dev, int chunkInNAND,
+				    const yaffs_Spare * spare)
+{
+}
+
+static int yaffs_VerifyCompare(const __u8 * d0, const __u8 * d1,
+			       const yaffs_Spare * s0, const yaffs_Spare * s1)
+{
+
+	if (memcmp(d0, d1, YAFFS_BYTES_PER_CHUNK) != 0 ||
+	    s0->tagByte0 != s1->tagByte0 ||
+	    s0->tagByte1 != s1->tagByte1 ||
+	    s0->tagByte2 != s1->tagByte2 ||
+	    s0->tagByte3 != s1->tagByte3 ||
+	    s0->tagByte4 != s1->tagByte4 ||
+	    s0->tagByte5 != s1->tagByte5 ||
+	    s0->tagByte6 != s1->tagByte6 ||
+	    s0->tagByte7 != s1->tagByte7 ||
+	    s0->ecc1[0] != s1->ecc1[0] ||
+	    s0->ecc1[1] != s1->ecc1[1] ||
+	    s0->ecc1[2] != s1->ecc1[2] ||
+	    s0->ecc2[0] != s1->ecc2[0] ||
+	    s0->ecc2[1] != s1->ecc2[1] || s0->ecc2[2] != s1->ecc2[2]) {
+		return 0;
+	}
+
+	return 1;
+}
+#endif				/* NOTYET */
+
+int yaffs_TagsCompatabilityWriteChunkWithTagsToNAND(yaffs_Device * dev,
+						    int chunkInNAND,
+						    const __u8 * data,
+						    const yaffs_ExtendedTags *
+						    eTags)
+{
+	yaffs_Spare spare;
+	yaffs_Tags tags;
+
+	yaffs_SpareInitialise(&spare);
+
+	if (eTags->chunkDeleted) {
+		spare.pageStatus = 0;
+	} else {
+		tags.objectId = eTags->objectId;
+		tags.chunkId = eTags->chunkId;
+		tags.byteCount = eTags->byteCount;
+		tags.serialNumber = eTags->serialNumber;
+
+		if (!dev->useNANDECC && data) {
+			yaffs_CalcECC(data, &spare);
+		}
+		yaffs_LoadTagsIntoSpare(&spare, &tags);
+
+	}
+
+	return yaffs_WriteChunkToNAND(dev, chunkInNAND, data, &spare);
+}
+
+int yaffs_TagsCompatabilityReadChunkWithTagsFromNAND(yaffs_Device * dev,
+						     int chunkInNAND,
+						     __u8 * data,
+						     yaffs_ExtendedTags * eTags)
+{
+
+	yaffs_Spare spare;
+	yaffs_Tags tags;
+	yaffs_ECCResult eccResult = YAFFS_ECC_RESULT_NO_ERROR;
+
+	static yaffs_Spare spareFF;
+	static int init;
+
+	if (!init) {
+		memset(&spareFF, 0xFF, sizeof(spareFF));
+		init = 1;
+	}
+
+	if (yaffs_ReadChunkFromNAND
+	    (dev, chunkInNAND, data, &spare, &eccResult, 1)) {
+		/* eTags may be NULL */
+		if (eTags) {
+
+			int deleted =
+			    (yaffs_CountBits(spare.pageStatus) < 7) ? 1 : 0;
+
+			eTags->chunkDeleted = deleted;
+			eTags->eccResult = eccResult;
+			eTags->blockBad = 0;	/* We're reading it */
+			/* therefore it is not a bad block */
+			eTags->chunkUsed =
+			    (memcmp(&spareFF, &spare, sizeof(spareFF)) !=
+			     0) ? 1 : 0;
+
+			if (eTags->chunkUsed) {
+				yaffs_GetTagsFromSpare(dev, &spare, &tags);
+
+				eTags->objectId = tags.objectId;
+				eTags->chunkId = tags.chunkId;
+				eTags->byteCount = tags.byteCount;
+				eTags->serialNumber = tags.serialNumber;
+			}
+		}
+
+		return YAFFS_OK;
+	} else {
+		return YAFFS_FAIL;
+	}
+}
+
+int yaffs_TagsCompatabilityMarkNANDBlockBad(struct yaffs_DeviceStruct *dev,
+					    int blockInNAND)
+{
+
+	yaffs_Spare spare;
+
+	memset(&spare, 0xff, sizeof(yaffs_Spare));
+
+	spare.blockStatus = 'Y';
+
+	yaffs_WriteChunkToNAND(dev, blockInNAND * dev->nChunksPerBlock, NULL,
+			       &spare);
+	yaffs_WriteChunkToNAND(dev, blockInNAND * dev->nChunksPerBlock + 1,
+			       NULL, &spare);
+
+	return YAFFS_OK;
+
+}
+
+int yaffs_TagsCompatabilityQueryNANDBlock(struct yaffs_DeviceStruct *dev,
+					  int blockNo, yaffs_BlockState *
+					  state,
+					  int *sequenceNumber)
+{
+
+	yaffs_Spare spare0, spare1;
+	static yaffs_Spare spareFF;
+	static int init;
+	yaffs_ECCResult dummy;
+
+	if (!init) {
+		memset(&spareFF, 0xFF, sizeof(spareFF));
+		init = 1;
+	}
+
+	*sequenceNumber = 0;
+
+	yaffs_ReadChunkFromNAND(dev, blockNo * dev->nChunksPerBlock, NULL,
+				&spare0, &dummy, 1);
+	yaffs_ReadChunkFromNAND(dev, blockNo * dev->nChunksPerBlock + 1, NULL,
+				&spare1, &dummy, 1);
+
+	if (yaffs_CountBits(spare0.blockStatus & spare1.blockStatus) < 7)
+		*state = YAFFS_BLOCK_STATE_DEAD;
+	else if (memcmp(&spareFF, &spare0, sizeof(spareFF)) == 0)
+		*state = YAFFS_BLOCK_STATE_EMPTY;
+	else
+		*state = YAFFS_BLOCK_STATE_NEEDS_SCANNING;
+
+	return YAFFS_OK;
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_tagscompat.h linux/fs/yaffs/yaffs_tagscompat.h
--- linux-2.6.35/fs/yaffs/yaffs_tagscompat.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_tagscompat.h	2011-05-02 10:08:28.271591934 +0300
@@ -0,0 +1,40 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yaffs_ramdisk.h: yaffs ram disk component
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * $Id: yaffs_tagscompat.h,v 1.2 2005/08/11 02:33:03 marty Exp $
+ */
+
+/* This provides a ram disk under yaffs.
+ * NB this is not intended for NAND emulation.
+ * Use this with dev->useNANDECC enabled, then ECC overheads are not required.
+ */
+#ifndef __YAFFS_TAGSCOMPAT_H__
+#define __YAFFS_TAGSCOMPAT_H__
+
+#include "yaffs_guts.h"
+int yaffs_TagsCompatabilityWriteChunkWithTagsToNAND(yaffs_Device * dev,
+						    int chunkInNAND,
+						    const __u8 * data,
+						    const yaffs_ExtendedTags *
+						    tags);
+int yaffs_TagsCompatabilityReadChunkWithTagsFromNAND(yaffs_Device * dev,
+						     int chunkInNAND,
+						     __u8 * data,
+						     yaffs_ExtendedTags *
+						     tags);
+int yaffs_TagsCompatabilityMarkNANDBlockBad(struct yaffs_DeviceStruct *dev,
+					    int blockNo);
+int yaffs_TagsCompatabilityQueryNANDBlock(struct yaffs_DeviceStruct *dev,
+					  int blockNo, yaffs_BlockState *
+					  state, int *sequenceNumber);
+
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_tagsvalidity.c linux/fs/yaffs/yaffs_tagsvalidity.c
--- linux-2.6.35/fs/yaffs/yaffs_tagsvalidity.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_tagsvalidity.c	2011-05-02 10:08:28.281594361 +0300
@@ -0,0 +1,31 @@
+
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * $Id: yaffs_tagsvalidity.c,v 1.2 2005/08/11 02:33:03 marty Exp $
+ */
+
+#include "yaffs_tagsvalidity.h"
+
+void yaffs_InitialiseTags(yaffs_ExtendedTags * tags)
+{
+	memset(tags, 0, sizeof(yaffs_ExtendedTags));
+	tags->validMarker0 = 0xAAAAAAAA;
+	tags->validMarker1 = 0x55555555;
+}
+
+int yaffs_ValidateTags(yaffs_ExtendedTags * tags)
+{
+	return (tags->validMarker0 == 0xAAAAAAAA &&
+		tags->validMarker1 == 0x55555555);
+
+}
diff -puNrb linux-2.6.35/fs/yaffs/yaffs_tagsvalidity.h linux/fs/yaffs/yaffs_tagsvalidity.h
--- linux-2.6.35/fs/yaffs/yaffs_tagsvalidity.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yaffs_tagsvalidity.h	2011-05-02 10:08:28.291545231 +0300
@@ -0,0 +1,25 @@
+
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * $Id: yaffs_tagsvalidity.h,v 1.2 2005/08/11 02:33:03 marty Exp $
+ */
+//yaffs_tagsvalidity.h
+
+#ifndef __YAFFS_TAGS_VALIDITY_H__
+#define __YAFFS_TAGS_VALIDITY_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_InitialiseTags(yaffs_ExtendedTags * tags);
+int yaffs_ValidateTags(yaffs_ExtendedTags * tags);
+#endif
diff -puNrb linux-2.6.35/fs/yaffs/yportenv.h linux/fs/yaffs/yportenv.h
--- linux-2.6.35/fs/yaffs/yportenv.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/fs/yaffs/yportenv.h	2011-05-02 10:08:28.301545374 +0300
@@ -0,0 +1,165 @@
+/*
+ * YAFFS: Yet another FFS. A NAND-flash specific file system. 
+ * yportenv.h: Portable services used by yaffs. This is done to allow
+ * simple migration from kernel space into app space for testing.
+ *
+ * Copyright (C) 2002 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ *
+ * $Id: yportenv.h,v 1.11 2006/05/21 09:39:12 charles Exp $
+ *
+ */
+
+#ifndef __YPORTENV_H__
+#define __YPORTENV_H__
+
+#if defined CONFIG_YAFFS_WINCE
+
+#include "ywinceenv.h"
+
+#elif  defined __KERNEL__
+
+#include "moduleconfig.h"
+
+/* Linux kernel */
+#include <linux/kernel.h>
+#include <linux/version.h>
+#include <linux/mm.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/sched.h>
+
+#define YCHAR char
+#define YUCHAR unsigned char
+#define _Y(x)     x
+#define yaffs_strcpy(a,b)    strcpy(a,b)
+#define yaffs_strncpy(a,b,c) strncpy(a,b,c)
+#define yaffs_strlen(s)	     strlen(s)
+#define yaffs_sprintf	     sprintf
+#define yaffs_toupper(a)     toupper(a)
+
+#define Y_INLINE inline
+
+#define YAFFS_LOSTNFOUND_NAME		"lost+found"
+#define YAFFS_LOSTNFOUND_PREFIX		"obj"
+
+/* #define YPRINTF(x) printk x */
+#define YMALLOC(x) kmalloc(x,GFP_KERNEL)
+#define YFREE(x)   kfree(x)
+#define YMALLOC_ALT(x) vmalloc(x)
+#define YFREE_ALT(x)   vfree(x)
+#define YMALLOC_DMA(x) YMALLOC(x)
+
+// KR - added for use in scan so processes aren't blocked indefinitely.
+#define YYIELD() schedule()
+
+#define YAFFS_ROOT_MODE				0666
+#define YAFFS_LOSTNFOUND_MODE		0666
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2,5,0))
+#define Y_CURRENT_TIME CURRENT_TIME.tv_sec
+#define Y_TIME_CONVERT(x) (x).tv_sec
+#else
+#define Y_CURRENT_TIME CURRENT_TIME
+#define Y_TIME_CONVERT(x) (x)
+#endif
+
+#define yaffs_SumCompare(x,y) ((x) == (y))
+#define yaffs_strcmp(a,b) strcmp(a,b)
+
+#define TENDSTR "\n"
+#define TSTR(x) KERN_WARNING x
+#define TOUT(p) printk p
+
+#elif defined CONFIG_YAFFS_DIRECT
+
+/* Direct interface */
+#include "ydirectenv.h"
+
+#elif defined CONFIG_YAFFS_UTIL
+
+/* Stuff for YAFFS utilities */
+
+#include "stdlib.h"
+#include "stdio.h"
+#include "string.h"
+
+#include "devextras.h"
+
+#define YMALLOC(x) malloc(x)
+#define YFREE(x)   free(x)
+#define YMALLOC_ALT(x) malloc(x)
+#define YFREE_ALT(x) free(x)
+
+#define YCHAR char
+#define YUCHAR unsigned char
+#define _Y(x)     x
+#define yaffs_strcpy(a,b)    strcpy(a,b)
+#define yaffs_strncpy(a,b,c) strncpy(a,b,c)
+#define yaffs_strlen(s)	     strlen(s)
+#define yaffs_sprintf	     sprintf
+#define yaffs_toupper(a)     toupper(a)
+
+#define Y_INLINE inline
+
+/* #define YINFO(s) YPRINTF(( __FILE__ " %d %s\n",__LINE__,s)) */
+/* #define YALERT(s) YINFO(s) */
+
+#define TENDSTR "\n"
+#define TSTR(x) x
+#define TOUT(p) printf p
+
+#define YAFFS_LOSTNFOUND_NAME		"lost+found"
+#define YAFFS_LOSTNFOUND_PREFIX		"obj"
+/* #define YPRINTF(x) printf x */
+
+#define YAFFS_ROOT_MODE				0666
+#define YAFFS_LOSTNFOUND_MODE		0666
+
+#define yaffs_SumCompare(x,y) ((x) == (y))
+#define yaffs_strcmp(a,b) strcmp(a,b)
+
+#else
+/* Should have specified a configuration type */
+#error Unknown configuration
+
+#endif
+
+extern unsigned yaffs_traceMask;
+
+#define YAFFS_TRACE_ERROR		0x00000001
+#define YAFFS_TRACE_OS			0x00000002
+#define YAFFS_TRACE_ALLOCATE		0x00000004
+#define YAFFS_TRACE_SCAN		0x00000008
+#define YAFFS_TRACE_BAD_BLOCKS		0x00000010
+#define YAFFS_TRACE_ERASE		0x00000020
+#define YAFFS_TRACE_GC			0x00000040
+#define YAFFS_TRACE_WRITE		0x00000080
+#define YAFFS_TRACE_TRACING		0x00000100
+#define YAFFS_TRACE_DELETION		0x00000200
+#define YAFFS_TRACE_BUFFERS		0x00000400
+#define YAFFS_TRACE_NANDACCESS		0x00000800
+#define YAFFS_TRACE_GC_DETAIL		0x00001000
+#define YAFFS_TRACE_SCAN_DEBUG		0x00002000
+#define YAFFS_TRACE_MTD			0x00004000
+#define YAFFS_TRACE_CHECKPOINT		0x00008000
+#define YAFFS_TRACE_ALWAYS		0x40000000
+#define YAFFS_TRACE_BUG			0x80000000
+
+#define T(mask,p) do{ if((mask) & (yaffs_traceMask | YAFFS_TRACE_ERROR)) TOUT(p);} while(0)
+
+#ifndef CONFIG_YAFFS_WINCE
+#define YBUG() T(YAFFS_TRACE_BUG,(TSTR("==>> yaffs bug: " __FILE__ " %d" TENDSTR),__LINE__))
+#endif
+
+#endif
diff -puNrb linux-2.6.35/include/asm-generic/vmlinux.lds.h linux/include/asm-generic/vmlinux.lds.h
--- linux-2.6.35/include/asm-generic/vmlinux.lds.h	2011-04-26 16:25:56.181856796 +0300
+++ linux/include/asm-generic/vmlinux.lds.h	2011-05-02 10:08:28.321592634 +0300
@@ -513,6 +513,7 @@
 		*(.dynbss)						\
 		*(.bss)							\
 		*(COMMON)						\
+		. = (ALIGN(PAGE_SIZE) - .) < 8 ? ALIGN(PAGE_SIZE) + 4 : . ; \
 	}
 
 /*
diff -puNrb linux-2.6.35/include/linux/etherdevice.h linux/include/linux/etherdevice.h
--- linux-2.6.35/include/linux/etherdevice.h	2011-04-26 16:26:02.461855449 +0300
+++ linux/include/linux/etherdevice.h	2011-05-02 10:08:28.331545485 +0300
@@ -139,7 +139,9 @@ static inline unsigned compare_ether_add
 	const u16 *b = (const u16 *) addr2;
 
 	BUILD_BUG_ON(ETH_ALEN != 6);
-	return ((a[0] ^ b[0]) | (a[1] ^ b[1]) | (a[2] ^ b[2])) != 0;
+
+	return ((get_unaligned((u32 *) addr1) ^ get_unaligned((u32 *) addr2))
+		| (get_unaligned(&a[2]) ^ get_unaligned(&b[2]))) != 0;
 }
 
 static inline unsigned long zap_last_2bytes(unsigned long value)
diff -puNrb linux-2.6.35/include/linux/fib_rules.h linux/include/linux/fib_rules.h
--- linux-2.6.35/include/linux/fib_rules.h	2011-04-26 16:26:02.361856954 +0300
+++ linux/include/linux/fib_rules.h	2011-05-02 10:08:28.341545379 +0300
@@ -64,6 +64,8 @@ enum {
 	FR_ACT_BLACKHOLE,	/* Drop without notification */
 	FR_ACT_UNREACHABLE,	/* Drop with ENETUNREACH */
 	FR_ACT_PROHIBIT,	/* Drop with EACCES */
+	FR_ACT_ONLY_TO_TBL,	/* Pass to fixed table and drop
+                                   with ENETUNREACH if table lookup failed */
 	__FR_ACT_MAX,
 };
 
diff -puNrb linux-2.6.35/include/linux/hdlc.h linux/include/linux/hdlc.h
--- linux-2.6.35/include/linux/hdlc.h	2011-04-26 16:26:02.371856999 +0300
+++ linux/include/linux/hdlc.h	2011-05-02 10:08:28.351592172 +0300
@@ -77,7 +77,7 @@ void unregister_hdlc_device(struct net_d
 void register_hdlc_protocol(struct hdlc_proto *proto);
 void unregister_hdlc_protocol(struct hdlc_proto *proto);
 
-struct net_device *alloc_hdlcdev(void *priv);
+struct net_device *alloc_hdlcdev(void *priv, const char *dnt);
 
 static inline struct hdlc_device* dev_to_hdlc(struct net_device *dev)
 {
diff -puNrb linux-2.6.35/include/linux/icmp.h linux/include/linux/icmp.h
--- linux-2.6.35/include/linux/icmp.h	2011-04-26 16:26:02.472790023 +0300
+++ linux/include/linux/icmp.h	2011-05-02 10:08:28.371588391 +0300
@@ -80,7 +80,7 @@ struct icmphdr {
 		__be16	mtu;
 	} frag;
   } un;
-};
+} __attribute__((packed));
 
 #ifdef __KERNEL__
 #include <linux/skbuff.h>
@@ -99,7 +99,7 @@ static inline struct icmphdr *icmp_hdr(c
 
 struct icmp_filter {
 	__u32		data;
-};
+} __attribute__((packed));
 
 
 #endif	/* _LINUX_ICMP_H */
diff -puNrb linux-2.6.35/include/linux/if_arp.h linux/include/linux/if_arp.h
--- linux-2.6.35/include/linux/if_arp.h	2011-04-26 16:26:02.612813823 +0300
+++ linux/include/linux/if_arp.h	2011-05-02 10:08:28.401591054 +0300
@@ -151,7 +151,7 @@ struct arphdr {
 	unsigned char		ar_tip[4];		/* target IP address		*/
 #endif
 
-};
+} __attribute__((packed));
 
 #ifdef __KERNEL__
 #include <linux/skbuff.h>
diff -puNrb linux-2.6.35/include/linux/if_ether.h linux/include/linux/if_ether.h
--- linux-2.6.35/include/linux/if_ether.h	2011-04-26 16:26:02.601377687 +0300
+++ linux/include/linux/if_ether.h	2011-05-02 10:08:28.411563098 +0300
@@ -77,6 +77,7 @@
 					 */
 #define ETH_P_PAE	0x888E		/* Port Access Entity (IEEE 802.1X) */
 #define ETH_P_AOE	0x88A2		/* ATA over Ethernet		*/
+#define ETH_P_8021Q_S	0x88A8		/* 802.1Q service tag (802.1ad) */
 #define ETH_P_TIPC	0x88CA		/* TIPC 			*/
 #define ETH_P_1588	0x88F7		/* IEEE 1588 Timesync */
 #define ETH_P_FCOE	0x8906		/* Fibre Channel over Ethernet  */
diff -puNrb linux-2.6.35/include/linux/if.h linux/include/linux/if.h
--- linux-2.6.35/include/linux/if.h	2011-04-26 16:26:02.482789986 +0300
+++ linux/include/linux/if.h	2011-05-02 10:08:28.423156796 +0300
@@ -85,6 +85,7 @@
 #define IF_IFACE_E1	0x1004		/* E1 telco serial interface	*/
 #define IF_IFACE_SYNC_SERIAL 0x1005	/* can't be set by software	*/
 #define IF_IFACE_X21D   0x1006          /* X.21 Dual Clocking (FarSite) */
+#define IF_IFACE_SHDSL  0x1007          /* SHDSL (FarSite)              */
 
 /* For definitions see hdlc.h */
 #define IF_PROTO_HDLC	0x2000		/* raw HDLC protocol		*/
diff -puNrb linux-2.6.35/include/linux/if_link.h linux/include/linux/if_link.h
--- linux-2.6.35/include/linux/if_link.h	2011-04-26 16:26:02.571855611 +0300
+++ linux/include/linux/if_link.h	2011-05-02 10:08:28.443216077 +0300
@@ -109,6 +109,7 @@ enum {
 	IFLA_LINKINFO,
 #define IFLA_LINKINFO IFLA_LINKINFO
 	IFLA_NET_NS_PID,
+	IFLA_L2MTU,
 	IFLA_IFALIAS,
 	IFLA_NUM_VF,		/* Number of VFs if device is SR-IOV PF */
 	IFLA_VFINFO_LIST,
@@ -195,6 +196,7 @@ enum {
 	IFLA_VLAN_FLAGS,
 	IFLA_VLAN_EGRESS_QOS,
 	IFLA_VLAN_INGRESS_QOS,
+	IFLA_VLAN_PROTO,
 	__IFLA_VLAN_MAX,
 };
 
diff -puNrb linux-2.6.35/include/linux/if_ppp.h linux/include/linux/if_ppp.h
--- linux-2.6.35/include/linux/if_ppp.h	2011-04-26 16:26:02.571855611 +0300
+++ linux/include/linux/if_ppp.h	2011-05-02 10:08:28.463214557 +0300
@@ -161,6 +161,8 @@ struct pppol2tp_ioc_stats {
 #define PPPIOCATTCHAN	_IOW('t', 56, int)	/* attach to ppp channel */
 #define PPPIOCGCHAN	_IOR('t', 55, int)	/* get ppp channel number */
 #define PPPIOCGL2TPSTATS _IOR('t', 54, struct pppol2tp_ioc_stats)
+#define PPPIOCSMTU	_IOW('t', 51, int)	/* set channel mtu */
+#define PPPIOCSUSER	_IOW('t', 50, char[32]) /* set active ppp username */
 
 #define SIOCGPPPSTATS   (SIOCDEVPRIVATE + 0)
 #define SIOCGPPPVER     (SIOCDEVPRIVATE + 1)	/* NEVER change this!! */
diff -puNrb linux-2.6.35/include/linux/if_switch.h linux/include/linux/if_switch.h
--- linux-2.6.35/include/linux/if_switch.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/include/linux/if_switch.h	2011-05-02 10:08:28.483212735 +0300
@@ -0,0 +1,23 @@
+#ifndef _LINUX_IF_SWITCH_H
+#define _LINUX_IF_SWITCH_H
+
+#include <linux/types.h>
+
+#define SIOCGTYPE	(SIOCDEVPRIVATE + 0)
+#define SIOCGSWITCH	(SIOCDEVPRIVATE + 1)
+#define SIOCSTXBW	(SIOCDEVPRIVATE + 2)
+#define SIOCSRXBW	(SIOCDEVPRIVATE + 3)
+#define SIOCSMASTER	(SIOCDEVPRIVATE + 4)
+#define SIOCSMIRROR	(SIOCDEVPRIVATE + 5)
+#define SIOCGREG	(SIOCDEVPRIVATE + 8)
+#define SIOCSREG	(SIOCDEVPRIVATE + 9)
+#define SIOCGPORT	(SIOCDEVPRIVATE + 10)
+
+#define SWITCH_ADMTEK		0
+#define SWITCH_ICPLUS175C	1
+
+#define MIRROR_NONE -1u
+#define MIRROR_CPU -2u
+
+
+#endif
diff -puNrb linux-2.6.35/include/linux/if_vlan.h linux/include/linux/if_vlan.h
--- linux-2.6.35/include/linux/if_vlan.h	2011-04-26 16:26:02.421855563 +0300
+++ linux/include/linux/if_vlan.h	2011-05-02 10:08:28.493102834 +0300
@@ -38,7 +38,7 @@
 struct vlan_hdr {
 	__be16	h_vlan_TCI;
 	__be16	h_vlan_encapsulated_proto;
-};
+} __attribute__((packed));
 
 /**
  *	struct vlan_ethhdr - vlan ethernet header (ethhdr + vlan_hdr)
@@ -54,7 +54,7 @@ struct vlan_ethhdr {
 	__be16		h_vlan_proto;
 	__be16		h_vlan_TCI;
 	__be16		h_vlan_encapsulated_proto;
-};
+} __attribute__((packed));
 
 #include <linux/skbuff.h>
 
@@ -84,6 +84,7 @@ struct vlan_group {
 	struct net_device	*real_dev; /* The ethernet(like) device
 					    * the vlan is attached to.
 					    */
+	unsigned short		proto;
 	unsigned int		nr_vlans;
 	int			killall;
 	struct hlist_node	hlist;	/* linked list */
@@ -204,7 +205,8 @@ static inline int vlan_hwaccel_receive_s
  * Following the skb_unshare() example, in case of error, the calling function
  * doesn't have to worry about freeing the original skb.
  */
-static inline struct sk_buff *__vlan_put_tag(struct sk_buff *skb, u16 vlan_tci)
+static inline struct sk_buff *__vlan_put_tag_proto(struct sk_buff *skb, u16 vlan_tci,
+						   unsigned short proto)
 {
 	struct vlan_ethhdr *veth;
 
@@ -219,16 +221,20 @@ static inline struct sk_buff *__vlan_put
 	skb->mac_header -= VLAN_HLEN;
 
 	/* first, the ethernet type */
-	veth->h_vlan_proto = htons(ETH_P_8021Q);
+	veth->h_vlan_proto = htons(proto);
 
 	/* now, the TCI */
 	veth->h_vlan_TCI = htons(vlan_tci);
 
-	skb->protocol = htons(ETH_P_8021Q);
+	skb->protocol = htons(proto);
 
 	return skb;
 }
 
+static inline struct sk_buff *__vlan_put_tag(struct sk_buff *skb, u16 vlan_tci) {
+	return __vlan_put_tag_proto(skb, vlan_tci, ETH_P_8021Q);
+}
+
 /**
  * __vlan_hwaccel_put_tag - hardware accelerated VLAN inserting
  * @skb: skbuff to tag
@@ -255,6 +261,12 @@ static inline struct sk_buff *__vlan_hwa
  */
 static inline struct sk_buff *vlan_put_tag(struct sk_buff *skb, u16 vlan_tci)
 {
+	if (skb->dev->l2mtu
+	    && (skb->len - ETH_HLEN + VLAN_HLEN) > skb->dev->l2mtu) {
+		kfree_skb(skb);
+		return NULL;
+	}
+
 	if (skb->dev->features & NETIF_F_HW_VLAN_TX) {
 		return __vlan_hwaccel_put_tag(skb, vlan_tci);
 	} else {
@@ -318,6 +330,9 @@ static inline int vlan_get_tag(const str
 	}
 }
 
+#define ANY_VLAN_PROTO_N(p) (((p) == __constant_htons(ETH_P_8021Q)) \
+			     || ((p) == __constant_htons(ETH_P_8021Q_S)))
+
 #endif /* __KERNEL__ */
 
 /* VLAN IOCTLs are found in sockios.h */
@@ -362,8 +377,8 @@ struct vlan_ioctl_args {
 		unsigned int bind_type;
 		unsigned int flag; /* Matches vlan_dev_info flags */
         } u;
-
 	short vlan_qos;   
+	unsigned short vlan_proto;
 };
 
 #endif /* !(_LINUX_IF_VLAN_H_) */
diff -puNrb linux-2.6.35/include/linux/igmp.h linux/include/linux/igmp.h
--- linux-2.6.35/include/linux/igmp.h	2011-04-26 16:26:02.551854968 +0300
+++ linux/include/linux/igmp.h	2011-05-02 10:08:28.513215291 +0300
@@ -32,7 +32,7 @@ struct igmphdr {
 	__u8 code;		/* For newer IGMP */
 	__sum16 csum;
 	__be32 group;
-};
+} __attribute__((packed));
 
 /* V3 group record types [grec_type] */
 #define IGMPV3_MODE_IS_INCLUDE		1
@@ -48,7 +48,7 @@ struct igmpv3_grec {
 	__be16	grec_nsrcs;
 	__be32	grec_mca;
 	__be32	grec_src[0];
-};
+} __attribute__((packed));
 
 struct igmpv3_report {
 	__u8 type;
@@ -57,7 +57,7 @@ struct igmpv3_report {
 	__be16 resv2;
 	__be16 ngrec;
 	struct igmpv3_grec grec[0];
-};
+} __attribute__((packed));
 
 struct igmpv3_query {
 	__u8 type;
@@ -78,7 +78,7 @@ struct igmpv3_query {
 	__u8 qqic;
 	__be16 nsrcs;
 	__be32 srcs[0];
-};
+} __attribute__((packed));
 
 #define IGMP_HOST_MEMBERSHIP_QUERY	0x11	/* From RFC1112 */
 #define IGMP_HOST_MEMBERSHIP_REPORT	0x12	/* Ditto */
diff -puNrb linux-2.6.35/include/linux/imq.h linux/include/linux/imq.h
--- linux-2.6.35/include/linux/imq.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/include/linux/imq.h	2011-05-02 10:08:28.533103420 +0300
@@ -0,0 +1,13 @@
+#ifndef _IMQ_H
+#define _IMQ_H
+
+/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
+#define IMQ_F_BITS	5
+
+#define IMQ_F_IFMASK	0x0f
+#define IMQ_F_ENQUEUE	0x10
+
+#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
+
+#endif /* _IMQ_H */
+
diff -puNrb linux-2.6.35/include/linux/in6.h linux/include/linux/in6.h
--- linux-2.6.35/include/linux/in6.h	2011-04-26 16:26:02.431855544 +0300
+++ linux/include/linux/in6.h	2011-05-02 10:08:28.553102960 +0300
@@ -36,7 +36,7 @@ struct in6_addr {
 #define s6_addr			in6_u.u6_addr8
 #define s6_addr16		in6_u.u6_addr16
 #define s6_addr32		in6_u.u6_addr32
-};
+} __attribute__((packed));
 
 /* IPv6 Wildcard Address (::) and Loopback Address (::1) defined in RFC2553
  * NOTE: Be aware the IN6ADDR_* constants and in6addr_* externals are defined
diff -puNrb linux-2.6.35/include/linux/ip.h linux/include/linux/ip.h
--- linux-2.6.35/include/linux/ip.h	2011-04-26 16:26:02.571855611 +0300
+++ linux/include/linux/ip.h	2011-05-02 10:08:28.573102968 +0300
@@ -102,7 +102,7 @@ struct iphdr {
 	__be32	saddr;
 	__be32	daddr;
 	/*The options start here. */
-};
+} __attribute__((packed));
 
 #ifdef __KERNEL__
 #include <linux/skbuff.h>
diff -puNrb linux-2.6.35/include/linux/ipv6.h linux/include/linux/ipv6.h
--- linux-2.6.35/include/linux/ipv6.h	2011-04-26 16:26:02.451854664 +0300
+++ linux/include/linux/ipv6.h	2011-05-02 10:08:28.593213700 +0300
@@ -126,7 +126,7 @@ struct ipv6hdr {
 
 	struct	in6_addr	saddr;
 	struct	in6_addr	daddr;
-};
+} __attribute__((packed));
 
 #ifdef __KERNEL__
 /*
diff -puNrb linux-2.6.35/include/linux/kernel.h linux/include/linux/kernel.h
--- linux-2.6.35/include/linux/kernel.h	2011-04-26 16:26:02.532791750 +0300
+++ linux/include/linux/kernel.h	2011-05-02 10:08:28.603194361 +0300
@@ -162,6 +162,11 @@ extern int _cond_resched(void);
 		(__x < 0) ? -__x : __x;		\
 	})
 
+struct notifier_block;
+
+extern int register_panic_notifier(struct notifier_block *nb);
+extern int unregister_panic_notifier(struct notifier_block *nb);
+
 #ifdef CONFIG_PROVE_LOCKING
 void might_fault(void);
 #else
@@ -223,6 +228,8 @@ extern int func_ptr_is_kernel_text(void 
 struct pid;
 extern struct pid *session_of_pgrp(struct pid *pgrp);
 
+extern void get_some_log(char *buf, int amount);
+
 /*
  * FW_BUG
  * Add this to a message where you are sure the firmware is buggy or behaves
diff -puNrb linux-2.6.35/include/linux/mii.h linux/include/linux/mii.h
--- linux-2.6.35/include/linux/mii.h	2011-04-26 16:26:02.601377687 +0300
+++ linux/include/linux/mii.h	2011-05-02 10:08:28.623210391 +0300
@@ -173,7 +173,7 @@ extern int mii_nway_restart (struct mii_
 extern int mii_ethtool_gset(struct mii_if_info *mii, struct ethtool_cmd *ecmd);
 extern int mii_ethtool_sset(struct mii_if_info *mii, struct ethtool_cmd *ecmd);
 extern int mii_check_gmii_support(struct mii_if_info *mii);
-extern void mii_check_link (struct mii_if_info *mii);
+extern int mii_check_link (struct mii_if_info *mii);
 extern unsigned int mii_check_media (struct mii_if_info *mii,
 				     unsigned int ok_to_print,
 				     unsigned int init_media);
diff -puNrb linux-2.6.35/include/linux/mroute.h linux/include/linux/mroute.h
--- linux-2.6.35/include/linux/mroute.h	2011-04-26 16:26:02.431855544 +0300
+++ linux/include/linux/mroute.h	2011-05-02 10:08:28.633214363 +0300
@@ -34,7 +34,6 @@
 #define SIOCGETSGCNT	(SIOCPROTOPRIVATE+1)
 #define SIOCGETRPF	(SIOCPROTOPRIVATE+2)
 
-#define MAXVIFS		32	
 typedef unsigned long vifbitmap_t;	/* User mode code depends on this lot */
 typedef unsigned short vifi_t;
 #define ALL_VIFS	((vifi_t)(-1))
@@ -81,11 +80,11 @@ struct mfcctl {
 	struct in_addr mfcc_origin;		/* Origin of mcast	*/
 	struct in_addr mfcc_mcastgrp;		/* Group in question	*/
 	vifi_t	mfcc_parent;			/* Where it arrived	*/
-	unsigned char mfcc_ttls[MAXVIFS];	/* Where it is going	*/
 	unsigned int mfcc_pkt_cnt;		/* pkt count for src-grp */
 	unsigned int mfcc_byte_cnt;
 	unsigned int mfcc_wrong_if;
 	int	     mfcc_expire;
+	unsigned mfcc_output_dev_cnt;
 };
 
 /* 
@@ -179,6 +178,9 @@ static inline int ip_mr_init(void)
 #endif
 
 struct vif_device {
+	struct list_head list;
+	unsigned index;
+
 	struct net_device 	*dev;			/* Device we are using */
 	unsigned long	bytes_in,bytes_out;
 	unsigned long	pkt_in,pkt_out;		/* Statistics 			*/
@@ -195,7 +197,7 @@ struct mfc_cache {
 	struct list_head list;
 	__be32 mfc_mcastgrp;			/* Group the entry belongs to 	*/
 	__be32 mfc_origin;			/* Source of packet 		*/
-	vifi_t mfc_parent;			/* Source interface		*/
+	struct vif_device *mfc_parent;		/* Source interface		*/
 	int mfc_flags;				/* Flags on line		*/
 
 	union {
@@ -205,12 +207,11 @@ struct mfc_cache {
 		} unres;
 		struct {
 			unsigned long last_assert;
-			int minvif;
-			int maxvif;
 			unsigned long bytes;
 			unsigned long pkt;
 			unsigned long wrong_if;
-			unsigned char ttls[MAXVIFS];	/* TTL thresholds		*/
+			unsigned output_dev_count;
+			struct vif_device **output_devs;
 		} res;
 	} mfc_un;
 };
diff -puNrb linux-2.6.35/include/linux/mtd/nand_ecc_mlc.h linux/include/linux/mtd/nand_ecc_mlc.h
--- linux-2.6.35/include/linux/mtd/nand_ecc_mlc.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/include/linux/mtd/nand_ecc_mlc.h	2011-05-02 10:08:28.643103482 +0300
@@ -0,0 +1,7 @@
+#ifndef __MTD_NAND_ECC_MLC_H__
+#define __MTD_NAND_ECC_MLC_H__
+
+int nand_calculate_ecc_mlc(const u_char *dat, u_char *ecc_code);
+int nand_correct_data_mlc(u_char *dat, u_char *read_ecc);
+
+#endif /* __MTD_NAND_ECC_H__ */
diff -puNrb linux-2.6.35/include/linux/mtd/nand.h linux/include/linux/mtd/nand.h
--- linux-2.6.35/include/linux/mtd/nand.h	2011-04-26 16:26:01.841857429 +0300
+++ linux/include/linux/mtd/nand.h	2011-05-02 10:08:28.653157344 +0300
@@ -412,6 +412,9 @@ struct nand_chip {
 	uint8_t		cellinfo;
 	int		badblockpos;
 	int		badblockbits;
+#ifdef MIPSEL
+	unsigned	backup_offset;
+#endif
 
 	flstate_t	state;
 
@@ -434,6 +437,14 @@ struct nand_chip {
 	void		*priv;
 };
 
+#define BACKUP_4xFF_OFFSET	36
+#define ALWAYS_4x00_OFFSET	32
+#define ECC_ID_OFFSET		01
+/* ECC_ID_OFFSET contains:
+ *	0x00 => mlc ecc (>= 4bit/512 bytes),
+ *	0xff => slc ecc (>= 1bit/256 bytes)
+ */
+
 /*
  * NAND Flash Manufacturer ID Codes
  */
diff -puNrb linux-2.6.35/include/linux/netdevice.h linux/include/linux/netdevice.h
--- linux-2.6.35/include/linux/netdevice.h	2011-04-26 16:26:02.512795595 +0300
+++ linux/include/linux/netdevice.h	2011-05-02 10:08:28.673214162 +0300
@@ -218,6 +218,7 @@ enum {
 struct neighbour;
 struct neigh_parms;
 struct sk_buff;
+struct m_port;
 
 struct netdev_hw_addr {
 	struct list_head	list;
@@ -714,6 +715,8 @@ struct net_device_ops {
 					          struct ifmap *map);
 	int			(*ndo_change_mtu)(struct net_device *dev,
 						  int new_mtu);
+	int			(*ndo_change_l2mtu)(struct net_device *dev,
+						  int new_l2mtu);
 	int			(*ndo_neigh_setup)(struct net_device *dev,
 						   struct neigh_parms *);
 	void			(*ndo_tx_timeout) (struct net_device *dev);
@@ -892,6 +895,7 @@ struct net_device {
 	unsigned char		link_mode; /* mapping policy to operstate */
 
 	unsigned int		mtu;	/* interface MTU value		*/
+	unsigned		l2mtu;	/* real layer 2 MTU */
 	unsigned short		type;	/* interface hardware type	*/
 	unsigned short		hard_header_len;	/* hardware hdr length	*/
 
@@ -1031,6 +1035,8 @@ struct net_device {
 	/* GARP */
 	struct garp_port	*garp_port;
 
+	struct m_port		*mesh_port;
+
 	/* class/net/name entry */
 	struct device		dev;
 	/* space for optional device, statistics, and wireless sysfs groups */
@@ -1046,6 +1052,12 @@ struct net_device {
 #define GSO_MAX_SIZE		65536
 	unsigned int		gso_max_size;
 
+	unsigned		devid;
+
+	/* interface total rate limit */
+	void *rate_limit_stuff_rx;
+	void *rate_limit_stuff_tx;
+
 #ifdef CONFIG_DCB
 	/* Data Center Bridging netlink ops */
 	const struct dcbnl_rtnl_ops *dcbnl_ops;
@@ -1281,6 +1293,7 @@ extern int		dev_alloc_name(struct net_de
 extern int		dev_open(struct net_device *dev);
 extern int		dev_close(struct net_device *dev);
 extern void		dev_disable_lro(struct net_device *dev);
+extern struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb);
 extern int		dev_queue_xmit(struct sk_buff *skb);
 extern int		register_netdevice(struct net_device *dev);
 extern void		unregister_netdevice_queue(struct net_device *dev,
@@ -2116,6 +2129,7 @@ extern void		netdev_state_change(struct 
 extern int		netdev_bonding_change(struct net_device *dev,
 					      unsigned long event);
 extern void		netdev_features_change(struct net_device *dev);
+extern void		netdev_l2mtu_change(struct net_device *dev);
 /* Load a device via the kmod */
 extern void		dev_load(struct net *net, const char *name);
 extern void		dev_mcast_init(void);
diff -puNrb linux-2.6.35/include/linux/netfilter/nf_conntrack_common.h linux/include/linux/netfilter/nf_conntrack_common.h
--- linux-2.6.35/include/linux/netfilter/nf_conntrack_common.h	2011-04-26 16:25:58.901856580 +0300
+++ linux/include/linux/netfilter/nf_conntrack_common.h	2011-05-02 10:08:28.683103578 +0300
@@ -90,6 +90,7 @@ enum ip_conntrack_events {
 	IPCT_MARK,		/* new mark has been set */
 	IPCT_NATSEQADJ,		/* NAT is doing sequence adjustment */
 	IPCT_SECMARK,		/* new security mark has been set */
+	IPCT_P2P,
 };
 
 enum ip_conntrack_expect_events {
diff -puNrb linux-2.6.35/include/linux/netfilter/nf_conntrack_h323.h linux/include/linux/netfilter/nf_conntrack_h323.h
--- linux-2.6.35/include/linux/netfilter/nf_conntrack_h323.h	2011-04-26 16:25:58.881902437 +0300
+++ linux/include/linux/netfilter/nf_conntrack_h323.h	2011-05-02 10:08:28.703213653 +0300
@@ -7,7 +7,7 @@
 
 #define RAS_PORT 1719
 #define Q931_PORT 1720
-#define H323_RTP_CHANNEL_MAX 4	/* Audio, video, FAX and other */
+#define H323_RTP_CHANNEL_MAX 8	/* Audio, video, FAX and other */
 
 /* This structure exists only once per master */
 struct nf_ct_h323_master {
diff -puNrb linux-2.6.35/include/linux/netfilter/nf_conntrack_pptp.h linux/include/linux/netfilter/nf_conntrack_pptp.h
--- linux-2.6.35/include/linux/netfilter/nf_conntrack_pptp.h	2011-04-26 16:25:58.891857411 +0300
+++ linux/include/linux/netfilter/nf_conntrack_pptp.h	2011-05-02 10:08:28.713103478 +0300
@@ -57,7 +57,7 @@ struct pptp_pkt_hdr {
 	__u16	packetLength;
 	__be16	packetType;
 	__be32	magicCookie;
-};
+} __attribute__((packed));
 
 /* PptpControlMessageType values */
 #define PPTP_START_SESSION_REQUEST	1
diff -puNrb linux-2.6.35/include/linux/netfilter/nfnetlink_conntrack.h linux/include/linux/netfilter/nfnetlink_conntrack.h
--- linux-2.6.35/include/linux/netfilter/nfnetlink_conntrack.h	2011-04-26 16:25:58.891857411 +0300
+++ linux/include/linux/netfilter/nfnetlink_conntrack.h	2011-05-02 10:08:28.723104236 +0300
@@ -36,6 +36,7 @@ enum ctattr_type {
 	CTA_USE,
 	CTA_ID,
 	CTA_NAT_DST,
+	CTA_P2P,
 	CTA_TUPLE_MASTER,
 	CTA_NAT_SEQ_ADJ_ORIG,
 	CTA_NAT_SEQ_ADJ_REPLY,
diff -puNrb linux-2.6.35/include/linux/netfilter/xt_connmark.h linux/include/linux/netfilter/xt_connmark.h
--- linux-2.6.35/include/linux/netfilter/xt_connmark.h	2011-04-26 16:25:58.901856580 +0300
+++ linux/include/linux/netfilter/xt_connmark.h	2011-05-02 10:08:28.733103311 +0300
@@ -21,6 +21,7 @@ enum {
 struct xt_connmark_tginfo1 {
 	__u32 ctmark, ctmask, nfmask;
 	__u8 mode;
+        __u8 passthrough;
 };
 
 struct xt_connmark_mtinfo1 {
diff -puNrb linux-2.6.35/include/linux/netfilter/xt_mark.h linux/include/linux/netfilter/xt_mark.h
--- linux-2.6.35/include/linux/netfilter/xt_mark.h	2011-04-26 16:25:58.891857411 +0300
+++ linux/include/linux/netfilter/xt_mark.h	2011-05-02 10:08:28.753214141 +0300
@@ -5,6 +5,7 @@
 
 struct xt_mark_tginfo2 {
 	__u32 mark, mask;
+	__u8 passthrough;
 };
 
 struct xt_mark_mtinfo1 {
diff -puNrb linux-2.6.35/include/linux/netfilter_bridge.h linux/include/linux/netfilter_bridge.h
--- linux-2.6.35/include/linux/netfilter_bridge.h	2011-04-26 16:26:02.391855449 +0300
+++ linux/include/linux/netfilter_bridge.h	2011-05-02 10:08:28.763213378 +0300
@@ -60,6 +60,7 @@ static inline unsigned int nf_bridge_enc
 {
 	switch (skb->protocol) {
 	case __cpu_to_be16(ETH_P_8021Q):
+	case __constant_htons(ETH_P_8021Q_S):
 		return VLAN_HLEN;
 	case __cpu_to_be16(ETH_P_PPP_SES):
 		return PPPOE_SES_HLEN;
diff -puNrb linux-2.6.35/include/linux/netfilter_ipv4/ip_tables.h linux/include/linux/netfilter_ipv4/ip_tables.h
--- linux-2.6.35/include/linux/netfilter_ipv4/ip_tables.h	2011-04-26 16:25:58.551857133 +0300
+++ linux/include/linux/netfilter_ipv4/ip_tables.h	2011-05-02 10:08:28.773162802 +0300
@@ -220,7 +220,7 @@ struct ipt_get_entries {
 static __inline__ struct ipt_entry_target *
 ipt_get_target(struct ipt_entry *e)
 {
-	return (void *)e + e->target_offset;
+	return (struct ipt_entry_target *) ((char *)e + e->target_offset);
 }
 
 #ifndef __KERNEL__
diff -puNrb linux-2.6.35/include/linux/netfilter_ipv4/ipt_IMQ.h linux/include/linux/netfilter_ipv4/ipt_IMQ.h
--- linux-2.6.35/include/linux/netfilter_ipv4/ipt_IMQ.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/include/linux/netfilter_ipv4/ipt_IMQ.h	2011-05-02 10:08:28.783157753 +0300
@@ -0,0 +1,8 @@
+#ifndef _IPT_IMQ_H
+#define _IPT_IMQ_H
+
+struct ipt_imq_info {
+       unsigned int todev;     /* target imq device */
+};
+
+#endif /* _IPT_IMQ_H */
diff -puNrb linux-2.6.35/include/linux/netfilter_ipv6/ip6_tables.h linux/include/linux/netfilter_ipv6/ip6_tables.h
--- linux-2.6.35/include/linux/netfilter_ipv6/ip6_tables.h	2011-04-26 16:25:58.591903473 +0300
+++ linux/include/linux/netfilter_ipv6/ip6_tables.h	2011-05-02 10:08:28.793103766 +0300
@@ -277,7 +277,7 @@ struct ip6t_get_entries {
 static __inline__ struct ip6t_entry_target *
 ip6t_get_target(struct ip6t_entry *e)
 {
-	return (void *)e + e->target_offset;
+	return (struct ip6t_entry_target *) ((char *)e + e->target_offset);
 }
 
 #ifndef __KERNEL__
diff -puNrb linux-2.6.35/include/linux/netfilter_ipv6/ip6t_IMQ.h linux/include/linux/netfilter_ipv6/ip6t_IMQ.h
--- linux-2.6.35/include/linux/netfilter_ipv6/ip6t_IMQ.h	1970-01-01 03:00:00.000000000 +0300
+++ linux/include/linux/netfilter_ipv6/ip6t_IMQ.h	2011-05-02 10:08:28.813102933 +0300
@@ -0,0 +1,8 @@
+#ifndef _IP6T_IMQ_H
+#define _IP6T_IMQ_H
+
+struct ip6t_imq_info {
+       unsigned int todev;     /* target imq device */
+};
+
+#endif /* _IP6T_IMQ_H */
diff -puNrb linux-2.6.35/include/linux/netlink.h linux/include/linux/netlink.h
--- linux-2.6.35/include/linux/netlink.h	2011-04-26 16:26:02.431855544 +0300
+++ linux/include/linux/netlink.h	2011-05-02 10:08:28.821544899 +0300
@@ -24,6 +24,11 @@
 /* leave room for NETLINK_DM (DM Events) */
 #define NETLINK_SCSITRANSPORT	18	/* SCSI Transports */
 #define NETLINK_ECRYPTFS	19
+#define NETLINK_WIRELESS	17
+#define NETLINK_ADDRLIST	20
+#define NETLINK_STP		21
+#define NETLINK_UNICL		22
+#define NETLINK_MESH		24
 
 #define MAX_LINKS 32		
 
diff -puNrb linux-2.6.35/include/linux/notifier.h linux/include/linux/notifier.h
--- linux-2.6.35/include/linux/notifier.h	2011-04-26 16:26:02.591855643 +0300
+++ linux/include/linux/notifier.h	2011-05-02 10:08:28.831545003 +0300
@@ -210,6 +210,7 @@ static inline int notifier_to_errno(int 
 #define NETDEV_POST_INIT	0x0010
 #define NETDEV_UNREGISTER_BATCH 0x0011
 #define NETDEV_BONDING_DESLAVE  0x0012
+#define NETDEV_CHANGEL2MTU	0x0013
 
 #define SYS_DOWN	0x0001	/* Notify of system down */
 #define SYS_RESTART	SYS_DOWN
diff -puNrb linux-2.6.35/include/linux/pkt_sched.h linux/include/linux/pkt_sched.h
--- linux-2.6.35/include/linux/pkt_sched.h	2011-04-26 16:26:02.381855642 +0300
+++ linux/include/linux/pkt_sched.h	2011-05-02 10:08:28.851588477 +0300
@@ -255,11 +255,17 @@ struct tc_gred_sopt {
 struct tc_htb_opt {
 	struct tc_ratespec 	rate;
 	struct tc_ratespec 	ceil;
+	struct tc_ratespec	burst;
 	__u32	buffer;
 	__u32	cbuffer;
+	__u32	bbuffer;
 	__u32	quantum;
 	__u32	level;		/* out only */
 	__u32	prio;
+
+	__u32	thr_ceil;
+	__u32	thr_burst;
+	__u32	interval;
 };
 struct tc_htb_glob {
 	__u32 version;		/* to match HTB/TC */
@@ -274,6 +280,7 @@ enum {
 	TCA_HTB_UNSPEC,
 	TCA_HTB_PARMS,
 	TCA_HTB_INIT,
+	TCA_HTB_BTAB,
 	TCA_HTB_CTAB,
 	TCA_HTB_RTAB,
 	__TCA_HTB_MAX,
diff -puNrb linux-2.6.35/include/linux/ppp-comp.h linux/include/linux/ppp-comp.h
--- linux-2.6.35/include/linux/ppp-comp.h	2011-04-26 16:26:02.532791750 +0300
+++ linux/include/linux/ppp-comp.h	2011-05-02 10:08:28.861592080 +0300
@@ -143,7 +143,7 @@ struct compressor {
  * Max # bytes for a CCP option
  */
 
-#define CCP_MAX_OPTION_LENGTH	32
+#define CCP_MAX_OPTION_LENGTH	64
 
 /*
  * Parts of a CCP packet.
diff -puNrb linux-2.6.35/include/linux/ppp_defs.h linux/include/linux/ppp_defs.h
--- linux-2.6.35/include/linux/ppp_defs.h	2011-04-26 16:26:02.512795595 +0300
+++ linux/include/linux/ppp_defs.h	2011-05-02 10:08:28.871586659 +0300
@@ -70,6 +70,7 @@
 #define PPP_IPX		0x2b	/* IPX protocol */
 #define	PPP_VJC_COMP	0x2d	/* VJ compressed TCP */
 #define	PPP_VJC_UNCOMP	0x2f	/* VJ uncompressed TCP */
+#define PPP_BRIDGE	0x31	/* Bridged ethernet */
 #define PPP_MP		0x3d	/* Multilink protocol */
 #define PPP_IPV6	0x57	/* Internet Protocol Version 6 */
 #define PPP_COMPFRAG	0xfb	/* fragment compressed below bundle */
diff -puNrb linux-2.6.35/include/linux/rtnetlink.h linux/include/linux/rtnetlink.h
--- linux-2.6.35/include/linux/rtnetlink.h	2011-04-26 16:26:02.492814086 +0300
+++ linux/include/linux/rtnetlink.h	2011-05-02 10:08:28.881545104 +0300
@@ -282,6 +282,7 @@ enum rtattr_type_t {
 	RTA_SESSION, /* no longer used */
 	RTA_MP_ALGO, /* no longer used */
 	RTA_TABLE,
+	RTA_MPLSKEY,
 	__RTA_MAX
 };
 
diff -puNrb linux-2.6.35/include/linux/serial_core.h linux/include/linux/serial_core.h
--- linux-2.6.35/include/linux/serial_core.h	2011-04-26 16:26:02.441855705 +0300
+++ linux/include/linux/serial_core.h	2011-05-02 10:08:28.901589539 +0300
@@ -112,6 +112,9 @@
 /* TXX9 type number */
 #define PORT_TXX9	64
 
+/* ADMtek ADM5120 SoC */
+#define PORT_ADM5120	68
+
 /* NEC VR4100 series SIU/DSIU */
 #define PORT_VR41XX_SIU		65
 #define PORT_VR41XX_DSIU	66
diff -puNrb linux-2.6.35/include/linux/skbuff.h linux/include/linux/skbuff.h
--- linux-2.6.35/include/linux/skbuff.h	2011-04-26 16:26:02.522789927 +0300
+++ linux/include/linux/skbuff.h	2011-05-02 10:08:28.911545229 +0300
@@ -29,6 +29,9 @@
 #include <linux/rcupdate.h>
 #include <linux/dmaengine.h>
 #include <linux/hrtimer.h>
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#include <linux/imq.h>
+#endif
 
 /* Don't change this without changing skb_csum_unnecessary! */
 #define CHECKSUM_NONE 0
@@ -327,6 +330,9 @@ struct sk_buff {
 	 * first. This is owned by whoever has the skb queued ATM.
 	 */
 	char			cb[48] __aligned(8);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	void			*cb_next;
+#endif
 
 	unsigned long		_skb_refdst;
 #ifdef CONFIG_XFRM
@@ -343,7 +349,8 @@ struct sk_buff {
 			__u16	csum_offset;
 		};
 	};
-	__u32			priority;
+	__u16			priority;
+	__u16			ingress_priority;
 	kmemcheck_bitfield_begin(flags1);
 	__u8			local_df:1,
 				cloned:1,
@@ -363,16 +370,25 @@ struct sk_buff {
 	struct nf_conntrack	*nfct;
 	struct sk_buff		*nfct_reasm;
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	struct nf_queue_entry	*nf_queue_entry;
+#endif
 #ifdef CONFIG_BRIDGE_NETFILTER
 	struct nf_bridge_info	*nf_bridge;
 #endif
 
+	int			sched_pkt_len;
+	unsigned short		prmark;
+	unsigned short		hsmark;
+	unsigned char		layer7seen;
+
 	int			skb_iif;
 #ifdef CONFIG_NET_SCHED
 	__u16			tc_index;	/* traffic control index */
 #ifdef CONFIG_NET_CLS_ACT
 	__u16			tc_verd;	/* traffic control verdict */
 #endif
+
 #endif
 
 	__u32			rxhash;
@@ -389,6 +405,10 @@ struct sk_buff {
 
 	/* 0/14 bit hole */
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	__u8			imq_flags:IMQ_F_BITS;
+#endif
+
 #ifdef CONFIG_NET_DMA
 	dma_cookie_t		dma_cookie;
 #endif
@@ -487,6 +507,12 @@ static inline struct rtable *skb_rtable(
 	return (struct rtable *)skb_dst(skb);
 }
 
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+extern int skb_save_cb(struct sk_buff *skb);
+extern int skb_restore_cb(struct sk_buff *skb);
+#endif
+
 extern void kfree_skb(struct sk_buff *skb);
 extern void consume_skb(struct sk_buff *skb);
 extern void	       __kfree_skb(struct sk_buff *skb);
@@ -1653,7 +1679,7 @@ static inline int skb_padto(struct sk_bu
 }
 
 static inline int skb_add_data(struct sk_buff *skb,
-			       char __user *from, int copy)
+			       unsigned char __user *from, int copy)
 {
 	const int off = skb->len;
 
@@ -2034,6 +2060,10 @@ static inline void __nf_copy(struct sk_b
 	dst->nfct_reasm = src->nfct_reasm;
 	nf_conntrack_get_reasm(src->nfct_reasm);
 #endif
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	dst->imq_flags = src->imq_flags;
+	dst->nf_queue_entry = src->nf_queue_entry;
+#endif
 #ifdef CONFIG_BRIDGE_NETFILTER
 	dst->nf_bridge  = src->nf_bridge;
 	nf_bridge_get(src->nf_bridge);
diff -puNrb linux-2.6.35/include/linux/slab.h linux/include/linux/slab.h
--- linux-2.6.35/include/linux/slab.h	2011-04-26 16:26:02.571855611 +0300
+++ linux/include/linux/slab.h	2011-05-02 10:08:28.931592252 +0300
@@ -130,8 +130,8 @@ int kmem_ptr_validate(struct kmem_cache 
  * to do various tricks to work around compiler limitations in order to
  * ensure proper constant folding.
  */
-#define KMALLOC_SHIFT_HIGH	((MAX_ORDER + PAGE_SHIFT - 1) <= 25 ? \
-				(MAX_ORDER + PAGE_SHIFT - 1) : 25)
+#define KMALLOC_SHIFT_HIGH	((MAX_ORDER + PAGE_SHIFT - 1) <= 17 ? \
+				(MAX_ORDER + PAGE_SHIFT - 1) : 17)
 
 #define KMALLOC_MAX_SIZE	(1UL << KMALLOC_SHIFT_HIGH)
 #define KMALLOC_MAX_ORDER	(KMALLOC_SHIFT_HIGH - PAGE_SHIFT)
diff -puNrb linux-2.6.35/include/linux/sockios.h linux/include/linux/sockios.h
--- linux-2.6.35/include/linux/sockios.h	2011-04-26 16:26:02.532791750 +0300
+++ linux/include/linux/sockios.h	2011-05-02 10:08:28.941618468 +0300
@@ -65,6 +65,7 @@
 #define SIOCDIFADDR	0x8936		/* delete PA address		*/
 #define	SIOCSIFHWBROADCAST	0x8937	/* set hardware broadcast addr	*/
 #define SIOCGIFCOUNT	0x8938		/* get number of devices */
+#define SIOCSPROXYARP	0x8939		/* set device proxy-arp setting */
 
 #define SIOCGIFBR	0x8940		/* Bridging support		*/
 #define SIOCSIFBR	0x8941		/* Set bridging options 	*/
@@ -83,6 +84,8 @@
 
 #define SIOCWANDEV	0x894A		/* get/set netdev parameters	*/
 
+#define SIOCSIFL2MTU	0x894B		/* set net_device l2mtu		*/
+
 /* ARP cache control calls. */
 		    /*  0x8950 - 0x8952  * obsolete calls, don't re-use */
 #define SIOCDARP	0x8953		/* delete ARP table entry	*/
@@ -116,6 +119,9 @@
 #define SIOCBONDINFOQUERY      0x8994	/* rtn info about bond state    */
 #define SIOCBONDCHANGEACTIVE   0x8995   /* update to a new active slave */
 			
+#define SIOCSDEVID	0x899e		/* set device id */
+#define SIOCGDEVID	0x899f		/* get device id */
+			
 /* bridge calls */
 #define SIOCBRADDBR     0x89a0		/* create new bridge device     */
 #define SIOCBRDELBR     0x89a1		/* remove bridge device         */
diff -puNrb linux-2.6.35/include/linux/spi/spi.h linux/include/linux/spi/spi.h
--- linux-2.6.35/include/linux/spi/spi.h	2011-04-26 16:25:56.351898414 +0300
+++ linux/include/linux/spi/spi.h	2011-05-02 10:08:28.951589278 +0300
@@ -428,6 +428,8 @@ struct spi_transfer {
 	dma_addr_t	rx_dma;
 
 	unsigned	cs_change:1;
+	unsigned	verify:1;
+	unsigned	fast_write:1;
 	u8		bits_per_word;
 	u16		delay_usecs;
 	u32		speed_hz;
@@ -469,6 +471,7 @@ struct spi_message {
 	struct spi_device	*spi;
 
 	unsigned		is_dma_mapped:1;
+	unsigned		fast_read:1;
 
 	/* REVISIT:  we might want a flag affecting the behavior of the
 	 * last transfer ... allowing things like "read 16 bit length L"
diff -puNrb linux-2.6.35/include/linux/tcp.h linux/include/linux/tcp.h
--- linux-2.6.35/include/linux/tcp.h	2011-04-26 16:26:02.571855611 +0300
+++ linux/include/linux/tcp.h	2011-05-02 10:08:28.971590522 +0300
@@ -54,7 +54,7 @@ struct tcphdr {
 	__be16	window;
 	__sum16	check;
 	__be16	urg_ptr;
-};
+} __attribute__((packed));
 
 /*
  *	The union cast uses a gcc extension to avoid aliasing problems
@@ -64,21 +64,21 @@ struct tcphdr {
 union tcp_word_hdr { 
 	struct tcphdr hdr;
 	__be32 		  words[5];
-}; 
+} __attribute__((packed));
 
 #define tcp_flag_word(tp) ( ((union tcp_word_hdr *)(tp))->words [3]) 
 
 enum { 
-	TCP_FLAG_CWR = __cpu_to_be32(0x00800000),
-	TCP_FLAG_ECE = __cpu_to_be32(0x00400000),
-	TCP_FLAG_URG = __cpu_to_be32(0x00200000),
-	TCP_FLAG_ACK = __cpu_to_be32(0x00100000),
-	TCP_FLAG_PSH = __cpu_to_be32(0x00080000),
-	TCP_FLAG_RST = __cpu_to_be32(0x00040000),
-	TCP_FLAG_SYN = __cpu_to_be32(0x00020000),
-	TCP_FLAG_FIN = __cpu_to_be32(0x00010000),
-	TCP_RESERVED_BITS = __cpu_to_be32(0x0F000000),
-	TCP_DATA_OFFSET = __cpu_to_be32(0xF0000000)
+	TCP_FLAG_CWR = __constant_cpu_to_be32(0x00800000),
+	TCP_FLAG_ECE = __constant_cpu_to_be32(0x00400000),
+	TCP_FLAG_URG = __constant_cpu_to_be32(0x00200000),
+	TCP_FLAG_ACK = __constant_cpu_to_be32(0x00100000),
+	TCP_FLAG_PSH = __constant_cpu_to_be32(0x00080000),
+	TCP_FLAG_RST = __constant_cpu_to_be32(0x00040000),
+	TCP_FLAG_SYN = __constant_cpu_to_be32(0x00020000),
+	TCP_FLAG_FIN = __constant_cpu_to_be32(0x00010000),
+	TCP_RESERVED_BITS = __constant_cpu_to_be32(0x0F000000),
+	TCP_DATA_OFFSET = __constant_cpu_to_be32(0xF0000000)
 }; 
 
 /*
@@ -234,7 +234,7 @@ struct tcp_sack_block_wire {
 struct tcp_sack_block {
 	u32	start_seq;
 	u32	end_seq;
-};
+} __attribute__((packed));
 
 struct tcp_options_received {
 /*	PAWS/RTTM data	*/
diff -puNrb linux-2.6.35/include/linux/udp.h linux/include/linux/udp.h
--- linux-2.6.35/include/linux/udp.h	2011-04-26 16:26:02.461855449 +0300
+++ linux/include/linux/udp.h	2011-05-02 10:08:28.981586431 +0300
@@ -24,7 +24,7 @@ struct udphdr {
 	__be16	dest;
 	__be16	len;
 	__sum16	check;
-};
+} __attribute__((packed));
 
 /* UDP socket options */
 #define UDP_CORK	1	/* Never send partially complete segments */
diff -puNrb linux-2.6.35/include/linux/usb/serial.h linux/include/linux/usb/serial.h
--- linux-2.6.35/include/linux/usb/serial.h	2011-04-26 16:25:57.141283775 +0300
+++ linux/include/linux/usb/serial.h	2011-05-02 10:08:28.991545075 +0300
@@ -231,6 +231,8 @@ struct usb_serial_driver {
 	const struct usb_device_id *id_table;
 	char	num_ports;
 
+	unsigned max_buf_size;
+
 	struct list_head	driver_list;
 	struct device_driver	driver;
 	struct usb_driver	*usb_driver;
diff -puNrb linux-2.6.35/include/net/inet_sock.h linux/include/net/inet_sock.h
--- linux-2.6.35/include/net/inet_sock.h	2011-04-26 16:25:55.552477755 +0300
+++ linux/include/net/inet_sock.h	2011-05-02 10:08:29.001545098 +0300
@@ -55,7 +55,7 @@ struct ip_options {
 	unsigned char	cipso;
 	unsigned char	__pad2;
 	unsigned char	__data[0];
-};
+} __attribute__((packed));
 
 #define optlength(opt) (sizeof(struct ip_options) + opt->optlen)
 
diff -puNrb linux-2.6.35/include/net/ip_fib.h linux/include/net/ip_fib.h
--- linux-2.6.35/include/net/ip_fib.h	2011-04-26 16:25:55.572495025 +0300
+++ linux/include/net/ip_fib.h	2011-05-02 10:08:29.021587757 +0300
@@ -41,6 +41,7 @@ struct fib_config {
 	u32			fc_flow;
 	u32			fc_nlflags;
 	struct nl_info		fc_nlinfo;
+	u32			fc_mplskey;
  };
 
 struct fib_info;
@@ -58,6 +59,7 @@ struct fib_nh {
 #ifdef CONFIG_NET_CLS_ROUTE
 	__u32			nh_tclassid;
 #endif
+	__u32			nh_mplskey;
 	int			nh_oif;
 	__be32			nh_gw;
 };
diff -puNrb linux-2.6.35/include/net/netfilter/nf_conntrack_acct.h linux/include/net/netfilter/nf_conntrack_acct.h
--- linux-2.6.35/include/net/netfilter/nf_conntrack_acct.h	2011-04-26 16:25:55.312477790 +0300
+++ linux/include/net/netfilter/nf_conntrack_acct.h	2011-05-02 10:08:29.041590568 +0300
@@ -17,6 +17,10 @@
 struct nf_conn_counter {
 	u_int64_t packets;
 	u_int64_t bytes;
+
+	u_int32_t bytes_prev_second;
+	u_int32_t bytes_this_second;
+	unsigned long second_end_jiffies;
 };
 
 static inline
diff -puNrb linux-2.6.35/include/net/netfilter/nf_conntrack.h linux/include/net/netfilter/nf_conntrack.h
--- linux-2.6.35/include/net/netfilter/nf_conntrack.h	2011-04-26 16:25:55.312477790 +0300
+++ linux/include/net/netfilter/nf_conntrack.h	2011-05-02 10:08:29.051582381 +0300
@@ -112,10 +112,20 @@ struct nf_conn {
 	u_int32_t mark;
 #endif
 
+	u_int32_t p2p_mark;
+
+	u_int32_t extra_timeout;
+
 #ifdef CONFIG_NF_CONNTRACK_SECMARK
 	u_int32_t secmark;
 #endif
 
+	struct {
+		unsigned proto;
+		char *data;
+		unsigned int data_len;
+	} layer7;
+
 	/* Storage reserved for other modules: */
 	union nf_conntrack_proto proto;
 
@@ -206,6 +216,7 @@ extern void nf_ct_delete_from_lists(stru
 extern void nf_ct_insert_dying_list(struct nf_conn *ct);
 
 extern void nf_conntrack_flush_report(struct net *net, u32 pid, int report);
+extern void nf_conntrack_change_ip(unsigned old_ip, unsigned new_ip);
 
 extern bool nf_ct_get_tuplepr(const struct sk_buff *skb,
 			      unsigned int nhoff, u_int16_t l3num,
diff -puNrb linux-2.6.35/include/net/netfilter/nf_conntrack_tuple.h linux/include/net/netfilter/nf_conntrack_tuple.h
--- linux-2.6.35/include/net/netfilter/nf_conntrack_tuple.h	2011-04-26 16:25:55.312477790 +0300
+++ linux/include/net/netfilter/nf_conntrack_tuple.h	2011-05-02 10:08:29.071592022 +0300
@@ -12,7 +12,9 @@
 
 #include <linux/netfilter/x_tables.h>
 #include <linux/netfilter/nf_conntrack_tuple_common.h>
+#ifdef __KERNEL__
 #include <linux/list_nulls.h>
+#endif
 
 /* A `tuple' is a structure containing the information to uniquely
   identify a connection.  ie. if two packets have the same tuple, they
@@ -148,8 +150,6 @@ struct nf_conntrack_tuple_hash {
 	struct nf_conntrack_tuple tuple;
 };
 
-#endif /* __KERNEL__ */
-
 static inline bool __nf_ct_tuple_src_equal(const struct nf_conntrack_tuple *t1,
 					   const struct nf_conntrack_tuple *t2)
 { 
@@ -213,4 +213,6 @@ nf_ct_tuple_mask_cmp(const struct nf_con
 	       __nf_ct_tuple_dst_equal(t, tuple);
 }
 
+#endif /* __KERNEL__ */
+
 #endif /* _NF_CONNTRACK_TUPLE_H */
diff -puNrb linux-2.6.35/include/net/netfilter/nf_queue.h linux/include/net/netfilter/nf_queue.h
--- linux-2.6.35/include/net/netfilter/nf_queue.h	2011-04-26 16:25:55.312477790 +0300
+++ linux/include/net/netfilter/nf_queue.h	2011-05-02 10:08:29.081544478 +0300
@@ -13,6 +13,12 @@ struct nf_queue_entry {
 	struct net_device	*indev;
 	struct net_device	*outdev;
 	int			(*okfn)(struct sk_buff *);
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	int			(*next_outfn)(struct nf_queue_entry *entry,
+					      unsigned int queuenum);
+	unsigned int		next_queuenum;
+#endif
 };
 
 #define nf_queue_entry_reroute(x) ((void *)x + sizeof(struct nf_queue_entry))
@@ -30,5 +36,11 @@ extern int nf_unregister_queue_handler(u
 				       const struct nf_queue_handler *qh);
 extern void nf_unregister_queue_handlers(const struct nf_queue_handler *qh);
 extern void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
+extern void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+extern void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
+extern void nf_unregister_queue_imq_handler(void);
+#endif
 
 #endif /* _NF_QUEUE_H */
diff -puNrb linux-2.6.35/include/net/sch_generic.h linux/include/net/sch_generic.h
--- linux-2.6.35/include/net/sch_generic.h	2011-04-26 16:25:55.562477600 +0300
+++ linux/include/net/sch_generic.h	2011-05-02 10:08:29.091589110 +0300
@@ -373,7 +373,7 @@ static inline bool qdisc_tx_is_noop(cons
 
 static inline unsigned int qdisc_pkt_len(struct sk_buff *skb)
 {
-	return qdisc_skb_cb(skb)->pkt_len;
+	return skb->sched_pkt_len;
 }
 
 /* additional qdisc xmit flags (NET_XMIT_MASK in linux/netdevice.h) */
@@ -399,7 +399,7 @@ static inline int qdisc_enqueue(struct s
 
 static inline int qdisc_enqueue_root(struct sk_buff *skb, struct Qdisc *sch)
 {
-	qdisc_skb_cb(skb)->pkt_len = skb->len;
+	skb->sched_pkt_len = skb->len;
 	return qdisc_enqueue(skb, sch) & NET_XMIT_MASK;
 }
 
diff -puNrb linux-2.6.35/include/net/sock.h linux/include/net/sock.h
--- linux-2.6.35/include/net/sock.h	2011-04-26 16:25:55.562477600 +0300
+++ linux/include/net/sock.h	2011-05-02 10:08:29.111587917 +0300
@@ -1363,7 +1363,7 @@ static inline int skb_copy_to_page(struc
 {
 	if (skb->ip_summed == CHECKSUM_NONE) {
 		int err = 0;
-		__wsum csum = csum_and_copy_from_user(from,
+		__wsum csum = csum_and_copy_from_user((unsigned char *) from,
 						     page_address(page) + off,
 							    copy, 0, &err);
 		if (err)
diff -puNrb linux-2.6.35/include/scsi/scsi.h linux/include/scsi/scsi.h
--- linux-2.6.35/include/scsi/scsi.h	2011-04-26 16:26:02.661855624 +0300
+++ linux/include/scsi/scsi.h	2011-05-02 10:08:29.131586484 +0300
@@ -151,10 +151,10 @@ struct scsi_cmnd;
 
 /* defined in T10 SCSI Primary Commands-2 (SPC2) */
 struct scsi_varlen_cdb_hdr {
-	u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
-	u8 control;
-	u8 misc[5];
-	u8 additional_cdb_length;         /* total cdb length - 8 */
+	__u8 opcode;        /* opcode always == VARIABLE_LENGTH_CMD */
+	__u8 control;
+	__u8 misc[5];
+	__u8 additional_cdb_length;         /* total cdb length - 8 */
 	__be16 service_action;
 	/* service specific data follows */
 };
diff -puNrb linux-2.6.35/kernel/acct.c linux/kernel/acct.c
--- linux-2.6.35/kernel/acct.c	2011-04-26 16:25:53.731856535 +0300
+++ linux/kernel/acct.c	2011-05-02 10:08:29.141544483 +0300
@@ -224,10 +224,12 @@ static int acct_on(char *name)
 	if (IS_ERR(file))
 		return PTR_ERR(file);
 
+#if 0
 	if (!S_ISREG(file->f_path.dentry->d_inode->i_mode)) {
 		filp_close(file, NULL);
 		return -EACCES;
 	}
+#endif
 
 	if (!file->f_op->write) {
 		filp_close(file, NULL);
diff -puNrb linux-2.6.35/kernel/irq/proc.c linux/kernel/irq/proc.c
--- linux-2.6.35/kernel/irq/proc.c	2011-04-26 16:25:53.521857482 +0300
+++ linux/kernel/irq/proc.c	2011-05-02 10:08:29.161591691 +0300
@@ -214,7 +214,7 @@ static int irq_spurious_proc_show(struct
 
 static int irq_spurious_proc_open(struct inode *inode, struct file *file)
 {
-	return single_open(file, irq_spurious_proc_show, NULL);
+	return single_open(file, irq_spurious_proc_show, PDE(inode)->data);
 }
 
 static const struct file_operations irq_spurious_proc_fops = {
diff -puNrb linux-2.6.35/kernel/kmod.c linux/kernel/kmod.c
--- linux-2.6.35/kernel/kmod.c	2011-04-26 16:25:53.761855156 +0300
+++ linux/kernel/kmod.c	2011-05-02 10:08:29.171593351 +0300
@@ -67,6 +67,7 @@ char modprobe_path[KMOD_PATH_LEN] = "/sb
  */
 int __request_module(bool wait, const char *fmt, ...)
 {
+#if 0
 	va_list args;
 	char module_name[MODULE_NAME_LEN];
 	unsigned int max_modprobes;
@@ -122,6 +123,9 @@ int __request_module(bool wait, const ch
 
 	atomic_dec(&kmod_concurrent);
 	return ret;
+#else
+	return 0;
+#endif
 }
 EXPORT_SYMBOL(__request_module);
 #endif /* CONFIG_MODULES */
diff -puNrb linux-2.6.35/kernel/module.c linux/kernel/module.c
--- linux-2.6.35/kernel/module.c	2011-04-26 16:25:53.731856535 +0300
+++ linux/kernel/module.c	2011-05-02 10:08:29.181545355 +0300
@@ -2283,6 +2283,10 @@ static noinline struct module *load_modu
 	symoffs = layout_symtab(mod, sechdrs, symindex, strindex, hdr,
 				secstrings, &stroffs, strmap);
 
+#ifdef __mips
+	module_relayout(hdr, sechdrs, secstrings, symindex, mod);
+#endif
+
 	/* Do the allocs. */
 	ptr = module_alloc_update_bounds(mod->core_size);
 	/*
@@ -3109,6 +3113,7 @@ EXPORT_SYMBOL_GPL(__module_text_address)
 /* Don't grab lock, we're oopsing. */
 void print_modules(void)
 {
+#if 0
 	struct module *mod;
 	char buf[8];
 
@@ -3121,6 +3126,7 @@ void print_modules(void)
 	if (last_unloaded_module[0])
 		printk(" [last unloaded: %s]", last_unloaded_module);
 	printk("\n");
+#endif
 }
 
 #ifdef CONFIG_MODVERSIONS
diff -puNrb linux-2.6.35/kernel/panic.c linux/kernel/panic.c
--- linux-2.6.35/kernel/panic.c	2011-04-26 16:25:53.721855568 +0300
+++ linux/kernel/panic.c	2011-05-02 10:08:29.201587901 +0300
@@ -36,6 +36,32 @@ ATOMIC_NOTIFIER_HEAD(panic_notifier_list
 
 EXPORT_SYMBOL(panic_notifier_list);
 
+int register_panic_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_register(&panic_notifier_list, nb);
+}
+EXPORT_SYMBOL(register_panic_notifier);
+
+int unregister_panic_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_unregister(&panic_notifier_list, nb);
+}
+EXPORT_SYMBOL(unregister_panic_notifier);
+
+ATOMIC_NOTIFIER_HEAD(oops_notifier_list);
+
+int register_oops_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_register(&oops_notifier_list, nb);
+}
+EXPORT_SYMBOL(register_oops_notifier);
+
+int unregister_oops_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_unregister(&oops_notifier_list, nb);
+}
+EXPORT_SYMBOL(unregister_oops_notifier);
+
 /* Returns how long it waited in ms */
 long (*panic_blink)(long time);
 EXPORT_SYMBOL(panic_blink);
@@ -359,6 +385,8 @@ void oops_exit(void)
 {
 	do_oops_enter_exit();
 	print_oops_end_marker();
+
+	atomic_notifier_call_chain(&oops_notifier_list, 0, 0);
 	kmsg_dump(KMSG_DUMP_OOPS);
 }
 
diff -puNrb linux-2.6.35/kernel/printk.c linux/kernel/printk.c
--- linux-2.6.35/kernel/printk.c	2011-04-26 16:25:53.741856604 +0300
+++ linux/kernel/printk.c	2011-05-02 10:08:29.211544585 +0300
@@ -60,7 +60,7 @@ void asmlinkage __attribute__((weak)) ea
 
 /* We show everything that is MORE important than this.. */
 #define MINIMUM_CONSOLE_LOGLEVEL 1 /* Minimum loglevel we let people use */
-#define DEFAULT_CONSOLE_LOGLEVEL 7 /* anything MORE serious than KERN_DEBUG */
+#define DEFAULT_CONSOLE_LOGLEVEL 1 /* anything MORE serious than KERN_DEBUG */
 
 DECLARE_WAIT_QUEUE_HEAD(log_wait);
 
@@ -1024,6 +1024,7 @@ int is_console_locked(void)
 
 static DEFINE_PER_CPU(int, printk_pending);
 
+#if defined CONFIG_PRINTK
 void printk_tick(void)
 {
 	if (__get_cpu_var(printk_pending)) {
@@ -1036,6 +1037,10 @@ int printk_needs_cpu(int cpu)
 {
 	return per_cpu(printk_pending, cpu);
 }
+#else
+void printk_tick(void) {
+}
+#endif
 
 void wake_up_klogd(void)
 {
@@ -1425,6 +1430,23 @@ bool printk_timed_ratelimit(unsigned lon
 }
 EXPORT_SYMBOL(printk_timed_ratelimit);
 
+void get_some_log(char *buf, int amount) {
+	int spare;
+	unsigned long flags;
+
+	if (amount > log_buf_len) amount = log_buf_len;
+	spin_lock_irqsave(&logbuf_lock, flags);
+	spare = amount - (log_end & LOG_BUF_MASK);
+	if (spare > 0) {
+		memcpy(buf + spare, log_buf, log_end & LOG_BUF_MASK);
+		memcpy(buf, log_buf + (log_buf_len - spare), spare);
+	} else {
+		memcpy(buf, log_buf - spare, amount);
+	}
+	spin_unlock_irqrestore(&logbuf_lock, flags);
+}
+EXPORT_SYMBOL(get_some_log);
+
 static DEFINE_SPINLOCK(dump_list_lock);
 static LIST_HEAD(dump_list);
 
diff -puNrb linux-2.6.35/kernel/profile.c linux/kernel/profile.c
--- linux-2.6.35/kernel/profile.c	2011-04-26 16:25:53.741856604 +0300
+++ linux/kernel/profile.c	2011-05-02 10:08:29.231588263 +0300
@@ -438,7 +438,8 @@ void profile_tick(int type)
 	if (type == CPU_PROFILING && timer_hook)
 		timer_hook(regs);
 	if (!user_mode(regs) && prof_cpu_mask != NULL &&
-	    cpumask_test_cpu(smp_processor_id(), prof_cpu_mask))
+	    cpumask_test_cpu(smp_processor_id(), prof_cpu_mask)
+	    && prof_on == type)
 		profile_hit(type, (void *)profile_pc(regs));
 }
 
diff -puNrb linux-2.6.35/kernel/softirq.c linux/kernel/softirq.c
--- linux-2.6.35/kernel/softirq.c	2011-04-26 16:25:53.761855156 +0300
+++ linux/kernel/softirq.c	2011-05-02 10:08:29.241586287 +0300
@@ -55,6 +55,7 @@ EXPORT_SYMBOL(irq_stat);
 static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
 
 static DEFINE_PER_CPU(struct task_struct *, ksoftirqd);
+static int do_softirq_pending;
 
 char *softirq_to_name[NR_SOFTIRQS] = {
 	"HI", "TIMER", "NET_TX", "NET_RX", "BLOCK", "BLOCK_IOPOLL",
@@ -155,7 +156,8 @@ static inline void _local_bh_enable_ip(u
  	 */
  	sub_preempt_count(SOFTIRQ_OFFSET - 1);
 
-	if (unlikely(!in_interrupt() && local_softirq_pending()))
+	if (unlikely(do_softirq_pending
+		     && !in_interrupt() && local_softirq_pending()))
 		do_softirq();
 
 	dec_preempt_count();
@@ -186,7 +188,7 @@ EXPORT_SYMBOL(local_bh_enable_ip);
  * we want to handle softirqs as soon as possible, but they
  * should not be able to lock up the box.
  */
-#define MAX_SOFTIRQ_RESTART 10
+#define MAX_SOFTIRQ_RESTART 2
 
 asmlinkage void __do_softirq(void)
 {
@@ -195,6 +197,7 @@ asmlinkage void __do_softirq(void)
 	int max_restart = MAX_SOFTIRQ_RESTART;
 	int cpu;
 
+	do_softirq_pending = 0;
 	pending = local_softirq_pending();
 	account_system_vtime(current);
 
@@ -301,6 +304,8 @@ void irq_exit(void)
 	sub_preempt_count(IRQ_EXIT_OFFSET);
 	if (!in_interrupt() && local_softirq_pending())
 		invoke_softirq();
+	else
+		do_softirq_pending = local_softirq_pending();
 
 	rcu_irq_exit();
 #ifdef CONFIG_NO_HZ
diff -puNrb linux-2.6.35/kernel/sys.c linux/kernel/sys.c
--- linux-2.6.35/kernel/sys.c	2011-04-26 16:25:53.741856604 +0300
+++ linux/kernel/sys.c	2011-05-02 10:08:29.251592181 +0300
@@ -902,8 +902,12 @@ SYSCALL_DEFINE1(times, struct tms __user
 		if (copy_to_user(tbuf, &tmp, sizeof(struct tms)))
 			return -EFAULT;
 	}
+#if HZ == USER_HZ
+	return jiffies;
+#else
 	force_successful_syscall_return();
 	return (long) jiffies_64_to_clock_t(get_jiffies_64());
+#endif
 }
 
 /*
diff -puNrb linux-2.6.35/kernel/time.c linux/kernel/time.c
--- linux-2.6.35/kernel/time.c	2011-04-26 16:25:53.721855568 +0300
+++ linux/kernel/time.c	2011-05-02 10:08:29.271586825 +0300
@@ -689,6 +689,7 @@ unsigned long nsecs_to_jiffies(u64 n)
 	return div_u64(n * 9, (9ull * NSEC_PER_SEC + HZ / 2) / HZ);
 #endif
 }
+EXPORT_SYMBOL(nsecs_to_jiffies);
 
 #if (BITS_PER_LONG < 64)
 u64 get_jiffies_64(void)
diff -puNrb linux-2.6.35/lib/bug.c linux/lib/bug.c
--- linux-2.6.35/lib/bug.c	2011-04-26 16:26:19.442477357 +0300
+++ linux/lib/bug.c	2011-05-02 10:08:29.283103084 +0300
@@ -136,7 +136,7 @@ enum bug_trap_type report_bug(unsigned l
 
 	bug = find_bug(bugaddr);
 
-	printk(KERN_EMERG "------------[ cut here ]------------\n");
+	printk(KERN_INFO "------------[ cut here ]------------\n");
 
 	file = NULL;
 	line = 0;
diff -puNrb linux-2.6.35/lib/kobject_uevent.c linux/lib/kobject_uevent.c
--- linux-2.6.35/lib/kobject_uevent.c	2011-04-26 16:26:19.432477974 +0300
+++ linux/lib/kobject_uevent.c	2011-05-02 10:08:29.293102779 +0300
@@ -291,10 +291,11 @@ int kobject_uevent_env(struct kobject *k
 #endif
 
 	/* call uevent_helper, usually only enabled during early boot */
-	if (uevent_helper[0] && !kobj_usermode_filter(kobj)) {
+	if ((uevent_helper[0] || strcmp(subsystem, "firmware") == 0)
+	    && !kobj_usermode_filter(kobj)) {
 		char *argv [3];
 
-		argv [0] = uevent_helper;
+		argv [0] = uevent_helper[0] ? uevent_helper : "/sbin/firmware";
 		argv [1] = (char *)subsystem;
 		argv [2] = NULL;
 		retval = add_uevent_var(env, "HOME=/");
diff -puNrb linux-2.6.35/Makefile linux/Makefile
--- linux-2.6.35/Makefile	2011-04-26 16:28:35.293204010 +0300
+++ linux/Makefile	2011-05-02 10:08:29.303161749 +0300
@@ -314,9 +314,9 @@ include $(srctree)/scripts/Kbuild.includ
 # Make variables (CC, etc...)
 
 AS		= $(CROSS_COMPILE)as
-LD		= $(CROSS_COMPILE)ld
 CC		= $(CROSS_COMPILE)gcc
 CPP		= $(CC) -E
+LD		= $(shell $(CC) --print-prog-name=ld)
 AR		= $(CROSS_COMPILE)ar
 NM		= $(CROSS_COMPILE)nm
 STRIP		= $(CROSS_COMPILE)strip
@@ -552,10 +552,11 @@ else
 KBUILD_CFLAGS	+= -fomit-frame-pointer
 endif
 
-ifdef CONFIG_DEBUG_INFO
+#ifdef CONFIG_DEBUG_INFO
 KBUILD_CFLAGS	+= -g
 KBUILD_AFLAGS	+= -gdwarf-2
-endif
+LDFLAGS_vmlinux += -g
+#endif
 
 ifdef CONFIG_FUNCTION_TRACER
 KBUILD_CFLAGS	+= -pg
diff -puNrb linux-2.6.35/mm/page_alloc.c linux/mm/page_alloc.c
--- linux-2.6.35/mm/page_alloc.c	2011-04-26 16:26:38.631233570 +0300
+++ linux/mm/page_alloc.c	2011-05-02 10:08:29.323162434 +0300
@@ -1959,6 +1959,14 @@ __alloc_pages_slowpath(gfp_t gfp_mask, u
 	struct task_struct *p = current;
 
 	/*
+	 * Code in arch/mips/kernel/module.c wants physically
+	 * contiguous memory only if there is plenty of free of them.
+	 */
+	if ((gfp_mask & (__GFP_THISNODE | __GFP_NORETRY | __GFP_NOWARN))
+	    == (__GFP_THISNODE | __GFP_NORETRY | __GFP_NOWARN))
+		goto nopage;
+
+	/*
 	 * In the slowpath, we sanity check order to avoid ever trying to
 	 * reclaim >= MAX_ORDER areas which will never succeed. Callers may
 	 * be using allocators in order of preference for an area that is
@@ -1983,6 +1991,9 @@ __alloc_pages_slowpath(gfp_t gfp_mask, u
 restart:
 	wake_all_kswapd(order, zonelist, high_zoneidx);
 
+	if (gfp_mask & 0x80000000)
+	    goto nopage;
+
 	/*
 	 * OK, we're below the kswapd watermark and have kicked background
 	 * reclaim. Now things get more complex, so set up alloc_flags according
diff -puNrb linux-2.6.35/net/8021q/vlan.c linux/net/8021q/vlan.c
--- linux-2.6.35/net/8021q/vlan.c	2011-04-26 16:26:06.102479362 +0300
+++ linux/net/8021q/vlan.c	2011-05-02 10:08:29.343213492 +0300
@@ -57,6 +57,11 @@ static struct packet_type vlan_packet_ty
 	.func = vlan_skb_recv, /* VLAN receive method */
 };
 
+static struct packet_type vlan_s_packet_type = {
+	.type = __constant_htons(ETH_P_8021Q_S),
+	.func = vlan_skb_recv, /* VLAN receive method */
+};
+
 /* End of global variables definitions. */
 
 static inline unsigned int vlan_grp_hashfn(unsigned int idx)
@@ -65,14 +70,15 @@ static inline unsigned int vlan_grp_hash
 }
 
 /* Must be invoked with RCU read lock (no preempt) */
-static struct vlan_group *__vlan_find_group(struct net_device *real_dev)
+static struct vlan_group *__vlan_find_group(struct net_device *real_dev,
+					    unsigned short proto)
 {
 	struct vlan_group *grp;
 	struct hlist_node *n;
 	int hash = vlan_grp_hashfn(real_dev->ifindex);
 
 	hlist_for_each_entry_rcu(grp, n, &vlan_group_hash[hash], hlist) {
-		if (grp->real_dev == real_dev)
+		if (grp->real_dev == real_dev && grp->proto == proto)
 			return grp;
 	}
 
@@ -83,9 +89,10 @@ static struct vlan_group *__vlan_find_gr
  *
  * Must be invoked with RCU read lock (no preempt)
  */
-struct net_device *__find_vlan_dev(struct net_device *real_dev, u16 vlan_id)
+struct net_device *__find_vlan_dev(struct net_device *real_dev, u16 vlan_id,
+				   unsigned short proto)
 {
-	struct vlan_group *grp = __vlan_find_group(real_dev);
+	struct vlan_group *grp = __vlan_find_group(real_dev, proto);
 
 	if (grp)
 		return vlan_group_get_device(grp, vlan_id);
@@ -102,7 +109,8 @@ static void vlan_group_free(struct vlan_
 	kfree(grp);
 }
 
-static struct vlan_group *vlan_group_alloc(struct net_device *real_dev)
+static struct vlan_group *vlan_group_alloc(struct net_device *real_dev,
+					   unsigned short proto)
 {
 	struct vlan_group *grp;
 
@@ -111,6 +119,7 @@ static struct vlan_group *vlan_group_all
 		return NULL;
 
 	grp->real_dev = real_dev;
+	grp->proto = proto;
 	hlist_add_head_rcu(&grp->hlist,
 			&vlan_group_hash[vlan_grp_hashfn(real_dev->ifindex)]);
 	return grp;
@@ -148,16 +157,18 @@ void unregister_vlan_dev(struct net_devi
 	const struct net_device_ops *ops = real_dev->netdev_ops;
 	struct vlan_group *grp;
 	u16 vlan_id = vlan->vlan_id;
+	unsigned short vlan_proto = vlan->vlan_proto;
 
 	ASSERT_RTNL();
 
-	grp = __vlan_find_group(real_dev);
+	grp = __vlan_find_group(real_dev, vlan_proto);
 	BUG_ON(!grp);
 
 	/* Take it out of our own structures, but be sure to interlock with
 	 * HW accelerating devices or SW vlan input packet processing.
 	 */
-	if (real_dev->features & NETIF_F_HW_VLAN_FILTER)
+	if (vlan_proto == ETH_P_8021Q
+	    && real_dev->features & NETIF_F_HW_VLAN_FILTER)
 		ops->ndo_vlan_rx_kill_vid(real_dev, vlan_id);
 
 	grp->nr_vlans--;
@@ -172,7 +183,8 @@ void unregister_vlan_dev(struct net_devi
 	if (grp->nr_vlans == 0) {
 		vlan_gvrp_uninit_applicant(real_dev);
 
-		if (real_dev->features & NETIF_F_HW_VLAN_RX)
+		if (vlan_proto == ETH_P_8021Q
+		    && real_dev->features & NETIF_F_HW_VLAN_RX)
 			ops->ndo_vlan_rx_register(real_dev, NULL);
 
 		hlist_del_rcu(&grp->hlist);
@@ -185,7 +197,8 @@ void unregister_vlan_dev(struct net_devi
 	dev_put(real_dev);
 }
 
-int vlan_check_real_dev(struct net_device *real_dev, u16 vlan_id)
+int vlan_check_real_dev(struct net_device *real_dev, u16 vlan_id,
+		        unsigned short proto)
 {
 	const char *name = real_dev->name;
 	const struct net_device_ops *ops = real_dev->netdev_ops;
@@ -206,7 +219,7 @@ int vlan_check_real_dev(struct net_devic
 		return -EOPNOTSUPP;
 	}
 
-	if (__find_vlan_dev(real_dev, vlan_id) != NULL)
+	if (__find_vlan_dev(real_dev, vlan_id, proto) != NULL)
 		return -EEXIST;
 
 	return 0;
@@ -218,12 +231,13 @@ int register_vlan_dev(struct net_device 
 	struct net_device *real_dev = vlan->real_dev;
 	const struct net_device_ops *ops = real_dev->netdev_ops;
 	u16 vlan_id = vlan->vlan_id;
+	unsigned short vlan_proto = vlan->vlan_proto;
 	struct vlan_group *grp, *ngrp = NULL;
 	int err;
 
-	grp = __vlan_find_group(real_dev);
+	grp = __vlan_find_group(real_dev, vlan_proto);
 	if (!grp) {
-		ngrp = grp = vlan_group_alloc(real_dev);
+		ngrp = grp = vlan_group_alloc(real_dev, vlan_proto);
 		if (!grp)
 			return -ENOBUFS;
 		err = vlan_gvrp_init_applicant(real_dev);
@@ -251,9 +265,11 @@ int register_vlan_dev(struct net_device 
 	vlan_group_set_device(grp, vlan_id, dev);
 	grp->nr_vlans++;
 
-	if (ngrp && real_dev->features & NETIF_F_HW_VLAN_RX)
+	if (vlan_proto == ETH_P_8021Q
+	    && ngrp && real_dev->features & NETIF_F_HW_VLAN_RX)
 		ops->ndo_vlan_rx_register(real_dev, ngrp);
-	if (real_dev->features & NETIF_F_HW_VLAN_FILTER)
+	if (vlan_proto == ETH_P_8021Q
+	    && real_dev->features & NETIF_F_HW_VLAN_FILTER)
 		ops->ndo_vlan_rx_add_vid(real_dev, vlan_id);
 
 	return 0;
@@ -273,7 +289,8 @@ out_free_group:
 /*  Attach a VLAN device to a mac address (ie Ethernet Card).
  *  Returns 0 if the device was created or a negative error code otherwise.
  */
-static int register_vlan_device(struct net_device *real_dev, u16 vlan_id)
+static int register_vlan_device(struct net_device *real_dev, u16 vlan_id,
+				unsigned short vlan_proto)
 {
 	struct net_device *new_dev;
 	struct net *net = dev_net(real_dev);
@@ -284,7 +301,9 @@ static int register_vlan_device(struct n
 	if (vlan_id >= VLAN_VID_MASK)
 		return -ERANGE;
 
-	err = vlan_check_real_dev(real_dev, vlan_id);
+	if (!vlan_proto) vlan_proto = ETH_P_8021Q;
+
+	err = vlan_check_real_dev(real_dev, vlan_id, vlan_proto);
 	if (err < 0)
 		return err;
 
@@ -326,8 +345,10 @@ static int register_vlan_device(struct n
 	 * hope the underlying device can handle it.
 	 */
 	new_dev->mtu = real_dev->mtu;
+	new_dev->l2mtu = (real_dev->l2mtu > 4) ? (real_dev->l2mtu - 4) : 0;
 
 	vlan_dev_info(new_dev)->vlan_id = vlan_id;
+	vlan_dev_info(new_dev)->vlan_proto = vlan_proto;
 	vlan_dev_info(new_dev)->real_dev = real_dev;
 	vlan_dev_info(new_dev)->dent = NULL;
 	vlan_dev_info(new_dev)->flags = VLAN_FLAG_REORDER_HDR;
@@ -406,20 +427,35 @@ static void __vlan_device_event(struct n
 	}
 }
 
+static int vlan_device_event_proto(unsigned long event, struct net_device *dev,
+				   unsigned short proto);
+
 static int vlan_device_event(struct notifier_block *unused, unsigned long event,
 			     void *ptr)
 {
 	struct net_device *dev = ptr;
+	int ret;
+
+	if (is_vlan_dev(dev))
+		__vlan_device_event(dev, event);
+
+	ret = vlan_device_event_proto(event, dev, ETH_P_8021Q);
+	if (ret != NOTIFY_DONE)
+		return ret;
+	ret = vlan_device_event_proto(event, dev, ETH_P_8021Q_S);
+
+	return ret;
+}
+
+static int vlan_device_event_proto(unsigned long event, struct net_device *dev,
+				    unsigned short proto) {
 	struct vlan_group *grp;
 	int i, flgs;
 	struct net_device *vlandev;
 	struct vlan_dev_info *vlan;
 	LIST_HEAD(list);
 
-	if (is_vlan_dev(dev))
-		__vlan_device_event(dev, event);
-
-	grp = __vlan_find_group(dev);
+	grp = __vlan_find_group(dev, proto);
 	if (!grp)
 		goto out;
 
@@ -537,6 +573,23 @@ static int vlan_device_event(struct noti
 	case NETDEV_PRE_TYPE_CHANGE:
 		/* Forbid underlaying device to change its type. */
 		return NOTIFY_BAD;
+
+	case NETDEV_CHANGEL2MTU:
+		/* update l2mtu for VLANs */
+		for (i = 0; i < VLAN_GROUP_ARRAY_LEN; i++) {
+			int l2mtu;
+			vlandev = vlan_group_get_device(grp, i);
+			if (!vlandev)
+				continue;
+
+			l2mtu = (dev->l2mtu > 4) ? (dev->l2mtu - 4) : 0;
+			if (l2mtu != vlandev->l2mtu) {
+				vlandev->l2mtu = l2mtu;
+				if (vlandev->flags & IFF_UP)
+					netdev_l2mtu_change(vlandev);
+			}
+		}
+		break;
 	}
 
 out:
@@ -634,7 +687,7 @@ static int vlan_ioctl_handler(struct net
 		err = -EPERM;
 		if (!capable(CAP_NET_ADMIN))
 			break;
-		err = register_vlan_device(dev, args.u.VID);
+		err = register_vlan_device(dev, args.u.VID, args.vlan_proto);
 		break;
 
 	case DEL_VLAN_CMD:
@@ -718,6 +771,7 @@ static int __init vlan_proto_init(void)
 		goto err4;
 
 	dev_add_pack(&vlan_packet_type);
+	dev_add_pack(&vlan_s_packet_type);
 	vlan_ioctl_set(vlan_ioctl_handler);
 	return 0;
 
@@ -741,6 +795,7 @@ static void __exit vlan_cleanup_module(v
 	unregister_netdevice_notifier(&vlan_notifier_block);
 
 	dev_remove_pack(&vlan_packet_type);
+	dev_remove_pack(&vlan_s_packet_type);
 
 	/* This table must be empty if there are no module references left. */
 	for (i = 0; i < VLAN_GRP_HASH_SIZE; i++)
diff -puNrb linux-2.6.35/net/8021q/vlan_core.c linux/net/8021q/vlan_core.c
--- linux-2.6.35/net/8021q/vlan_core.c	2011-04-26 16:26:06.102479362 +0300
+++ linux/net/8021q/vlan_core.c	2011-05-02 10:08:29.353161976 +0300
@@ -38,7 +38,11 @@ int vlan_hwaccel_do_receive(struct sk_bu
 	netif_nit_deliver(skb);
 
 	skb->dev = dev;
+#if 0
 	skb->priority = vlan_get_ingress_priority(dev, skb->vlan_tci);
+#else
+        skb->ingress_priority = skb->vlan_tci >> 13;
+#endif
 	skb->vlan_tci = 0;
 
 	rx_stats = per_cpu_ptr(vlan_dev_info(dev)->vlan_rx_stats,
diff -puNrb linux-2.6.35/net/8021q/vlan_dev.c linux/net/8021q/vlan_dev.c
--- linux-2.6.35/net/8021q/vlan_dev.c	2011-04-26 16:26:06.102479362 +0300
+++ linux/net/8021q/vlan_dev.c	2011-05-02 10:08:29.373212307 +0300
@@ -157,7 +157,7 @@ int vlan_skb_recv(struct sk_buff *skb, s
 	vlan_id = vlan_tci & VLAN_VID_MASK;
 
 	rcu_read_lock();
-	skb->dev = __find_vlan_dev(dev, vlan_id);
+	skb->dev = __find_vlan_dev(dev, vlan_id, ntohs(ptype->type));
 	if (!skb->dev) {
 		pr_debug("%s: ERROR: No net_device for VID: %u on dev: %s\n",
 			 __func__, vlan_id, dev->name);
@@ -171,7 +171,11 @@ int vlan_skb_recv(struct sk_buff *skb, s
 
 	skb_pull_rcsum(skb, VLAN_HLEN);
 
+#if 0
 	skb->priority = vlan_get_ingress_priority(skb->dev, vlan_tci);
+#else
+	skb->ingress_priority = vlan_tci >> 13;
+#endif
 
 	pr_debug("%s: priority: %u for TCI: %hu\n",
 		 __func__, skb->priority, vlan_tci);
@@ -220,6 +224,7 @@ err_free:
 static inline u16
 vlan_dev_get_egress_qos_mask(struct net_device *dev, struct sk_buff *skb)
 {
+#if 0
 	struct vlan_priority_tci_mapping *mp;
 
 	mp = vlan_dev_info(dev)->egress_priority_map[(skb->priority & 0xF)];
@@ -232,6 +237,9 @@ vlan_dev_get_egress_qos_mask(struct net_
 		mp = mp->next;
 	}
 	return 0;
+#else
+	return (skb->priority & 0x7) << 13;
+#endif
 }
 
 /*
@@ -272,8 +280,8 @@ static int vlan_dev_hard_header(struct s
 		else
 			vhdr->h_vlan_encapsulated_proto = htons(len);
 
-		skb->protocol = htons(ETH_P_8021Q);
-		type = ETH_P_8021Q;
+		skb->protocol = htons(vlan_dev_info(dev)->vlan_proto);
+		type = vlan_dev_info(dev)->vlan_proto;
 		vhdrlen = VLAN_HLEN;
 	}
 
@@ -294,7 +302,9 @@ static netdev_tx_t vlan_dev_hard_start_x
 {
 	int i = skb_get_queue_mapping(skb);
 	struct netdev_queue *txq = netdev_get_tx_queue(dev, i);
+#ifdef NO_VLAN_IN_VLAN
 	struct vlan_ethhdr *veth = (struct vlan_ethhdr *)(skb->data);
+#endif
 	unsigned int len;
 	int ret;
 
@@ -303,16 +313,39 @@ static netdev_tx_t vlan_dev_hard_start_x
 	 * NOTE: THIS ASSUMES DIX ETHERNET, SPECIFICALLY NOT SUPPORTING
 	 * OTHER THINGS LIKE FDDI/TokenRing/802.3 SNAPs...
 	 */
-	if (veth->h_vlan_proto != htons(ETH_P_8021Q) ||
+#ifndef NO_VLAN_IN_VLAN
+#if 0 /* Allow QinQinQ... introduces risk of having loops!!! */
+	if (ANY_VLAN_PROTO_N(veth->h_vlan_proto)
+		&& ANY_VLAN_PROTO_N(veth->h_vlan_encapsulated_proto)) {
+		/* already double encapsulated, drop so we do not loop it in */
+		kfree_skb(skb);
+		return 0;
+	}
+#endif
+	if (1) {
+#else
+	if (!ANY_VLAN_PROTO_N(veth->h_vlan_proto) ||
 	    vlan_dev_info(dev)->flags & VLAN_FLAG_REORDER_HDR) {
+#endif
 		unsigned int orig_headroom = skb_headroom(skb);
 		u16 vlan_tci;
 
 		vlan_dev_info(dev)->cnt_encap_on_xmit++;
 
+		{
+			struct net_device *rd = vlan_dev_info(dev)->real_dev;
+			if (rd->l2mtu
+			    && (skb->len - ETH_HLEN + VLAN_HLEN) > rd->l2mtu) {
+				kfree_skb(skb);
+				txq->tx_dropped++;
+				return NETDEV_TX_OK;
+			}
+		}
+
 		vlan_tci = vlan_dev_info(dev)->vlan_id;
 		vlan_tci |= vlan_dev_get_egress_qos_mask(dev, skb);
-		skb = __vlan_put_tag(skb, vlan_tci);
+		skb = __vlan_put_tag_proto(skb, vlan_tci,
+					   vlan_dev_info(dev)->vlan_proto);
 		if (!skb) {
 			txq->tx_dropped++;
 			return NETDEV_TX_OK;
@@ -323,6 +356,11 @@ static netdev_tx_t vlan_dev_hard_start_x
 	}
 
 
+	skb->protocol = htons(vlan_dev_info(dev)->vlan_proto);
+	skb->mac_header -= VLAN_HLEN;
+	skb->network_header -= VLAN_HLEN;
+	skb->transport_header -= VLAN_HLEN;
+
 	skb_set_dev(skb, vlan_dev_info(dev)->real_dev);
 	len = skb->len;
 	ret = dev_queue_xmit(skb);
@@ -345,6 +383,16 @@ static netdev_tx_t vlan_dev_hwaccel_hard
 	unsigned int len;
 	int ret;
 
+	{
+		struct net_device *rd = vlan_dev_info(dev)->real_dev;
+		if (rd->l2mtu
+		    && (skb->len - ETH_HLEN + VLAN_HLEN) > rd->l2mtu) {
+			kfree_skb(skb);
+			txq->tx_dropped++;
+			return NETDEV_TX_OK;
+		}
+	}
+
 	vlan_tci = vlan_dev_info(dev)->vlan_id;
 	vlan_tci |= vlan_dev_get_egress_qos_mask(dev, skb);
 	skb = __vlan_hwaccel_put_tag(skb, vlan_tci);
@@ -375,7 +423,8 @@ static int vlan_dev_change_mtu(struct ne
 	/* TODO: gotta make sure the underlying layer can handle it,
 	 * maybe an IFF_VLAN_CAPABLE flag for devices?
 	 */
-	if (vlan_dev_info(dev)->real_dev->mtu < new_mtu)
+	struct net_device *rd = vlan_dev_info(dev)->real_dev;
+	if (rd->l2mtu == 0 && rd->mtu < new_mtu)
 		return -ERANGE;
 
 	dev->mtu = new_mtu;
@@ -730,7 +779,8 @@ static int vlan_dev_init(struct net_devi
 	dev->fcoe_ddp_xid = real_dev->fcoe_ddp_xid;
 #endif
 
-	if (real_dev->features & NETIF_F_HW_VLAN_TX) {
+	if (vlan_dev_info(dev)->vlan_proto == ETH_P_8021Q
+	    && real_dev->features & NETIF_F_HW_VLAN_TX) {
 		dev->header_ops      = real_dev->header_ops;
 		dev->hard_header_len = real_dev->hard_header_len;
 		if (real_dev->netdev_ops->ndo_select_queue)
@@ -841,7 +891,6 @@ static const struct net_device_ops vlan_
 	.ndo_open		= vlan_dev_open,
 	.ndo_stop		= vlan_dev_stop,
 	.ndo_start_xmit =  vlan_dev_hard_start_xmit,
-	.ndo_validate_addr	= eth_validate_addr,
 	.ndo_set_mac_address	= vlan_dev_set_mac_address,
 	.ndo_set_rx_mode	= vlan_dev_set_rx_mode,
 	.ndo_set_multicast_list	= vlan_dev_set_rx_mode,
@@ -865,7 +914,6 @@ static const struct net_device_ops vlan_
 	.ndo_open		= vlan_dev_open,
 	.ndo_stop		= vlan_dev_stop,
 	.ndo_start_xmit =  vlan_dev_hwaccel_hard_start_xmit,
-	.ndo_validate_addr	= eth_validate_addr,
 	.ndo_set_mac_address	= vlan_dev_set_mac_address,
 	.ndo_set_rx_mode	= vlan_dev_set_rx_mode,
 	.ndo_set_multicast_list	= vlan_dev_set_rx_mode,
diff -puNrb linux-2.6.35/net/8021q/vlan.h linux/net/8021q/vlan.h
--- linux-2.6.35/net/8021q/vlan.h	2011-04-26 16:26:06.102479362 +0300
+++ linux/net/8021q/vlan.h	2011-05-02 10:08:29.383157577 +0300
@@ -53,6 +53,7 @@ struct vlan_dev_info {
 	struct vlan_priority_tci_mapping	*egress_priority_map[16];
 
 	u16					vlan_id;
+	unsigned short				vlan_proto;
 	u16					flags;
 
 	struct net_device			*real_dev;
@@ -84,7 +85,8 @@ static inline struct vlan_dev_info *vlan
  *  Must be invoked with rcu_read_lock (ie preempt disabled)
  *  or with RTNL.
  */
-struct net_device *__find_vlan_dev(struct net_device *real_dev, u16 vlan_id);
+struct net_device *__find_vlan_dev(struct net_device *real_dev, u16 vlan_id,
+				   unsigned short vlan_proto);
 
 /* found in vlan_dev.c */
 int vlan_skb_recv(struct sk_buff *skb, struct net_device *dev,
@@ -96,7 +98,8 @@ int vlan_dev_set_egress_priority(const s
 int vlan_dev_change_flags(const struct net_device *dev, u32 flag, u32 mask);
 void vlan_dev_get_realdev_name(const struct net_device *dev, char *result);
 
-int vlan_check_real_dev(struct net_device *real_dev, u16 vlan_id);
+int vlan_check_real_dev(struct net_device *real_dev, u16 vlan_id,
+		        unsigned short vlan_proto);
 void vlan_setup(struct net_device *dev);
 int register_vlan_dev(struct net_device *dev);
 void unregister_vlan_dev(struct net_device *dev, struct list_head *head);
diff -puNrb linux-2.6.35/net/8021q/vlan_netlink.c linux/net/8021q/vlan_netlink.c
--- linux-2.6.35/net/8021q/vlan_netlink.c	2011-04-26 16:26:06.102479362 +0300
+++ linux/net/8021q/vlan_netlink.c	2011-05-02 10:08:29.393159403 +0300
@@ -22,6 +22,7 @@ static const struct nla_policy vlan_poli
 	[IFLA_VLAN_FLAGS]	= { .len = sizeof(struct ifla_vlan_flags) },
 	[IFLA_VLAN_EGRESS_QOS]	= { .type = NLA_NESTED },
 	[IFLA_VLAN_INGRESS_QOS] = { .type = NLA_NESTED },
+	[IFLA_VLAN_PROTO]	= { .type = NLA_U16 },
 };
 
 static const struct nla_policy vlan_map_policy[IFLA_VLAN_QOS_MAX + 1] = {
@@ -137,10 +138,12 @@ static int vlan_newlink(struct net *src_
 		return -ENODEV;
 
 	vlan->vlan_id  = nla_get_u16(data[IFLA_VLAN_ID]);
+	vlan->vlan_proto = data[IFLA_VLAN_PROTO]
+		? nla_get_u16(data[IFLA_VLAN_PROTO]) : ETH_P_8021Q;
 	vlan->real_dev = real_dev;
 	vlan->flags    = VLAN_FLAG_REORDER_HDR;
 
-	err = vlan_check_real_dev(real_dev, vlan->vlan_id);
+	err = vlan_check_real_dev(real_dev, vlan->vlan_id, vlan->vlan_proto);
 	if (err < 0)
 		return err;
 
@@ -149,6 +152,8 @@ static int vlan_newlink(struct net *src_
 	else if (dev->mtu > real_dev->mtu)
 		return -EINVAL;
 
+	dev->l2mtu = (real_dev->l2mtu > 4) ? (real_dev->l2mtu - 4) : 0;
+
 	err = vlan_changelink(dev, tb, data);
 	if (err < 0)
 		return err;
diff -puNrb linux-2.6.35/net/bridge/br_forward.c linux/net/bridge/br_forward.c
--- linux-2.6.35/net/bridge/br_forward.c	2011-04-26 16:26:07.892478115 +0300
+++ linux/net/bridge/br_forward.c	2011-05-02 10:08:29.403184356 +0300
@@ -36,7 +36,7 @@ static inline int should_deliver(const s
 
 static inline unsigned packet_length(const struct sk_buff *skb)
 {
-	return skb->len - (skb->protocol == htons(ETH_P_8021Q) ? VLAN_HLEN : 0);
+	return skb->len - (ANY_VLAN_PROTO_N(skb->protocol) ? VLAN_HLEN : 0);
 }
 
 int br_dev_queue_push_xmit(struct sk_buff *skb)
diff -puNrb linux-2.6.35/net/bridge/br_netfilter.c linux/net/bridge/br_netfilter.c
--- linux-2.6.35/net/bridge/br_netfilter.c	2011-04-26 16:26:07.892478115 +0300
+++ linux/net/bridge/br_netfilter.c	2011-05-02 10:08:29.423102975 +0300
@@ -65,17 +65,17 @@ static inline __be16 vlan_proto(const st
 }
 
 #define IS_VLAN_IP(skb) \
-	(skb->protocol == htons(ETH_P_8021Q) && \
+	(ANY_VLAN_PROTO_N(skb->protocol) && \
 	 vlan_proto(skb) == htons(ETH_P_IP) && 	\
 	 brnf_filter_vlan_tagged)
 
 #define IS_VLAN_IPV6(skb) \
-	(skb->protocol == htons(ETH_P_8021Q) && \
+	(ANY_VLAN_PROTO_N(skb->protocol) && \
 	 vlan_proto(skb) == htons(ETH_P_IPV6) &&\
 	 brnf_filter_vlan_tagged)
 
 #define IS_VLAN_ARP(skb) \
-	(skb->protocol == htons(ETH_P_8021Q) &&	\
+	(ANY_VLAN_PROTO_N(skb->protocol) &&	\
 	 vlan_proto(skb) == htons(ETH_P_ARP) &&	\
 	 brnf_filter_vlan_tagged)
 
diff -puNrb linux-2.6.35/net/bridge/netfilter/ebt_vlan.c linux/net/bridge/netfilter/ebt_vlan.c
--- linux-2.6.35/net/bridge/netfilter/ebt_vlan.c	2011-04-26 16:26:07.832478005 +0300
+++ linux/net/bridge/netfilter/ebt_vlan.c	2011-05-02 10:08:29.433103378 +0300
@@ -85,7 +85,8 @@ static int ebt_vlan_mt_check(const struc
 	const struct ebt_entry *e = par->entryinfo;
 
 	/* Is it 802.1Q frame checked? */
-	if (e->ethproto != htons(ETH_P_8021Q)) {
+	if (e->ethproto != htons(ETH_P_8021Q)
+	    && e->ethproto != htons(ETH_P_8021Q_S)) {
 		pr_debug("passed entry proto %2.4X is not 802.1Q (8100)\n",
 			 ntohs(e->ethproto));
 		return -EINVAL;
diff -puNrb linux-2.6.35/net/core/dev.c linux/net/core/dev.c
--- linux-2.6.35/net/core/dev.c	2011-04-26 16:26:04.131857069 +0300
+++ linux/net/core/dev.c	2011-05-02 10:08:29.453215572 +0300
@@ -1108,6 +1108,12 @@ int netdev_bonding_change(struct net_dev
 }
 EXPORT_SYMBOL(netdev_bonding_change);
 
+void netdev_l2mtu_change(struct net_device *dev)
+{
+	call_netdevice_notifiers(NETDEV_CHANGEL2MTU, dev);
+}
+EXPORT_SYMBOL(netdev_l2mtu_change);
+
 /**
  *	dev_load 	- load a network module
  *	@net: the applicable net namespace
@@ -2027,8 +2033,7 @@ static inline u16 dev_cap_txqueue(struct
 	return queue_index;
 }
 
-static struct netdev_queue *dev_pick_tx(struct net_device *dev,
-					struct sk_buff *skb)
+struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb)
 {
 	int queue_index;
 	struct sock *sk = skb->sk;
@@ -2057,6 +2062,7 @@ static struct netdev_queue *dev_pick_tx(
 	skb_set_queue_mapping(skb, queue_index);
 	return netdev_get_tx_queue(dev, queue_index);
 }
+EXPORT_SYMBOL(dev_pick_tx);
 
 static inline int __dev_xmit_skb(struct sk_buff *skb, struct Qdisc *q,
 				 struct net_device *dev,
@@ -2642,6 +2648,51 @@ static inline struct sk_buff *handle_bri
 #define handle_bridge(skb, pt_prev, ret, orig_dev)	(skb)
 #endif
 
+int (*vrrp_rx_hook)(struct sk_buff *);
+EXPORT_SYMBOL(vrrp_rx_hook);
+
+static inline int handle_vrrp(struct sk_buff *skb)
+{
+	int (*f)(struct sk_buff *) = rcu_dereference(vrrp_rx_hook);
+
+	return f ? f(skb) : 0;
+}
+
+int (*vif_frame_hook)(struct sk_buff *);
+EXPORT_SYMBOL(vif_frame_hook);
+
+static inline int handle_vif(struct sk_buff *skb)
+{
+#ifndef __i386__
+	int (*f)(struct sk_buff *) = rcu_dereference(vif_frame_hook);
+
+	return f ? f(skb) : 0;
+#else
+	return 0;
+#endif
+}
+
+int (*mesh_frame_hook)(struct m_port *, struct sk_buff *);
+EXPORT_SYMBOL(mesh_frame_hook);
+
+static int handle_mesh(struct sk_buff *skb, struct packet_type **pt_prev, 
+	               int *ret, struct net_device *orig_dev)
+{
+	struct m_port *p;
+	int (*f)(struct m_port *, struct sk_buff *);
+
+	if ((f = rcu_dereference(mesh_frame_hook)) == NULL
+	    || (p = rcu_dereference(skb->dev->mesh_port)) == NULL)
+		return 0;
+
+	if (*pt_prev) {
+		*ret = deliver_skb(skb, *pt_prev, orig_dev);
+		*pt_prev = NULL;
+    	}
+
+	return f(p, skb);
+}
+
 #if defined(CONFIG_MACVLAN) || defined(CONFIG_MACVLAN_MODULE)
 struct sk_buff *(*macvlan_handle_frame_hook)(struct macvlan_port *p,
 					     struct sk_buff *skb) __read_mostly;
@@ -2866,6 +2917,11 @@ static int __netif_receive_skb(struct sk
 
 	rcu_read_lock();
 
+	if (handle_vrrp(skb))
+		goto out;
+	if (handle_vif(skb))
+		goto out;
+
 #ifdef CONFIG_NET_CLS_ACT
 	if (skb->tc_verd & TC_NCLS) {
 		skb->tc_verd = CLR_TC_NCLS(skb->tc_verd);
@@ -2882,6 +2938,9 @@ static int __netif_receive_skb(struct sk
 		}
 	}
 
+	if (handle_mesh(skb, &pt_prev, &ret, orig_dev))
+		goto out;
+
 #ifdef CONFIG_NET_CLS_ACT
 	skb = handle_ing(skb, &pt_prev, &ret, orig_dev);
 	if (!skb)
@@ -4480,6 +4539,15 @@ static int dev_ifsioc(struct net *net, s
 	case SIOCSIFMTU:	/* Set the MTU of a device */
 		return dev_set_mtu(dev, ifr->ifr_mtu);
 
+	case SIOCSIFL2MTU:	/* Set the L2MTU of a device */
+		if (!netif_device_present(dev)) return -ENODEV;
+		if (!ops->ndo_change_l2mtu) return -EOPNOTSUPP;
+		err = ops->ndo_change_l2mtu(dev, ifr->ifr_mtu);
+		if (err) return err;
+		if (dev->flags & IFF_UP)
+			call_netdevice_notifiers(NETDEV_CHANGEL2MTU, dev);
+		return 0;
+
 	case SIOCSIFHWADDR:
 		return dev_set_mac_address(dev, &ifr->ifr_hwaddr);
 
@@ -4521,6 +4589,14 @@ static int dev_ifsioc(struct net *net, s
 		dev->tx_queue_len = ifr->ifr_qlen;
 		return 0;
 
+	case SIOCSDEVID:
+		dev->devid = ifr->ifr_ifru.ifru_ivalue;
+		return 0;
+
+	case SIOCGDEVID:
+		ifr->ifr_ifru.ifru_ivalue = dev->devid;
+		return 0;
+
 	case SIOCSIFNAME:
 		ifr->ifr_newname[IFNAMSIZ-1] = '\0';
 		return dev_change_name(dev, ifr->ifr_newname);
@@ -4623,6 +4699,7 @@ int dev_ioctl(struct net *net, unsigned 
 	case SIOCGIFMAP:
 	case SIOCGIFINDEX:
 	case SIOCGIFTXQLEN:
+	case SIOCGDEVID:
 		dev_load(net, ifr.ifr_name);
 		rcu_read_lock();
 		ret = dev_ifsioc_locked(net, &ifr, cmd);
@@ -4683,6 +4760,7 @@ int dev_ioctl(struct net *net, unsigned 
 	case SIOCSIFFLAGS:
 	case SIOCSIFMETRIC:
 	case SIOCSIFMTU:
+	case SIOCSIFL2MTU:
 	case SIOCSIFMAP:
 	case SIOCSIFHWADDR:
 	case SIOCSIFSLAVE:
@@ -4691,6 +4769,7 @@ int dev_ioctl(struct net *net, unsigned 
 	case SIOCSIFHWBROADCAST:
 	case SIOCSIFTXQLEN:
 	case SIOCSMIIREG:
+	case SIOCSDEVID:
 	case SIOCBONDENSLAVE:
 	case SIOCBONDRELEASE:
 	case SIOCBONDSETHWADDR:
@@ -5191,10 +5270,10 @@ static void netdev_wait_allrefs(struct n
 			rebroadcast_time = jiffies;
 		}
 
-		msleep(250);
+		msleep(10);
 
 		if (time_after(jiffies, warning_time + 10 * HZ)) {
-			printk(KERN_EMERG "unregister_netdevice: "
+			printk(KERN_NOTICE "unregister_netdevice: "
 			       "waiting for %s to become free. Usage "
 			       "count = %d\n",
 			       dev->name, atomic_read(&dev->refcnt));
diff -puNrb linux-2.6.35/net/core/net-sysfs.c linux/net/core/net-sysfs.c
--- linux-2.6.35/net/core/net-sysfs.c	2011-04-26 16:26:04.121872403 +0300
+++ linux/net/core/net-sysfs.c	2011-05-02 10:08:29.473214872 +0300
@@ -870,6 +870,9 @@ void netdev_unregister_kobject(struct ne
 	rx_queue_remove_kobjects(net);
 #endif
 
+	if (net->type == ARPHRD_PPP)
+		return;
+
 	device_del(dev);
 }
 
@@ -903,6 +906,11 @@ int netdev_register_kobject(struct net_d
 #endif
 #endif /* CONFIG_SYSFS */
 
+	/* no need to send hotplug events & populate /sys/class/net
+	   with interces, just waistes precious time */
+	if (net->type == ARPHRD_PPP)
+		return 0;
+
 	error = device_add(dev);
 	if (error)
 		return error;
diff -puNrb linux-2.6.35/net/core/rtnetlink.c linux/net/core/rtnetlink.c
--- linux-2.6.35/net/core/rtnetlink.c	2011-04-26 16:26:04.121872403 +0300
+++ linux/net/core/rtnetlink.c	2011-05-02 10:08:29.483103545 +0300
@@ -700,6 +700,7 @@ static inline size_t if_nlmsg_size(const
 	       + nla_total_size(4) /* IFLA_TXQLEN */
 	       + nla_total_size(4) /* IFLA_WEIGHT */
 	       + nla_total_size(4) /* IFLA_MTU */
+	       + nla_total_size(4) /* IFLA_L2MTU */
 	       + nla_total_size(4) /* IFLA_LINK */
 	       + nla_total_size(4) /* IFLA_MASTER */
 	       + nla_total_size(1) /* IFLA_OPERSTATE */
@@ -816,6 +817,9 @@ static int rtnl_fill_ifinfo(struct sk_bu
 	if (dev->ifindex != dev->iflink)
 		NLA_PUT_U32(skb, IFLA_LINK, dev->iflink);
 
+	if (dev->l2mtu)
+		NLA_PUT_U32(skb, IFLA_L2MTU, dev->l2mtu);
+
 	if (dev->master)
 		NLA_PUT_U32(skb, IFLA_MASTER, dev->master->ifindex);
 
@@ -955,6 +959,7 @@ const struct nla_policy ifla_policy[IFLA
 	[IFLA_LINKMODE]		= { .type = NLA_U8 },
 	[IFLA_LINKINFO]		= { .type = NLA_NESTED },
 	[IFLA_NET_NS_PID]	= { .type = NLA_U32 },
+	[IFLA_L2MTU]		= { .type = NLA_U32 },
 	[IFLA_IFALIAS]	        = { .type = NLA_STRING, .len = IFALIASZ-1 },
 	[IFLA_VFINFO_LIST]	= {. type = NLA_NESTED },
 	[IFLA_VF_PORTS]		= { .type = NLA_NESTED },
diff -puNrb linux-2.6.35/net/core/skbuff.c linux/net/core/skbuff.c
--- linux-2.6.35/net/core/skbuff.c	2011-04-26 16:26:04.131857069 +0300
+++ linux/net/core/skbuff.c	2011-05-02 10:08:29.501586142 +0300
@@ -72,6 +72,9 @@
 
 static struct kmem_cache *skbuff_head_cache __read_mostly;
 static struct kmem_cache *skbuff_fclone_cache __read_mostly;
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
+#endif
 
 static void sock_pipe_buf_release(struct pipe_inode_info *pipe,
 				  struct pipe_buffer *buf)
@@ -91,6 +94,83 @@ static int sock_pipe_buf_steal(struct pi
 	return 1;
 }
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+/* Control buffer save/restore for IMQ devices */
+struct skb_cb_table {
+	void			*cb_next;
+	atomic_t		refcnt;
+	char      		cb[48];
+};
+
+static DEFINE_SPINLOCK(skb_cb_store_lock);
+
+int skb_save_cb(struct sk_buff *skb)
+{
+	struct skb_cb_table *next;
+
+	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
+	if (!next)
+		return -ENOMEM;
+
+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
+
+	memcpy(next->cb, skb->cb, sizeof(skb->cb));
+	next->cb_next = skb->cb_next;
+
+	atomic_set(&next->refcnt, 1);
+
+	skb->cb_next = next;
+	return 0;
+}
+EXPORT_SYMBOL(skb_save_cb);
+
+int skb_restore_cb(struct sk_buff *skb)
+{
+	struct skb_cb_table *next;
+
+	if (!skb->cb_next)
+		return 0;
+
+	next = skb->cb_next;
+
+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
+
+	memcpy(skb->cb, next->cb, sizeof(skb->cb));
+	skb->cb_next = next->cb_next;
+
+	spin_lock(&skb_cb_store_lock);
+
+	if (atomic_dec_and_test(&next->refcnt)) {
+		kmem_cache_free(skbuff_cb_store_cache, next);
+	}
+
+	spin_unlock(&skb_cb_store_lock);
+
+	return 0;
+}
+EXPORT_SYMBOL(skb_restore_cb);
+
+static void skb_copy_stored_cb(struct sk_buff *new, const struct sk_buff *__old)
+{
+	struct skb_cb_table *next;
+	struct sk_buff *old;
+
+	if (!__old->cb_next) {
+		new->cb_next = NULL;
+		return;
+	}
+
+	spin_lock(&skb_cb_store_lock);
+
+	old = (struct sk_buff *)__old;
+
+	next = old->cb_next;
+	atomic_inc(&next->refcnt);
+	new->cb_next = next;
+
+	spin_unlock(&skb_cb_store_lock);
+}
+#endif
 
 /* Pipe buffer operations for a socket. */
 static const struct pipe_buf_operations sock_pipe_buf_ops = {
@@ -183,6 +263,10 @@ struct sk_buff *__alloc_skb(unsigned int
 		goto out;
 	prefetchw(skb);
 
+#ifdef CONFIG_MIPS_MIKROTIK
+	gfp_mask |= __GFP_DMA;
+#endif
+
 	size = SKB_DATA_ALIGN(size);
 	data = kmalloc_node_track_caller(size + sizeof(struct skb_shared_info),
 			gfp_mask, node);
@@ -391,6 +475,26 @@ static void skb_release_head_state(struc
 		WARN_ON(in_irq());
 		skb->destructor(skb);
 	}
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	/* This should not happen. When it does, avoid memleak by restoring
+	the chain of cb-backups. */
+	while(skb->cb_next != NULL) {
+		if (net_ratelimit())
+			printk(KERN_WARNING "IMQ: kfree_skb: skb->cb_next: "
+				"%08x\n", (unsigned int)skb->cb_next);
+
+		skb_restore_cb(skb);
+	}
+	/* This should not happen either, nf_queue_entry is nullified in
+	 * imq_dev_xmit(). If we have non-NULL nf_queue_entry then we are
+	 * leaking entry pointers, maybe memory. We don't know if this is
+	 * pointer to already freed memory, or should this be freed.
+	 * If this happens we need to add refcounting, etc for nf_queue_entry.
+	 */
+	if (skb->nf_queue_entry && net_ratelimit())
+		printk(KERN_WARNING
+				"IMQ: kfree_skb: skb->nf_queue_entry != NULL");
+#endif
 #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
 	nf_conntrack_put(skb->nfct);
 	nf_conntrack_put_reasm(skb->nfct_reasm);
@@ -526,6 +630,9 @@ static void __copy_skb_header(struct sk_
 	new->sp			= secpath_get(old->sp);
 #endif
 	memcpy(new->cb, old->cb, sizeof(old->cb));
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	skb_copy_stored_cb(new, old);
+#endif
 	new->csum		= old->csum;
 	new->local_df		= old->local_df;
 	new->pkt_type		= old->pkt_type;
@@ -533,11 +640,14 @@ static void __copy_skb_header(struct sk_
 	skb_copy_queue_mapping(new, old);
 	new->priority		= old->priority;
 	new->deliver_no_wcard	= old->deliver_no_wcard;
+	new->ingress_priority   = old->ingress_priority;
 #if defined(CONFIG_IP_VS) || defined(CONFIG_IP_VS_MODULE)
 	new->ipvs_property	= old->ipvs_property;
 #endif
 	new->protocol		= old->protocol;
 	new->mark		= old->mark;
+	new->prmark		= old->prmark;
+	new->hsmark		= old->hsmark;
 	new->skb_iif		= old->skb_iif;
 	__nf_copy(new, old);
 #if defined(CONFIG_NETFILTER_XT_TARGET_TRACE) || \
@@ -805,6 +915,10 @@ int pskb_expand_head(struct sk_buff *skb
 
 	size = SKB_DATA_ALIGN(size);
 
+#ifdef CONFIG_MIPS_MIKROTIK
+	gfp_mask |= __GFP_DMA;
+#endif
+
 	data = kmalloc(size + sizeof(struct skb_shared_info), gfp_mask);
 	if (!data)
 		goto nodata;
@@ -2776,6 +2890,13 @@ void __init skb_init(void)
 						0,
 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
 						NULL);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
+						  sizeof(struct skb_cb_table),
+						  0,
+						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+						  NULL);
+#endif
 }
 
 /**
diff -puNrb linux-2.6.35/net/core/utils.c linux/net/core/utils.c
--- linux-2.6.35/net/core/utils.c	2011-04-26 16:26:04.121872403 +0300
+++ linux/net/core/utils.c	2011-05-02 10:08:29.521589000 +0300
@@ -31,6 +31,7 @@
 #include <asm/byteorder.h>
 #include <asm/system.h>
 #include <asm/uaccess.h>
+#include <asm/unaligned.h>
 
 int net_msg_warn __read_mostly = 1;
 EXPORT_SYMBOL(net_msg_warn);
@@ -288,13 +289,17 @@ void inet_proto_csum_replace4(__sum16 *s
 {
 	__be32 diff[] = { ~from, to };
 	if (skb->ip_summed != CHECKSUM_PARTIAL) {
-		*sum = csum_fold(csum_partial(diff, sizeof(diff),
-				~csum_unfold(*sum)));
+		put_unaligned(
+		    csum_fold(csum_partial(diff, sizeof(diff),
+					   ~csum_unfold(get_unaligned(sum)))),
+		    sum);
 		if (skb->ip_summed == CHECKSUM_COMPLETE && pseudohdr)
 			skb->csum = ~csum_partial(diff, sizeof(diff),
 						~skb->csum);
 	} else if (pseudohdr)
-		*sum = ~csum_fold(csum_partial(diff, sizeof(diff),
-				csum_unfold(*sum)));
+	    put_unaligned(
+		~csum_fold(csum_partial(diff, sizeof(diff),
+					csum_unfold(get_unaligned(sum)))),
+		sum);
 }
 EXPORT_SYMBOL(inet_proto_csum_replace4);
diff -puNrb linux-2.6.35/net/ethernet/eth.c linux/net/ethernet/eth.c
--- linux-2.6.35/net/ethernet/eth.c	2011-04-26 16:26:06.182218066 +0300
+++ linux/net/ethernet/eth.c	2011-05-02 10:08:29.531586395 +0300
@@ -52,6 +52,7 @@
 #include <linux/errno.h>
 #include <linux/init.h>
 #include <linux/if_ether.h>
+#include <linux/if_vlan.h>
 #include <net/dst.h>
 #include <net/arp.h>
 #include <net/sock.h>
@@ -196,8 +197,16 @@ __be16 eth_type_trans(struct sk_buff *sk
 	if (netdev_uses_trailer_tags(dev))
 		return htons(ETH_P_TRAILER);
 
-	if (ntohs(eth->h_proto) >= 1536)
+	if (ntohs(eth->h_proto) >= 1536) {
+		/* set ingress_priority if vlan frame */
+		if (eth->h_proto == htons(ETH_P_8021Q)
+		    || eth->h_proto == htons(ETH_P_8021Q_S)) {
+		        struct vlan_hdr *vhdr = (struct vlan_hdr *)(skb->data);
+			unsigned short vlan_TCI = ntohs(vhdr->h_vlan_TCI);
+			skb->ingress_priority = vlan_TCI >> 13;
+		}
 		return eth->h_proto;
+	}
 
 	rawp = skb->data;
 
@@ -207,7 +216,7 @@ __be16 eth_type_trans(struct sk_buff *sk
 	 *      layer. We look for FFFF which isn't a used 802.2 SSAP/DSAP. This
 	 *      won't work for fault tolerant netware but does for the rest.
 	 */
-	if (*(unsigned short *)rawp == 0xFFFF)
+	if (get_unaligned((unsigned short *)rawp) == 0xFFFF)
 		return htons(ETH_P_802_3);
 
 	/*
diff -puNrb linux-2.6.35/net/ipv4/af_inet.c linux/net/ipv4/af_inet.c
--- linux-2.6.35/net/ipv4/af_inet.c	2011-04-26 16:26:07.172523939 +0300
+++ linux/net/ipv4/af_inet.c	2011-05-02 10:08:29.551588757 +0300
@@ -864,6 +864,7 @@ int inet_ioctl(struct socket *sock, unsi
 	case SIOCSIFPFLAGS:
 	case SIOCGIFPFLAGS:
 	case SIOCSIFFLAGS:
+	case SIOCSPROXYARP:
 		err = devinet_ioctl(net, cmd, (void __user *)arg);
 		break;
 	default:
diff -puNrb linux-2.6.35/net/ipv4/arp.c linux/net/ipv4/arp.c
--- linux-2.6.35/net/ipv4/arp.c	2011-04-26 16:26:07.182507531 +0300
+++ linux/net/ipv4/arp.c	2011-05-02 10:08:29.561592263 +0300
@@ -194,9 +194,9 @@ struct neigh_table arp_tbl = {
 		.locktime =		1 * HZ,
 	},
 	.gc_interval =	30 * HZ,
-	.gc_thresh1 =	128,
-	.gc_thresh2 =	512,
-	.gc_thresh3 =	1024,
+	.gc_thresh1 =	1024,
+	.gc_thresh2 =	4096,
+	.gc_thresh3 =	8192,
 };
 
 int arp_mc_map(__be32 addr, u8 *haddr, struct net_device *dev, int dir)
@@ -299,12 +299,12 @@ static int arp_constructor(struct neighb
 		if (neigh->type == RTN_MULTICAST) {
 			neigh->nud_state = NUD_NOARP;
 			arp_mc_map(addr, neigh->ha, dev, 1);
-		} else if (dev->flags&(IFF_NOARP|IFF_LOOPBACK)) {
-			neigh->nud_state = NUD_NOARP;
-			memcpy(neigh->ha, dev->dev_addr, dev->addr_len);
 		} else if (neigh->type == RTN_BROADCAST || dev->flags&IFF_POINTOPOINT) {
 			neigh->nud_state = NUD_NOARP;
 			memcpy(neigh->ha, dev->broadcast, dev->addr_len);
+		} else if (dev->flags&(IFF_NOARP|IFF_LOOPBACK)) {
+			neigh->nud_state = NUD_NOARP;
+			memcpy(neigh->ha, dev->dev_addr, dev->addr_len);
 		}
 
 		if (dev->header_ops->cache)
@@ -338,6 +338,11 @@ static void arp_solicit(struct neighbour
 	if (!in_dev)
 		return;
 
+	/* we may occasionally get non-IP packets here, so we can not
+	   know where IP header is, if any */
+	if (skb && skb->protocol != __constant_htons(ETH_P_IP))
+		skb = NULL;
+
 	switch (IN_DEV_ARP_ANNOUNCE(in_dev)) {
 	default:
 	case 0:		/* By default announce any local IP */
@@ -1141,6 +1146,7 @@ static int arp_req_delete(struct net *ne
 	int err;
 	__be32 ip;
 	struct neighbour *neigh;
+	int skip_perm = (dev == NULL) && (r->arp_flags == ATF_PERM);
 
 	if (r->arp_flags & ATF_PUBL)
 		return arp_req_delete_public(net, r, dev);
@@ -1160,7 +1166,9 @@ static int arp_req_delete(struct net *ne
 	err = -ENXIO;
 	neigh = neigh_lookup(&arp_tbl, &ip, dev);
 	if (neigh) {
-		if (neigh->nud_state&~NUD_NOARP)
+		if ((neigh->nud_state&NUD_PERMANENT) && skip_perm)
+			err = -EEXIST;
+		else if (neigh->nud_state&~NUD_NOARP)
 			err = neigh_update(neigh, NULL, NUD_FAILED,
 					   NEIGH_UPDATE_F_OVERRIDE|
 					   NEIGH_UPDATE_F_ADMIN);
diff -puNrb linux-2.6.35/net/ipv4/devinet.c linux/net/ipv4/devinet.c
--- linux-2.6.35/net/ipv4/devinet.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/devinet.c	2011-05-02 10:08:29.581591460 +0300
@@ -627,6 +627,7 @@ int devinet_ioctl(struct net *net, unsig
 		break;
 
 	case SIOCSIFFLAGS:
+	case SIOCSPROXYARP:
 		ret = -EACCES;
 		if (!capable(CAP_NET_ADMIN))
 			goto out;
@@ -686,7 +687,8 @@ int devinet_ioctl(struct net *net, unsig
 	}
 
 	ret = -EADDRNOTAVAIL;
-	if (!ifa && cmd != SIOCSIFADDR && cmd != SIOCSIFFLAGS)
+	if (!ifa && cmd != SIOCSIFADDR && cmd != SIOCSIFFLAGS
+	    && cmd != SIOCSPROXYARP)
 		goto done;
 
 	switch (cmd) {
@@ -719,6 +721,14 @@ int devinet_ioctl(struct net *net, unsig
 		ret = dev_change_flags(dev, ifr.ifr_flags);
 		break;
 
+	case SIOCSPROXYARP:
+		ret = -EINVAL;
+		if (in_dev) {
+			ret = 0;
+			IN_DEV_CONF_SET(in_dev, PROXY_ARP, ifr.ifr_flags ? 1 : 0);
+		}
+		break;
+
 	case SIOCSIFADDR:	/* Set interface address (and family) */
 		ret = -EINVAL;
 		if (inet_abc_len(sin->sin_addr.s_addr) < 0)
@@ -925,7 +935,10 @@ static __be32 confirm_addr_indev(struct 
 				break;
 		}
 		if (!same) {
-			same = (!local || inet_ifa_match(local, ifa)) &&
+			/* match iface local address by local as well
+			   to support ethernets with /32 addresses */
+			same = (!local || inet_ifa_match(local, ifa)
+				|| local == ifa->ifa_local) &&
 				(!dst || inet_ifa_match(dst, ifa));
 			if (same && addr) {
 				if (local || !dst)
@@ -1493,15 +1506,19 @@ static void __devinet_sysctl_unregister(
 
 static void devinet_sysctl_register(struct in_device *idev)
 {
+#if 0
 	neigh_sysctl_register(idev->dev, idev->arp_parms, "ipv4", NULL);
 	__devinet_sysctl_register(dev_net(idev->dev), idev->dev->name,
 					&idev->cnf);
+#endif
 }
 
 static void devinet_sysctl_unregister(struct in_device *idev)
 {
+#if 0
 	__devinet_sysctl_unregister(&idev->cnf);
 	neigh_sysctl_unregister(idev->arp_parms);
+#endif
 }
 
 static struct ctl_table ctl_forward_entry[] = {
diff -puNrb linux-2.6.35/net/ipv4/fib_frontend.c linux/net/ipv4/fib_frontend.c
--- linux-2.6.35/net/ipv4/fib_frontend.c	2011-04-26 16:26:07.172523939 +0300
+++ linux/net/ipv4/fib_frontend.c	2011-05-02 10:08:29.591590686 +0300
@@ -45,6 +45,8 @@
 #include <net/ip_fib.h>
 #include <net/rtnetlink.h>
 
+int sysctl_kernel_adds_connected_routes __read_mostly = 0;
+
 #ifndef CONFIG_IP_MULTIPLE_TABLES
 
 static int __net_init fib4_rules_init(struct net *net)
@@ -513,6 +515,7 @@ const struct nla_policy rtm_ipv4_policy[
 	[RTA_METRICS]		= { .type = NLA_NESTED },
 	[RTA_MULTIPATH]		= { .len = sizeof(struct rtnexthop) },
 	[RTA_FLOW]		= { .type = NLA_U32 },
+        [RTA_MPLSKEY]		= { .type = NLA_U32 },
 };
 
 static int rtm_to_fib_config(struct net *net, struct sk_buff *skb,
@@ -578,6 +581,9 @@ static int rtm_to_fib_config(struct net 
 		case RTA_TABLE:
 			cfg->fc_table = nla_get_u32(attr);
 			break;
+		case RTA_MPLSKEY:
+			cfg->fc_mplskey = nla_get_u32(attr);
+			break;
 		}
 	}
 
@@ -743,9 +749,10 @@ void fib_add_ifaddr(struct in_ifaddr *if
 
 	if (!ipv4_is_zeronet(prefix) && !(ifa->ifa_flags&IFA_F_SECONDARY) &&
 	    (prefix != addr || ifa->ifa_prefixlen < 32)) {
+		if (sysctl_kernel_adds_connected_routes) {
 		fib_magic(RTM_NEWROUTE, dev->flags&IFF_LOOPBACK ? RTN_LOCAL :
 			  RTN_UNICAST, prefix, ifa->ifa_prefixlen, prim);
-
+		}
 		/* Add network specific broadcasts, when it takes a sense */
 		if (ifa->ifa_prefixlen < 31) {
 			fib_magic(RTM_NEWROUTE, RTN_BROADCAST, prefix, 32, prim);
@@ -768,10 +775,12 @@ static void fib_del_ifaddr(struct in_ifa
 #define BRD1_OK		8
 	unsigned ok = 0;
 
-	if (!(ifa->ifa_flags&IFA_F_SECONDARY))
+	if (!(ifa->ifa_flags&IFA_F_SECONDARY)) {
+		if (sysctl_kernel_adds_connected_routes) {
 		fib_magic(RTM_DELROUTE, dev->flags&IFF_LOOPBACK ? RTN_LOCAL :
 			  RTN_UNICAST, any, ifa->ifa_prefixlen, prim);
-	else {
+		}
+	} else {
 		prim = inet_ifa_byprefix(in_dev, any, ifa->ifa_mask);
 		if (prim == NULL) {
 			printk(KERN_WARNING "fib_del_ifaddr: bug: prim == NULL\n");
diff -puNrb linux-2.6.35/net/ipv4/fib_rules.c linux/net/ipv4/fib_rules.c
--- linux-2.6.35/net/ipv4/fib_rules.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/fib_rules.c	2011-05-02 10:08:29.601544878 +0300
@@ -75,6 +75,7 @@ static int fib4_rule_action(struct fib_r
 
 	switch (rule->action) {
 	case FR_ACT_TO_TBL:
+	case FR_ACT_ONLY_TO_TBL:
 		break;
 
 	case FR_ACT_UNREACHABLE:
@@ -92,11 +93,14 @@ static int fib4_rule_action(struct fib_r
 	}
 
 	if ((tbl = fib_get_table(rule->fr_net, rule->table)) == NULL)
-		goto errout;
+		goto errout2;
 
 	err = fib_table_lookup(tbl, flp, (struct fib_result *) arg->result);
-	if (err > 0)
-		err = -EAGAIN;
+	if (err > 0) {
+errout2:
+		if (rule->action == FR_ACT_ONLY_TO_TBL) err = -ENETUNREACH;
+		else err = -EAGAIN;
+        }
 errout:
 	return err;
 }
diff -puNrb linux-2.6.35/net/ipv4/fib_semantics.c linux/net/ipv4/fib_semantics.c
--- linux-2.6.35/net/ipv4/fib_semantics.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/fib_semantics.c	2011-05-02 10:08:29.621589313 +0300
@@ -187,6 +187,7 @@ static __inline__ int nh_comp(const stru
 #ifdef CONFIG_NET_CLS_ROUTE
 		    nh->nh_tclassid != onh->nh_tclassid ||
 #endif
+		    nh->nh_mplskey != onh->nh_mplskey ||
 		    ((nh->nh_flags^onh->nh_flags)&~RTNH_F_DEAD))
 			return -1;
 		onh++;
@@ -411,6 +412,8 @@ static int fib_get_nhs(struct fib_info *
 			nla = nla_find(attrs, attrlen, RTA_FLOW);
 			nexthop_nh->nh_tclassid = nla ? nla_get_u32(nla) : 0;
 #endif
+			nla = nla_find(attrs, attrlen, RTA_MPLSKEY);
+			nexthop_nh->nh_mplskey = nla ? nla_get_u32(nla) : 0;
 		}
 
 		rtnh = rtnh_next(rtnh, &remaining);
@@ -431,8 +434,9 @@ int fib_nh_match(struct fib_config *cfg,
 	if (cfg->fc_priority && cfg->fc_priority != fi->fib_priority)
 		return 1;
 
-	if (cfg->fc_oif || cfg->fc_gw) {
+	if (cfg->fc_oif || cfg->fc_gw || cfg->fc_mplskey) {
 		if ((!cfg->fc_oif || cfg->fc_oif == fi->fib_nh->nh_oif) &&
+		    (!cfg->fc_mplskey || cfg->fc_mplskey == fi->fib_nh->nh_mplskey) &&
 		    (!cfg->fc_gw  || cfg->fc_gw == fi->fib_nh->nh_gw))
 			return 0;
 		return 1;
@@ -466,6 +470,9 @@ int fib_nh_match(struct fib_config *cfg,
 			if (nla && nla_get_u32(nla) != nh->nh_tclassid)
 				return 1;
 #endif
+			nla = nla_find(attrs, attrlen, RTA_MPLSKEY);
+			if (nla && nla_get_u32(nla) != nh->nh_mplskey)
+				return 1;
 		}
 
 		rtnh = rtnh_next(rtnh, &remaining);
@@ -767,6 +774,8 @@ struct fib_info *fib_create_info(struct 
 		if (cfg->fc_flow && fi->fib_nh->nh_tclassid != cfg->fc_flow)
 			goto err_inval;
 #endif
+		if (cfg->fc_mplskey && fi->fib_nh->nh_mplskey != cfg->fc_mplskey)
+			goto err_inval;
 #else
 		goto err_inval;
 #endif
@@ -782,10 +791,11 @@ struct fib_info *fib_create_info(struct 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 		nh->nh_weight = 1;
 #endif
+		nh->nh_mplskey = cfg->fc_mplskey;
 	}
 
 	if (fib_props[cfg->fc_type].error) {
-		if (cfg->fc_gw || cfg->fc_oif || cfg->fc_mp)
+		if (cfg->fc_gw || cfg->fc_oif || cfg->fc_mp || cfg->fc_mplskey)
 			goto err_inval;
 		goto link_it;
 	}
@@ -811,12 +821,14 @@ struct fib_info *fib_create_info(struct 
 		} endfor_nexthops(fi)
 	}
 
+#if 0 /* Do not check validity of prefsrc addresses */
 	if (fi->fib_prefsrc) {
 		if (cfg->fc_type != RTN_LOCAL || !cfg->fc_dst ||
 		    fi->fib_prefsrc != cfg->fc_dst)
 			if (inet_addr_type(net, fi->fib_prefsrc) != RTN_LOCAL)
 				goto err_inval;
 	}
+#endif
 
 link_it:
 	if ((ofi = fib_find_info(fi)) != NULL) {
@@ -988,6 +1000,8 @@ int fib_dump_info(struct sk_buff *skb, u
 		if (fi->fib_nh[0].nh_tclassid)
 			NLA_PUT_U32(skb, RTA_FLOW, fi->fib_nh[0].nh_tclassid);
 #endif
+		if (fi->fib_nh[0].nh_mplskey)
+			NLA_PUT_U32(skb, RTA_MPLSKEY, fi->fib_nh[0].nh_mplskey);
 	}
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 	if (fi->fib_nhs > 1) {
@@ -1013,6 +1027,8 @@ int fib_dump_info(struct sk_buff *skb, u
 			if (nh->nh_tclassid)
 				NLA_PUT_U32(skb, RTA_FLOW, nh->nh_tclassid);
 #endif
+			if (nh->nh_mplskey)
+				NLA_PUT_U32(skb, RTA_MPLSKEY, nh->nh_mplskey);
 			/* length of rtnetlink header + attributes */
 			rtnh->rtnh_len = nlmsg_get_pos(skb) - (void *) rtnh;
 		} endfor_nexthops(fi);
@@ -1047,10 +1063,12 @@ int fib_sync_down_addr(struct net *net, 
 	hlist_for_each_entry(fi, node, head, fib_lhash) {
 		if (!net_eq(fi->fib_net, net))
 			continue;
+#if (0) /* Do not invalidate routes based on prefsrc */
 		if (fi->fib_prefsrc == local) {
 			fi->fib_flags |= RTNH_F_DEAD;
 			ret++;
 		}
+#endif
 	}
 	return ret;
 }
diff -puNrb linux-2.6.35/net/ipv4/icmp.c linux/net/ipv4/icmp.c
--- linux-2.6.35/net/ipv4/icmp.c	2011-04-26 16:26:07.192511828 +0300
+++ linux/net/ipv4/icmp.c	2011-05-02 10:08:29.631544844 +0300
@@ -388,6 +388,7 @@ static void icmp_reply(struct icmp_bxm *
 					      { .daddr = daddr,
 						.saddr = rt->rt_spec_dst,
 						.tos = RT_TOS(ip_hdr(skb)->tos) } },
+				    .mark = skb->prmark | 0xffff0000,
 				    .proto = IPPROTO_ICMP };
 		security_skb_classify_flow(skb, &fl);
 		if (ip_route_output_key(net, &rt, &fl))
@@ -549,6 +550,7 @@ void icmp_send(struct sk_buff *skb_in, i
 					.tos = RT_TOS(tos)
 				}
 			},
+			.mark = skb_in->prmark | 0xffff0000,
 			.proto = IPPROTO_ICMP,
 			.uli_u = {
 				.icmpt = {
diff -puNrb linux-2.6.35/net/ipv4/ip_forward.c linux/net/ipv4/ip_forward.c
--- linux-2.6.35/net/ipv4/ip_forward.c	2011-04-26 16:26:07.192511828 +0300
+++ linux/net/ipv4/ip_forward.c	2011-05-02 10:08:29.641588707 +0300
@@ -110,7 +110,7 @@ int ip_forward(struct sk_buff *skb)
 	if (rt->rt_flags&RTCF_DOREDIRECT && !opt->srr && !skb_sec_path(skb))
 		ip_rt_send_redirect(skb);
 
-	skb->priority = rt_tos2priority(iph->tos);
+	/* skb->priority = rt_tos2priority(iph->tos); */
 
 	return NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, skb, skb->dev,
 		       rt->u.dst.dev, ip_forward_finish);
diff -puNrb linux-2.6.35/net/ipv4/ip_gre.c linux/net/ipv4/ip_gre.c
--- linux-2.6.35/net/ipv4/ip_gre.c	2011-04-26 16:26:07.152478086 +0300
+++ linux/net/ipv4/ip_gre.c	2011-05-02 10:08:29.661591293 +0300
@@ -486,7 +486,7 @@ static void ipgre_err(struct sk_buff *sk
 	rcu_read_lock();
 	t = ipgre_tunnel_lookup(skb->dev, iph->daddr, iph->saddr,
 				flags & GRE_KEY ?
-				*(((__be32 *)p) + (grehlen / 4) - 1) : 0,
+				get_unaligned(((__be32 *)p) + (grehlen / 4) - 1) : 0,
 				p[1]);
 	if (t == NULL || t->parms.iph.daddr == 0 ||
 	    ipv4_is_multicast(t->parms.iph.daddr))
@@ -567,11 +567,11 @@ static int ipgre_rcv(struct sk_buff *skb
 			offset += 4;
 		}
 		if (flags&GRE_KEY) {
-			key = *(__be32*)(h + offset);
+			key = get_unaligned((__be32*)(h + offset));
 			offset += 4;
 		}
 		if (flags&GRE_SEQ) {
-			seqno = ntohl(*(__be32*)(h + offset));
+			seqno = ntohl(get_unaligned((__be32*)(h + offset)));
 			offset += 4;
 		}
 	}
@@ -865,15 +865,15 @@ static netdev_tx_t ipgre_tunnel_xmit(str
 
 		if (tunnel->parms.o_flags&GRE_SEQ) {
 			++tunnel->o_seqno;
-			*ptr = htonl(tunnel->o_seqno);
+			put_unaligned(htonl(tunnel->o_seqno), ptr);
 			ptr--;
 		}
 		if (tunnel->parms.o_flags&GRE_KEY) {
-			*ptr = tunnel->parms.o_key;
+			put_unaligned(tunnel->parms.o_key, ptr);
 			ptr--;
 		}
 		if (tunnel->parms.o_flags&GRE_CSUM) {
-			*ptr = 0;
+			put_unaligned(0, ptr);
 			*(__sum16*)ptr = ip_compute_csum((void*)(iph+1), skb->len - sizeof(struct iphdr));
 		}
 	}
diff -puNrb linux-2.6.35/net/ipv4/ip_input.c linux/net/ipv4/ip_input.c
--- linux-2.6.35/net/ipv4/ip_input.c	2011-04-26 16:26:07.182507531 +0300
+++ linux/net/ipv4/ip_input.c	2011-05-02 10:08:29.671544967 +0300
@@ -454,3 +454,5 @@ drop:
 out:
 	return NET_RX_DROP;
 }
+
+EXPORT_SYMBOL(ip_rcv);
diff -puNrb linux-2.6.35/net/ipv4/ipmr.c linux/net/ipv4/ipmr.c
--- linux-2.6.35/net/ipv4/ipmr.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/ipmr.c	2011-05-02 10:08:29.691586623 +0300
@@ -28,6 +28,7 @@
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
+#include <asm/unaligned.h>
 #include <linux/types.h>
 #include <linux/capability.h>
 #include <linux/errno.h>
@@ -79,13 +80,13 @@ struct mr_table {
 	struct timer_list	ipmr_expire_timer;
 	struct list_head	mfc_unres_queue;
 	struct list_head	mfc_cache_array[MFC_LINES];
-	struct vif_device	vif_table[MAXVIFS];
+	struct list_head	vif_list;
 	int			maxvif;
 	atomic_t		cache_resolve_queue_len;
 	int			mroute_do_assert;
 	int			mroute_do_pim;
-#if defined(CONFIG_IP_PIMSM_V1) || defined(CONFIG_IP_PIMSM_V2)
-	int			mroute_reg_vif_num;
+#ifdef CONFIG_IP_PIMSM
+	struct vif_device	*reg_vif;
 #endif
 };
 
@@ -107,7 +108,16 @@ static DEFINE_RWLOCK(mrt_lock);
  *	Multicast router control variables
  */
 
-#define VIF_EXISTS(_mrt, _idx) ((_mrt)->vif_table[_idx].dev != NULL)
+
+static struct vif_device *vif_find(struct mr_table *mrt, int vifi) {
+	struct vif_device *i;
+
+	list_for_each_entry(i, &mrt->vif_list, list) {
+		if (i->index == vifi) return i;
+	}
+	return NULL;
+}
+
 
 /* Special spinlock for queue of unresolved entries */
 static DEFINE_SPINLOCK(mfc_unres_lock);
@@ -127,7 +137,7 @@ static int ip_mr_forward(struct net *net
 			 struct sk_buff *skb, struct mfc_cache *cache,
 			 int local);
 static int ipmr_cache_report(struct mr_table *mrt,
-			     struct sk_buff *pkt, vifi_t vifi, int assert);
+			     struct sk_buff *pkt, struct vif_device *vif, int assert);
 static int __ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,
 			      struct mfc_cache *c, struct rtmsg *rtm);
 static void ipmr_expire_process(unsigned long arg);
@@ -321,13 +331,14 @@ static struct mr_table *ipmr_new_table(s
 		INIT_LIST_HEAD(&mrt->mfc_cache_array[i]);
 
 	INIT_LIST_HEAD(&mrt->mfc_unres_queue);
+	INIT_LIST_HEAD(&mrt->vif_list);
+#ifdef CONFIG_IP_PIMSM
+	mrt->reg_vif = NULL;
+#endif
 
 	setup_timer(&mrt->ipmr_expire_timer, ipmr_expire_process,
 		    (unsigned long)mrt);
 
-#ifdef CONFIG_IP_PIMSM
-	mrt->mroute_reg_vif_num = -1;
-#endif
 #ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES
 	list_add_tail_rcu(&mrt->list, &net->ipv4.mr_tables);
 #endif
@@ -450,7 +461,7 @@ static netdev_tx_t reg_vif_xmit(struct s
 	read_lock(&mrt_lock);
 	dev->stats.tx_bytes += skb->len;
 	dev->stats.tx_packets++;
-	ipmr_cache_report(mrt, skb, mrt->mroute_reg_vif_num, IGMPMSG_WHOLEPKT);
+	ipmr_cache_report(mrt, skb, mrt->reg_vif, IGMPMSG_WHOLEPKT);
 	read_unlock(&mrt_lock);
 	kfree_skb(skb);
 	return NETDEV_TX_OK;
@@ -526,17 +537,31 @@ failure:
  *	@notify: Set to 1, if the caller is a notifier_call
  */
 
+static void vif_delete_from_mfc(struct vif_device *vif, struct mfc_cache *c) {
+	unsigned count = c->mfc_un.res.output_dev_count;
+	unsigned i;
+
+	for (i = 0; i < count; ++i) {
+		if (c->mfc_un.res.output_devs[i] == vif) {
+			c->mfc_un.res.output_devs[i] = NULL;
+			break;
+		}
+	}
+}
+
 static int vif_delete(struct mr_table *mrt, int vifi, int notify,
 		      struct list_head *head)
 {
 	struct vif_device *v;
 	struct net_device *dev;
 	struct in_device *in_dev;
+	struct mfc_cache *c;
+	int i;
 
-	if (vifi < 0 || vifi >= mrt->maxvif)
+	v = vif_find(mrt, vifi);
+	if (!v) {
 		return -EADDRNOTAVAIL;
-
-	v = &mrt->vif_table[vifi];
+	}
 
 	write_lock_bh(&mrt_lock);
 	dev = v->dev;
@@ -547,19 +572,26 @@ static int vif_delete(struct mr_table *m
 		return -EADDRNOTAVAIL;
 	}
 
-#ifdef CONFIG_IP_PIMSM
-	if (vifi == mrt->mroute_reg_vif_num)
-		mrt->mroute_reg_vif_num = -1;
-#endif
 
-	if (vifi+1 == mrt->maxvif) {
-		int tmp;
-		for (tmp=vifi-1; tmp>=0; tmp--) {
-			if (VIF_EXISTS(mrt, tmp))
-				break;
+	/* remove vif from existing routes */
+	for (i = 0; i < MFC_LINES; i++) {
+		list_for_each_entry(c, &mrt->mfc_cache_array[i], list) {
+			vif_delete_from_mfc(v, c);
 		}
-		mrt->maxvif = tmp+1;
 	}
+	if (atomic_read(&mrt->cache_resolve_queue_len) != 0) {
+		spin_lock_bh(&mfc_unres_lock);
+		list_for_each_entry(c, &mrt->mfc_unres_queue, list) {
+			vif_delete_from_mfc(v, c);
+		}
+		spin_unlock_bh(&mfc_unres_lock);
+	}
+
+
+#ifdef CONFIG_IP_PIMSM
+	if (v == mrt->reg_vif)
+		mrt->reg_vif = NULL;
+#endif
 
 	write_unlock_bh(&mrt_lock);
 
@@ -574,6 +606,9 @@ static int vif_delete(struct mr_table *m
 		unregister_netdevice_queue(dev, head);
 
 	dev_put(dev);
+
+	list_del(&v->list);
+	kfree(v);
 	return 0;
 }
 
@@ -652,41 +687,19 @@ out:
 	spin_unlock(&mfc_unres_lock);
 }
 
-/* Fill oifs list. It is called under write locked mrt_lock. */
-
-static void ipmr_update_thresholds(struct mr_table *mrt, struct mfc_cache *cache,
-				   unsigned char *ttls)
-{
-	int vifi;
-
-	cache->mfc_un.res.minvif = MAXVIFS;
-	cache->mfc_un.res.maxvif = 0;
-	memset(cache->mfc_un.res.ttls, 255, MAXVIFS);
-
-	for (vifi = 0; vifi < mrt->maxvif; vifi++) {
-		if (VIF_EXISTS(mrt, vifi) &&
-		    ttls[vifi] && ttls[vifi] < 255) {
-			cache->mfc_un.res.ttls[vifi] = ttls[vifi];
-			if (cache->mfc_un.res.minvif > vifi)
-				cache->mfc_un.res.minvif = vifi;
-			if (cache->mfc_un.res.maxvif <= vifi)
-				cache->mfc_un.res.maxvif = vifi + 1;
-		}
-	}
-}
-
 static int vif_add(struct net *net, struct mr_table *mrt,
 		   struct vifctl *vifc, int mrtsock)
 {
 	int vifi = vifc->vifc_vifi;
-	struct vif_device *v = &mrt->vif_table[vifi];
+	struct vif_device *v = vif_find(mrt, vifi);
 	struct net_device *dev;
 	struct in_device *in_dev;
 	int err;
 
 	/* Is vif busy ? */
-	if (VIF_EXISTS(mrt, vifi))
+	if (v) {
 		return -EADDRINUSE;
+	}
 
 	switch (vifc->vifc_flags) {
 #ifdef CONFIG_IP_PIMSM
@@ -695,7 +708,7 @@ static int vif_add(struct net *net, stru
 		 * Special Purpose VIF in PIM
 		 * All the packets will be sent to the daemon
 		 */
-		if (mrt->mroute_reg_vif_num >= 0)
+		if (mrt->reg_vif)
 			return -EADDRINUSE;
 		dev = ipmr_reg_vif(net, mrt);
 		if (!dev)
@@ -747,6 +760,15 @@ static int vif_add(struct net *net, stru
 		dev_put(dev);
 		return -EADDRNOTAVAIL;
 	}
+
+	v = kmalloc(sizeof(struct vif_device), GFP_KERNEL);
+	if (!v) {
+		return -ENOMEM;
+	}
+	memset(v, 0, sizeof(struct vif_device));
+	v->index = vifi;
+	list_add(&v->list, &mrt->vif_list);
+
 	IPV4_DEVCONF(in_dev->cnf, MC_FORWARDING)++;
 	ip_rt_multicast_event(in_dev);
 
@@ -773,10 +795,8 @@ static int vif_add(struct net *net, stru
 	v->dev = dev;
 #ifdef CONFIG_IP_PIMSM
 	if (v->flags&VIFF_REGISTER)
-		mrt->mroute_reg_vif_num = vifi;
+		mrt->reg_vif = v;
 #endif
-	if (vifi+1 > mrt->maxvif)
-		mrt->maxvif = vifi+1;
 	write_unlock_bh(&mrt_lock);
 	return 0;
 }
@@ -803,7 +823,8 @@ static struct mfc_cache *ipmr_cache_allo
 	struct mfc_cache *c = kmem_cache_zalloc(mrt_cachep, GFP_KERNEL);
 	if (c == NULL)
 		return NULL;
-	c->mfc_un.res.minvif = MAXVIFS;
+	c->mfc_un.res.output_dev_count = 0;
+	c->mfc_un.res.output_devs = NULL;
 	return c;
 }
 
@@ -861,7 +882,7 @@ static void ipmr_cache_resolve(struct ne
  */
 
 static int ipmr_cache_report(struct mr_table *mrt,
-			     struct sk_buff *pkt, vifi_t vifi, int assert)
+			     struct sk_buff *pkt, struct vif_device *vif, int assert)
 {
 	struct sk_buff *skb;
 	const int ihl = ip_hdrlen(pkt);
@@ -893,7 +914,7 @@ static int ipmr_cache_report(struct mr_t
 		memcpy(msg, skb_network_header(pkt), sizeof(struct iphdr));
 		msg->im_msgtype = IGMPMSG_WHOLEPKT;
 		msg->im_mbz = 0;
-		msg->im_vif = mrt->mroute_reg_vif_num;
+		msg->im_vif = mrt->reg_vif ? mrt->reg_vif->index : -1;
 		ip_hdr(skb)->ihl = sizeof(struct iphdr) >> 2;
 		ip_hdr(skb)->tot_len = htons(ntohs(ip_hdr(pkt)->tot_len) +
 					     sizeof(struct iphdr));
@@ -910,7 +931,7 @@ static int ipmr_cache_report(struct mr_t
 	skb_copy_to_linear_data(skb, pkt->data, ihl);
 	ip_hdr(skb)->protocol = 0;			/* Flag to the kernel this is a route add */
 	msg = (struct igmpmsg *)skb_network_header(skb);
-	msg->im_vif = vifi;
+	msg->im_vif = vif ? vif->index : -1;
 	skb_dst_set(skb, dst_clone(skb_dst(pkt)));
 
 	/*
@@ -948,7 +969,8 @@ static int ipmr_cache_report(struct mr_t
  */
 
 static int
-ipmr_cache_unresolved(struct mr_table *mrt, vifi_t vifi, struct sk_buff *skb)
+ipmr_cache_unresolved(struct mr_table *mrt, struct vif_device *vif,
+		      struct sk_buff *skb)
 {
 	bool found = false;
 	int err;
@@ -980,14 +1002,14 @@ ipmr_cache_unresolved(struct mr_table *m
 		/*
 		 *	Fill in the new cache entry
 		 */
-		c->mfc_parent	= -1;
+		c->mfc_parent	= NULL;
 		c->mfc_origin	= iph->saddr;
 		c->mfc_mcastgrp	= iph->daddr;
 
 		/*
 		 *	Reflect first query at mrouted.
 		 */
-		err = ipmr_cache_report(mrt, skb, vifi, IGMPMSG_NOCACHE);
+		err = ipmr_cache_report(mrt, skb, vif, IGMPMSG_NOCACHE);
 		if (err < 0) {
 			/* If the report failed throw the cache entry
 			   out - Brad Parker
@@ -1039,6 +1061,10 @@ static int ipmr_mfc_delete(struct mr_tab
 			list_del(&c->list);
 			write_unlock_bh(&mrt_lock);
 
+			if (c->mfc_un.res.output_devs) {
+				kfree(c->mfc_un.res.output_devs);
+			}
+
 			ipmr_cache_free(c);
 			return 0;
 		}
@@ -1046,15 +1072,49 @@ static int ipmr_mfc_delete(struct mr_tab
 	return -ENOENT;
 }
 
+static int ipmr_update_output_devs(struct mr_table *mrt,
+				   struct mfc_cache *c, struct mfcctl *mfc,
+				   char __user *opts) {
+	int count = mfc->mfcc_output_dev_cnt;
+	int i;
+
+	if (c->mfc_un.res.output_devs) {
+		kfree(c->mfc_un.res.output_devs);
+		c->mfc_un.res.output_devs = NULL;
+	}
+	c->mfc_un.res.output_dev_count = 0;
+
+	if (!count) {
+		return 0;
+	}
+
+	c->mfc_un.res.output_devs =
+		kmalloc(count * sizeof(struct vif_device *), GFP_ATOMIC);
+	if (!c->mfc_un.res.output_devs) {
+		return -ENOMEM;
+	}
+
+	if (copy_from_user(c->mfc_un.res.output_devs,
+			   opts, count * sizeof(struct vif_device *))) {
+		return -EFAULT;
+	}
+
+	c->mfc_un.res.output_dev_count = count;
+	for (i = 0; i < count; ++i) {
+		c->mfc_un.res.output_devs[i] =
+			vif_find(mrt, (unsigned)c->mfc_un.res.output_devs[i]);
+	}
+
+	return 0;
+}
+
 static int ipmr_mfc_add(struct net *net, struct mr_table *mrt,
-			struct mfcctl *mfc, int mrtsock)
+			struct mfcctl *mfc, int mrtsock, char __user *opts)
 {
 	bool found = false;
 	int line;
 	struct mfc_cache *uc, *c;
-
-	if (mfc->mfcc_parent >= MAXVIFS)
-		return -ENFILE;
+	int ret;
 
 	line = MFC_HASH(mfc->mfcc_mcastgrp.s_addr, mfc->mfcc_origin.s_addr);
 
@@ -1068,8 +1128,12 @@ static int ipmr_mfc_add(struct net *net,
 
 	if (found) {
 		write_lock_bh(&mrt_lock);
-		c->mfc_parent = mfc->mfcc_parent;
-		ipmr_update_thresholds(mrt, c, mfc->mfcc_ttls);
+		ret = ipmr_update_output_devs(mrt, c, mfc, opts);
+		if (ret) {
+			write_unlock_bh(&mrt_lock);
+			return ret;
+		}
+		c->mfc_parent = vif_find(mrt, mfc->mfcc_parent);
 		if (!mrtsock)
 			c->mfc_flags |= MFC_STATIC;
 		write_unlock_bh(&mrt_lock);
@@ -1083,10 +1147,15 @@ static int ipmr_mfc_add(struct net *net,
 	if (c == NULL)
 		return -ENOMEM;
 
+	c->mfc_un.res.output_devs = NULL;
+	ret = ipmr_update_output_devs(mrt, c, mfc, opts);
+	if (ret) {
+		ipmr_cache_free(c);
+		return ret;
+	}
 	c->mfc_origin = mfc->mfcc_origin.s_addr;
 	c->mfc_mcastgrp = mfc->mfcc_mcastgrp.s_addr;
-	c->mfc_parent = mfc->mfcc_parent;
-	ipmr_update_thresholds(mrt, c, mfc->mfcc_ttls);
+	c->mfc_parent = vif_find(mrt, mfc->mfcc_parent);
 	if (!mrtsock)
 		c->mfc_flags |= MFC_STATIC;
 
@@ -1133,9 +1202,12 @@ static void mroute_clean_tables(struct m
 	/*
 	 *	Shut down all active vif entries
 	 */
-	for (i = 0; i < mrt->maxvif; i++) {
-		if (!(mrt->vif_table[i].flags&VIFF_STATIC))
-			vif_delete(mrt, i, 0, &list);
+	struct vif_device *v, *n;
+
+	list_for_each_entry_safe(v, n, &mrt->vif_list, list) {
+		if (!(v->flags&VIFF_STATIC)) {
+			vif_delete(mrt, v->index, 0, &list);
+		}
 	}
 	unregister_netdevice_many(&list);
 
@@ -1242,8 +1314,6 @@ int ip_mroute_setsockopt(struct sock *sk
 			return -EINVAL;
 		if (copy_from_user(&vif, optval, sizeof(vif)))
 			return -EFAULT;
-		if (vif.vifc_vifi >= MAXVIFS)
-			return -ENFILE;
 		rtnl_lock();
 		if (optname == MRT_ADD_VIF) {
 			ret = vif_add(net, mrt, &vif, sk == mrt->mroute_sk);
@@ -1259,7 +1329,7 @@ int ip_mroute_setsockopt(struct sock *sk
 		 */
 	case MRT_ADD_MFC:
 	case MRT_DEL_MFC:
-		if (optlen != sizeof(mfc))
+		if (optlen < sizeof(mfc))
 			return -EINVAL;
 		if (copy_from_user(&mfc, optval, sizeof(mfc)))
 			return -EFAULT;
@@ -1267,7 +1337,8 @@ int ip_mroute_setsockopt(struct sock *sk
 		if (optname == MRT_DEL_MFC)
 			ret = ipmr_mfc_delete(mrt, &mfc);
 		else
-			ret = ipmr_mfc_add(net, mrt, &mfc, sk == mrt->mroute_sk);
+			ret = ipmr_mfc_add(net, mrt, &mfc, sk == mrt->mroute_sk,
+					   optval + sizeof(mfc));
 		rtnl_unlock();
 		return ret;
 		/*
@@ -1395,15 +1466,13 @@ int ipmr_ioctl(struct sock *sk, int cmd,
 	case SIOCGETVIFCNT:
 		if (copy_from_user(&vr, arg, sizeof(vr)))
 			return -EFAULT;
-		if (vr.vifi >= mrt->maxvif)
-			return -EINVAL;
 		read_lock(&mrt_lock);
-		vif = &mrt->vif_table[vr.vifi];
-		if (VIF_EXISTS(mrt, vr.vifi)) {
-			vr.icount = vif->pkt_in;
-			vr.ocount = vif->pkt_out;
-			vr.ibytes = vif->bytes_in;
-			vr.obytes = vif->bytes_out;
+		vif = vif_find(mrt, vr.vifi);
+		if (vif) {
+			vr.icount=vif->pkt_in;
+			vr.ocount=vif->pkt_out;
+			vr.ibytes=vif->bytes_in;
+			vr.obytes=vif->bytes_out;
 			read_unlock(&mrt_lock);
 
 			if (copy_to_user(arg, &vr, sizeof(vr)))
@@ -1441,18 +1510,17 @@ static int ipmr_device_event(struct noti
 	struct net_device *dev = ptr;
 	struct net *net = dev_net(dev);
 	struct mr_table *mrt;
-	struct vif_device *v;
-	int ct;
+	struct vif_device *v, *n;
 	LIST_HEAD(list);
 
 	if (event != NETDEV_UNREGISTER)
 		return NOTIFY_DONE;
 
 	ipmr_for_each_table(mrt, net) {
-		v = &mrt->vif_table[0];
-		for (ct = 0; ct < mrt->maxvif; ct++, v++) {
-			if (v->dev == dev)
-				vif_delete(mrt, ct, 1, &list);
+		list_for_each_entry_safe(v, n, &mrt->vif_list, list) {
+			if (v->dev == dev) {
+				vif_delete(mrt, v->index, 1, &list);
+			}
 		}
 	}
 	unregister_netdevice_many(&list);
@@ -1513,10 +1581,10 @@ static inline int ipmr_forward_finish(st
  */
 
 static void ipmr_queue_xmit(struct net *net, struct mr_table *mrt,
-			    struct sk_buff *skb, struct mfc_cache *c, int vifi)
+			    struct sk_buff *skb, struct mfc_cache *c,
+			    struct vif_device *vif)
 {
 	const struct iphdr *iph = ip_hdr(skb);
-	struct vif_device *vif = &mrt->vif_table[vifi];
 	struct net_device *dev;
 	struct rtable *rt;
 	int    encap = 0;
@@ -1530,7 +1598,7 @@ static void ipmr_queue_xmit(struct net *
 		vif->bytes_out += skb->len;
 		vif->dev->stats.tx_bytes += skb->len;
 		vif->dev->stats.tx_packets++;
-		ipmr_cache_report(mrt, skb, vifi, IGMPMSG_WHOLEPKT);
+		ipmr_cache_report(mrt, skb, vif, IGMPMSG_WHOLEPKT);
 		goto out_free;
 	}
 #endif
@@ -1612,15 +1680,17 @@ out_free:
 	kfree_skb(skb);
 }
 
-static int ipmr_find_vif(struct mr_table *mrt, struct net_device *dev)
+static struct vif_device *ipmr_find_vif(struct mr_table *mrt,
+					struct net_device *dev)
 {
-	int ct;
+	struct vif_device *i;
 
-	for (ct = mrt->maxvif-1; ct >= 0; ct--) {
-		if (mrt->vif_table[ct].dev == dev)
-			break;
+	list_for_each_entry(i, &mrt->vif_list, list) {
+		if (i->dev == dev) {
+			return i;
+		}
 	}
-	return ct;
+	return NULL;
 }
 
 /* "local" means that we should preserve one skb (for local delivery) */
@@ -1629,18 +1699,19 @@ static int ip_mr_forward(struct net *net
 			 struct sk_buff *skb, struct mfc_cache *cache,
 			 int local)
 {
-	int psend = -1;
-	int vif, ct;
+	struct vif_device *psend = NULL;
+	struct vif_device *v;
+	int i;
 
-	vif = cache->mfc_parent;
+	v = cache->mfc_parent;
 	cache->mfc_un.res.pkt++;
 	cache->mfc_un.res.bytes += skb->len;
 
 	/*
 	 * Wrong interface: drop packet and (maybe) send PIM assert.
 	 */
-	if (mrt->vif_table[vif].dev != skb->dev) {
-		int true_vifi;
+	if (!v || v->dev != skb->dev) {
+		struct vif_device *true_vif;
 
 		if (skb_rtable(skb)->fl.iif == 0) {
 			/* It is our own packet, looped back.
@@ -1658,42 +1729,54 @@ static int ip_mr_forward(struct net *net
 		}
 
 		cache->mfc_un.res.wrong_if++;
-		true_vifi = ipmr_find_vif(mrt, skb->dev);
+		true_vif = ipmr_find_vif(mrt, skb->dev);
+
+		if (true_vif && mrt->mroute_do_assert) {
+			int xxx = 0;
+			for (i = 0; i < cache->mfc_un.res.output_dev_count; ++i) {
+				struct vif_device *x = cache->mfc_un.res.output_devs[i];
+				if (x == true_vif) {
+					xxx = 1;
+					break;
+				}
+			}
 
-		if (true_vifi >= 0 && mrt->mroute_do_assert &&
 		    /* pimsm uses asserts, when switching from RPT to SPT,
 		       so that we cannot check that packet arrived on an oif.
 		       It is bad, but otherwise we would need to move pretty
 		       large chunk of pimd to kernel. Ough... --ANK
 		     */
-		    (mrt->mroute_do_pim ||
-		     cache->mfc_un.res.ttls[true_vifi] < 255) &&
+			if ((mrt->mroute_do_pim || xxx) &&
 		    time_after(jiffies,
 			       cache->mfc_un.res.last_assert + MFC_ASSERT_THRESH)) {
 			cache->mfc_un.res.last_assert = jiffies;
-			ipmr_cache_report(mrt, skb, true_vifi, IGMPMSG_WRONGVIF);
+				ipmr_cache_report(mrt, skb, true_vif, IGMPMSG_WRONGVIF);
 		}
+		}
+
 		goto dont_forward;
 	}
 
-	mrt->vif_table[vif].pkt_in++;
-	mrt->vif_table[vif].bytes_in += skb->len;
+	v->pkt_in++;
+	v->bytes_in+=skb->len;
 
 	/*
 	 *	Forward the frame
 	 */
-	for (ct = cache->mfc_un.res.maxvif-1; ct >= cache->mfc_un.res.minvif; ct--) {
-		if (ip_hdr(skb)->ttl > cache->mfc_un.res.ttls[ct]) {
-			if (psend != -1) {
+	for (i = 0; i < cache->mfc_un.res.output_dev_count; ++i) {
+		struct vif_device *x = cache->mfc_un.res.output_devs[i];
+		if (!x) continue;
+		if (ip_hdr(skb)->ttl > x->threshold) {
+			if (psend) {
 				struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
 				if (skb2)
 					ipmr_queue_xmit(net, mrt, skb2, cache,
 							psend);
 			}
-			psend = ct;
+			psend = x;
 		}
 	}
-	if (psend != -1) {
+	if (psend) {
 		if (local) {
 			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
 			if (skb2)
@@ -1764,7 +1847,7 @@ int ip_mr_input(struct sk_buff *skb)
 	 *	No usable cache entry
 	 */
 	if (cache == NULL) {
-		int vif;
+		struct vif_device *vif;
 
 		if (local) {
 			struct sk_buff *skb2 = skb_clone(skb, GFP_ATOMIC);
@@ -1777,7 +1860,7 @@ int ip_mr_input(struct sk_buff *skb)
 		}
 
 		vif = ipmr_find_vif(mrt, skb->dev);
-		if (vif >= 0) {
+		if (vif) {
 			int err2 = ipmr_cache_unresolved(mrt, vif, skb);
 			read_unlock(&mrt_lock);
 
@@ -1824,8 +1907,8 @@ static int __pim_rcv(struct mr_table *mr
 		return 1;
 
 	read_lock(&mrt_lock);
-	if (mrt->mroute_reg_vif_num >= 0)
-		reg_dev = mrt->vif_table[mrt->mroute_reg_vif_num].dev;
+	if (mrt->reg_vif)
+		reg_dev = mrt->reg_vif->dev;
 	if (reg_dev)
 		dev_hold(reg_dev);
 	read_unlock(&mrt_lock);
@@ -1891,8 +1974,8 @@ static int pim_rcv(struct sk_buff * skb)
 		goto drop;
 
 	pim = (struct pimreghdr *)skb_transport_header(skb);
-	if (pim->type != ((PIM_VERSION<<4)|(PIM_REGISTER)) ||
-	    (pim->flags&PIM_NULL_REGISTER) ||
+	if (pim->type != ((PIM_VERSION << 4) | (PIM_REGISTER)) ||
+	    (get_unaligned(&pim->flags) & PIM_NULL_REGISTER) ||
 	    (ip_compute_csum((void *)pim, sizeof(*pim)) != 0 &&
 	     csum_fold(skb_checksum(skb, 0, skb->len, 0))))
 		goto drop;
@@ -1911,28 +1994,25 @@ drop:
 static int __ipmr_fill_mroute(struct mr_table *mrt, struct sk_buff *skb,
 			      struct mfc_cache *c, struct rtmsg *rtm)
 {
-	int ct;
+	int i;
 	struct rtnexthop *nhp;
 	u8 *b = skb_tail_pointer(skb);
 	struct rtattr *mp_head;
 
-	/* If cache is unresolved, don't try to parse IIF and OIF */
-	if (c->mfc_parent >= MAXVIFS)
-		return -ENOENT;
-
-	if (VIF_EXISTS(mrt, c->mfc_parent))
-		RTA_PUT(skb, RTA_IIF, 4, &mrt->vif_table[c->mfc_parent].dev->ifindex);
+	if (c->mfc_parent->dev)
+		RTA_PUT(skb, RTA_IIF, 4, &c->mfc_parent->dev->ifindex);
 
 	mp_head = (struct rtattr *)skb_put(skb, RTA_LENGTH(0));
 
-	for (ct = c->mfc_un.res.minvif; ct < c->mfc_un.res.maxvif; ct++) {
-		if (VIF_EXISTS(mrt, ct) && c->mfc_un.res.ttls[ct] < 255) {
+	for (i = 0; i < c->mfc_un.res.output_dev_count; ++i) {
+		struct vif_device *x = c->mfc_un.res.output_devs[i];
+		if (x) {
 			if (skb_tailroom(skb) < RTA_ALIGN(RTA_ALIGN(sizeof(*nhp)) + 4))
 				goto rtattr_failure;
 			nhp = (struct rtnexthop *)skb_put(skb, RTA_ALIGN(sizeof(*nhp)));
 			nhp->rtnh_flags = 0;
-			nhp->rtnh_hops = c->mfc_un.res.ttls[ct];
-			nhp->rtnh_ifindex = mrt->vif_table[ct].dev->ifindex;
+			nhp->rtnh_hops = x->threshold;
+			nhp->rtnh_ifindex = x->dev->ifindex;
 			nhp->rtnh_len = sizeof(*nhp);
 		}
 	}
@@ -1965,7 +2045,7 @@ int ipmr_get_route(struct net *net,
 		struct sk_buff *skb2;
 		struct iphdr *iph;
 		struct net_device *dev;
-		int vif;
+		struct vif_device *vif;
 
 		if (nowait) {
 			read_unlock(&mrt_lock);
@@ -1973,7 +2053,7 @@ int ipmr_get_route(struct net *net,
 		}
 
 		dev = skb->dev;
-		if (dev == NULL || (vif = ipmr_find_vif(mrt, dev)) < 0) {
+		if (dev == NULL || (vif = ipmr_find_vif(mrt, dev)) == NULL) {
 			read_unlock(&mrt_lock);
 			return -ENODEV;
 		}
@@ -2099,12 +2179,13 @@ static struct vif_device *ipmr_vif_seq_i
 					   loff_t pos)
 {
 	struct mr_table *mrt = iter->mrt;
+	struct vif_device *i;
 
-	for (iter->ct = 0; iter->ct < mrt->maxvif; ++iter->ct) {
-		if (!VIF_EXISTS(mrt, iter->ct))
-			continue;
-		if (pos-- == 0)
-			return &mrt->vif_table[iter->ct];
+	list_for_each_entry(i, &mrt->vif_list, list) {
+		if (!pos) {
+			return i;
+		}
+		--pos;
 	}
 	return NULL;
 }
@@ -2131,18 +2212,12 @@ static void *ipmr_vif_seq_next(struct se
 {
 	struct ipmr_vif_iter *iter = seq->private;
 	struct net *net = seq_file_net(seq);
-	struct mr_table *mrt = iter->mrt;
 
 	++*pos;
 	if (v == SEQ_START_TOKEN)
 		return ipmr_vif_seq_idx(net, iter, 0);
 
-	while (++iter->ct < mrt->maxvif) {
-		if (!VIF_EXISTS(mrt, iter->ct))
-			continue;
-		return &mrt->vif_table[iter->ct];
-	}
-	return NULL;
+	return ipmr_vif_seq_idx(net, iter, ++iter->ct);
 }
 
 static void ipmr_vif_seq_stop(struct seq_file *seq, void *v)
@@ -2153,9 +2228,6 @@ static void ipmr_vif_seq_stop(struct seq
 
 static int ipmr_vif_seq_show(struct seq_file *seq, void *v)
 {
-	struct ipmr_vif_iter *iter = seq->private;
-	struct mr_table *mrt = iter->mrt;
-
 	if (v == SEQ_START_TOKEN) {
 		seq_puts(seq,
 			 "Interface      BytesIn  PktsIn  BytesOut PktsOut Flags Local    Remote\n");
@@ -2165,7 +2237,7 @@ static int ipmr_vif_seq_show(struct seq_
 
 		seq_printf(seq,
 			   "%2Zd %-10s %8ld %7ld  %8ld %7ld %05X %08X %08X\n",
-			   vif - mrt->vif_table,
+			   vif->index,
 			   name, vif->bytes_in, vif->pkt_in,
 			   vif->bytes_out, vif->pkt_out,
 			   vif->flags, vif->local, vif->remote);
@@ -2302,8 +2374,6 @@ static void ipmr_mfc_seq_stop(struct seq
 
 static int ipmr_mfc_seq_show(struct seq_file *seq, void *v)
 {
-	int n;
-
 	if (v == SEQ_START_TOKEN) {
 		seq_puts(seq,
 		 "Group    Origin   Iif     Pkts    Bytes    Wrong Oifs\n");
@@ -2315,20 +2385,21 @@ static int ipmr_mfc_seq_show(struct seq_
 		seq_printf(seq, "%08X %08X %-3hd",
 			   (__force u32) mfc->mfc_mcastgrp,
 			   (__force u32) mfc->mfc_origin,
-			   mfc->mfc_parent);
+			   mfc->mfc_parent ? mfc->mfc_parent->index : -1);
 
 		if (it->cache != &mrt->mfc_unres_queue) {
+			int i;
+
 			seq_printf(seq, " %8lu %8lu %8lu",
 				   mfc->mfc_un.res.pkt,
 				   mfc->mfc_un.res.bytes,
 				   mfc->mfc_un.res.wrong_if);
-			for (n = mfc->mfc_un.res.minvif;
-			     n < mfc->mfc_un.res.maxvif; n++ ) {
-				if (VIF_EXISTS(mrt, n) &&
-				    mfc->mfc_un.res.ttls[n] < 255)
-					seq_printf(seq,
-					   " %2d:%-3d",
-					   n, mfc->mfc_un.res.ttls[n]);
+			for (i = 0; i < mfc->mfc_un.res.output_dev_count; ++i) {
+				struct vif_device *x = mfc->mfc_un.res.output_devs[i];
+				if (x) {
+					seq_printf(seq, " %2d:%-3d",
+						   x->index, x->threshold);
+				}
 			}
 		} else {
 			/* unresolved mfc_caches don't contain
@@ -2389,6 +2460,7 @@ static int __net_init ipmr_net_init(stru
 	if (!proc_net_fops_create(net, "ip_mr_cache", 0, &ipmr_mfc_fops))
 		goto proc_cache_fail;
 #endif
+fail:
 	return 0;
 
 #ifdef CONFIG_PROC_FS
@@ -2397,7 +2469,6 @@ proc_cache_fail:
 proc_vif_fail:
 	ipmr_rules_exit(net);
 #endif
-fail:
 	return err;
 }
 
diff -puNrb linux-2.6.35/net/ipv4/ip_output.c linux/net/ipv4/ip_output.c
--- linux-2.6.35/net/ipv4/ip_output.c	2011-04-26 16:26:07.172523939 +0300
+++ linux/net/ipv4/ip_output.c	2011-05-02 10:08:29.711591017 +0300
@@ -167,7 +167,7 @@ int ip_build_and_send_pkt(struct sk_buff
 	}
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 
 	/* Send it out. */
 	return ip_local_out(skb);
@@ -187,6 +187,13 @@ static inline int ip_finish_output2(stru
 	} else if (rt->rt_type == RTN_BROADCAST)
 		IP_UPD_PO_STATS(dev_net(dev), IPSTATS_MIB_OUTBCAST, skb->len);
 
+	if (dst->child) {
+		struct dst_entry *child = dst_clone(dst->child);
+		skb_dst_drop(skb);
+		skb_dst_set(skb, child);
+		return dst_output(skb);
+	}
+
 	/* Be paranoid, rather than too clever. */
 	if (unlikely(skb_headroom(skb) < hh_len && dev->header_ops)) {
 		struct sk_buff *skb2;
@@ -391,7 +398,7 @@ packet_routed:
 			     (skb_shinfo(skb)->gso_segs ?: 1) - 1);
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 
 	res = ip_local_out(skb);
 	rcu_read_unlock();
@@ -414,6 +421,8 @@ static void ip_copy_metadata(struct sk_b
 	skb_dst_set(to, dst_clone(skb_dst(from)));
 	to->dev = from->dev;
 	to->mark = from->mark;
+	to->prmark = from->prmark;
+	to->hsmark = from->hsmark;
 
 	/* Copy the flags to each fragment. */
 	IPCB(to)->flags = IPCB(from)->flags;
@@ -1305,7 +1314,7 @@ int ip_push_pending_frames(struct sock *
 	iph->daddr = rt->rt_dst;
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 	/*
 	 * Steal rt from cork.dst to avoid a pair of atomic_inc/atomic_dec
 	 * on dst refcount
@@ -1452,3 +1461,7 @@ void __init ip_init(void)
 EXPORT_SYMBOL(ip_generic_getfrag);
 EXPORT_SYMBOL(ip_queue_xmit);
 EXPORT_SYMBOL(ip_send_check);
+
+#ifdef CONFIG_SYSCTL
+EXPORT_SYMBOL(sysctl_ip_default_ttl);
+#endif
diff -puNrb linux-2.6.35/net/ipv4/ip_sockglue.c linux/net/ipv4/ip_sockglue.c
--- linux-2.6.35/net/ipv4/ip_sockglue.c	2011-04-26 16:26:07.192511828 +0300
+++ linux/net/ipv4/ip_sockglue.c	2011-05-02 10:08:29.721591676 +0300
@@ -554,7 +554,7 @@ static int do_ip_setsockopt(struct sock 
 		}
 		if (inet->tos != val) {
 			inet->tos = val;
-			sk->sk_priority = rt_tos2priority(val);
+			/* sk->sk_priority = rt_tos2priority(val); */
 			sk_dst_reset(sk);
 		}
 		break;
diff -puNrb linux-2.6.35/net/ipv4/netfilter/iptable_mangle.c linux/net/ipv4/netfilter/iptable_mangle.c
--- linux-2.6.35/net/ipv4/netfilter/iptable_mangle.c	2011-04-26 16:26:06.652169597 +0300
+++ linux/net/ipv4/netfilter/iptable_mangle.c	2011-05-02 10:08:29.731545079 +0300
@@ -43,7 +43,7 @@ ipt_mangle_out(struct sk_buff *skb, cons
 	const struct iphdr *iph;
 	u_int8_t tos;
 	__be32 saddr, daddr;
-	u_int32_t mark;
+	u_int32_t prmark;
 
 	/* root is playing with raw sockets. */
 	if (skb->len < sizeof(struct iphdr) ||
@@ -51,7 +51,7 @@ ipt_mangle_out(struct sk_buff *skb, cons
 		return NF_ACCEPT;
 
 	/* Save things which could affect route */
-	mark = skb->mark;
+	prmark = skb->prmark;
 	iph = ip_hdr(skb);
 	saddr = iph->saddr;
 	daddr = iph->daddr;
@@ -65,7 +65,7 @@ ipt_mangle_out(struct sk_buff *skb, cons
 
 		if (iph->saddr != saddr ||
 		    iph->daddr != daddr ||
-		    skb->mark != mark ||
+		    skb->prmark != prmark ||
 		    iph->tos != tos)
 			if (ip_route_me_harder(skb, RTN_UNSPEC))
 				ret = NF_DROP;
diff -puNrb linux-2.6.35/net/ipv4/netfilter/ipt_IMQ.c linux/net/ipv4/netfilter/ipt_IMQ.c
--- linux-2.6.35/net/ipv4/netfilter/ipt_IMQ.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/net/ipv4/netfilter/ipt_IMQ.c	2011-05-02 10:08:29.751589603 +0300
@@ -0,0 +1,80 @@
+/*
+ * This target marks packets to be enqueued to an imq device
+ */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/netfilter_ipv4/ipt_IMQ.h>
+#include <linux/imq.h>
+
+static unsigned int imq_target(struct sk_buff **pskb,
+                              const struct net_device *in,
+                              const struct net_device *out,
+                              unsigned int hooknum,
+                              const void *targinfo,
+                              void *userdata)
+{
+       struct ipt_imq_info *mr = (struct ipt_imq_info*)targinfo;
+
+       (*pskb)->imq_flags = mr->todev | IMQ_F_ENQUEUE;
+
+       return IPT_CONTINUE;
+}
+
+static int imq_checkentry(const char *tablename,
+                         const struct ipt_entry *e,
+                         void *targinfo,
+                         unsigned int targinfosize,
+                         unsigned int hook_mask)
+{
+       struct ipt_imq_info *mr;
+
+       if (targinfosize != IPT_ALIGN(sizeof(struct ipt_imq_info))) {
+               printk(KERN_WARNING "IMQ: invalid targinfosize\n");
+               return 0;
+       }
+       mr = (struct ipt_imq_info*)targinfo;
+
+       if (strcmp(tablename, "mangle") != 0) {
+               printk(KERN_WARNING
+                      "IMQ: IMQ can only be called from \"mangle\" table, not \"%s\"\n",
+                      tablename);
+               return 0;
+       }
+
+       if (mr->todev > IMQ_MAX_DEVS) {
+               printk(KERN_WARNING
+                      "IMQ: invalid device specified, highest is %u\n",
+                      IMQ_MAX_DEVS);
+               return 0;
+       }
+
+       return 1;
+}
+
+static struct ipt_target ipt_imq_reg = {
+       .name           = "IMQ",
+       .target         = imq_target,
+       .checkentry     = imq_checkentry,
+       .me             = THIS_MODULE
+};
+
+static int __init init(void)
+{
+       if (ipt_register_target(&ipt_imq_reg))
+               return -EINVAL;
+
+       return 0;
+}
+
+static void __exit fini(void)
+{
+       ipt_unregister_target(&ipt_imq_reg);
+}
+
+module_init(init);
+module_exit(fini);
+
+MODULE_AUTHOR("http://www.linuximq.net");
+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
+MODULE_LICENSE("GPL");
diff -puNrb linux-2.6.35/net/ipv4/netfilter/Kconfig linux/net/ipv4/netfilter/Kconfig
--- linux-2.6.35/net/ipv4/netfilter/Kconfig	2011-04-26 16:26:06.642169352 +0300
+++ linux/net/ipv4/netfilter/Kconfig	2011-05-02 10:08:29.761591683 +0300
@@ -123,6 +123,17 @@ config IP_NF_TARGET_REJECT
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config IP_NF_TARGET_IMQ
+       tristate "IMQ target support"
+       depends on IP_NF_MANGLE
+       help
+         This option adds a `IMQ' target which is used to specify if and
+         to which IMQ device packets should get enqueued/dequeued.
+
+	 For more information visit: http://www.linuximq.net/
+
+         To compile it as a module, choose M here.  If unsure, say N.
+
 config IP_NF_TARGET_LOG
 	tristate "LOG target support"
 	default m if NETFILTER_ADVANCED=n
diff -puNrb linux-2.6.35/net/ipv4/netfilter/Makefile linux/net/ipv4/netfilter/Makefile
--- linux-2.6.35/net/ipv4/netfilter/Makefile	2011-04-26 16:26:06.642169352 +0300
+++ linux/net/ipv4/netfilter/Makefile	2011-05-02 10:08:29.771586636 +0300
@@ -55,6 +55,7 @@ obj-$(CONFIG_IP_NF_MATCH_ECN) += ipt_ecn
 # targets
 obj-$(CONFIG_IP_NF_TARGET_CLUSTERIP) += ipt_CLUSTERIP.o
 obj-$(CONFIG_IP_NF_TARGET_ECN) += ipt_ECN.o
+obj-$(CONFIG_IP_NF_TARGET_IMQ) += ipt_IMQ.o
 obj-$(CONFIG_IP_NF_TARGET_LOG) += ipt_LOG.o
 obj-$(CONFIG_IP_NF_TARGET_MASQUERADE) += ipt_MASQUERADE.o
 obj-$(CONFIG_IP_NF_TARGET_NETMAP) += ipt_NETMAP.o
diff -puNrb linux-2.6.35/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c linux/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c
--- linux-2.6.35/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2011-04-26 16:26:06.642169352 +0300
+++ linux/net/ipv4/netfilter/nf_conntrack_l3proto_ipv4.c	2011-05-02 10:08:29.801590703 +0300
@@ -7,6 +7,7 @@
  * published by the Free Software Foundation.
  */
 
+#include <asm/unaligned.h>
 #include <linux/types.h>
 #include <linux/ip.h>
 #include <linux/netfilter.h>
@@ -44,8 +45,8 @@ static bool ipv4_pkt_to_tuple(const stru
 	if (ap == NULL)
 		return false;
 
-	tuple->src.u3.ip = ap[0];
-	tuple->dst.u3.ip = ap[1];
+	tuple->src.u3.ip = get_unaligned(&ap[0]);
+	tuple->dst.u3.ip = get_unaligned(&ap[1]);
 
 	return true;
 }
diff -puNrb linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_gre.c linux/net/ipv4/netfilter/nf_nat_proto_gre.c
--- linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_gre.c	2011-04-26 16:26:06.652169597 +0300
+++ linux/net/ipv4/netfilter/nf_nat_proto_gre.c	2011-05-02 10:08:29.811277308 +0300
@@ -23,6 +23,7 @@
  *
  */
 
+#include <asm/unaligned.h>
 #include <linux/module.h>
 #include <linux/skbuff.h>
 #include <linux/ip.h>
diff -puNrb linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_tcp.c linux/net/ipv4/netfilter/nf_nat_proto_tcp.c
--- linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_tcp.c	2011-04-26 16:26:06.642169352 +0300
+++ linux/net/ipv4/netfilter/nf_nat_proto_tcp.c	2011-05-02 10:08:29.841591026 +0300
@@ -17,6 +17,7 @@
 #include <net/netfilter/nf_nat_rule.h>
 #include <net/netfilter/nf_nat_protocol.h>
 #include <net/netfilter/nf_nat_core.h>
+#include <asm/unaligned.h>
 
 static u_int16_t tcp_port_rover;
 
@@ -69,8 +70,8 @@ tcp_manip_pkt(struct sk_buff *skb,
 		portptr = &hdr->dest;
 	}
 
-	oldport = *portptr;
-	*portptr = newport;
+	oldport = get_unaligned(portptr);
+	put_unaligned(newport, portptr);
 
 	if (hdrsize < sizeof(*hdr))
 		return true;
diff -puNrb linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_udp.c linux/net/ipv4/netfilter/nf_nat_proto_udp.c
--- linux-2.6.35/net/ipv4/netfilter/nf_nat_proto_udp.c	2011-04-26 16:26:06.642169352 +0300
+++ linux/net/ipv4/netfilter/nf_nat_proto_udp.c	2011-05-02 10:08:29.851588983 +0300
@@ -16,6 +16,7 @@
 #include <net/netfilter/nf_nat_core.h>
 #include <net/netfilter/nf_nat_rule.h>
 #include <net/netfilter/nf_nat_protocol.h>
+#include <asm/unaligned.h>
 
 static u_int16_t udp_port_rover;
 
@@ -62,12 +63,12 @@ udp_manip_pkt(struct sk_buff *skb,
 	}
 	if (hdr->check || skb->ip_summed == CHECKSUM_PARTIAL) {
 		inet_proto_csum_replace4(&hdr->check, skb, oldip, newip, 1);
-		inet_proto_csum_replace2(&hdr->check, skb, *portptr, newport,
-					 0);
+		inet_proto_csum_replace2(
+		    &hdr->check, skb, get_unaligned(portptr), newport, 0);
 		if (!hdr->check)
 			hdr->check = CSUM_MANGLED_0;
 	}
-	*portptr = newport;
+	put_unaligned(newport, portptr);
 	return true;
 }
 
diff -puNrb linux-2.6.35/net/ipv4/netfilter.c linux/net/ipv4/netfilter.c
--- linux-2.6.35/net/ipv4/netfilter.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/netfilter.c	2011-05-02 10:08:29.861544917 +0300
@@ -36,7 +36,7 @@ int ip_route_me_harder(struct sk_buff *s
 			fl.nl_u.ip4_u.saddr = iph->saddr;
 		fl.nl_u.ip4_u.tos = RT_TOS(iph->tos);
 		fl.oif = skb->sk ? skb->sk->sk_bound_dev_if : 0;
-		fl.mark = skb->mark;
+		fl.mark = skb->prmark;
 		fl.flags = skb->sk ? inet_sk_flowi_flags(skb->sk) : 0;
 		if (ip_route_output_key(net, &rt, &fl) != 0)
 			return -1;
diff -puNrb linux-2.6.35/net/ipv4/raw.c linux/net/ipv4/raw.c
--- linux-2.6.35/net/ipv4/raw.c	2011-04-26 16:26:07.172523939 +0300
+++ linux/net/ipv4/raw.c	2011-05-02 10:08:29.871544956 +0300
@@ -340,7 +340,7 @@ static int raw_send_hdrinc(struct sock *
 	skb_reserve(skb, LL_RESERVED_SPACE(rt->u.dst.dev));
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 	skb_dst_set(skb, dst_clone(&rt->u.dst));
 
 	skb_reset_network_header(skb);
diff -puNrb linux-2.6.35/net/ipv4/route.c linux/net/ipv4/route.c
--- linux-2.6.35/net/ipv4/route.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/route.c	2011-05-02 10:08:29.891591633 +0300
@@ -910,6 +910,7 @@ void rt_cache_flush(struct net *net, int
 	if (delay >= 0)
 		rt_do_flush(!in_softirq());
 }
+EXPORT_SYMBOL(rt_cache_flush);
 
 /* Flush previous cache invalidated entries from the cache */
 void rt_cache_flush_batch(void)
@@ -1802,6 +1803,9 @@ static void set_class_tag(struct rtable 
 }
 #endif
 
+int (*mpls_rt_hook)(__u32, struct dst_entry *) = NULL;
+EXPORT_SYMBOL(mpls_rt_hook);
+
 static void rt_set_nexthop(struct rtable *rt, struct fib_result *res, u32 itag)
 {
 	struct fib_info *fi = res->fi;
@@ -1812,7 +1816,13 @@ static void rt_set_nexthop(struct rtable
 			rt->rt_gateway = FIB_RES_GW(*res);
 		memcpy(rt->u.dst.metrics, fi->fib_metrics,
 		       sizeof(rt->u.dst.metrics));
-		if (fi->fib_mtu == 0) {
+
+		if (FIB_RES_NH(*res).nh_mplskey && mpls_rt_hook) {
+			(*mpls_rt_hook)(FIB_RES_NH(*res).nh_mplskey,
+					&rt->u.dst);
+		}
+
+		if (rt->u.dst.metrics[RTAX_MTU-1] == 0) {
 			rt->u.dst.metrics[RTAX_MTU-1] = rt->u.dst.dev->mtu;
 			if (dst_metric_locked(&rt->u.dst, RTAX_MTU) &&
 			    rt->rt_gateway != rt->rt_dst &&
@@ -1884,7 +1894,7 @@ static int ip_route_input_mc(struct sk_b
 	rth->fl.fl4_dst	= daddr;
 	rth->rt_dst	= daddr;
 	rth->fl.fl4_tos	= tos;
-	rth->fl.mark    = skb->mark;
+	rth->fl.mark    = skb->prmark;
 	rth->fl.fl4_src	= saddr;
 	rth->rt_src	= saddr;
 #ifdef CONFIG_NET_CLS_ROUTE
@@ -2029,7 +2039,7 @@ static int __mkroute_input(struct sk_buf
 	rth->fl.fl4_dst	= daddr;
 	rth->rt_dst	= daddr;
 	rth->fl.fl4_tos	= tos;
-	rth->fl.mark    = skb->mark;
+	rth->fl.mark    = skb->prmark;
 	rth->fl.fl4_src	= saddr;
 	rth->rt_src	= saddr;
 	rth->rt_gateway	= daddr;
@@ -2105,7 +2115,7 @@ static int ip_route_input_slow(struct sk
 					.tos = tos,
 					.scope = RT_SCOPE_UNIVERSE,
 				      } },
-			    .mark = skb->mark,
+			    .mark = skb->prmark,
 			    .iif = dev->ifindex };
 	unsigned	flags = 0;
 	u32		itag = 0;
@@ -2216,7 +2226,7 @@ local_input:
 	rth->fl.fl4_dst	= daddr;
 	rth->rt_dst	= daddr;
 	rth->fl.fl4_tos	= tos;
-	rth->fl.mark    = skb->mark;
+	rth->fl.mark    = skb->prmark;
 	rth->fl.fl4_src	= saddr;
 	rth->rt_src	= saddr;
 #ifdef CONFIG_NET_CLS_ROUTE
@@ -2301,7 +2311,7 @@ int ip_route_input_common(struct sk_buff
 		     (rth->fl.iif ^ iif) |
 		     rth->fl.oif |
 		     (rth->fl.fl4_tos ^ tos)) == 0 &&
-		    rth->fl.mark == skb->mark &&
+		    rth->fl.mark == skb->prmark &&
 		    net_eq(dev_net(rth->u.dst.dev), net) &&
 		    !rt_is_expired(rth)) {
 			if (noref) {
diff -puNrb linux-2.6.35/net/ipv4/sysctl_net_ipv4.c linux/net/ipv4/sysctl_net_ipv4.c
--- linux-2.6.35/net/ipv4/sysctl_net_ipv4.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/sysctl_net_ipv4.c	2011-05-02 10:08:29.901592113 +0300
@@ -22,6 +22,9 @@
 #include <net/cipso_ipv4.h>
 #include <net/inet_frag.h>
 
+/* From fib_frontend.c */
+extern int sysctl_kernel_adds_connected_routes;
+
 static int zero;
 static int tcp_retr1_max = 255;
 static int ip_local_port_range_min[] = { 1, 1 };
@@ -577,6 +580,13 @@ static struct ctl_table ipv4_table[] = {
 		.proc_handler	= proc_dointvec,
 	},
 	{
+		.procname	= "kernel_adds_connected_routes",
+		.data		= &sysctl_kernel_adds_connected_routes,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec,
+	},
+	{
 		.procname	= "tcp_cookie_size",
 		.data		= &sysctl_tcp_cookie_size,
 		.maxlen		= sizeof(int),
diff -puNrb linux-2.6.35/net/ipv4/tcp_input.c linux/net/ipv4/tcp_input.c
--- linux-2.6.35/net/ipv4/tcp_input.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/tcp_input.c	2011-05-02 10:08:29.931593146 +0300
@@ -3863,13 +3863,13 @@ static int tcp_parse_aligned_timestamp(s
 {
 	__be32 *ptr = (__be32 *)(th + 1);
 
-	if (*ptr == htonl((TCPOPT_NOP << 24) | (TCPOPT_NOP << 16)
+	if (get_unaligned_be32(ptr) == htonl((TCPOPT_NOP << 24) | (TCPOPT_NOP << 16)
 			  | (TCPOPT_TIMESTAMP << 8) | TCPOLEN_TIMESTAMP)) {
 		tp->rx_opt.saw_tstamp = 1;
 		++ptr;
-		tp->rx_opt.rcv_tsval = ntohl(*ptr);
+		tp->rx_opt.rcv_tsval = ntohl(get_unaligned(ptr));
 		++ptr;
-		tp->rx_opt.rcv_tsecr = ntohl(*ptr);
+		tp->rx_opt.rcv_tsecr = ntohl(get_unaligned(ptr));
 		return 1;
 	}
 	return 0;
diff -puNrb linux-2.6.35/net/ipv4/xfrm4_output.c linux/net/ipv4/xfrm4_output.c
--- linux-2.6.35/net/ipv4/xfrm4_output.c	2011-04-26 16:26:07.161365424 +0300
+++ linux/net/ipv4/xfrm4_output.c	2011-05-02 10:08:29.941545148 +0300
@@ -86,6 +86,7 @@ static int xfrm4_output_finish(struct sk
 
 int xfrm4_output(struct sk_buff *skb)
 {
+	skb->dev = skb_dst(skb)->dev;
 	return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb,
 			    NULL, skb_dst(skb)->dev, xfrm4_output_finish,
 			    !(IPCB(skb)->flags & IPSKB_REROUTED));
diff -puNrb linux-2.6.35/net/ipv4/xfrm4_policy.c linux/net/ipv4/xfrm4_policy.c
--- linux-2.6.35/net/ipv4/xfrm4_policy.c	2011-04-26 16:26:07.182507531 +0300
+++ linux/net/ipv4/xfrm4_policy.c	2011-05-02 10:08:29.951595519 +0300
@@ -14,6 +14,7 @@
 #include <net/dst.h>
 #include <net/xfrm.h>
 #include <net/ip.h>
+#include <asm/unaligned.h>
 
 static struct xfrm_policy_afinfo xfrm4_policy_afinfo;
 
@@ -121,8 +122,10 @@ _decode_session4(struct sk_buff *skb, st
 			    pskb_may_pull(skb, xprth + 4 - skb->data)) {
 				__be16 *ports = (__be16 *)xprth;
 
-				fl->fl_ip_sport = ports[!!reverse];
-				fl->fl_ip_dport = ports[!reverse];
+				fl->fl_ip_sport =
+				    get_unaligned(ports + !!reverse);
+				fl->fl_ip_dport =
+				    get_unaligned(ports + !reverse);
 			}
 			break;
 
@@ -139,7 +142,7 @@ _decode_session4(struct sk_buff *skb, st
 			if (pskb_may_pull(skb, xprth + 4 - skb->data)) {
 				__be32 *ehdr = (__be32 *)xprth;
 
-				fl->fl_ipsec_spi = ehdr[0];
+				fl->fl_ipsec_spi = get_unaligned(ehdr + 0);
 			}
 			break;
 
@@ -147,7 +150,7 @@ _decode_session4(struct sk_buff *skb, st
 			if (pskb_may_pull(skb, xprth + 8 - skb->data)) {
 				__be32 *ah_hdr = (__be32*)xprth;
 
-				fl->fl_ipsec_spi = ah_hdr[1];
+				fl->fl_ipsec_spi = get_unaligned(ah_hdr + 1);
 			}
 			break;
 
@@ -155,7 +158,8 @@ _decode_session4(struct sk_buff *skb, st
 			if (pskb_may_pull(skb, xprth + 4 - skb->data)) {
 				__be16 *ipcomp_hdr = (__be16 *)xprth;
 
-				fl->fl_ipsec_spi = htonl(ntohs(ipcomp_hdr[1]));
+				fl->fl_ipsec_spi =
+				    htonl(ntohs(get_unaligned(ipcomp_hdr + 1)));
 			}
 			break;
 		default:
diff -puNrb linux-2.6.35/net/ipv6/addrconf.c linux/net/ipv6/addrconf.c
--- linux-2.6.35/net/ipv6/addrconf.c	2011-04-26 16:26:07.642477548 +0300
+++ linux/net/ipv6/addrconf.c	2011-05-02 10:08:29.971589678 +0300
@@ -236,6 +236,8 @@ const struct in6_addr in6addr_loopback =
 const struct in6_addr in6addr_linklocal_allnodes = IN6ADDR_LINKLOCAL_ALLNODES_INIT;
 const struct in6_addr in6addr_linklocal_allrouters = IN6ADDR_LINKLOCAL_ALLROUTERS_INIT;
 
+static unsigned char zero_macaddr[ETH_ALEN];
+
 /* Check if a valid qdisc is available */
 static inline bool addrconf_qdisc_ok(const struct net_device *dev)
 {
@@ -2165,8 +2167,10 @@ static int inet6_addr_add(struct net *ne
 		ifp->tstamp = jiffies;
 		spin_unlock_bh(&ifp->lock);
 
+		if (0 /*sysctl_kernel_adds_connected_routes*/) {   
 		addrconf_prefix_route(&ifp->addr, ifp->prefix_len, dev,
 				      expires, flags);
+		}
 		/*
 		 * Note that section 3.1 of RFC 4429 indicates
 		 * that the Optimistic flag should not be set for
@@ -2384,6 +2388,10 @@ static void addrconf_dev_config(struct n
 	if (IS_ERR(idev))
 		return;
 
+        /* do not generate the link-local address if interface has zero mac address */
+        if (!memcmp(dev->dev_addr, zero_macaddr, ETH_ALEN))
+		return;
+
 	memset(&addr, 0, sizeof(struct in6_addr));
 	addr.s6_addr32[0] = htonl(0xFE800000);
 
@@ -2486,6 +2494,7 @@ static int addrconf_notify(struct notifi
 	struct inet6_dev *idev = __in6_dev_get(dev);
 	int run_pending = 0;
 	int err;
+	struct in6_addr addr_buf;
 
 	switch (event) {
 	case NETDEV_REGISTER:
@@ -2583,6 +2592,14 @@ static int addrconf_notify(struct notifi
 		}
 		break;
 
+	case NETDEV_CHANGEADDR:
+		/* if there is idev, but no link-local address, try to create one. */
+		if (idev && (idev->if_flags & IF_READY)
+			&& ipv6_get_lladdr(dev, &addr_buf, 0) != 0) {
+			addrconf_dev_config(dev);
+		}
+		break;
+
 	case NETDEV_CHANGEMTU:
 		if (idev && dev->mtu >= IPV6_MIN_MTU) {
 			rt6_mtu_change(dev, dev->mtu);
diff -puNrb linux-2.6.35/net/ipv6/ip6_output.c linux/net/ipv6/ip6_output.c
--- linux-2.6.35/net/ipv6/ip6_output.c	2011-04-26 16:26:07.632484261 +0300
+++ linux/net/ipv6/ip6_output.c	2011-05-02 10:08:29.991588712 +0300
@@ -248,7 +248,7 @@ int ip6_xmit(struct sock *sk, struct sk_
 	ipv6_addr_copy(&hdr->daddr, first_hop);
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 
 	mtu = dst_mtu(dst);
 	if ((skb->len <= mtu) || skb->local_df || skb_is_gso(skb)) {
@@ -1501,7 +1501,7 @@ int ip6_push_pending_frames(struct sock 
 	ipv6_addr_copy(&hdr->daddr, final_dst);
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 
 	skb_dst_set(skb, dst_clone(&rt->u.dst));
 	IP6_UPD_PO_STATS(net, rt->rt6i_idev, IPSTATS_MIB_OUT, skb->len);
diff -puNrb linux-2.6.35/net/ipv6/netfilter/ip6table_mangle.c linux/net/ipv6/netfilter/ip6table_mangle.c
--- linux-2.6.35/net/ipv6/netfilter/ip6table_mangle.c	2011-04-26 16:26:07.312495715 +0300
+++ linux/net/ipv6/netfilter/ip6table_mangle.c	2011-05-02 10:08:30.001589671 +0300
@@ -36,7 +36,7 @@ ip6t_mangle_out(struct sk_buff *skb, con
 	unsigned int ret;
 	struct in6_addr saddr, daddr;
 	u_int8_t hop_limit;
-	u_int32_t flowlabel, mark;
+	u_int32_t flowlabel, prmark;
 
 #if 0
 	/* root is playing with raw sockets. */
@@ -48,10 +48,10 @@ ip6t_mangle_out(struct sk_buff *skb, con
 	}
 #endif
 
-	/* save source/dest address, mark, hoplimit, flowlabel, priority,  */
+	/* save source/dest address, prmark, hoplimit, flowlabel, priority,  */
 	memcpy(&saddr, &ipv6_hdr(skb)->saddr, sizeof(saddr));
 	memcpy(&daddr, &ipv6_hdr(skb)->daddr, sizeof(daddr));
-	mark = skb->mark;
+	prmark = skb->prmark;
 	hop_limit = ipv6_hdr(skb)->hop_limit;
 
 	/* flowlabel and prio (includes version, which shouldn't change either */
@@ -63,7 +63,7 @@ ip6t_mangle_out(struct sk_buff *skb, con
 	if (ret != NF_DROP && ret != NF_STOLEN &&
 	    (memcmp(&ipv6_hdr(skb)->saddr, &saddr, sizeof(saddr)) ||
 	     memcmp(&ipv6_hdr(skb)->daddr, &daddr, sizeof(daddr)) ||
-	     skb->mark != mark ||
+	     skb->prmark != prmark ||
 	     ipv6_hdr(skb)->hop_limit != hop_limit))
 		return ip6_route_me_harder(skb) == 0 ? ret : NF_DROP;
 
diff -puNrb linux-2.6.35/net/ipv6/netfilter/ip6t_IMQ.c linux/net/ipv6/netfilter/ip6t_IMQ.c
--- linux-2.6.35/net/ipv6/netfilter/ip6t_IMQ.c	1970-01-01 03:00:00.000000000 +0300
+++ linux/net/ipv6/netfilter/ip6t_IMQ.c	2011-05-02 10:08:30.011593258 +0300
@@ -0,0 +1,80 @@
+/*
+ * This target marks packets to be enqueued to an imq device
+ */
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter_ipv6/ip6_tables.h>
+#include <linux/netfilter_ipv6/ip6t_IMQ.h>
+#include <linux/imq.h>
+
+static unsigned int imq_target(struct sk_buff **pskb,
+                              unsigned int hooknum,
+                              const struct net_device *in,
+                              const struct net_device *out,
+                              const void *targinfo,
+                              void *userdata)
+{
+       struct ip6t_imq_info *mr = (struct ip6t_imq_info*)targinfo;
+
+       (*pskb)->imq_flags = mr->todev | IMQ_F_ENQUEUE;
+
+       return IP6T_CONTINUE;
+}
+
+static int imq_checkentry(const char *tablename,
+                         const struct ip6t_entry *e,
+                         void *targinfo,
+                         unsigned int targinfosize,
+                         unsigned int hook_mask)
+{
+       struct ip6t_imq_info *mr;
+
+       if (targinfosize != IP6T_ALIGN(sizeof(struct ip6t_imq_info))) {
+               printk(KERN_WARNING "IMQ: invalid targinfosize\n");
+               return 0;
+       }
+       mr = (struct ip6t_imq_info*)targinfo;
+
+       if (strcmp(tablename, "mangle") != 0) {
+               printk(KERN_WARNING
+                      "IMQ: IMQ can only be called from \"mangle\" table, not \"%s\"\n",
+                      tablename);
+               return 0;
+       }
+
+       if (mr->todev > IMQ_MAX_DEVS) {
+               printk(KERN_WARNING
+                      "IMQ: invalid device specified, highest is %u\n",
+                      IMQ_MAX_DEVS);
+               return 0;
+       }
+
+       return 1;
+}
+
+static struct ip6t_target ip6t_imq_reg = {
+       .name           = "IMQ",
+       .target         = imq_target,
+       .checkentry     = imq_checkentry,
+       .me             = THIS_MODULE
+};
+
+static int __init init(void)
+{
+       if (ip6t_register_target(&ip6t_imq_reg))
+               return -EINVAL;
+
+       return 0;
+}
+
+static void __exit fini(void)
+{
+       ip6t_unregister_target(&ip6t_imq_reg);
+}
+
+module_init(init);
+module_exit(fini);
+
+MODULE_AUTHOR("http://www.linuximq.net");
+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
+MODULE_LICENSE("GPL");
diff -puNrb linux-2.6.35/net/ipv6/netfilter/Kconfig linux/net/ipv6/netfilter/Kconfig
--- linux-2.6.35/net/ipv6/netfilter/Kconfig	2011-04-26 16:26:07.302483171 +0300
+++ linux/net/ipv6/netfilter/Kconfig	2011-05-02 10:08:30.021544216 +0300
@@ -158,6 +158,25 @@ config IP6_NF_FILTER
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config IP6_NF_TARGET_IMQ
+	tristate "IMQ target support"
+	depends on IP6_NF_MANGLE
+	help
+          This option adds a `IMQ' target which is used to specify if and
+          to which imq device packets should get enqueued/dequeued.
+
+          To compile it as a module, choose M here.  If unsure, say N.
+
+config IP6_NF_TARGET_LOG
+	tristate "LOG target support"
+	depends on IP6_NF_FILTER
+	default m if NETFILTER_ADVANCED=n
+	help
+	  This option adds a `LOG' target, which allows you to create rules in
+	  any iptables table which records the packet header to the syslog.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config IP6_NF_TARGET_REJECT
 	tristate "REJECT target support"
 	depends on IP6_NF_FILTER
diff -puNrb linux-2.6.35/net/ipv6/netfilter/Makefile linux/net/ipv6/netfilter/Makefile
--- linux-2.6.35/net/ipv6/netfilter/Makefile	2011-04-26 16:26:07.312495715 +0300
+++ linux/net/ipv6/netfilter/Makefile	2011-05-02 10:08:30.041590984 +0300
@@ -6,6 +6,7 @@
 obj-$(CONFIG_IP6_NF_IPTABLES) += ip6_tables.o
 obj-$(CONFIG_IP6_NF_FILTER) += ip6table_filter.o
 obj-$(CONFIG_IP6_NF_MANGLE) += ip6table_mangle.o
+obj-$(CONFIG_IP6_NF_TARGET_IMQ) += ip6t_IMQ.o
 obj-$(CONFIG_IP6_NF_QUEUE) += ip6_queue.o
 obj-$(CONFIG_IP6_NF_RAW) += ip6table_raw.o
 obj-$(CONFIG_IP6_NF_SECURITY) += ip6table_security.o
diff -puNrb linux-2.6.35/net/ipv6/raw.c linux/net/ipv6/raw.c
--- linux-2.6.35/net/ipv6/raw.c	2011-04-26 16:26:07.652529581 +0300
+++ linux/net/ipv6/raw.c	2011-05-02 10:08:30.051587026 +0300
@@ -625,7 +625,7 @@ static int rawv6_send_hdrinc(struct sock
 	skb_reserve(skb, LL_RESERVED_SPACE(rt->u.dst.dev));
 
 	skb->priority = sk->sk_priority;
-	skb->mark = sk->sk_mark;
+	skb->prmark = sk->sk_mark;
 	skb_dst_set(skb, dst_clone(&rt->u.dst));
 
 	skb_put(skb, length);
diff -puNrb linux-2.6.35/net/ipv6/route.c linux/net/ipv6/route.c
--- linux-2.6.35/net/ipv6/route.c	2011-04-26 16:26:07.642477548 +0300
+++ linux/net/ipv6/route.c	2011-05-02 10:08:30.061593631 +0300
@@ -56,6 +56,7 @@
 #include <net/netlink.h>
 
 #include <asm/uaccess.h>
+#include <asm/unaligned.h>
 
 #ifdef CONFIG_SYSCTL
 #include <linux/sysctl.h>
@@ -790,7 +791,7 @@ void ip6_route_input(struct sk_buff *skb
 			.ip6_u = {
 				.daddr = iph->daddr,
 				.saddr = iph->saddr,
-				.flowlabel = (* (__be32 *) iph)&IPV6_FLOWINFO_MASK,
+				.flowlabel = get_unaligned((__be32 *) iph)&IPV6_FLOWINFO_MASK,
 			},
 		},
 		.mark = skb->mark,
diff -puNrb linux-2.6.35/net/Kconfig linux/net/Kconfig
--- linux-2.6.35/net/Kconfig	2011-04-26 16:26:09.432521556 +0300
+++ linux/net/Kconfig	2011-05-02 10:08:30.081606391 +0300
@@ -205,7 +205,7 @@ source "net/sched/Kconfig"
 source "net/dcb/Kconfig"
 
 config RPS
-	boolean
+	boolean "RPS"
 	depends on SMP && SYSFS
 	default y
 
diff -puNrb linux-2.6.35/net/netfilter/nf_conntrack_core.c linux/net/netfilter/nf_conntrack_core.c
--- linux-2.6.35/net/netfilter/nf_conntrack_core.c	2011-04-26 16:26:05.211561252 +0300
+++ linux/net/netfilter/nf_conntrack_core.c	2011-05-02 10:08:30.091586376 +0300
@@ -202,6 +202,8 @@ destroy_conntrack(struct nf_conntrack *n
 	 * too. */
 	nf_ct_remove_expectations(ct);
 
+	if(ct->layer7.data) kfree(ct->layer7.data);
+
 	/* We overload first tuple to link into unconfirmed list. */
 	if (!nf_ct_is_confirmed(ct)) {
 		BUG_ON(hlist_nulls_unhashed(&ct->tuplehash[IP_CT_DIR_ORIGINAL].hnnode));
@@ -285,6 +287,47 @@ static void death_by_timeout(unsigned lo
 	nf_ct_put(ct);
 }
 
+#define SECS *HZ
+#define MINS * 60 SECS
+#define HOURS * 60 MINS
+#define DAYS * 24 HOURS
+
+static inline unsigned long ct_max_timeout(struct nf_conn *ct)
+{
+	struct net *net = nf_ct_net(ct);
+	unsigned nth = nf_conntrack_max >> 4;
+	unsigned count = atomic_read(&net->ct.count);
+
+	if (count < nth) return 100 DAYS;
+	if (count < 3 * nth) return 1 DAYS;
+	if (count < 8 * nth) return 1 HOURS;
+	if (count < 13 * nth) return 10 MINS;
+	return 1 MINS;
+}
+
+static void ct_timeout(unsigned long ul_conntrack)
+{
+	struct nf_conn *ct = (void *)ul_conntrack;
+
+	spin_lock_bh(&nf_conntrack_lock);
+	if (ct->extra_timeout == 0) {
+		spin_unlock_bh(&nf_conntrack_lock);
+		death_by_timeout(ul_conntrack);
+	} else {
+	    unsigned extra_jiffies;
+	    unsigned long old_timeout = ct->extra_timeout;
+
+	    ct->extra_timeout = min(ct_max_timeout(ct), old_timeout);
+
+	    extra_jiffies = min(60u * HZ, ct->extra_timeout);
+	    ct->extra_timeout -= extra_jiffies;
+	    ct->timeout.expires = jiffies + extra_jiffies;
+	    add_timer(&ct->timeout);
+
+	    spin_unlock_bh(&nf_conntrack_lock);
+	}
+}
+
 /*
  * Warning :
  * - Caller must take a reference on returned object
@@ -585,15 +628,30 @@ struct nf_conn *nf_conntrack_alloc(struc
 
 	if (nf_conntrack_max &&
 	    unlikely(atomic_read(&net->ct.count) > nf_conntrack_max)) {
-		unsigned int hash = hash_conntrack(net, zone, orig);
-		if (!early_drop(net, hash)) {
+
+		/* Try dropping from random hash chains (hopefully old ones). */
+		unsigned i;
+
+		for (i = 0; i < 8; ++i) {
+			static unsigned int drop_next = 0;
+			unsigned int next = (drop_next++) % net->ct.htable_size;
+
+			while (hlist_nulls_empty(&net->ct.hash[next])) {
+				next = (drop_next++) % net->ct.htable_size;
+			}
+
+			if (early_drop(net, next)) goto dropped;
+		}
 			atomic_dec(&net->ct.count);
+
 			if (net_ratelimit())
 				printk(KERN_WARNING
 				       "nf_conntrack: table full, dropping"
 				       " packet.\n");
 			return ERR_PTR(-ENOMEM);
-		}
+
+	  dropped:
+		;
 	}
 
 	/*
@@ -618,7 +676,7 @@ struct nf_conn *nf_conntrack_alloc(struc
 	ct->tuplehash[IP_CT_DIR_REPLY].tuple = *repl;
 	ct->tuplehash[IP_CT_DIR_REPLY].hnnode.pprev = NULL;
 	/* Don't set timer yet: wait for confirmation */
-	setup_timer(&ct->timeout, death_by_timeout, (unsigned long)ct);
+	setup_timer(&ct->timeout, ct_timeout, (unsigned long)ct);
 #ifdef CONFIG_NET_NS
 	ct->ct_net = net;
 #endif
@@ -933,6 +991,77 @@ void nf_conntrack_alter_reply(struct nf_
 }
 EXPORT_SYMBOL_GPL(nf_conntrack_alter_reply);
 
+static void nf_conntrack_change_tuple_ip(struct nf_conntrack_tuple_hash *th,
+					 unsigned new_ip)
+{
+    struct nf_conn *ct = nf_ct_tuplehash_to_ctrack(th);
+    struct net *net = nf_ct_net(ct);
+    u16 zone = nf_ct_zone(ct);
+
+    /*
+     * userspace uses conntrack tuples to identify conntrack =>
+     * after conntrack tuple is changed, userspace will not be able to
+     * identify it anymore.
+     * To workaround this, we send IPCT_DESTROY on old conntrack,
+     * modify conntrack and send IPCT_NEW on this new one.
+     */
+    nf_conntrack_event(IPCT_DESTROY, ct);
+
+    th->tuple.src.u3.ip = new_ip;
+    hlist_nulls_del_rcu(&th->hnnode);
+    hlist_nulls_add_head_rcu(&th->hnnode,
+			     &net->ct.hash[hash_conntrack(net, zone, &th->tuple)]);
+    set_bit(IPS_SRC_NAT_BIT, &ct->status);
+
+    nf_conntrack_event(IPCT_NEW, ct);
+}
+
+/* Change source ip address of conntrack entry in use */
+void nf_conntrack_change_ip(unsigned old_ip, unsigned new_ip)
+{
+    struct hlist_nulls_head *hi;
+    struct hlist_nulls_head *hi_end;
+    struct nf_conntrack_tuple_hash *th;
+    struct hlist_nulls_node *n;
+    struct hlist_nulls_node *next;
+    struct hlist_nulls_head tlist;
+    struct net *net = &init_net;
+
+    INIT_HLIST_NULLS_HEAD(&tlist, 0);
+
+    printk(KERN_INFO "nf_conntrack_change_ip %u.%u.%u.%u -> %u.%u.%u.%u\n",
+	   NIPQUAD(old_ip), NIPQUAD(new_ip));
+    if (old_ip == 0 || new_ip == 0) return;
+
+    spin_lock_bh(&nf_conntrack_lock);
+    rcu_read_lock();
+
+    /* Traverse all hashed tuple entries */
+    hi_end = net->ct.hash + nf_conntrack_htable_size;
+    for (hi = net->ct.hash; hi < hi_end; ++hi) {
+	for (n = rcu_dereference(hi->first); !is_a_nulls(n); n = next) {
+	    next = rcu_dereference(n->next);
+	    th = hlist_nulls_entry(n, struct nf_conntrack_tuple_hash, hnnode);
+	    if (th->tuple.src.u3.ip == old_ip) {
+		hlist_nulls_del_rcu(&th->hnnode);
+		hlist_nulls_add_head_rcu(&th->hnnode, &tlist);
+	    }
+	}
+    }
+
+    /* process all matched tuples */
+    for (n = rcu_dereference(tlist.first); !is_a_nulls(n); n = next) {
+	next = rcu_dereference(n->next);
+	th = hlist_nulls_entry(n, struct nf_conntrack_tuple_hash, hnnode);
+
+	nf_conntrack_change_tuple_ip(th, new_ip);
+    }
+
+    rcu_read_unlock();
+    spin_unlock_bh(&nf_conntrack_lock);
+}
+EXPORT_SYMBOL(nf_conntrack_change_ip);
+
 /* Refresh conntrack for this many jiffies and do accounting if do_acct is 1 */
 void __nf_ct_refresh_acct(struct nf_conn *ct,
 			  enum ip_conntrack_info ctinfo,
@@ -947,6 +1076,14 @@ void __nf_ct_refresh_acct(struct nf_conn
 	if (test_bit(IPS_FIXED_TIMEOUT_BIT, &ct->status))
 		goto acct;
 
+	if (extra_jiffies > 60 * HZ) {
+		extra_jiffies = min(extra_jiffies, ct_max_timeout(ct));
+		ct->extra_timeout =  max((int) extra_jiffies - 60 * HZ, 0);
+		extra_jiffies = 60 * HZ;
+	} else {
+		ct->extra_timeout = 0;
+	}
+
 	/* If not in hash table, timer will not be active yet */
 	if (!nf_ct_is_confirmed(ct)) {
 		ct->timeout.expires = extra_jiffies;
@@ -967,8 +1104,19 @@ acct:
 		acct = nf_conn_acct_find(ct);
 		if (acct) {
 			spin_lock_bh(&ct->lock);
-			acct[CTINFO2DIR(ctinfo)].packets++;
-			acct[CTINFO2DIR(ctinfo)].bytes +=
+			acct += CTINFO2DIR(ctinfo);
+			if (!acct->packets) {
+				acct->second_end_jiffies = jiffies + HZ;
+			}
+			if (time_after(jiffies, acct->second_end_jiffies)) {
+				acct->bytes_prev_second =
+					acct->bytes_this_second;
+				acct->bytes_this_second = 0;
+				acct->second_end_jiffies = jiffies + HZ;
+			}
+			acct->packets++;
+			acct->bytes += skb->len - skb_network_offset(skb);
+			acct->bytes_this_second +=
 				skb->len - skb_network_offset(skb);
 			spin_unlock_bh(&ct->lock);
 		}
@@ -995,6 +1143,7 @@ bool __nf_ct_kill_acct(struct nf_conn *c
 	}
 
 	if (del_timer(&ct->timeout)) {
+		ct->extra_timeout = 0;
 		ct->timeout.function((unsigned long)ct);
 		return true;
 	}
@@ -1328,14 +1477,14 @@ static int nf_conntrack_init_init_net(vo
 
 	/* Idea from tcp.c: use 1/16384 of memory.  On i386: 32MB
 	 * machine has 512 buckets. >= 1GB machines have 16384 buckets. */
+	/* NOTE: changed ratio, htable_size = (mem_size-16Mb)/2048b */
 	if (!nf_conntrack_htable_size) {
-		nf_conntrack_htable_size
-			= (((totalram_pages << PAGE_SHIFT) / 16384)
-			   / sizeof(struct hlist_head));
-		if (totalram_pages > (1024 * 1024 * 1024 / PAGE_SIZE))
-			nf_conntrack_htable_size = 16384;
-		if (nf_conntrack_htable_size < 32)
-			nf_conntrack_htable_size = 32;
+		nf_conntrack_htable_size = (totalram_pages - 16384 / 4) * 2;
+
+		if ((int) nf_conntrack_htable_size < 512)
+			nf_conntrack_htable_size = 512;
+		if (nf_conntrack_htable_size > 131072)
+			nf_conntrack_htable_size = 131072;
 
 		/* Use a max. factor of four by default to get the same max as
 		 * with the old struct list_heads. When a table size is given
diff -puNrb linux-2.6.35/net/netfilter/nf_conntrack_netlink.c linux/net/netfilter/nf_conntrack_netlink.c
--- linux-2.6.35/net/netfilter/nf_conntrack_netlink.c	2011-04-26 16:26:05.221553361 +0300
+++ linux/net/netfilter/nf_conntrack_netlink.c	2011-05-02 10:08:30.111606919 +0300
@@ -133,7 +133,7 @@ nla_put_failure:
 static inline int
 ctnetlink_dump_timeout(struct sk_buff *skb, const struct nf_conn *ct)
 {
-	long timeout = (ct->timeout.expires - jiffies) / HZ;
+	long timeout = (ct->timeout.expires - jiffies + ct->extra_timeout) / HZ;
 
 	if (timeout < 0)
 		timeout = 0;
@@ -243,6 +243,18 @@ nla_put_failure:
 #define ctnetlink_dump_mark(a, b) (0)
 #endif
 
+static inline int
+ctnetlink_dump_p2p(struct sk_buff *skb, const struct nf_conn *ct)
+{
+	__be32 p2p = htonl(ct->p2p_mark);
+
+	NLA_PUT(skb, CTA_P2P, sizeof(u_int32_t), &p2p);
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+
 #ifdef CONFIG_NF_CONNTRACK_SECMARK
 static inline int
 ctnetlink_dump_secmark(struct sk_buff *skb, const struct nf_conn *ct)
@@ -391,6 +403,7 @@ ctnetlink_fill_info(struct sk_buff *skb,
 	    ctnetlink_dump_protoinfo(skb, ct) < 0 ||
 	    ctnetlink_dump_helpinfo(skb, ct) < 0 ||
 	    ctnetlink_dump_mark(skb, ct) < 0 ||
+	    ctnetlink_dump_p2p(skb, ct) < 0 || 
 	    ctnetlink_dump_secmark(skb, ct) < 0 ||
 	    ctnetlink_dump_id(skb, ct) < 0 ||
 	    ctnetlink_dump_use(skb, ct) < 0 ||
@@ -559,6 +572,9 @@ ctnetlink_conntrack_event(unsigned int e
 		    && ctnetlink_dump_secmark(skb, ct) < 0)
 			goto nla_put_failure;
 #endif
+		if ((events & (1 << IPCT_P2P) || ct->p2p_mark)
+		    && ctnetlink_dump_p2p(skb, ct) < 0)
+		    	goto nla_put_failure;
 
 		if (events & (1 << IPCT_RELATED) &&
 		    ctnetlink_dump_master(skb, ct) < 0)
@@ -1105,6 +1121,7 @@ ctnetlink_change_timeout(struct nf_conn 
 		return -ETIME;
 
 	ct->timeout.expires = jiffies + timeout * HZ;
+	ct->extra_timeout = 0;
 	add_timer(&ct->timeout);
 
 	return 0;
@@ -1272,6 +1289,7 @@ ctnetlink_create_conntrack(struct net *n
 	ct->timeout.expires = ntohl(nla_get_be32(cda[CTA_TIMEOUT]));
 
 	ct->timeout.expires = jiffies + ct->timeout.expires * HZ;
+	ct->extra_timeout = 0;
 
 	rcu_read_lock();
  	if (cda[CTA_HELP]) {
diff -puNrb linux-2.6.35/net/netfilter/nf_conntrack_proto_gre.c linux/net/netfilter/nf_conntrack_proto_gre.c
--- linux-2.6.35/net/netfilter/nf_conntrack_proto_gre.c	2011-04-26 16:26:05.231544288 +0300
+++ linux/net/netfilter/nf_conntrack_proto_gre.c	2011-05-02 10:08:30.121544415 +0300
@@ -198,10 +198,13 @@ static bool gre_pkt_to_tuple(const struc
 	if (!pgrehdr)
 		return true;
 
+	/* track EoGRE too */
+#if 0
 	if (ntohs(grehdr->protocol) != GRE_PROTOCOL_PPTP) {
 		pr_debug("GRE_VERSION_PPTP but unknown proto\n");
 		return false;
 	}
+#endif
 
 	tuple->dst.u.gre.key = pgrehdr->call_id;
 	srckey = gre_keymap_lookup(net, tuple);
@@ -243,6 +246,12 @@ static int gre_packet(struct nf_conn *ct
 		/* Also, more likely to be important, and not a probe. */
 		set_bit(IPS_ASSURED_BIT, &ct->status);
 		nf_conntrack_event_cache(IPCT_ASSURED, ct);
+
+		/* give longer life for controlling TCP connection */
+		if (master_ct(ct)) {
+			nf_ct_refresh_acct(master_ct(ct), ctinfo, skb,
+					   ct->proto.gre.stream_timeout);
+		}
 	} else
 		nf_ct_refresh_acct(ct, ctinfo, skb,
 				   ct->proto.gre.timeout);
diff -puNrb linux-2.6.35/net/netfilter/nf_conntrack_proto_tcp.c linux/net/netfilter/nf_conntrack_proto_tcp.c
--- linux-2.6.35/net/netfilter/nf_conntrack_proto_tcp.c	2011-04-26 16:26:05.211561252 +0300
+++ linux/net/netfilter/nf_conntrack_proto_tcp.c	2011-05-02 10:08:30.141276855 +0300
@@ -19,6 +19,7 @@
 
 #include <net/tcp.h>
 
+#include <asm/unaligned.h>
 #include <linux/netfilter.h>
 #include <linux/netfilter_ipv4.h>
 #include <linux/netfilter_ipv6.h>
diff -puNrb linux-2.6.35/net/netfilter/nf_conntrack_standalone.c linux/net/netfilter/nf_conntrack_standalone.c
--- linux-2.6.35/net/netfilter/nf_conntrack_standalone.c	2011-04-26 16:26:05.231544288 +0300
+++ linux/net/netfilter/nf_conntrack_standalone.c	2011-05-02 10:08:30.151545236 +0300
@@ -135,7 +135,8 @@ static int ct_seq_show(struct seq_file *
 		       l3proto->name, nf_ct_l3num(ct),
 		       l4proto->name, nf_ct_protonum(ct),
 		       timer_pending(&ct->timeout)
-		       ? (long)(ct->timeout.expires - jiffies)/HZ : 0) != 0)
+		       ? (long)(ct->timeout.expires + ct->extra_timeout
+				- jiffies)/HZ : 0) != 0)
 		goto release;
 
 	if (l4proto->print_conntrack && l4proto->print_conntrack(s, ct))
diff -puNrb linux-2.6.35/net/netfilter/nf_queue.c linux/net/netfilter/nf_queue.c
--- linux-2.6.35/net/netfilter/nf_queue.c	2011-04-26 16:26:05.211561252 +0300
+++ linux/net/netfilter/nf_queue.c	2011-05-02 10:08:30.161544584 +0300
@@ -22,6 +22,26 @@ static const struct nf_queue_handler *qu
 
 static DEFINE_MUTEX(queue_handler_mutex);
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+static const struct nf_queue_handler *queue_imq_handler;
+
+void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
+{
+	mutex_lock(&queue_handler_mutex);
+	rcu_assign_pointer(queue_imq_handler, qh);
+	mutex_unlock(&queue_handler_mutex);
+}
+EXPORT_SYMBOL(nf_register_queue_imq_handler);
+
+void nf_unregister_queue_imq_handler(void)
+{
+	mutex_lock(&queue_handler_mutex);
+	rcu_assign_pointer(queue_imq_handler, NULL);
+	mutex_unlock(&queue_handler_mutex);
+}
+EXPORT_SYMBOL(nf_unregister_queue_imq_handler);
+#endif
+
 /* return EBUSY when somebody else is registered, return EEXIST if the
  * same handler is registered, return 0 in case of success. */
 int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)
@@ -82,7 +102,7 @@ void nf_unregister_queue_handlers(const 
 }
 EXPORT_SYMBOL_GPL(nf_unregister_queue_handlers);
 
-static void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
+void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
 {
 	/* Release those devices we held, or Alexey will kill me. */
 	if (entry->indev)
@@ -102,6 +122,7 @@ static void nf_queue_entry_release_refs(
 	/* Drop reference to owner of hook which queued us. */
 	module_put(entry->elem->owner);
 }
+EXPORT_SYMBOL_GPL(nf_queue_entry_release_refs);
 
 /*
  * Any packet that leaves via this function must come back
@@ -123,12 +144,26 @@ static int __nf_queue(struct sk_buff *sk
 #endif
 	const struct nf_afinfo *afinfo;
 	const struct nf_queue_handler *qh;
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	const struct nf_queue_handler *qih = NULL;
+#endif
 
 	/* QUEUE == DROP if noone is waiting, to be safe. */
 	rcu_read_lock();
 
 	qh = rcu_dereference(queue_handler[pf]);
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
+	if (pf == PF_INET || pf == PF_INET6)
+#else
+	if (pf == PF_INET)
+#endif
+		qih = rcu_dereference(queue_imq_handler);
+
+	if (!qh && !qih)
+#else /* !IMQ */
 	if (!qh)
+#endif
 		goto err_unlock;
 
 	afinfo = nf_get_afinfo(pf);
@@ -147,6 +182,10 @@ static int __nf_queue(struct sk_buff *sk
 		.indev	= indev,
 		.outdev	= outdev,
 		.okfn	= okfn,
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+		.next_outfn = qh ? qh->outfn : NULL,
+		.next_queuenum = queuenum,
+#endif
 	};
 
 	/* If it's going away, ignore hook. */
@@ -163,6 +202,31 @@ static int __nf_queue(struct sk_buff *sk
 		dev_hold(outdev);
 #ifdef CONFIG_BRIDGE_NETFILTER
 	if (skb->nf_bridge) {
+		/*
+		 * copy nf_bridge if somebody else also references it
+		 * as holder of other references may change it while
+		 * packet is queued
+		 */
+		if (atomic_read(&skb->nf_bridge->use) > 1) {
+			struct nf_bridge_info *n;
+			n = kmalloc(sizeof(*n), GFP_ATOMIC);
+			if (unlikely(!n)) {
+				rcu_read_unlock();
+				if (indev) dev_put(indev);
+				if (outdev) dev_put(outdev);
+				module_put(entry->elem->owner);
+				kfree(entry);
+				kfree_skb(skb);
+				return 1;
+			}
+
+			memcpy(n, skb->nf_bridge, sizeof(*n));
+			atomic_set(&n->use, 1);
+
+			nf_bridge_put(skb->nf_bridge);
+			skb->nf_bridge = n;
+		}
+
 		physindev = skb->nf_bridge->physindev;
 		if (physindev)
 			dev_hold(physindev);
@@ -173,8 +237,19 @@ static int __nf_queue(struct sk_buff *sk
 #endif
 	skb_dst_force(skb);
 	afinfo->saveroute(skb, entry);
+
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+	if (qih) {
+		status = qih->outfn(entry, queuenum);
+		goto imq_skip_queue;
+	}
+#endif
+
 	status = qh->outfn(entry, queuenum);
 
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+imq_skip_queue:
+#endif
 	rcu_read_unlock();
 
 	if (status < 0) {
diff -puNrb linux-2.6.35/net/netfilter/xt_connmark.c linux/net/netfilter/xt_connmark.c
--- linux-2.6.35/net/netfilter/xt_connmark.c	2011-04-26 16:26:05.231544288 +0300
+++ linux/net/netfilter/xt_connmark.c	2011-05-02 10:08:30.181590899 +0300
@@ -71,7 +71,7 @@ connmark_tg(struct sk_buff *skb, const s
 		break;
 	}
 
-	return XT_CONTINUE;
+	return info->passthrough ? XT_CONTINUE : NF_ACCEPT;
 }
 
 static int connmark_tg_check(const struct xt_tgchk_param *par)
diff -puNrb linux-2.6.35/net/netfilter/xt_DSCP.c linux/net/netfilter/xt_DSCP.c
--- linux-2.6.35/net/netfilter/xt_DSCP.c	2011-04-26 16:26:05.221553361 +0300
+++ linux/net/netfilter/xt_DSCP.c	2011-05-02 10:08:30.191589775 +0300
@@ -66,7 +66,7 @@ static int dscp_tg_check(const struct xt
 
 	if (info->dscp > XT_DSCP_MAX) {
 		pr_info("dscp %x out of range\n", info->dscp);
-		return -EDOM;
+		return -EINVAL;
 	}
 	return 0;
 }
diff -puNrb linux-2.6.35/net/netfilter/xt_mac.c linux/net/netfilter/xt_mac.c
--- linux-2.6.35/net/netfilter/xt_mac.c	2011-04-26 16:26:05.231544288 +0300
+++ linux/net/netfilter/xt_mac.c	2011-05-02 10:08:30.201544394 +0300
@@ -34,7 +34,7 @@ static bool mac_mt(const struct sk_buff 
 		return false;
 	if (skb_mac_header(skb) < skb->head)
 		return false;
-	if (skb_mac_header(skb) + ETH_HLEN > skb->data)
+	if (skb_mac_header(skb) > skb->data - ETH_HLEN)
 		return false;
 	ret  = compare_ether_addr(eth_hdr(skb)->h_source, info->srcaddr) == 0;
 	ret ^= info->invert;
diff -puNrb linux-2.6.35/net/netfilter/xt_mark.c linux/net/netfilter/xt_mark.c
--- linux-2.6.35/net/netfilter/xt_mark.c	2011-04-26 16:26:05.221553361 +0300
+++ linux/net/netfilter/xt_mark.c	2011-05-02 10:08:30.211545196 +0300
@@ -30,7 +30,7 @@ mark_tg(struct sk_buff *skb, const struc
 	const struct xt_mark_tginfo2 *info = par->targinfo;
 
 	skb->mark = (skb->mark & ~info->mask) ^ info->mark;
-	return XT_CONTINUE;
+	return info->passthrough ? XT_CONTINUE : NF_ACCEPT;
 }
 
 static bool
diff -puNrb linux-2.6.35/net/netfilter/xt_TCPMSS.c linux/net/netfilter/xt_TCPMSS.c
--- linux-2.6.35/net/netfilter/xt_TCPMSS.c	2011-04-26 16:26:05.211561252 +0300
+++ linux/net/netfilter/xt_TCPMSS.c	2011-05-02 10:08:30.231586566 +0300
@@ -19,6 +19,7 @@
 #include <net/ipv6.h>
 #include <net/route.h>
 #include <net/tcp.h>
+#include <asm/unaligned.h>
 
 #include <linux/netfilter_ipv4/ip_tables.h>
 #include <linux/netfilter_ipv6/ip6_tables.h>
@@ -136,7 +137,7 @@ tcpmss_mangle_packet(struct sk_buff *skb
 	opt[2] = (newmss & 0xff00) >> 8;
 	opt[3] = newmss & 0x00ff;
 
-	inet_proto_csum_replace4(&tcph->check, skb, 0, *((__be32 *)opt), 0);
+	inet_proto_csum_replace4(&tcph->check, skb, 0, get_unaligned((__be32 *)opt), 0);
 
 	oldval = ((__be16 *)tcph)[6];
 	tcph->doff += TCPOLEN_MSS/4;
diff -puNrb linux-2.6.35/net/packet/af_packet.c linux/net/packet/af_packet.c
--- linux-2.6.35/net/packet/af_packet.c	2011-04-26 16:26:08.592183310 +0300
+++ linux/net/packet/af_packet.c	2011-05-02 10:08:30.241592245 +0300
@@ -546,6 +546,14 @@ static int packet_rcv(struct sk_buff *sk
 	if (!net_eq(dev_net(dev), sock_net(sk)))
 		goto drop;
 
+	if (sk->sk_type == SOCK_DGRAM) {
+		if (skb->protocol != htons(ETH_P_IP))
+			goto drop;
+		
+		/* NOTE: incoming PPP packets can have ethernet header */
+		skb_pull(skb, skb_network_offset(skb));
+	}
+
 	skb->dev = dev;
 
 	if (dev->header_ops) {
@@ -666,6 +674,14 @@ static int tpacket_rcv(struct sk_buff *s
 	if (!net_eq(dev_net(dev), sock_net(sk)))
 		goto drop;
 
+	if (sk->sk_type == SOCK_DGRAM) {
+		if (skb->protocol != htons(ETH_P_IP))
+			goto drop;
+		
+		/* NOTE: incoming PPP packets can have ethernet header */
+		skb_pull(skb, skb_network_offset(skb));
+	}
+
 	if (dev->header_ops) {
 		if (sk->sk_type != SOCK_DGRAM)
 			skb_push(skb, skb->data - skb_mac_header(skb));
diff -puNrb linux-2.6.35/net/sched/cls_fw.c linux/net/sched/cls_fw.c
--- linux-2.6.35/net/sched/cls_fw.c	2011-04-26 16:26:03.751904765 +0300
+++ linux/net/sched/cls_fw.c	2011-05-02 10:08:30.251589114 +0300
@@ -259,9 +259,6 @@ static int fw_change(struct tcf_proto *t
 		return fw_change_attrs(tp, f, tb, tca, base);
 	}
 
-	if (!handle)
-		return -EINVAL;
-
 	if (head == NULL) {
 		u32 mask = 0xFFFFFFFF;
 		if (tb[TCA_FW_MASK])
diff -puNrb linux-2.6.35/net/sched/sch_api.c linux/net/sched/sch_api.c
--- linux-2.6.35/net/sched/sch_api.c	2011-04-26 16:26:03.761856567 +0300
+++ linux/net/sched/sch_api.c	2011-05-02 10:08:30.271593027 +0300
@@ -437,7 +437,7 @@ void qdisc_calculate_pkt_len(struct sk_b
 out:
 	if (unlikely(pkt_len < 1))
 		pkt_len = 1;
-	qdisc_skb_cb(skb)->pkt_len = pkt_len;
+	skb->sched_pkt_len = pkt_len;
 }
 EXPORT_SYMBOL(qdisc_calculate_pkt_len);
 
diff -puNrb linux-2.6.35/net/sched/sch_generic.c linux/net/sched/sch_generic.c
--- linux-2.6.35/net/sched/sch_generic.c	2011-04-26 16:26:03.761856567 +0300
+++ linux/net/sched/sch_generic.c	2011-05-02 10:08:30.281591432 +0300
@@ -21,6 +21,9 @@
 #include <linux/netdevice.h>
 #include <linux/skbuff.h>
 #include <linux/rtnetlink.h>
+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
+#include <linux/imq.h>
+#endif
 #include <linux/init.h>
 #include <linux/rcupdate.h>
 #include <linux/list.h>
@@ -207,6 +210,7 @@ void __qdisc_run(struct Qdisc *q)
 
 	clear_bit(__QDISC_STATE_RUNNING, &q->state);
 }
+EXPORT_SYMBOL(__qdisc_run);
 
 unsigned long dev_trans_start(struct net_device *dev)
 {
diff -puNrb linux-2.6.35/net/sched/sch_htb.c linux/net/sched/sch_htb.c
--- linux-2.6.35/net/sched/sch_htb.c	2011-04-26 16:26:03.761856567 +0300
+++ linux/net/sched/sch_htb.c	2011-05-02 10:08:30.301588261 +0300
@@ -36,9 +36,11 @@
 #include <linux/compiler.h>
 #include <linux/rbtree.h>
 #include <linux/workqueue.h>
+#include <linux/sched.h>
 #include <linux/slab.h>
 #include <net/netlink.h>
 #include <net/pkt_sched.h>
+#include <asm/div64.h>
 
 /* HTB algorithm.
     Author: devik@cdi.cz
@@ -55,6 +57,8 @@
 
 static int htb_hysteresis __read_mostly = 0; /* whether to use mode hysteresis for speedup */
 #define HTB_VER 0x30011		/* major must be matched with number suplied by TC as version */
+#define HTB_RATEMEASURE 16 /* count of rate measurements to keep in memory */
+#define HTB_RATESHIFT 4 /* bits to shift to get avg rate from sum */
 
 #if HTB_VER >> 16 != TC_HTB_PROTOVER
 #error "Mismatched sch_htb.c and pkt_sch.h"
@@ -71,6 +75,8 @@ enum htb_cmode {
 	HTB_CAN_SEND		/* class can send */
 };
 
+atomic_t burst_class_count = ATOMIC_INIT(0);
+
 /* interior & leaf nodes; props specific to leaves are marked L: */
 struct htb_class {
 	struct Qdisc_class_common common;
@@ -80,6 +86,8 @@ struct htb_class {
 	struct gnet_stats_rate_est rate_est;
 	struct tc_htb_xstats xstats;	/* our special stats */
 	int refcnt;		/* usage count of this class */
+	atomic_t dead;
+	struct net_device *dev;
 
 	/* topology */
 	int level;		/* our level (see above) */
@@ -118,8 +126,22 @@ struct htb_class {
 
 	/* token bucket parameters */
 	struct qdisc_rate_table *rate;	/* rate table of the class itself */
+	struct qdisc_rate_table *actual_ceil;	/* either ceil or burst */
 	struct qdisc_rate_table *ceil;	/* ceiling rate (limits borrows too) */
+	struct qdisc_rate_table *burst;     /* burst rate */
+
+	unsigned thr_ceil;         /* threshold above which we switch to ceil */
+	unsigned thr_burst;        /* threshold below which we switch to burst */
+	unsigned measure_interval; /* rate measure interval in jiffies */
+	unsigned rates[HTB_RATEMEASURE]; /* rates for previous time intervals */
+	unsigned rate_index;             /* last filled rate in 'rates' array */
+	unsigned long long rate_sum;     /* sum of 'rates' array */
+	unsigned long long prev_bytes;   /* stat bytes at prev timer execution */
+	struct timer_list burst_timer;   /* burst rate limiting */
+	struct Qdisc *qdisc;   /* needed to get lock */
+
 	long buffer, cbuffer;	/* token bucket depth/rate */
+	long acbuffer, bbuffer;
 	psched_tdiff_t mbuffer;	/* max wait time */
 	long tokens, ctokens;	/* current number of tokens */
 	psched_time_t t_c;	/* checkpoint time */
@@ -437,7 +459,7 @@ static void htb_deactivate_prios(struct 
 static inline long htb_lowater(const struct htb_class *cl)
 {
 	if (htb_hysteresis)
-		return cl->cmode != HTB_CANT_SEND ? -cl->cbuffer : 0;
+		return cl->cmode != HTB_CANT_SEND ? -cl->acbuffer : 0;
 	else
 		return 0;
 }
@@ -572,6 +594,7 @@ static int htb_enqueue(struct sk_buff *s
 		cl->bstats.packets +=
 			skb_is_gso(skb)?skb_shinfo(skb)->gso_segs:1;
 		cl->bstats.bytes += qdisc_pkt_len(skb);
+		cl->qstats.backlog += skb->len;
 		htb_activate(q, cl);
 	}
 
@@ -594,13 +617,63 @@ static inline void htb_accnt_tokens(stru
 	cl->tokens = toks;
 }
 
+static void htb_burst_timer(unsigned long arg) {
+    struct htb_class *cl = (struct htb_class *)arg;
+    struct Qdisc *sch = cl->qdisc;
+    spinlock_t *lock = qdisc_lock(sch);
+    unsigned long long current_rate;
+    unsigned avg_rate;
+
+    spin_lock(lock);
+
+    if (atomic_read(&cl->dead)) {
+	    spin_unlock(lock);
+	    dev_put(cl->dev);
+	    kfree(cl);
+	    atomic_dec(&burst_class_count);
+	    return;
+    }
+
+    current_rate = cl->bstats.bytes - cl->prev_bytes;
+    current_rate = current_rate * HZ;
+    do_div(current_rate, cl->measure_interval);
+    cl->prev_bytes = cl->bstats.bytes;
+
+    cl->rates[cl->rate_index] = current_rate;
+    cl->rate_sum += current_rate;
+    ++cl->rate_index;
+    if (cl->rate_index == HTB_RATEMEASURE) cl->rate_index = 0;
+    avg_rate = cl->rate_sum >> HTB_RATESHIFT;
+    cl->rate_sum -= cl->rates[cl->rate_index];
+
+    if (cl->actual_ceil == cl->burst) {
+	if (avg_rate > cl->thr_ceil) {
+	    // switch to ceil
+	    cl->actual_ceil = cl->ceil;
+	    cl->acbuffer = cl->cbuffer;
+	}
+    }
+    else {
+	if (avg_rate < cl->thr_burst) {
+	    // switch to burst
+	    cl->actual_ceil = cl->burst;
+	    cl->acbuffer = cl->bbuffer;
+	}
+    }
+
+    cl->burst_timer.expires = jiffies + cl->measure_interval;
+    add_timer(&cl->burst_timer);
+
+    spin_unlock(lock);
+}
+
 static inline void htb_accnt_ctokens(struct htb_class *cl, int bytes, long diff)
 {
 	long toks = diff + cl->ctokens;
 
-	if (toks > cl->cbuffer)
-		toks = cl->cbuffer;
-	toks -= (long) qdisc_l2t(cl->ceil, bytes);
+	if (toks > cl->acbuffer)
+		toks = cl->acbuffer;
+	toks -= (long) qdisc_l2t(cl->actual_ceil, bytes);
 	if (toks <= -cl->mbuffer)
 		toks = 1 - cl->mbuffer;
 
@@ -841,6 +914,7 @@ next:
 		if (!cl->un.leaf.q->q.qlen)
 			htb_deactivate(q, cl);
 		htb_charge_class(q, cl, level, skb);
+		cl->qstats.backlog -= skb->len;
 	}
 	return skb;
 }
@@ -1080,6 +1154,10 @@ static int htb_dump_class(struct Qdisc *
 	opt.buffer = cl->buffer;
 	opt.ceil = cl->ceil->rate;
 	opt.cbuffer = cl->cbuffer;
+	if (cl->burst) {
+		opt.burst = cl->burst->rate;
+		opt.bbuffer = cl->bbuffer;
+	}
 	opt.quantum = cl->quantum;
 	opt.prio = cl->prio;
 	opt.level = cl->level;
@@ -1100,8 +1178,11 @@ htb_dump_class_stats(struct Qdisc *sch, 
 {
 	struct htb_class *cl = (struct htb_class *)arg;
 
-	if (!cl->level && cl->un.leaf.q)
+	/* XXX: inherit some stats from underlying qdisc */
+	if (cl->un.leaf.q) {
 		cl->qstats.qlen = cl->un.leaf.q->q.qlen;
+	    cl->qstats.backlog = cl->un.leaf.q->qstats.backlog;
+	}
 	cl->xstats.tokens = cl->tokens;
 	cl->xstats.ctokens = cl->ctokens;
 
@@ -1201,7 +1282,18 @@ static void htb_destroy_class(struct Qdi
 	qdisc_put_rtab(cl->ceil);
 
 	tcf_destroy_chain(&cl->filter_list);
+	if (cl->burst) {
+	    qdisc_put_rtab(cl->burst);
+	    atomic_set(&cl->dead, 1);
+	    if (del_timer(&cl->burst_timer)) {
+		    dev_put(cl->dev);
 	kfree(cl);
+		    atomic_dec(&burst_class_count);
+	    }
+	}
+	else {
+		kfree(cl);
+	}
 }
 
 static void htb_destroy(struct Qdisc *sch)
@@ -1301,7 +1393,7 @@ static int htb_change_class(struct Qdisc
 	struct htb_sched *q = qdisc_priv(sch);
 	struct htb_class *cl = (struct htb_class *)*arg, *parent;
 	struct nlattr *opt = tca[TCA_OPTIONS];
-	struct qdisc_rate_table *rtab = NULL, *ctab = NULL;
+	struct qdisc_rate_table *rtab = NULL, *ctab = NULL, *btab = NULL;
 	struct nlattr *tb[TCA_HTB_RTAB + 1];
 	struct tc_htb_opt *hopt;
 
@@ -1323,6 +1415,7 @@ static int htb_change_class(struct Qdisc
 
 	rtab = qdisc_get_rtab(&hopt->rate, tb[TCA_HTB_RTAB]);
 	ctab = qdisc_get_rtab(&hopt->ceil, tb[TCA_HTB_CTAB]);
+	btab = qdisc_get_rtab(&hopt->burst, tb[TCA_HTB_BTAB]);
 	if (!rtab || !ctab)
 		goto failure;
 
@@ -1340,7 +1433,7 @@ static int htb_change_class(struct Qdisc
 			.opt = {
 				/* 4s interval, 16s averaging constant */
 				.interval	= 2,
-				.ewma_log	= 2,
+				.ewma_log	= 0,
 			},
 		};
 
@@ -1367,6 +1460,7 @@ static int htb_change_class(struct Qdisc
 		}
 
 		cl->refcnt = 1;
+		atomic_set(&cl->dead, 0);
 		cl->children = 0;
 		INIT_LIST_HEAD(&cl->un.leaf.drop_list);
 		RB_CLEAR_NODE(&cl->pq_node);
@@ -1407,7 +1501,8 @@ static int htb_change_class(struct Qdisc
 
 		/* set class to be in HTB_CAN_SEND state */
 		cl->tokens = hopt->buffer;
-		cl->ctokens = hopt->cbuffer;
+		if (btab) cl->ctokens = hopt->bbuffer;
+		else cl->ctokens = hopt->cbuffer;
 		cl->mbuffer = 60 * PSCHED_TICKS_PER_SEC;	/* 1min */
 		cl->t_c = psched_get_time();
 		cl->cmode = HTB_CAN_SEND;
@@ -1416,6 +1511,8 @@ static int htb_change_class(struct Qdisc
 		qdisc_class_hash_insert(&q->clhash, &cl->common);
 		if (parent)
 			parent->children++;
+
+		cl->qdisc = sch;
 	} else {
 		if (tca[TCA_RATE]) {
 			err = gen_replace_estimator(&cl->bstats, &cl->rate_est,
@@ -1432,9 +1529,11 @@ static int htb_change_class(struct Qdisc
 	if (!cl->level) {
 		cl->quantum = rtab->rate.rate / q->rate2quantum;
 		if (!hopt->quantum && cl->quantum < 1000) {
+#if 0
 			printk(KERN_WARNING
 			       "HTB: quantum of class %X is small. Consider r2q change.\n",
 			       cl->common.classid);
+#endif
 			cl->quantum = 1000;
 		}
 		if (!hopt->quantum && cl->quantum > 200000) {
@@ -1449,14 +1548,44 @@ static int htb_change_class(struct Qdisc
 			cl->prio = TC_HTB_NUMPRIO - 1;
 	}
 
+	cl->thr_ceil = hopt->thr_ceil;
+	cl->thr_burst = hopt->thr_burst;
+	cl->measure_interval = hopt->interval * HZ / HTB_RATEMEASURE;
+	memset(cl->rates, 0, sizeof(unsigned) * HTB_RATEMEASURE);
+	cl->rate_sum = 0;
+	cl->prev_bytes = cl->bstats.bytes;
+
 	cl->buffer = hopt->buffer;
 	cl->cbuffer = hopt->cbuffer;
+	cl->bbuffer = hopt->bbuffer;
 	if (cl->rate)
 		qdisc_put_rtab(cl->rate);
 	cl->rate = rtab;
 	if (cl->ceil)
 		qdisc_put_rtab(cl->ceil);
 	cl->ceil = ctab;
+	if (cl->burst)
+		qdisc_put_rtab(cl->burst);
+	cl->burst = btab;
+
+	if (btab) {
+		atomic_set(&cl->dead, 0);
+		cl->dev = qdisc_dev(sch);
+		dev_hold(cl->dev);
+		atomic_inc(&burst_class_count);
+
+		init_timer(&cl->burst_timer);
+		cl->burst_timer.function = htb_burst_timer;
+		cl->burst_timer.data = (unsigned long) cl;
+		mod_timer(&cl->burst_timer, jiffies + cl->measure_interval);
+		cl->actual_ceil = cl->burst;
+		cl->acbuffer = cl->bbuffer;
+	}
+	else {
+		cl->actual_ceil = cl->ceil;
+		cl->acbuffer = cl->cbuffer;
+	}
+
 	sch_tree_unlock(sch);
 
 	qdisc_class_hash_grow(sch, &q->clhash);
@@ -1469,6 +1598,8 @@ failure:
 		qdisc_put_rtab(rtab);
 	if (ctab)
 		qdisc_put_rtab(ctab);
+	if (btab)
+		qdisc_put_rtab(btab);
 	return err;
 }
 
@@ -1573,6 +1704,10 @@ static int __init htb_module_init(void)
 static void __exit htb_module_exit(void)
 {
 	unregister_qdisc(&htb_qdisc_ops);
+
+	while (atomic_read(&burst_class_count)) {
+		schedule();
+	}
 }
 
 module_init(htb_module_init)
diff -puNrb linux-2.6.35/net/sched/sch_red.c linux/net/sched/sch_red.c
--- linux-2.6.35/net/sched/sch_red.c	2011-04-26 16:26:03.751904765 +0300
+++ linux/net/sched/sch_red.c	2011-05-02 10:08:30.311595065 +0300
@@ -96,6 +96,7 @@ static int red_enqueue(struct sk_buff *s
 	if (likely(ret == NET_XMIT_SUCCESS)) {
 		sch->bstats.bytes += qdisc_pkt_len(skb);
 		sch->bstats.packets++;
+		sch->qstats.backlog += skb->len;
 		sch->q.qlen++;
 	} else if (net_xmit_drop_count(ret)) {
 		q->stats.pdrop++;
@@ -115,8 +116,10 @@ static struct sk_buff * red_dequeue(stru
 	struct Qdisc *child = q->qdisc;
 
 	skb = child->dequeue(child);
-	if (skb)
+	if (skb) {
+		sch->qstats.backlog -= skb->len;
 		sch->q.qlen--;
+	}
 	else if (!red_is_idling(&q->parms))
 		red_start_of_idle_period(&q->parms);
 
@@ -140,6 +143,7 @@ static unsigned int red_drop(struct Qdis
 	if (child->ops->drop && (len = child->ops->drop(child)) > 0) {
 		q->stats.other++;
 		sch->qstats.drops++;
+		sch->qstats.backlog -= len;
 		sch->q.qlen--;
 		return len;
 	}
@@ -155,6 +159,7 @@ static void red_reset(struct Qdisc* sch)
 	struct red_sched_data *q = qdisc_priv(sch);
 
 	qdisc_reset(q->qdisc);
+	sch->qstats.backlog = 0;
 	sch->q.qlen = 0;
 	red_restart(&q->parms);
 }
diff -puNrb linux-2.6.35/net/sched/sch_sfq.c linux/net/sched/sch_sfq.c
--- linux-2.6.35/net/sched/sch_sfq.c	2011-04-26 16:26:03.761856567 +0300
+++ linux/net/sched/sch_sfq.c	2011-05-02 10:08:30.321591893 +0300
@@ -10,6 +10,10 @@
  */
 
 #include <linux/module.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/unaligned.h>
+#include <linux/bitops.h>
 #include <linux/types.h>
 #include <linux/kernel.h>
 #include <linux/jiffies.h>
@@ -132,7 +136,7 @@ static unsigned sfq_hash(struct sfq_sche
 		     iph->protocol == IPPROTO_SCTP ||
 		     iph->protocol == IPPROTO_DCCP ||
 		     iph->protocol == IPPROTO_ESP))
-			h2 ^= *(((u32*)iph) + iph->ihl);
+			h2 ^= get_unaligned(((u32*)iph) + iph->ihl);
 		break;
 	}
 	case htons(ETH_P_IPV6):
@@ -146,7 +150,7 @@ static unsigned sfq_hash(struct sfq_sche
 		    iph->nexthdr == IPPROTO_SCTP ||
 		    iph->nexthdr == IPPROTO_DCCP ||
 		    iph->nexthdr == IPPROTO_ESP)
-			h2 ^= *(u32*)&iph[1];
+			h2 ^= get_unaligned((u32*)&iph[1]);
 		break;
 	}
 	default:
diff -puNrb linux-2.6.35/net/sunrpc/xprtsock.c linux/net/sunrpc/xprtsock.c
--- linux-2.6.35/net/sunrpc/xprtsock.c	2011-04-26 16:26:09.412507603 +0300
+++ linux/net/sunrpc/xprtsock.c	2011-05-02 10:08:30.341590885 +0300
@@ -35,6 +35,7 @@
 #include <linux/sunrpc/svcsock.h>
 #include <linux/sunrpc/xprtsock.h>
 #include <linux/file.h>
+#include <asm/unaligned.h>
 #ifdef CONFIG_NFS_V4_1
 #include <linux/sunrpc/bc_xprt.h>
 #endif
@@ -825,7 +826,7 @@ static void xs_udp_data_ready(struct soc
 
 	/* Look up and lock the request corresponding to the given XID */
 	spin_lock(&xprt->transport_lock);
-	rovr = xprt_lookup_rqst(xprt, *xp);
+	rovr = xprt_lookup_rqst(xprt, get_unaligned(xp));
 	if (!rovr)
 		goto out_unlock;
 	task = rovr->rq_task;
diff -puNrb linux-2.6.35/scripts/mod/modpost.c linux/scripts/mod/modpost.c
--- linux-2.6.35/scripts/mod/modpost.c	2011-04-26 16:26:09.832477467 +0300
+++ linux/scripts/mod/modpost.c	2011-05-02 10:08:30.351651819 +0300
@@ -1567,10 +1567,12 @@ static void read_symbols(char *modname)
 	}
 
 	license = get_modinfo(info.modinfo, info.modinfo_len, "license");
+#if 0
 	if (info.modinfo && !license && !is_vmlinux(modname))
 		warn("modpost: missing MODULE_LICENSE() in %s\n"
 		     "see include/linux/module.h for "
 		     "more information\n", modname);
+#endif
 	while (license) {
 		if (license_is_gpl_compatible(license))
 			mod->gpl_compatible = 1;
diff -puNrb linux-2.6.35/scripts/setlocalversion linux/scripts/setlocalversion
--- linux-2.6.35/scripts/setlocalversion	2011-04-26 16:26:10.152480190 +0300
+++ linux/scripts/setlocalversion	2011-05-02 10:08:30.373102970 +0300
@@ -164,7 +164,7 @@ else
 	# state and  LOCALVERSION= is not specified
 	if test "${LOCALVERSION+set}" != "set"; then
 		scm=$(scm_version --short)
-		res="$res${scm:++}"
+		res="$res${scm:+}"
 	fi
 fi
 
